<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">New Credit Flow Settings on RabbitMQ 3.5.5 | RabbitMQ</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" name="twitter:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" property="og:url" content="https://www.rabbitmq.com/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="New Credit Flow Settings on RabbitMQ 3.5.5 | RabbitMQ"><meta data-rh="true" name="description" content="This blog post was written for RabbitMQ 3.5, released in 2015. While some parts still"><meta data-rh="true" property="og:description" content="This blog post was written for RabbitMQ 3.5, released in 2015. While some parts still"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2015-10-06T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Performance"><link data-rh="true" rel="icon" href="/rabbitmq-website/img/rabbitmq-logo.svg"><link data-rh="true" rel="canonical" href="https://www.rabbitmq.com/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://H10VQIW16Y-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://www.rabbitmq.com/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","mainEntityOfPage":"https://www.rabbitmq.com/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","url":"https://www.rabbitmq.com/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","headline":"New Credit Flow Settings on RabbitMQ 3.5.5","name":"New Credit Flow Settings on RabbitMQ 3.5.5","description":"This blog post was written for RabbitMQ 3.5, released in 2015. While some parts still","datePublished":"2015-10-06T00:00:00.000Z","author":{"@type":"Person","name":"Álvaro Videla"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://www.rabbitmq.com/rabbitmq-website/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/rabbitmq-website/blog/rss.xml" title="RabbitMQ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/rabbitmq-website/blog/atom.xml" title="RabbitMQ Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="RabbitMQ" href="/rabbitmq-website/opensearch.xml">







<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-domain-script="018ee308-473e-754f-b0c2-cbe82d25512f"></script>
<script>function OptanonWrapper(){}</script>
<script>function setGTM(e,t,o,n,r){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var i=t.getElementsByTagName(o)[0],a=t.createElement(o),s="dataLayer"!=n?"&l="+n:"";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+r+s,i.parentNode.insertBefore(a,i)}var timer;function waitForOnetrustActiveGroups(){document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?(clearTimeout(timer),setGTM(window,document,"script","dataLayer","GTM-TT84L8K")):timer=setTimeout(waitForOnetrustActiveGroups,250)}document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?setGTM(window,document,"script","dataLayer","GTM-TT84L8K"):waitForOnetrustActiveGroups()</script><link rel="stylesheet" href="/rabbitmq-website/styles.css">
<script src="/rabbitmq-website/runtime~main.js" defer="defer"></script>
<script src="/rabbitmq-website/main.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:var(--ifm-color-primary-contrast-background);color:var(--ifm-font-color-base)" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><strong style="font-size: var(--ifm-h4-font-size);"><a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0">RabbitMQ 4.1.0 is out</a></strong></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/rabbitmq-website/"><div class="navbar__logo"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/rabbitmq-website/tutorials">Getting Started</a><a class="navbar__item navbar__link" href="/rabbitmq-website/docs">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rabbitmq-website/blog">Blog</a><a class="navbar__item navbar__link" href="/rabbitmq-website/contact">Support</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/rabbitmq-website/docs">4.1</a><ul class="dropdown__menu"><li class=""><strong>Release series</strong></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/next">Next</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs">4.1</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/4.0">4.0</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/3.13">3.13</a></li><li><a href="https://v3-12.rabbitmq.com/documentation.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">3.12<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/rabbitmq-website/release-information">Release Information</a></li></ul></div><a href="https://github.com/rabbitmq/rabbitmq-website" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article class=""><header><h1 class="title_f1Hy">New Credit Flow Settings on RabbitMQ 3.5.5</h1><div class="container_mt6G margin-vert--md"><time datetime="2015-10-06T00:00:00.000Z">October 6, 2015</time> · <!-- -->15 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><span class="authorName_yefp">Álvaro Videla</span></div><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>This blog post was written for RabbitMQ 3.5, released in 2015. While some parts still
apply, there&#x27;s a lot of outdated information. For example, RabbitMQ 4.0
doesn&#x27;t support queue mirroring anymore and &quot;paging messages to disk&quot; is
no longer something that RabbitMQ has to do, since messages are almost
always persisted to disk right away.</p></div></div>
<p>In order to prevent fast publishers from overflowing the broker with
more messages than it can handle at any particular moment, RabbitMQ
implements an internal mechanism called <em>credit flow</em> that will be
used by the various systems inside RabbitMQ to throttle down
publishers, while allowing the message consumers to catch up. In this
blog post we are going to see how <em>credit flow</em> works, and what we can
do to tune its configuration for an optimal behaviour.</p>
<p>The <a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_5_5" target="_blank" rel="noopener noreferrer">latest</a> version of RabbitMQ includes a couple of new configuration
values that let users fiddle with the internal credit flow
settings. Understanding how these work according to your particular
workload can help you get the most out of RabbitMQ in terms of
performance, but beware, increasing these values <em>just to see what
happens</em> can have adverse effects on how RabbitMQ is able to respond
to message bursts, affecting the internal strategies that RabbitMQ has
in order to deal with memory pressure. <strong>Handle with care</strong>.</p>
<p>To understand the new credit flow settings first we need to understand
how the internals of RabbitMQ work with regards to message publishing
and paging messages to disk. Let&#x27;s see first how message publishing
works in RabbitMQ.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="message-publishing">Message Publishing<a href="#message-publishing" class="hash-link" aria-label="Direct link to Message Publishing" title="Direct link to Message Publishing">​</a></h2>
<p>To see how <code>credit_flow</code> and its settings affect publishing, let&#x27;s see
how internal messages flow in RabbitMQ. Keep in mind that RabbitMQ is
implemented in Erlang, where processes communicate by sending messages
to each other.</p>
<p>Whenever a RabbitMQ instance is running, there are probably hundreds
of Erlang processes exchanging messages to communicate with each
other. We have for example a reader process that reads AMQP frames
from the network. Those frames are transformed into AMQP commands that
are forwarded to the AMQP channel process. If this channel is handling
a publish, it needs to ask a particular exchange for the list of
queues where this message should end up going, which means the channel
will deliver the message to each of those queues. Finally if the AMQP
message needs to be persisted, the msg_store process will receive it
and write it to disk. So whenever we publish an AMQP message to
RabbitMQ we have the following erlang message flow<sup><a href="#user-content-fn-1-77b397" id="user-content-fnref-1-77b397" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">reader -&gt; channel -&gt; queue process -&gt; message store.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In order to prevent any of those processes from overflowing the next
one down the chain, we have a <em>credit flow</em> mechanism in place. Each
process initially grants certain amount of credits to the process that
it&#x27;s sending them messages. Once a process is able to handle N of
those messages, it will grant more credit to the process that sent
them. Under default <em>credit flow</em> settings
(<code>credit_flow_default_credit</code> under <code>rabbitmq.config</code>) these values
are 200 messages of initial credit, and after 50 messages processed by
the receiving process, the process that sent the messages will be
granted 50 more credits.</p>
<p>Say we are publishing messages to RabbitMQ, this means the <em>reader</em>
will be sending one erlang message to the channel process per AMQP
<code>basic.publish</code> received. Each of those messages will consume one of
these credits from the channel. Once the channel is able to process 50
of those messages, it will grant more credit to the reader. So far so
good.</p>
<p>In turn the channel will send the message to the queue process that
matched the message routing rules. This will consume one credit from
the credit granted by the queue process to the channel. After the
queue process manages to handle 50 deliveries, it will grant 50 more
credits to the channel.</p>
<p>Finally if a message is deemed to be persistent (it&#x27;s persistent and
published to a durable queue), it will be sent to the message store,
which in this case will also consume credits from the ones granted by
the message store to the queue process. In this case the initial
values are different and handled by the <code>msg_store_credit_disc_bound</code>
setting: <strong>2000</strong> messages of initial credit and <strong>500</strong> more credits
after 500 messages are processed by the message store.</p>
<p>So we know how internal messages flow inside RabbitMQ and when credit
is granted to a process that&#x27;s above in the msg stream. The tricky
part comes when credit is granted between processes. Under normal
conditions a channel will process 50 messages from the reader, and
then grant the reader 50 more credits, but keep in mind that a channel
is not just handling publishes, it&#x27;s also sending messages to
consumers, routing messages to queues and so on.</p>
<p>What happens if the reader is sending messages to the channel at a
higher speed of what the channel is able to process? If we reach this
situation, then the channel will block the reader process, which will
result in producers being throttled down by RabbitMQ. Under default
settings, the reader will be blocked once it sends 200 messages to the
channel, but the channel is not able to process at least 50 of them,
in order to grant credit back to the reader.</p>
<p>Again, under normal conditions, once the channel manages to go through
the message backlog, it will grant more credit to the reader, but
there&#x27;s a catch. What if the channel process is being blocked by the
queue process, due to similar reasons? Then the <strong>new credit</strong> that
was supposed to go to the reader process <strong>will be deferred</strong>. The
reader process <strong>will remain blocked</strong>.</p>
<p>Once the queue process manages to go through the deliveries backlog
from the channel, it will grant more credit to the channel, unblocking
it, which will result in the channel granting more credit to the
reader, unblocking it. Once again, that&#x27;s under normal conditions,
but, you guessed it, what if the message store is blocking the queue
process? Then credit to the channel will be deferred, which will
remain blocked, deferring credit to the reader, <strong>leaving the reader
blocked</strong>. At some point, the message store will grant messages to the
queue process, which will grant messages back to the channel, and then
the channel will finally grant messages to the reader and <strong>unblock
the reader</strong>:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">reader &lt;--[grant]-- channel &lt;--[grant]-- queue process &lt;--[grant]-- message store.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Having one channel and one queue process makes things easier to
undertand but it might not reflect reality. It&#x27;s common for RabbitMQ
users to have more than one channel publishing messages on the same
connection. Even more common is to have one message being routed to
more than one queue. What happens with the credit flow scheme we&#x27;ve
just explained is that <strong>if one of those queues blocks the channel</strong>,
then <strong>the reader will be blocked as well</strong>.</p>
<p>The problem is that from a reader standpoint, when we read a frame
from the network, we don&#x27;t even know to which channel it belongs
to. Keep in mind that channels are a logical concept on top of AMQP
connections. So even if a new AMQP command will end up in a channel
that is not blocking the reader, the reader has no way of knowing
it. Note that <strong>we only block publishing</strong> connections, consumers
connections are unaffected since we want consumers to drain messages
from queues. This is a good reason why it might be better to have
connections dedicated to publishing messages, and connections
dedicated for consumers only.</p>
<p>On a similar fashion, whenever a channel is processing message
publishes, it doesn&#x27;t know where messages will end up going, until it
performs routing. So a channel might be receiving a message that
should end up in a queue that is not blocking the channel. Since at
ingress time we don&#x27;t know any of this, then the credit flow strategy
in place is to block the reader until processes down the chain are
able to handle new messages.</p>
<p>One of the new settings introduced in RabbitMQ 3.5.5 is the ability to
modify the values for <code>credit_flow_default_credit</code>. This setting takes
a tuple of the form <code>{InitialCredit, MoreCreditAfter}</code>. InitialCredit
is set to <strong>200</strong> by default, and MoreCreditAfter is set to
<strong>50</strong>. Depending on your particular workflow, you need to decide if
it&#x27;s worth bumping those values. Let&#x27;s see the message flow scheme
again:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">reader -&gt; channel -&gt; queue process -&gt; message store.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Bumping the values for <code>{InitialCredit, MoreCreditAfter}</code> will mean
that at any point in that chain we could end up with more messages
than those that can be handled by the broker at that particular point
in time. More messages means more RAM usage. The same can be said
about <code>msg_store_credit_disc_bound</code>, but keep in mind that there&#x27;s
only one message store<sup><a href="#user-content-fn-2-77b397" id="user-content-fnref-2-77b397" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup> per RabbitMQ instance, and there
can be <strong>many channels</strong> sending messages to the <strong>same queue
process</strong>. So while a queue process has a value of 2000 as
<code>InitialCredit</code> from the message store, that queue can be ingesting
many times that value from different channel/connection sources. So
200 credits as initial <code>credit_flow_default_credit</code> value could be
seen as too conservative, but you need to understand if according to
your workflow that&#x27;s still good enough or not.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="message-paging">Message Paging<a href="#message-paging" class="hash-link" aria-label="Direct link to Message Paging" title="Direct link to Message Paging">​</a></h2>
<p>Let&#x27;s take a look at how RabbitMQ queues store messages. When a
message enters the queue, the queue needs to determine if the message
should be persisted or not. If the message has to be persisted, then
RabbitMQ will do so right away<sup><a href="#user-content-fn-3-77b397" id="user-content-fnref-3-77b397" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup>. Now even if a message was
persisted to disk, this doesn&#x27;t mean the message got removed from RAM,
since RabbitMQ keeps a cache of messages in RAM for fast access when
delivering messages to consumers. Whenever we are talking about
<em>paging messages out to disk</em>, we are talking about what RabbitMQ does
when it has to send messages from this cache to the file system.</p>
<p>When RabbitMQ decides it needs to page messages to disk it will call
the function <code>reduce_memory_use</code> on the internal queue implementation
in order to send messages to the file system. Messages are going to be
paged out in batches; how big are those batches depends on the current
memory pressure status. It basically works like this:</p>
<p>The function <code>reduce_memory_use</code> will receive a number called <code>target ram count</code> which tells RabbitMQ that it should try to page out
messages until only that many remain in RAM. Keep in mind that whether
messages are persistent or not, they are still kept in RAM for fast
delivery to consumers. Only when memory pressure kicks in, is when
messages in memory are paged out to disk. Quoting from our code
comments: The question of whether a message is in RAM and whether it
is persistent are orthogonal.</p>
<p>The number of messages that are accounted for during this chunk
calculation are those messages that are in RAM (in the aforementioned
cache), plus the number of pending acks that are kept in RAM (i.e.:
messages that were delivered to consumers and are pending
acknowledgment). If we have 20000 messages in RAM (cache + pending
acks) and then <code>target ram count</code> is set to 8000, we will have to page
out 12000 messages. This means paging will receive a quota of 12000
messages. Each message paged out to disk will consume one unit from
that quota, whether it&#x27;s a pending ack, or an actual message from the
cache.</p>
<p>Once we know how many messages need to be paged out, we need to decide
from where we should page them first: pending acks, or the message
cache. If pending acks is growing faster than messages the cache, ie:
more messages are being delivered to consumers than those being
ingested, this means the algorithm will try to page out pending acks
first, and then try to push messages from the cache to the file
system. If the cache is growing faster than pending acks, then
messages from the cache will be pushed out first.</p>
<p>The catch here is that paging messages from pending acks (or the cache
if that comes first) might result in the first part of the process
consuming all the quota of messages that need to be pushed to disk. So
if pending acks pushes 12000 acks to disk as in our example, this
means we won&#x27;t page out messages from the cache, and vice versa.</p>
<p>This first part of the paging process sent to disk certain amount of
messages (between acks + messages paged from the cache). The messages
that were paged out just had their contents paged out, but their
position in the queue is still in RAM. Now the queue needs to decide
if this extra information that&#x27;s kept in RAM needs to be paged out as
well, to further reduce memory usage. Here is were finally
<code>msg_store_io_batch_size</code> enters into play (coupled with
<code>msg_store_credit_disc_bound</code> as well). Let&#x27;s try to understand how
they work.</p>
<p>The settings for <code>msg_store_credit_disc_bound</code> affect how internal
credit flow is handled when sending message to disk. The
<code>rabbitmq_msg_store</code> module implements a database that takes care of
persisting messages to disk. Some details about the why&#x27;s of this
implementation can be found here:
<a href="/rabbitmq-website/blog/2011/01/20/rabbitmq-backing-stores-databases-and-disks">RabbitMQ, backing stores, databases and disks</a>.</p>
<p>The message store has a credit system for each of the clients that
send writes to it. Every RabbitMQ queue would be a read/write client
for this store. The message store has a credits mechanism to prevent a
particular writer to overflow its inbox it with messages. Assuming
current default values, when a writer starts talking to the message
store, it receives an initial credit of <strong>2000</strong> messages, and it will
receive more credit once <strong>500</strong> messages are processed. When is this
credit consumed then? Credit is consumed whenever we write to the
message store, but that doesn&#x27;t happen for every message. The plot
thickens.</p>
<p>Since version 3.5.0 it&#x27;s possible to embed small messages into the
queue index, instead of having to reach the message store for
that. Messages that are smaller than a configurable setting (currently
4096 bytes) will go to the queue index when persisted, so those
messages won&#x27;t consume this credit. Now, let&#x27;s see what happens with
messages that do need to go to the message store.</p>
<p>Whenever we publish a message that&#x27;s determined to be persistent
(persistent messages published to a durable queue), then that message
will consume one of these credits. If a message has to paged out to
disk from the cache mentioned above, it will also consume one
credit. So if during message paging we consume more credits than those
currently available for our queue, the first half of the paging
process might stop, since there&#x27;s no point in sending writes to the
message store when it won&#x27;t accept them. This means that from the
initial quota of 12000 that we would have had to page out, we only
managed to process 2000 of them (assuming all of them need to go to
the message store).</p>
<p>So we managed to page out 2000 messages, but we still keep their
position in the queue in RAM. Now the paging process will determine if
it needs to also page out any of these messages positions to disk as
well. RabbitMQ will calculate how many of them can stay in RAM, and
then it will try to page out the remaining of them to disk. For this
second paging to happen, the amount of messages that has to be paged
to disk must be greater than <code>msg_store_io_batch_size</code>. The bigger
this number is, the more message positions RabbitMQ will keep in RAM,
so again, depending on your particular workload, you need to tune this
parameter as well.</p>
<p>Another thing we improved significantly in 3.5.5 is the performance of
paging queue index contents to disk. If your messages are generally
smaller than <code>queue_index_embed_msgs_below</code>, then you&#x27;ll see the
benefit of these changes. These changes also affect how message
positions are paged out to disk, so you should see improvements in
this area as well. So while having a low <code>msg_store_io_batch_size</code>
might mean the queue index will have more work paging to disk, keep in
mind this process has been optimized.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="queue-mirroring">Queue Mirroring<a href="#queue-mirroring" class="hash-link" aria-label="Direct link to Queue Mirroring" title="Direct link to Queue Mirroring">​</a></h2>
<p>To keep the descriptions above a bit simpler, we avoided bringing queue
mirroring into the picture. Credit flows also affects mirroring from a
channel point of view. When a channel delivers AMQP messages to
queues, it sends the message to each mirror, consuming one credit from
each mirror process. If any of the mirrors is slow processing the
message then that particular mirror might be responsible for the
channel being blocked. If the channel is being blocked by a mirror,
and that queue mirror gets partitioned from the network, then the
channel will be unblocked only after RabbitMQ detects the mirror
death.</p>
<p>Credit flow also takes part when synchronising mirrored queues, but
this is something you shouldn&#x27;t care too much about, mostly because
there&#x27;s nothing you could do about it, since mirror synchronisation is
handled entirely by RabbitMQ.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>In any case, we hope this blog post has been informative and helps you
with your RabbitMQ tuning. If you have comments or questions about the
new credit flow settings, don&#x27;t hesitate to contact us at the RabbitMQ
mailing list:
<a href="https://groups.google.com/forum/#!forum/rabbitmq-users" target="_blank" rel="noopener noreferrer">rabbitmq-users</a>.</p>
<!-- -->
<section data-footnotes="true" class="footnotes"><h2 class="anchor anchorWithStickyNavbar_LWe7 sr-only" id="footnote-label">Footnotes<a href="#footnote-label" class="hash-link" aria-label="Direct link to Footnotes" title="Direct link to Footnotes">​</a></h2>
<ol>
<li id="user-content-fn-1-77b397">
<p>A message can be delivered to more than one queue process. <a href="#user-content-fnref-1-77b397" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-2-77b397">
<p>There are two message stores, one for transient messages and one for persistent messages. <a href="#user-content-fnref-2-77b397" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-3-77b397">
<p>RabbitMQ will call fsync every 200 ms. <a href="#user-content-fnref-3-77b397" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/performance">Performance</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2015-10-06-new-credit-flow-settings-on-rabbitmq-3-5-5/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/rabbitmq-website/blog/2015/12/28/whats-new-in-rabbitmq-3-6-0"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">What&#x27;s new in RabbitMQ 3.6.0</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rabbitmq-website/blog/2015/04/16/scheduling-messages-with-rabbitmq"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Scheduling Messages with RabbitMQ</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#message-publishing" class="table-of-contents__link toc-highlight">Message Publishing</a></li><li><a href="#message-paging" class="table-of-contents__link toc-highlight">Message Paging</a></li><li><a href="#queue-mirroring" class="table-of-contents__link toc-highlight">Queue Mirroring</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn about RabbitMQ</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/tutorials">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/docs">Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Reach out to the RabbitMQ team</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/rabbitmq" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/rabbitmq/rabbitmq-server/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact?utm_source=rmq_release-information_tableheader&amp;utm_medium=rmq_website&amp;utm_campaign=tanzu">Long Term Commercial Support</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact">Contact Us</a></li><li class="footer__item"><a href="https://www.rabbitmq.com/discord" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Broadcom</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://tanzu.vmware.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">VMware Tanzu<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/legal.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms of Use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/trademark-guidelines">Trademark Guidelines</a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy/california-privacy-rights.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Your California Privacy Rights<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item ot-sdk-show-settings">Cookie Settings</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2005-2025 Broadcom. All Rights Reserved. The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.</div></div></div></footer></div>
</body>
</html>
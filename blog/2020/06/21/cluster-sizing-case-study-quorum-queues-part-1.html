<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Cluster Sizing Case Study – Quorum Queues Part 1 | RabbitMQ</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" name="twitter:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" property="og:url" content="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Cluster Sizing Case Study – Quorum Queues Part 1 | RabbitMQ"><meta data-rh="true" name="description" content="In a first post in this sizing series we covered the workload, the tests, and the cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with quorum queues. We also ran a sizing analysis on mirrored queues."><meta data-rh="true" property="og:description" content="In a first post in this sizing series we covered the workload, the tests, and the cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with quorum queues. We also ran a sizing analysis on mirrored queues."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-06-21T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Performance,Capacity Planning"><link data-rh="true" rel="icon" href="/rabbitmq-website/img/rabbitmq-logo.svg"><link data-rh="true" rel="canonical" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://H10VQIW16Y-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","mainEntityOfPage":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","url":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","headline":"Cluster Sizing Case Study – Quorum Queues Part 1","name":"Cluster Sizing Case Study – Quorum Queues Part 1","description":"In a first post in this sizing series we covered the workload, the tests, and the cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with quorum queues. We also ran a sizing analysis on mirrored queues.","datePublished":"2020-06-21T00:00:00.000Z","author":{"@type":"Person","name":"Jack Vanlightly"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://www.rabbitmq.com/rabbitmq-website/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/rabbitmq-website/blog/rss.xml" title="RabbitMQ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/rabbitmq-website/blog/atom.xml" title="RabbitMQ Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="RabbitMQ" href="/rabbitmq-website/opensearch.xml">







<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-domain-script="018ee308-473e-754f-b0c2-cbe82d25512f"></script>
<script>function OptanonWrapper(){}</script>
<script>function setGTM(e,t,o,n,r){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var i=t.getElementsByTagName(o)[0],a=t.createElement(o),s="dataLayer"!=n?"&l="+n:"";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+r+s,i.parentNode.insertBefore(a,i)}var timer;function waitForOnetrustActiveGroups(){document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?(clearTimeout(timer),setGTM(window,document,"script","dataLayer","GTM-TT84L8K")):timer=setTimeout(waitForOnetrustActiveGroups,250)}document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?setGTM(window,document,"script","dataLayer","GTM-TT84L8K"):waitForOnetrustActiveGroups()</script><link rel="stylesheet" href="/rabbitmq-website/styles.css">
<script src="/rabbitmq-website/runtime~main.js" defer="defer"></script>
<script src="/rabbitmq-website/main.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:var(--ifm-color-primary-contrast-background);color:var(--ifm-font-color-base)" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><strong style="font-size: var(--ifm-h4-font-size);"><a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0">RabbitMQ 4.1.0 is out</a></strong></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/rabbitmq-website/"><div class="navbar__logo"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/rabbitmq-website/tutorials">Getting Started</a><a class="navbar__item navbar__link" href="/rabbitmq-website/docs">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rabbitmq-website/blog">Blog</a><a class="navbar__item navbar__link" href="/rabbitmq-website/contact">Support</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/rabbitmq-website/docs">4.1</a><ul class="dropdown__menu"><li class=""><strong>Release series</strong></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/next">Next</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs">4.1</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/4.0">4.0</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/3.13">3.13</a></li><li><a href="https://v3-12.rabbitmq.com/documentation.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">3.12<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/rabbitmq-website/release-information">Release Information</a></li></ul></div><a href="https://github.com/rabbitmq/rabbitmq-website" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article class=""><header><h1 class="title_f1Hy">Cluster Sizing Case Study – Quorum Queues Part 1</h1><div class="container_mt6G margin-vert--md"><time datetime="2020-06-21T00:00:00.000Z">June 21, 2020</time> · <!-- -->16 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><span class="authorName_yefp">Jack Vanlightly</span></div><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>In a <a href="/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations">first post</a> in this sizing series we covered the workload, the tests, and the cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with quorum queues. We also ran a <a href="/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1">sizing analysis on mirrored queues</a>.</p>
<p>In this post we&#x27;ll run the increasing intensity tests that will measure our candidate cluster sizes at varying publish rates, under ideal conditions. In the next post we&#x27;ll run resiliency tests that measure whether our clusters can handle our target peak load under adverse conditions.</p>
<p>All quorum queues are declared with the following properties:</p>
<ul>
<li>x-quorum-initial-group-size=3 (replication factor)</li>
<li>x-max-in-memory-length=0</li>
</ul>
<p>The <em>x-max-in-memory-length</em> property forces the quorum queue to remove message bodies from memory as soon as it is safe to do. You can set it to a longer limit, this is the most aggressive - designed to avoid large memory growth at the cost of more disk reads when consumers do not keep up. Without this property message bodies are kept in memory at all times which can place memory growth to the point of memory alarms setting off which severely impacts the publish rate - something we want to avoid in this workload case study.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ideal-conditions--growing-intensity-tests">Ideal Conditions - Growing Intensity Tests<a href="#ideal-conditions--growing-intensity-tests" class="hash-link" aria-label="Direct link to Ideal Conditions - Growing Intensity Tests" title="Direct link to Ideal Conditions - Growing Intensity Tests">​</a></h2>
<p>In a previous <a href="/rabbitmq-website/blog/2020/06/04/how-to-run-benchmarks">post </a>we discussed options for running benchmarks. You can run this workload, at these intensities with the following command:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bin/runjava com.rabbitmq.perf.PerfTest \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-z 1800 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-f persistent \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-q 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-c 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ct -1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ad false \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--rate 50 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--size 1024 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern &#x27;perf-test-%d&#x27; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-from 1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-to 100 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-qa auto-delete=false,durable=false,x-queue-type=quorum \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumer-latency 10000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producer-random-start-delay 30</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Just change the --rate argument to the rate you need for each test and remember that it is the rate per publisher rather than the total combined rate. Because the consumer processing time (consumer latency) is set to 10ms, we also need to increase the number of consumers for the higher publish rates.</p>
<p>Note that we set durable=false because this property is not relevant to quorum queues.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="io1---high-performance-ssd">io1 - High Performance SSD<a href="#io1---high-performance-ssd" class="hash-link" aria-label="Direct link to io1 - High Performance SSD" title="Direct link to io1 - High Performance SSD">​</a></h3>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 1. Increasing intensity tests and the io1 volume" src="/rabbitmq-website/assets/images/qq-io1-phase1-1-2a8984e5383a54fd3114a5a5ec8749c9.png" width="895" height="393" class="img_ev3q"><figcaption>Fig 1. Increasing intensity tests and the io1 volume</figcaption></figure><p></p>
<p>In the intensities where the quorum queues reached their limit, they tended to accumulate message backlogs, causing 95th percentile and above end-to-end latencies to go up. Below are the 50th and 75th latencies.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 2. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16." src="/rabbitmq-website/assets/images/qq-io1-phase1-50-75-latencies-1-4-54bffe0c8df215d71a41b4ba8974414c.png" width="782" height="550" class="img_ev3q"><figcaption>Fig 2. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 3. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8." src="/rabbitmq-website/assets/images/qq-io1-phase1-50-75-latencies-5-7-1-7c23aab236ba8f634f2c6b9f31469463.png" width="774" height="554" class="img_ev3q"><figcaption>Fig 3. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.</figcaption></figure><p></p>
<p>We see that in some cases latencies shot much higher when the quorum queues reached throughput capacity.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 4. 95th, 99th and 99.9th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16." src="/rabbitmq-website/assets/images/qq-io1-phase1-95-99-999-latencies-1-4-28ed3388c9d28883861f723fede18a41.png" width="764" height="549" class="img_ev3q"><figcaption>Fig 4. 95th, 99th and 99.9th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 5. 95th, 99th and 99.9th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8." src="/rabbitmq-website/assets/images/qq-io1-phase1-95-99-999-latencies-5-7-1-10421e2269b11197c9b8dc5caa3298b5.png" width="775" height="551" class="img_ev3q"><figcaption>Fig 5. 95th, 99th and 99.9th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.</figcaption></figure><p></p>
<p>All except for the 3x16 and 5x8 clusters managed the target peak of 30k msg/s and all at below the 1 second end-to-end latency requirement. As expected, the larger clusters achieved the highest throughput.</p>
<p><strong>Bottom throughput cluster (3x16) server metrics</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 6. CPU and network for the worst performing cluster (3x16)" src="/rabbitmq-website/assets/images/qq-io1-phase1-cpu-network-bottom-b942418bb0be8794d4f8ba592c4b4fc5.png" width="840" height="392" class="img_ev3q"><figcaption>Fig 6. CPU and network for the worst performing cluster (3x16)</figcaption></figure><p></p>
<p>We see that for this small cluster, CPU seemed to be the resource bottleneck.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 7. Disk stats for the worst performing cluster (3x16)" src="/rabbitmq-website/assets/images/qq-io1-phase1-disk-bottom-7dee953c28343fc43860de6d52431148.png" width="1013" height="670" class="img_ev3q"><figcaption>Fig 7. Disk stats for the worst performing cluster (3x16)</figcaption></figure><p></p>
<p>First of all we see a much lower number of IOPs compared to mirrored queues. As we progressed through the increasing intensities, the IOPs actually dropped, with each write operation getting larger and larger.</p>
<p><strong>Top throughput cluster server metrics</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 8. CPU and network of the top performing cluster (7x16)" src="/rabbitmq-website/assets/images/qq-io1-phase1-cpu-network-top-e430ac0512d4dd44f1a9de2c3986248d.png" width="799" height="391" class="img_ev3q"><figcaption>Fig 8. CPU and network of the top performing cluster (7x16)</figcaption></figure><p></p>
<p>CPU did not reached saturation for this large cluster. Network bandwidth hit 500 Mbps which was lower than the same tests with mirrored queues which reached 750 Mbps (even though the mirrored queues had a lower replication factor). The inefficient usage of network by mirrored queues was discussed in a previous blog post.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 9. Disk stats for the top performing cluster (7x16)" src="/rabbitmq-website/assets/images/qq-io1-phase1-disk-top-75e9048fb64d5c8ca7e469af39685625.png" width="1008" height="671" class="img_ev3q"><figcaption>Fig 9. Disk stats for the top performing cluster (7x16)</figcaption></figure><p></p>
<p>Just like with the mirrored queues tests, the worst performing cluster not only managed a lower throughput, but saw higher disk IO. This is because of how quorum queues write to disk. Every message is always written to the Write-Ahead Log (WAL). In order to keep the size of the WAL under control, WAL files are truncated which involves writing their messages to segment files. There is an optimisation where if a message is consumed and acknowledged before being written to a segment file, this second disk write is not performed - as far as RabbitMQ is concerned that message no longer exists. This means that if consumers keep up, messages are only written to disk once, but if consumers fall behind then messages can end up being written to disk twice.</p>
<p>The top throughput cluster saw no resource bottleneck, indicating that the limitation was the cost of coordination (Raft based replication).</p>
<p>The bottom throughput cluster did reach above 90% CPU utilisation early on which corresponded with the moment it stopped reaching the target throughput. It reached &gt; 90% on the 4th test and from the 5th test and onward it failed to match the target reliably.</p>
<p>So quorum queues will use more disk bandwidth than mirrored queues which write to disk once at most.</p>
<p>This was how each cluster coped with the target rate of 30k msg/s.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 10. The 30k msg/s peak load." src="/rabbitmq-website/assets/images/qq-io1-phase1-30k-0360e804ce95b66bee4d7dbe8c6dd9ad.png" width="910" height="391" class="img_ev3q"><figcaption>Fig 10. The 30k msg/s peak load.</figcaption></figure><p></p>
<p><strong>Leaderboard in matched target throughput</strong></p>
<p>From 35k msg/s, many of the sizes continued to show increases in throughput as the target throughput increased, but always fell a little short of the target.</p>
<p>The one size that was able to hit its target far beyond 30k msg/s was:</p>
<ol>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge) - 60k msg/s</li>
</ol>
<p>The rest fell short of their targets in each test from 35k msg/s and up, but still showed higher throughput as the tests progressed. This is the leaderboard in terms of top throughput:</p>
<ol>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 65k msg/s</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 63k msg/s</li>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 54k msg/s</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 53k msg/s</li>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 50k msg/s</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 40k msg/s</li>
<li>Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 37k msg/s</li>
</ol>
<p>Scaling out and the middle ground of up/out showed the best results. </p>
<p><strong>Leaderboard in cost per 1000 messages per month, at top throughput.</strong></p>
<ol>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $97 (50k)</li>
<li>Cluster: 3 nodes, 16 vCPUs (c5.4xlarge. Cost: $98 (37k)</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge. Cost: $115 (53k)</li>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge. Cost: $126 (54k)</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge. Cost: $137 (40k)</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge. Cost: $139 (63k)</li>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge. Cost: $142 (65k)</li>
</ol>
<p><strong>Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.</strong></p>
<p>We see that two clusters didn&#x27;t quite manage the 30k msg/s target. The leaderboard for the ones that did:</p>
<ol>
<li>Cluster: 5 nodes, 16 vCPU (c5.4xlarge). Cost: $135</li>
<li>Cluster: 7 nodes, 8 vCPU (c5.2xlarge). Cost: $151</li>
<li>Cluster: 3 nodes, 36 vCPU (c5.9xlarge). Cost: $183</li>
<li>Cluster: 9 nodes, 8 vCPU (c5.2xlarge). Cost: $194</li>
<li>Cluster: 7 nodes, 16 vCPU (c5.4xlarge). Cost: $204</li>
</ol>
<p>Cost effectiveness and performance were at odds with each other with this test. Scaling out is expensive when the storage volumes are the most costly item. The best value came from the middle ground of scaling out and up.</p>
<p>Do we really need those costly io1 SSDs? The IOPs in this test were relatively low and we didn’t go above 250MiB/s so the cheap gp2 volumes should be a good option. Let’s see.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="gp2---general-purpose-ssd">gp2 - General Purpose SSD<a href="#gp2---general-purpose-ssd" class="hash-link" aria-label="Direct link to gp2 - General Purpose SSD" title="Direct link to gp2 - General Purpose SSD">​</a></h2>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 11. Increasing intensity tests with the gp2 volume." src="/rabbitmq-website/assets/images/qq-gp2-phase1-d1f829256882ac52fd105aedd8a29e15.png" width="911" height="391" class="img_ev3q"><figcaption>Fig 11. Increasing intensity tests with the gp2 volume.</figcaption></figure><p></p>
<p>As before, the 50th and 75th percentiles remain pretty low.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 12. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16." src="/rabbitmq-website/assets/images/qq-gp2-phase1-50-75-latencies-1-4-232cd1417994d0011a2d64a2bb1560b8.png" width="912" height="551" class="img_ev3q"><figcaption>Fig 12. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 13. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8." src="/rabbitmq-website/assets/images/qq-gp2-phase1-50-75-latencies-5-7-44391e5da6dc69d053d05b81a2009a44.png" width="895" height="550" class="img_ev3q"><figcaption>Fig 13. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.</figcaption></figure><p></p>
<p>But the 95th, 99th and 99.9th percentiles shot up in some cases when the clusters reached their throughput capacity. This latency basically means that queues started accumulating messages. These backlogs only occurred on the larger 16 vCPU clusters.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 14. 95th, 99th and 99.9th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16." src="/rabbitmq-website/assets/images/qq-gp2-phase1-all-latencies-1-4-64f503d0c27f089fdaadb1f4307fbb6d.png" width="913" height="552" class="img_ev3q"><figcaption>Fig 14. 95th, 99th and 99.9th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 15. 95th, 99th and 99.9th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8." src="/rabbitmq-website/assets/images/qq-gp2-phase1-all-latencies-5-7-fe74519e80d493228b70b5bb4a2660a1.png" width="893" height="552" class="img_ev3q"><figcaption>Fig 15. 95th, 99th and 99.9th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.</figcaption></figure><p></p>
<p>The results for the gp2 volumes are no worse than the more expensive io1 volumes.</p>
<p><strong>Bottom throughput cluster (3x16) disk metrics</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 16. Worst performing cluster (3x16) disk stats." src="/rabbitmq-website/assets/images/qq-gp2-phase1-disk-bottom-1024x640-9c5a11cdcb76e4ef631f3df184a13145.png" width="1024" height="640" class="img_ev3q"><figcaption>Fig 16. Worst performing cluster (3x16) disk stats.</figcaption></figure><p></p>
<p><strong>Top throughput cluster (7x16) disk metrics.</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 17. Top performing cluster (7x16) disk stats." src="/rabbitmq-website/assets/images/qq-gp2-phase1-disk-top-1024x617-67708205f8cd4101ae526e1f7c33a579.png" width="1024" height="617" class="img_ev3q"><figcaption>Fig 17. Top performing cluster (7x16) disk stats.</figcaption></figure><p></p>
<p>In both cases IOPs started high being relatively close to the 3000 IOPs limit (reached 2.3k) but as load increased, IO sizes grew larger and the number of operations reduced.</p>
<p>With a target of 30k msg/s with 1kb messages, even if we wrote every message twice, we’d still not hit the 250MiB/s limit of gp2. As before, the smaller cluster saw more disk IO because it performed more double writes than the larger, higher performing cluster.</p>
<p>This is how the target of 30k msg/s turned out.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 18. Throughput for all clusters for the 30k msg/s target test." src="/rabbitmq-website/assets/images/qq-gp2-phase1-30k-608a6be1e4ad21a6bd23a36eb67a08fa.png" width="917" height="394" class="img_ev3q"><figcaption>Fig 18. Throughput for all clusters for the 30k msg/s target test.</figcaption></figure><p></p>
<p><strong>Leaderboard in matched target throughput</strong></p>
<p>From 35k msg/s and up, many of the sizes continued to show increases in throughput as the target throughput increased, but always fell a little short of the target.</p>
<p>The size that was able to hit its target far beyond that was:</p>
<ol>
<li>Cluster: 7 nodes, c5.4xlarge - 60k msg/s</li>
</ol>
<p>In the tests beyond 35k msg/s the rest fell short of their targets either by just a little or by some margin, but still showed higher throughput as the tests progressed. This is the leaderboard in terms of top throughput:</p>
<ol>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 67k msg/s</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 66k msg/s</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 54k msg/s</li>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 54k msg/s</li>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 42k msg/s</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 37k msg/s</li>
<li>Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 36k msg/s</li>
</ol>
<p>Scaling out and the middle ground of up/out showed the best results. </p>
<p><strong>Leaderboard in cost per 1000 messages per month, at top throughput.</strong></p>
<ol>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $41 (42k)</li>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $45 (54k)</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $47 (66k)</li>
<li>Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Cost: $49 (36k)</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $55 (54k)</li>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $72 (67k)</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $97 (37k)</li>
</ol>
<p><strong>Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.</strong></p>
<p>The clusters that managed the 30k msg/s target:</p>
<ol>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $54</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $69</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $98</li>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $107</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $120</li>
</ol>
<p>Cost effectiveness and performance were more aligned with this test. Small scaled out VMs showed great ROI due to their cheap storage volumes. For this workload, io1 is simply not worth it.</p>
<p>In a previous post we recommended the use of SSDs with quorum queues. We showed that quorum queues did fine on HDDs with a pure quorum queue workload. But when you run mixed workloads of classic queues and quorum queues we saw that HDDs couldn’t deliver the performance that quorum queues need. Seeing as this is a purely quorum workload, let’s see how they do on a HDD.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="st1---hdd">st1 - HDD<a href="#st1---hdd" class="hash-link" aria-label="Direct link to st1 - HDD" title="Direct link to st1 - HDD">​</a></h2>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 19. Increasing intensity tests with quorum queues and the st1 HDD." src="/rabbitmq-website/assets/images/qq-st1-phase1-bc76a0820aa2e7e20f288212eddb53e0.png" width="910" height="390" class="img_ev3q"><figcaption>Fig 19. Increasing intensity tests with quorum queues and the st1 HDD.</figcaption></figure><p></p>
<p>Quorum queues did fine on a HDD although the throughput was more choppy once a cluster had reached its throughput capacity. Throughput was also a little lower for all clusters except for the 7x16 cluster which reliably comes in at the top in these tests. We generally <a href="/rabbitmq-website/blog/2020/04/21/quorum-queues-and-why-disks-matter">recommend the usage of SSDs</a> because performance can suffer significantly with mixed classic/quorum queue workloads due to the random IO characteristics of classic queues. But this test shows that for a pure quorum queue workload, that HDD can perform well.</p>
<p>The 50th and 75th percentile latencies are higher than the SSDs though all sub-second except for the 5x8 cluster that saw message backlogs at the higher intensities.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 20. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16 and the st1 volume." src="/rabbitmq-website/assets/images/qq-st1-phase1-50-75-latencies-1-4-707576619ec64c9bdc0bd39dbc210713.png" width="901" height="547" class="img_ev3q"><figcaption>Fig 20. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16 and the st1 volume.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 21. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8 and the st1 volume." src="/rabbitmq-website/assets/images/qq-st1-phase1-50-75-latencies-5-7-c5d23fb9ce4a026c82a5f06fb5669c75.png" width="911" height="551" class="img_ev3q"><figcaption>Fig 21. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8 and the st1 volume.</figcaption></figure><p></p>
<p>As with the SSDs, in some cases latency shot up when clusters reached their throughput capacity (meaning that small message backlogs occurred).</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 22. All latencies for clusters 3x36, 3x16, 5x16 and 7x16, with the st1 volume." src="/rabbitmq-website/assets/images/qq-st1-phase1-all-latencies-1-4-4033df03445a7e693c463fa932996c86.png" width="909" height="550" class="img_ev3q"><figcaption>Fig 22. All latencies for clusters 3x36, 3x16, 5x16 and 7x16, with the st1 volume.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 23. All latencies for clusters 5x8, 7x8 and 9x8, with the st1 volume." src="/rabbitmq-website/assets/images/qq-st1-phase1-all-latencies-5-7-914d238ecc81a21996da53fec82e20c6.png" width="911" height="553" class="img_ev3q"><figcaption>Fig 23. All latencies for clusters 5x8, 7x8 and 9x8, with the st1 volume.</figcaption></figure><p></p>
<p>Importantly, all latencies were sub-second at the 30k msg/s target.</p>
<p>Looking at the disk metrics, as expected for a HDD, the IOPs were generally lower again with the correspondingly large write sizes.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 24. Top performing cluster (7x16) disk metrics." src="/rabbitmq-website/assets/images/qq-st1-phase1-disk-top-1024x647-9d3fc27b9d36af8545588f6869a9c301.png" width="1024" height="647" class="img_ev3q"><figcaption>Fig 24. Top performing cluster (7x16) disk metrics.</figcaption></figure><p></p>
<p>This is how the target of 30k msg/s turned out.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 25. All clusters at 30k msg/s throughput with the st1 volume." src="/rabbitmq-website/assets/images/qq-st1-phase1-30k-664685fd1b52ea79d46b0265e6b42379.png" width="908" height="392" class="img_ev3q"><figcaption>Fig 25. All clusters at 30k msg/s throughput with the st1 volume.</figcaption></figure><p></p>
<p>This time we could argue that the 5x8 cluster has achieved the 30k msg/s target, which it didn&#x27;t manage when on SSDs.</p>
<p>From 35k msg/s and onward, many of the sizes continued to show increases in throughput as the target throughput increased, but fell a little short of the target.</p>
<p>The sizes that were able to hit their target beyond that were:</p>
<ol>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 60k msg/s</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 40k msg/s</li>
</ol>
<p>The rest fell short of their targets in each test beyond 35k msg/s, but still showed higher throughput as the tests progressed. This is the leaderboard in terms of top throughput:</p>
<ol>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 67k msg/s</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 62k msg/s</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 54k msg/s</li>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 50k msg/s</li>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 37k msg/s</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 32k msg/s</li>
<li>Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 27k msg/s</li>
</ol>
<p>Scaling out and the middle ground of up/out showed the best results. </p>
<p><strong>Leaderboard in cost per 1000 messages per month, at top throughput.</strong></p>
<ol>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $74 (54k)</li>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $76 (37k)</li>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $78 (50k)</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $81 (62k)</li>
<li>Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Cost: $89 (27k)</li>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $94 (67k)</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $132 (32k)</li>
</ol>
<p><strong>Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.</strong></p>
<ol>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $93</li>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $131</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $134</li>
<li>Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $142</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $168</li>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $211</li>
</ol>
<p>Cost effectiveness and performance were not against each other in this case (like the io1) but they were not aligned either (like the gp2). Scaling out was best for performance but the more expensive volumes meant that scaling out was also now not the most cost effective. The middle ground and scaling out and up was best.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="end-to-end-latency-and-the-three-volume-types">End-to-end Latency and the Three Volume Types<a href="#end-to-end-latency-and-the-three-volume-types" class="hash-link" aria-label="Direct link to End-to-end Latency and the Three Volume Types" title="Direct link to End-to-end Latency and the Three Volume Types">​</a></h2>
<p>In these tests we treat end-to-end latency as the time between a message being published and consumed. If we look at the 30k msg/s target rate and the 7x16 cluster type we see:</p>
<p><strong>io1 SSD</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 26. 50 and 75th percentile end-to-end latency with the io1 SSD." src="/rabbitmq-website/assets/images/qq-latency-50-75-io1-7x16-30k-ff6feb066b502bf80f7e0768c560fb4f.png" width="908" height="232" class="img_ev3q"><figcaption>Fig 26. 50 and 75th percentile end-to-end latency with the io1 SSD.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 27. All percentiles end-to-end latency with the io1 SSD." src="/rabbitmq-website/assets/images/qq-latency-all-io1-7x16-30k-afe5548dec15c634e533d4e7cbfab0a2.png" width="907" height="230" class="img_ev3q"><figcaption>Fig 27. All percentiles end-to-end latency with the io1 SSD.</figcaption></figure><p></p>
<p><strong>gp2 SSD</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 28. 50 and 75th percentile end-to-end latency with the gp2 SSD." src="/rabbitmq-website/assets/images/qq-latency-50-75-gp2-7x16-30k-f0c0f758fca051481ce10a2e0222716a.png" width="907" height="228" class="img_ev3q"><figcaption>Fig 28. 50 and 75th percentile end-to-end latency with the gp2 SSD.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 29. All percentiles end-to-end latency with the gp2 SSD." src="/rabbitmq-website/assets/images/qq-latency-all-gp2-7x16-30k-ff6e0bc8a84019361b2661a98c1ee4ee.png" width="910" height="232" class="img_ev3q"><figcaption>Fig 29. All percentiles end-to-end latency with the gp2 SSD.</figcaption></figure><p></p>
<p><strong>st1 HDD</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 30. 50 and 75th percentile end-to-end latency with the st1 HDD." src="/rabbitmq-website/assets/images/qq-latency-50-75-st1-7x16-30k-2eb652677a9fc1a3717b5aeb67e9d696.png" width="905" height="232" class="img_ev3q"><figcaption>Fig 30. 50 and 75th percentile end-to-end latency with the st1 HDD.</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 31. All percentiles end-to-end latency with the st1 HDD." src="/rabbitmq-website/assets/images/qq-latency-all-st1-7x16-30k-e0ec7f72b64cf752af972927efd41ed1.png" width="910" height="232" class="img_ev3q"><figcaption>Fig 31. All percentiles end-to-end latency with the st1 HDD.</figcaption></figure><p></p>
<p>Unlike mirrored queues, we saw no benefit to latency when using the expensive io1 volumes compared to the gp2. The HDD showed higher end-to-end latencies than the SSDs as expected.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="increasing-intensity-benchmarks---conclusion">Increasing Intensity Benchmarks - Conclusion<a href="#increasing-intensity-benchmarks---conclusion" class="hash-link" aria-label="Direct link to Increasing Intensity Benchmarks - Conclusion" title="Direct link to Increasing Intensity Benchmarks - Conclusion">​</a></h2>
<p>So far the conclusions are:</p>
<ul>
<li>The expensive io1 volume just wasn’t worth it. It performed no better than the gp2. However, if we’d had a larger workload or larger messages we might have needed a volume capable of more than 250MiB/s, and in those cases we might choose the io1, but not with the high IOPS. With io1, you pay for the volume per GB, but also for the IOPs. So paying for 3000 (or less) instead of 10000 would make sense.</li>
<li>The inexpensive gp2 volume offers the best combination of performance and cost and is the best option for most workloads. Just remember that we used a 1TB size that does not have burst IOPs and there is a 250 MiBs limit (which we never hit).</li>
<li>With cheap storage volumes, scaling out the smaller 8 vCPU VMs was the most cost effective and best in terms of performance.</li>
<li>With expensive volumes, going with the middle ground of scaling out and up was most cost effective.</li>
<li>Scaling up with 3 large VMs was never optimal.</li>
</ul>
<p>Top 5 Configurations for cost per 1000 msg/s per month for the 30k msg/s throughput:</p>
<ol>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $54</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $69</li>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge), st1 HDD. Cost: $93</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $98</li>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $107</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="weve-only-tested-under-ideal-conditions">We&#x27;ve only tested under ideal conditions...<a href="#weve-only-tested-under-ideal-conditions" class="hash-link" aria-label="Direct link to We&#x27;ve only tested under ideal conditions..." title="Direct link to We&#x27;ve only tested under ideal conditions...">​</a></h2>
<p>We&#x27;ve gathered a lot of data from 21 different cluster configurations at 15 different workload intensities. We think that so far we should go with a medium to large cluster of small VMs on the inexpensive gp2 volumes. But this was testing the happy scenario where queues are empty or close to empty where RabbitMQ operates at its peak performance. Next we&#x27;ll run more tests that ensure that despite brokers being lost and queue backlogs occurring that our chosen cluster size continues to deliver the performance that we need. <a href="/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2">Next</a> we test resiliency.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/performance">Performance</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/capacity-planning">Capacity Planning</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-21-cluster-sizing-case-study-quorum-queues-part-1/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Cluster Sizing Case Study – Quorum Queues Part 2</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Cluster Sizing Case Study – Mirrored Queues Part 2</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#ideal-conditions--growing-intensity-tests" class="table-of-contents__link toc-highlight">Ideal Conditions - Growing Intensity Tests</a><ul><li><a href="#io1---high-performance-ssd" class="table-of-contents__link toc-highlight">io1 - High Performance SSD</a></li></ul></li><li><a href="#gp2---general-purpose-ssd" class="table-of-contents__link toc-highlight">gp2 - General Purpose SSD</a></li><li><a href="#st1---hdd" class="table-of-contents__link toc-highlight">st1 - HDD</a></li><li><a href="#end-to-end-latency-and-the-three-volume-types" class="table-of-contents__link toc-highlight">End-to-end Latency and the Three Volume Types</a></li><li><a href="#increasing-intensity-benchmarks---conclusion" class="table-of-contents__link toc-highlight">Increasing Intensity Benchmarks - Conclusion</a></li><li><a href="#weve-only-tested-under-ideal-conditions" class="table-of-contents__link toc-highlight">We&#39;ve only tested under ideal conditions...</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn about RabbitMQ</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/tutorials">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/docs">Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Reach out to the RabbitMQ team</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/rabbitmq" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/rabbitmq/rabbitmq-server/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact?utm_source=rmq_release-information_tableheader&amp;utm_medium=rmq_website&amp;utm_campaign=tanzu">Long Term Commercial Support</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact">Contact Us</a></li><li class="footer__item"><a href="https://www.rabbitmq.com/discord" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Broadcom</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://tanzu.vmware.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">VMware Tanzu<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/legal.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms of Use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/trademark-guidelines">Trademark Guidelines</a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy/california-privacy-rights.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Your California Privacy Rights<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item ot-sdk-show-settings">Cookie Settings</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2005-2025 Broadcom. All Rights Reserved. The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.</div></div></div></footer></div>
</body>
</html>
<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Cluster Sizing Case Study – Mirrored Queues Part 2 | RabbitMQ</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" name="twitter:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" property="og:url" content="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Cluster Sizing Case Study – Mirrored Queues Part 2 | RabbitMQ"><meta data-rh="true" name="description" content="In the last post we started a sizing analysis of our workload using mirrored queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month."><meta data-rh="true" property="og:description" content="In the last post we started a sizing analysis of our workload using mirrored queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-06-20T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Performance,Capacity Planning"><link data-rh="true" rel="icon" href="/rabbitmq-website/img/rabbitmq-logo.svg"><link data-rh="true" rel="canonical" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://H10VQIW16Y-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","mainEntityOfPage":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","url":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","headline":"Cluster Sizing Case Study – Mirrored Queues Part 2","name":"Cluster Sizing Case Study – Mirrored Queues Part 2","description":"In the last post we started a sizing analysis of our workload using mirrored queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.","datePublished":"2020-06-20T00:00:00.000Z","author":{"@type":"Person","name":"Jack Vanlightly"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://www.rabbitmq.com/rabbitmq-website/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/rabbitmq-website/blog/rss.xml" title="RabbitMQ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/rabbitmq-website/blog/atom.xml" title="RabbitMQ Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="RabbitMQ" href="/rabbitmq-website/opensearch.xml">







<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-domain-script="018ee308-473e-754f-b0c2-cbe82d25512f"></script>
<script>function OptanonWrapper(){}</script>
<script>function setGTM(e,t,o,n,r){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var i=t.getElementsByTagName(o)[0],a=t.createElement(o),s="dataLayer"!=n?"&l="+n:"";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+r+s,i.parentNode.insertBefore(a,i)}var timer;function waitForOnetrustActiveGroups(){document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?(clearTimeout(timer),setGTM(window,document,"script","dataLayer","GTM-TT84L8K")):timer=setTimeout(waitForOnetrustActiveGroups,250)}document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?setGTM(window,document,"script","dataLayer","GTM-TT84L8K"):waitForOnetrustActiveGroups()</script><link rel="stylesheet" href="/rabbitmq-website/styles.css">
<script src="/rabbitmq-website/runtime~main.js" defer="defer"></script>
<script src="/rabbitmq-website/main.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:var(--ifm-color-primary-contrast-background);color:var(--ifm-font-color-base)" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><strong style="font-size: var(--ifm-h4-font-size);"><a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0">RabbitMQ 4.1.0 is out</a></strong></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/rabbitmq-website/"><div class="navbar__logo"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/rabbitmq-website/tutorials">Getting Started</a><a class="navbar__item navbar__link" href="/rabbitmq-website/docs">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rabbitmq-website/blog">Blog</a><a class="navbar__item navbar__link" href="/rabbitmq-website/contact">Support</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/rabbitmq-website/docs">4.1</a><ul class="dropdown__menu"><li class=""><strong>Release series</strong></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/next">Next</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs">4.1</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/4.0">4.0</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/3.13">3.13</a></li><li><a href="https://v3-12.rabbitmq.com/documentation.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">3.12<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/rabbitmq-website/release-information">Release Information</a></li></ul></div><a href="https://github.com/rabbitmq/rabbitmq-website" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article class=""><header><h1 class="title_f1Hy">Cluster Sizing Case Study – Mirrored Queues Part 2</h1><div class="container_mt6G margin-vert--md"><time datetime="2020-06-20T00:00:00.000Z">June 20, 2020</time> · <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><span class="authorName_yefp">Jack Vanlightly</span></div><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>In the <a href="/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1">last post</a> we started a sizing analysis of our <a href="/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations">workload</a> using mirrored queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.</p>
<ol>
<li>Cluster: 5 nodes, 8 vCPUs, gp2 SDD. Cost: $58</li>
<li>Cluster: 7 nodes, 8 vCPUs, gp2 SDD. Cost: $81</li>
<li>Cluster: 5 nodes, 8 vCPUs, st1 HDD. Cost: $93</li>
<li>Cluster: 5 nodes, 16 vCPUs, gp2 SDD. Cost: $98</li>
<li>Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $104</li>
</ol>
<p>There are more tests to run to ensure these clusters can handle things like brokers failing and large backlogs accumulating during things like outages or system slowdowns.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions--coping-with-rolling-restarts-and-lost-brokers">Adverse Conditions - Coping with rolling restarts and lost brokers<a href="#adverse-conditions--coping-with-rolling-restarts-and-lost-brokers" class="hash-link" aria-label="Direct link to Adverse Conditions - Coping with rolling restarts and lost brokers" title="Direct link to Adverse Conditions - Coping with rolling restarts and lost brokers">​</a></h2>
<p>Will our gp2 SSD based clusters handle the same load if a broker goes down? Perhaps a VM or a disk fails, or you need to perform an emergency OS patch? We really need to make sure that on our Black Friday sales peak, that we’re going to be able to serve traffic even in the face of failures.</p>
<p>To that end, we run exactly the same test again, but hard kill a broker part way into each intensity level.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 1. One broker killed during each test" src="/rabbitmq-website/assets/images/mirrored-gp2-lost-broker-b28551991ef996877fab90f75455a2da.png" width="911" height="712" class="img_ev3q"><figcaption>Fig 1. One broker killed during each test</figcaption></figure><p></p>
<p>Some clusters did better than others but no cluster gets to the end of the test without seeing a drop in throughput when a broker is killed. The smaller 3 and 5 broker clusters see that drop in the lower intensity tests whereas the 7 and 9 broker clusters only start seeing that drop in the higher intensities.</p>
<p>Let’s look at our 30k msg/s target rate period.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 2. Different clusters handle a lost broker better than others" src="/rabbitmq-website/assets/images/mirrored-gp2-lost-broker-30k-32bccb9eecadee9032558af330136220.png" width="913" height="391" class="img_ev3q"><figcaption>Fig 2. Different clusters handle a lost broker better than others</figcaption></figure><p></p>
<p>You’ll notice that the 5x16, 7x16, 7x8 and 9x8 clusters fully recover, while at the other end of the spectrum the 3 node clusters see the biggest dip. For the ones that fully recover, the dip is small but this is with <em>ha-sync-mode</em> as <em>manual</em>. If you choose <em>automatic</em>, the recovery still happens but the dip is larger and longer duration.</p>
<p>The reason for this drop in throughput is that when a mirrored queue becomes under-replicated because of a broker loss it will create a new mirror on another broker if it can - maintaining the same redundancy level. This concentrates the same amount of traffic on fewer brokers. So if you use a replication factor of 2 (one master, one mirror) like in this test, have three brokers and lose one then you’ll be increasing load on the other two by a sizeable percentage. If you use* ha-mode=all*, then you won’t see such a dip as there will be no brokers to place new mirrors on.</p>
<p>However if you have nine nodes and lose one, then the load increase is marginal.</p>
<p>Scaling out wins this round.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions--consumer-slowdown">Adverse Conditions - Consumer Slowdown<a href="#adverse-conditions--consumer-slowdown" class="hash-link" aria-label="Direct link to Adverse Conditions - Consumer Slowdown" title="Direct link to Adverse Conditions - Consumer Slowdown">​</a></h2>
<p>When processing messages, consumers normally need to interact with other systems like databases or third party APIs. These downstream systems can slowdown due heavy load, or some kind of outage and this has the knock-on effect of slowing down your consumers. This then causes the number of messages in your queues to grow which can then also impact publishers. RabbitMQ delivers best performance when queues are small or empty (empty because messages are immediately consumed).</p>
<p>Our requirements dictated that if we suffer a consumer slowdown, the publishing should continue unaffected, even at the target peak load of 30k msg/s.</p>
<p>In this test the processing time per message varies:</p>
<ul>
<li>5 minutes at 10ms</li>
<li>Grows from 10ms to 30ms over a 20 minute period</li>
<li>5 minutes at 30ms</li>
<li>Reduces from 30ms to 10ms over a 20 minute period</li>
<li>50 minutes at 10ms</li>
</ul>
<p>The message backlogs can grow into the tens of millions as this is a high traffic system where backlogs can form fast. We shall see an S shape to the consume rate as first the processing time increases, then decreases and consume rate then exceeds the publish rate as the consumers process the backlog.</p>
<p>As the consume rate recovers but the queue length is still very large, this is when we might see impact on the publishers. The publish rate can drop for a period until the backlog is cleared. The higher performing clusters should see no impact or an impact for a short duration.</p>
<p>We&#x27;ll run the test at three different publish rates:</p>
<ul>
<li>10k msg/s with 200 consumers across the 100 queues. Top consume rate is 20k msg/s which then drops to 6.6k msg/s at the 30ms processing time.</li>
<li>20k msg/s with 300 consumers across the 100 queues. Top consume rate is  30k msg/s which then drops to 10k msg/s at the 30ms processing time.</li>
<li>30k msg/s with 400 consumers across the 100 queues. Top consume rate is  40k msg/s which then drops to 13.3k msg/s at the 30ms processing time.</li>
</ul>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 3. Consumer slowdown test at publish rates 10k msg/s, 20k msg/s and 30k msg/s." src="/rabbitmq-website/assets/images/consumer-slowdown-all-mirrored-e1884e68a67c00d1ea93d2924528215b.png" width="912" height="716" class="img_ev3q"><figcaption>Fig 3. Consumer slowdown test at publish rates 10k msg/s, 20k msg/s and 30k msg/s.</figcaption></figure><p></p>
<p>See some examples of how large the queue backlogs became.</p>
<p><strong>3x16 Cluster</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 4. Queue backlog size for the 3x36 cluster" src="/rabbitmq-website/assets/images/consumer-slowdown-3x36-backlog-70a689a2120185056b9266cb2536256f.png" width="909" height="192" class="img_ev3q"><figcaption>Fig 4. Queue backlog size for the 3x36 cluster</figcaption></figure><p></p>
<p><strong>7x16 Cluster</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 5. Queue backlog size for the 7x16 cluster" src="/rabbitmq-website/assets/images/consumer-slowdown-7x16-backlog-3ae8cdcaeaeaa77d2ae2d14cfc08c9f5.png" width="908" height="195" class="img_ev3q"><figcaption>Fig 5. Queue backlog size for the 7x16 cluster</figcaption></figure><p></p>
<p>The queue backlogs grow quite large, but even so, we only reach up to 50% of our maximum memory limit of 11GB. We&#x27;re using the default memory high watermark of 40% of server memory.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 7. Memory usage and memory high watermark for the 7x16 cluster." src="/rabbitmq-website/assets/images/consumer-slowdown-7x16-memory-1-460e14be94d34fec5f4ea95521a663f1.png" width="907" height="352" class="img_ev3q"><figcaption>Fig 7. Memory usage and memory high watermark for the 7x16 cluster.</figcaption></figure><p></p>
<p><strong>9x8 Cluster</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 6. Queue backlog size for the 9x8 cluster" src="/rabbitmq-website/assets/images/consumer-slowdown-9x8-backlog-dc5fc603b7f47196664ae5a32ee0e643.png" width="912" height="194" class="img_ev3q"><figcaption>Fig 6. Queue backlog size for the 9x8 cluster</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 8. Memory usage and memory high watermark for the 9x8 cluster." src="/rabbitmq-website/assets/images/consumer-slowdown-9x8-memory-cd5cbd41a38d1686600b5165c65cc272.png" width="908" height="352" class="img_ev3q"><figcaption>Fig 8. Memory usage and memory high watermark for the 9x8 cluster.</figcaption></figure><p></p>
<p>The smaller 8 vCPU instances have half the memory available with the high watermark at 6GB, but still these tests only use about half of that.</p>
<p>At 10k msg/s, all clusters handle the consumer slowdown and associated backlogs.</p>
<p>At 20k msg/s only the 7x16 and 9x8 clusters handle it without the publish rate dropping. The 7x8 is very close to handling it. The rest see a drop in publish rate as there is contention between consumers and publishers while the queue backlog is still high. Long queues are less efficient, both due to increase disk usage but also in-memory data structures. Note that this is our expected peak load, but we want to size for above that just in case (at 30k msg/s).</p>
<p>But at 30k msg/s none of our clusters were able to handle 30k msg/s sustained throughout the consumer slowdown. The best were the 7x16 and 9x8 clusters that had a reduced publish rate for around 20-25 minutes.</p>
<p>So either we decide that this is good enough or we need to go even bigger with either a 9x16 or an 11x8 cluster.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 9. The 30k msg/s test with 9x16 and 11x8 clusters." src="/rabbitmq-website/assets/images/consumer-slowdown-vlarge-mirrored-0725737149f47703c0d96df574757c86.png" width="910" height="394" class="img_ev3q"><figcaption>Fig 9. The 30k msg/s test with 9x16 and 11x8 clusters.</figcaption></figure><p></p>
<p>The 9x16 cluster handles the 30k msg/s load though with a slightly choppy publish rate. For the 8 vCPU instances, it looks like we would need to go up to 13 instances or more instances. These are large clusters, but this is also a very demanding workload.</p>
<p>You can run a test like with PerfTest (from version 2.12 and up):</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bin/runjava com.rabbitmq.perf.PerfTest \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-z 1800 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-f persistent \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-q 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-c 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ct -1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--rate 100 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--size 1024 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern &#x27;perf-test-%d&#x27; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-from 1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-to 100 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producer-random-start-delay 30 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 10000:300 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 11000:60 -vl 12000:60 -vl 13000:60 -vl 14000:60 -vl 15000:60 -vl 16000:60 -vl 17000:60 -vl 18000:60 -vl 19000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 20000:60 -vl 21000:60 -vl 22000:60 -vl 23000:60 -vl 24000:60 -vl 25000:60 -vl 26000:60 -vl 27000:60 -vl 28000:60 -vl 29000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 30000:300 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 29000:60 -vl 28000:60 -vl 27000:60 -vl 26000:60 -vl 25000:60 -vl 24000:60 -vl 23000:60 -vl 22000:60 -vl 21000:60 -vl 20000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 19000:60 -vl 18000:60 -vl 17000:60 -vl 16000:60 -vl 15000:60 -vl 14000:60 -vl 13000:60 -vl 12000:60 -vl 11000:60 -vl 10000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 10000:3000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions---publish-rate-peak-exceeds-consumer-capacity">Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity<a href="#adverse-conditions---publish-rate-peak-exceeds-consumer-capacity" class="hash-link" aria-label="Direct link to Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity" title="Direct link to Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity">​</a></h2>
<p>Like the consumer slowdown, we end up with a situation where the publish rate exceeds the consume rate causing message backlogs. But this time caused by a large peak in the publish rate, one that our backend systems are unable to handle. Absorbing peaks in the publish rate is one of the reasons to choose a message queue. You don&#x27;t need to scale-out your backend systems to handle peak load, which might be expensive, instead you allow the message queue to absorb the extra traffic instead. Then you process the backlog over a time period.</p>
<p>In this test we keep the processing time at 10ms but increase the publish rate then decrease it:</p>
<ul>
<li>5 minutes at base rate</li>
<li>Grows from base rate to peak over a 20 minute period</li>
<li>5 minutes at peak.</li>
<li>Reduces from peak to base rate over a 20 minute period</li>
<li>50 minutes at base</li>
</ul>
<p>We&#x27;ll run three tests:</p>
<ul>
<li>10 k msg/s base publish rate, 20k msg/s peak. 200 consumers with 13k msg/s top consume rate.</li>
<li>20 k msg/s base publish rate, 30k msg/s peak. 300 consumers with 23k msg/s top consume rate.</li>
<li>30 k msg/s base publish rate, 40k msg/s peak. 400 consumers with 33k msg/s top consume rate.</li>
</ul>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 10. 10k msg/s base rate, 20k msg/s peak with up to 7k msg/s consumer rate deficit." src="/rabbitmq-website/assets/images/publish-peak-all-10k-08d0423712167d05a94634ef293b1169.png" width="914" height="392" class="img_ev3q"><figcaption>Fig 10. 10k msg/s base rate, 20k msg/s peak with up to 7k msg/s consumer rate deficit.</figcaption></figure><p></p>
<p>The 7x16, 9x8, 7x8 clusters handle the peak, with the 5x8 mostly handling it with a couple of momentary drops in publish rate. The other clusters got close but were not able to handle the target rate.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 11. 20k msg/s base rate, 30k msg/s peak with up to 7k msg/s consumer rate deficit." src="/rabbitmq-website/assets/images/publish-peak-all-20k-dd4fb4721a3d38416501a95619e39434.png" width="911" height="391" class="img_ev3q"><figcaption>Fig 11. 20k msg/s base rate, 30k msg/s peak with up to 7k msg/s consumer rate deficit.</figcaption></figure><p></p>
<p>Only the 7x16 and 9x8 clusters could handle it, but the 5 node clusters were close.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 12. 30k msg/s base rate, 40k msg/s peak with up to 7k msg/s consumer rate deficit." src="/rabbitmq-website/assets/images/publish-peak-all-30k-2292ddad7d2d5ef91a1559cff087fbb4.png" width="913" height="391" class="img_ev3q"><figcaption>Fig 12. 30k msg/s base rate, 40k msg/s peak with up to 7k msg/s consumer rate deficit.</figcaption></figure><p></p>
<p>Only the 7x16 cluster reached the 40k msg/s publish rate but the 9x8 was close. The 7x16 saw its message backlog reach close to 7 million messages but it still handled it.</p>
<p><img decoding="async" loading="lazy" src="/rabbitmq-website/assets/images/publish-peak-7x16-30k-backlog-5dd10c2f2bec623d914ae38d19f2242c.png" width="910" height="195" class="img_ev3q"></p>
<p>You can run a test like with PerfTest:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bin/runjava com.rabbitmq.perf.PerfTest \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-z 1800 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-f persistent \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-q 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ct -1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-c 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--size 1024 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern &#x27;perf-test-%d&#x27; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-from 1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-to 100 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producer-random-start-delay 30 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumer-latency 10000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 100:300 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 102:60 -vr 104:60 -vr 106:60 -vr 108:60 -vr 110:60 -vr 112:60 -vr 114:60 -vr 116:60 -vr 118:60 -vr 120:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 122:60 -vr 124:60 -vr 126:60 -vr 128:60 -vr 130:60 -vr 132:60 -vr 134:60 -vr 136:60 -vr 138:60 -vr 140:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 142:60 -vr 144:60 -vr 146:60 -vr 148:60 -vr 150:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 148:60 -vr 146:60 -vr 144:60 -vr 142:60 -vr 140:60 -vr 138:60 -vr 136:60 -vr 134:60 -vr 132:60 -vr 130:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 128:60 -vr 126:60 -vr 124:60 -vr 122:60 -vr 120:60 -vr 118:60 -vr 116:60 -vr 114:60 -vr 112:60 -vr 110:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 108:60 -vr 106:60 -vr 104:60 -vr 102:60 -vr 100:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 100:3000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions-test-conclusions">Adverse Conditions Test Conclusions<a href="#adverse-conditions-test-conclusions" class="hash-link" aria-label="Direct link to Adverse Conditions Test Conclusions" title="Direct link to Adverse Conditions Test Conclusions">​</a></h2>
<p>After performing the happy scenario tests, we had many clusters that could handle the peak load so we ended up a top 5 leaderboard of clusters in terms of cost per 1000 msgs/s per month. Now after running the adverse conditions tests we&#x27;re down to two potentials from the original set:</p>
<ul>
<li>Cluster: 7 nodes, 16 vCPUs, gp2 SSD. Cost: $104 per 1000 msg/s</li>
<li>Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $81 per 1000 msg/s</li>
</ul>
<p>Scaling out the smaller VMs gave us the best top throughput and cost effectiveness in the happy scenario. But the 7x16 was the best all-rounder when taking into account the resiliency tests.</p>
<p>Of course even the 7x16 cluster struggled with the 30k msg/s consumer slowdown test. So we might still need to consider the clusters:</p>
<ul>
<li>Cluster: 9 nodes, 16 vCPUs, gp2 SSD. Cost: $133 per 1000 msg/s</li>
<li>Cluster: 11 nodes, 8 vCPUs, gp2 SSD. Cost: $99 per 1000 msg/s</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mirrored-queue-case-study-takeaways">Mirrored queue case study takeaways<a href="#mirrored-queue-case-study-takeaways" class="hash-link" aria-label="Direct link to Mirrored queue case study takeaways" title="Direct link to Mirrored queue case study takeaways">​</a></h2>
<p>Beware of only testing simple scenarios like our first happy scenario test where the publish rate is constant and the consume rate is fixed - you are only sizing RabbitMQ in ideal conditions. If you need RabbitMQ to deliver a certain throughput, even in the face of adversity then you need to include tests like the ones we&#x27;ve run in this post. You are more likely to see adverse scenarios when under heavier loads. Queue backlogs caused by slow consumers are more likely to occur when the wider system is under heavy load. Likewise, it can be peaks in traffic that causes the publish rate to exceed the consume rate. So testing at and beyond peak conditions is important to ensure that a cluster is resilient to your expected load.</p>
<p>The bottom line is that RabbitMQ can handle broker loss pretty well, what it struggles with more are queue backlogs. Our top clusters, the 7x16 and 9x8 configurations hit 65-70k msg/s in ideal conditions but only 20k msg/s in the most adverse conditions we threw at it. I say only 20k msg/s, but that is 1.7 billion daily messages which is higher than most use cases for RabbitMQ.</p>
<p>Finally...this was a specific workload, check out the other recommendations in the <a href="/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations">first post</a> that can apply to other workloads and scenarios.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/performance">Performance</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/capacity-planning">Capacity Planning</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-20-cluster-sizing-case-study-mirrored-queues-part-2/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Cluster Sizing Case Study – Quorum Queues Part 1</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Cluster Sizing Case Study - Mirrored Queues Part 1</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#adverse-conditions--coping-with-rolling-restarts-and-lost-brokers" class="table-of-contents__link toc-highlight">Adverse Conditions - Coping with rolling restarts and lost brokers</a></li><li><a href="#adverse-conditions--consumer-slowdown" class="table-of-contents__link toc-highlight">Adverse Conditions - Consumer Slowdown</a></li><li><a href="#adverse-conditions---publish-rate-peak-exceeds-consumer-capacity" class="table-of-contents__link toc-highlight">Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity</a></li><li><a href="#adverse-conditions-test-conclusions" class="table-of-contents__link toc-highlight">Adverse Conditions Test Conclusions</a></li><li><a href="#mirrored-queue-case-study-takeaways" class="table-of-contents__link toc-highlight">Mirrored queue case study takeaways</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn about RabbitMQ</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/tutorials">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/docs">Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Reach out to the RabbitMQ team</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/rabbitmq" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/rabbitmq/rabbitmq-server/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact?utm_source=rmq_release-information_tableheader&amp;utm_medium=rmq_website&amp;utm_campaign=tanzu">Long Term Commercial Support</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact">Contact Us</a></li><li class="footer__item"><a href="https://www.rabbitmq.com/discord" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Broadcom</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://tanzu.vmware.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">VMware Tanzu<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/legal.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms of Use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/trademark-guidelines">Trademark Guidelines</a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy/california-privacy-rights.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Your California Privacy Rights<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item ot-sdk-show-settings">Cookie Settings</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2005-2025 Broadcom. All Rights Reserved. The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.</div></div></div></footer></div>
</body>
</html>
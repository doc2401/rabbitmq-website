<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Cluster Sizing Case Study – Quorum Queues Part 2 | RabbitMQ</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" name="twitter:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" property="og:url" content="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Cluster Sizing Case Study – Quorum Queues Part 2 | RabbitMQ"><meta data-rh="true" name="description" content="In the last post we started a sizing analysis of our workload using quorum queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month."><meta data-rh="true" property="og:description" content="In the last post we started a sizing analysis of our workload using quorum queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-06-22T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Performance,Capacity Planning"><link data-rh="true" rel="icon" href="/rabbitmq-website/img/rabbitmq-logo.svg"><link data-rh="true" rel="canonical" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://H10VQIW16Y-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","mainEntityOfPage":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","url":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","headline":"Cluster Sizing Case Study – Quorum Queues Part 2","name":"Cluster Sizing Case Study – Quorum Queues Part 2","description":"In the last post we started a sizing analysis of our workload using quorum queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.","datePublished":"2020-06-22T00:00:00.000Z","author":{"@type":"Person","name":"Jack Vanlightly"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://www.rabbitmq.com/rabbitmq-website/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/rabbitmq-website/blog/rss.xml" title="RabbitMQ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/rabbitmq-website/blog/atom.xml" title="RabbitMQ Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="RabbitMQ" href="/rabbitmq-website/opensearch.xml">







<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-domain-script="018ee308-473e-754f-b0c2-cbe82d25512f"></script>
<script>function OptanonWrapper(){}</script>
<script>function setGTM(e,t,o,n,r){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var i=t.getElementsByTagName(o)[0],a=t.createElement(o),s="dataLayer"!=n?"&l="+n:"";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+r+s,i.parentNode.insertBefore(a,i)}var timer;function waitForOnetrustActiveGroups(){document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?(clearTimeout(timer),setGTM(window,document,"script","dataLayer","GTM-TT84L8K")):timer=setTimeout(waitForOnetrustActiveGroups,250)}document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?setGTM(window,document,"script","dataLayer","GTM-TT84L8K"):waitForOnetrustActiveGroups()</script><link rel="stylesheet" href="/rabbitmq-website/styles.css">
<script src="/rabbitmq-website/runtime~main.js" defer="defer"></script>
<script src="/rabbitmq-website/main.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:var(--ifm-color-primary-contrast-background);color:var(--ifm-font-color-base)" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><strong style="font-size: var(--ifm-h4-font-size);"><a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0">RabbitMQ 4.1.0 is out</a></strong></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/rabbitmq-website/"><div class="navbar__logo"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/rabbitmq-website/tutorials">Getting Started</a><a class="navbar__item navbar__link" href="/rabbitmq-website/docs">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rabbitmq-website/blog">Blog</a><a class="navbar__item navbar__link" href="/rabbitmq-website/contact">Support</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/rabbitmq-website/docs">4.1</a><ul class="dropdown__menu"><li class=""><strong>Release series</strong></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/next">Next</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs">4.1</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/4.0">4.0</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/3.13">3.13</a></li><li><a href="https://v3-12.rabbitmq.com/documentation.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">3.12<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/rabbitmq-website/release-information">Release Information</a></li></ul></div><a href="https://github.com/rabbitmq/rabbitmq-website" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article class=""><header><h1 class="title_f1Hy">Cluster Sizing Case Study – Quorum Queues Part 2</h1><div class="container_mt6G margin-vert--md"><time datetime="2020-06-22T00:00:00.000Z">June 22, 2020</time> · <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><span class="authorName_yefp">Jack Vanlightly</span></div><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>In the <a href="/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1">last post</a> we started a sizing analysis of our <a href="/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations">workload</a> using quorum queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.</p>
<ol>
<li>Cluster: 7 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $54</li>
<li>Cluster: 9 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $69</li>
<li>Cluster: 5 nodes, 8 vCPUs (c5.2xlarge), st1 HDD. Cost: $93</li>
<li>Cluster: 5 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $98</li>
<li>Cluster: 7 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $107</li>
</ol>
<p>There are more tests to run to ensure these clusters can handle things like brokers failing and large backlogs accumulating during things like outages or system slowdowns.</p>
<p>All quorum queues are declared with the following properties:</p>
<ul>
<li>x-quorum-initial-group-size=3</li>
<li>x-max-in-memory-length=0</li>
</ul>
<p>The <em>x-max-in-memory-length</em> property forces the quorum queue to remove message bodies from memory as soon as it is safe to do. You can set it to a longer limit, this is the most aggressive - designed to avoid large memory growth at the cost of more disk reads when consumers do not keep up. Without this property message bodies are kept in memory at all times which can place memory growth to the point of memory alarms setting off which severely impacts the publish rate - something we want to avoid in this workload case study.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions--coping-with-rolling-restarts-and-lost-brokers">Adverse Conditions - Coping with rolling restarts and lost brokers<a href="#adverse-conditions--coping-with-rolling-restarts-and-lost-brokers" class="hash-link" aria-label="Direct link to Adverse Conditions - Coping with rolling restarts and lost brokers" title="Direct link to Adverse Conditions - Coping with rolling restarts and lost brokers">​</a></h2>
<p>We are using quorum queues because we care about our data and availability. If we lose a broker due to a disk failure, or because we had to reboot as part of an emergency OS patch, then we get continued availability and no data loss, but can we maintain our target peak rate of 30k msg/s? Resiliency isn&#x27;t just about not losing data and remaining available, it&#x27;s about handling the load adequately as well.</p>
<p>To that end, we run exactly the same test again, but hard kill a broker part way into each intensity level.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 1. One broker killed during each test" src="/rabbitmq-website/assets/images/qq-lost-broker-4f4bae6e7564bd74293c9d159a1a86d4.png" width="906" height="710" class="img_ev3q"><figcaption>Fig 1. One broker killed during each test</figcaption></figure><p></p>
<p>In the same test with mirrored queues (with one master, one mirror) we saw a drop-off in throughput when a broker was killed off. With quorum queues we don’t see such a strong effect.</p>
<p>Let’s look at our 30k msg/s target rate period.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 2. 30k msg/s lost broker test" src="/rabbitmq-website/assets/images/qq-lost-broker-30k-3080baf91fd75b489ccceb83a21b0757.png" width="910" height="391" class="img_ev3q"><figcaption>Fig 2. 30k msg/s lost broker test</figcaption></figure><p></p>
<p>The reason why we saw the large impact of losing a broker with mirrored queues is that mirrored queues try to maintain the redundancy level by creating a new mirror on another broker when a master or mirror is lost. This concentrates the same amount of message traffic on fewer servers. Quorum queues do not do this. If a broker is lost that hosts a queue replica, then the membership of that queue does not change. As long as the majority of queue replicas (leader, followers) are available the queue continues to function. As soon as the broker comes back online, its follower replica on that broker will start getting replicated to again.</p>
<p>So replication traffic does not get concentrated on fewer servers, only the client traffic does. Quorum queues also benefit from the fact that if a consumer happens to connect to a broker that hosts a follower replica of the queue they want to consume, then they read directly from that replica - no proxying of messages from the broker that hosts the leader to the broker that the consumer is connected to.</p>
<p>The fact that mirrored queues try to maintain the redundancy level by creating new mirrors is undermined by the fact that synchronisation is blocking. So many admins use manual synchronisation to avoid a huge traffic spike between the remaining brokers as new mirrors get replicated to.</p>
<p>The largest clusters (7x16, 7x8 and 9x8) saw no noticeable impact of losing the broker. The fail-overs to new leaders was fast and throughput carried on as before.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions--consumer-slowdown">Adverse Conditions - Consumer Slowdown<a href="#adverse-conditions--consumer-slowdown" class="hash-link" aria-label="Direct link to Adverse Conditions - Consumer Slowdown" title="Direct link to Adverse Conditions - Consumer Slowdown">​</a></h2>
<p>When processing messages, consumers normally need to interact with other systems like databases or third party APIs. These downstream systems can slowdown due heavy load, or some kind of outage and this has the knock-on effect of slowing down your consumers. This then causes the number of messages in your queues to grow which can then also impact publishers. RabbitMQ delivers best performance when queues are small or empty (empty because messages are immediately consumed).</p>
<p>Our requirements dictated that if we suffer a consumer slowdown, the publishing should continue unaffected, even at the target peak load of 30k msg/s.</p>
<p>In this test the processing time per message varies:</p>
<ul>
<li>5 minutes at 10ms</li>
<li>Grows from 10ms to 30ms over a 20 minute period</li>
<li>5 minutes at 30ms</li>
<li>Reduces from 30ms to 10ms over a 20 minute period</li>
<li>50 minutes at 10ms</li>
</ul>
<p>The message backlogs can grow into the tens of millions as this is a high traffic system where backlogs can form fast. We shall see an S shape to the consume rate as first the processing time increases, then decreases and consume rate then exceeds the publish rate as the consumers process the backlog.</p>
<p>As the consume rate recovers but the queue length is still very large, this is when we might see impact on the publishers. The publish rate can drop for a period until the backlog is cleared. The higher performing clusters should see no impact or an impact for a short duration.</p>
<p>We&#x27;ll run the test at three different publish rates:</p>
<ul>
<li>10k msg/s with 200 consumers across the 100 queues. Top consume rate is 20k msg/s which then drops to 6.6k msg/s at the 30ms processing time.</li>
<li>20k msg/s with 300 consumers across the 100 queues. Top consume rate is  30k msg/s which then drops to 10k msg/s at the 30ms processing time.</li>
<li>30k msg/s with 400 consumers across the 100 queues. Top consume rate is  40k msg/s which then drops to 13.3k msg/s at the 30ms processing time.</li>
</ul>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 3. Consumer slowdown test at publish rates 10k msg/s, 20k msg/s and 30k msg/s and quorum queues." src="/rabbitmq-website/assets/images/qq-consumer-slowdown-all-eeb864a9e3e5f88ff7b1de6c3c2572eb.png" width="911" height="711" class="img_ev3q"><figcaption>Fig 3. Consumer slowdown test at publish rates 10k msg/s, 20k msg/s and 30k msg/s and quorum queues.</figcaption></figure><p></p>
<p>The first thing to notice is how much better quorum queues fared than mirrored queues. With mirrored queues, no clusters managed to maintain the 30k msg/s publish rate in this test, but with quorum queues the 7x16 cluster just managed to handle it.</p>
<p>See some examples of how large the queue backlogs became.</p>
<p><strong>3x16 Cluster</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 4. Queue backlog size for the 3x36 cluster with quorum queues" src="/rabbitmq-website/assets/images/qq-consumer-slowdown-3x36-backlog-7118256d578bdf1fc40fc199bd175d11.png" width="908" height="192" class="img_ev3q"><figcaption>Fig 4. Queue backlog size for the 3x36 cluster with quorum queues</figcaption></figure><p></p>
<p><strong>7x16 Cluster</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 5. Queue backlog size for the 7x16 cluster with quorum queues" src="/rabbitmq-website/assets/images/qq-consumer-slowdown-7x16-backlog-8f21d7e00cbbe5e3d4204da44cea751d.png" width="910" height="190" class="img_ev3q"><figcaption>Fig 5. Queue backlog size for the 7x16 cluster with quorum queues</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 6. Memory usage and memory high watermark for the 7x16 cluster with quorum queues." src="/rabbitmq-website/assets/images/qq-consumer-slowdown-7x16-memory-a277029e3491d67f97d5d3868759bb06.png" width="906" height="350" class="img_ev3q"><figcaption>Fig 6. Memory usage and memory high watermark for the 7x16 cluster with quorum queues.</figcaption></figure><p></p>
<p><strong>9x8 Cluster</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 7. Queue backlog size for the 9x8 cluster with quorum queues" src="/rabbitmq-website/assets/images/qq-consumer-slowdown-9x8-backlog-d514b4cbee52147e66b605332a97aac2.png" width="911" height="193" class="img_ev3q"><figcaption>Fig 7. Queue backlog size for the 9x8 cluster with quorum queues</figcaption></figure><p></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 8. Memory usage and memory high watermark for the 9x8 cluster with quorum queues." src="/rabbitmq-website/assets/images/qq-consumer-slowdown-9x8-memory-792240647c323e0c54d47be8ea7decbc.png" width="907" height="351" class="img_ev3q"><figcaption>Fig 8. Memory usage and memory high watermark for the 9x8 cluster with quorum queues.</figcaption></figure><p></p>
<p>Despite the queue backlogs across the 100 queues reaching as high as 25 million, memory usage stays well below the high watermark (which is when memory alarms would block the publishers).</p>
<p>All clusters handled this test at 10k msg/s. At 20k msg/s only two clusters handled it (7x16 and 9x8). The 7x16 cluster is the clear winner in this test as it managed to handle the very stressful 30k msg/s test which created backlogs of up to 25 million messages.</p>
<p>You can run a test like with PerfTest (from version 2.12 and up):</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bin/runjava com.rabbitmq.perf.PerfTest \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-z 1800 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-f persistent \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-q 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-c 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ct -1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ad false \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--rate 100 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--size 1024 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern &#x27;perf-test-%d&#x27; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-from 1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-to 100 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-qa auto-delete=false,durable=false,x-queue-type=quorum \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producer-random-start-delay 30 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 10000:300 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 11000:60 -vl 12000:60 -vl 13000:60 -vl 14000:60 -vl 15000:60 -vl 16000:60 -vl 17000:60 -vl 18000:60 -vl 19000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 20000:60 -vl 21000:60 -vl 22000:60 -vl 23000:60 -vl 24000:60 -vl 25000:60 -vl 26000:60 -vl 27000:60 -vl 28000:60 -vl 29000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 30000:300 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 29000:60 -vl 28000:60 -vl 27000:60 -vl 26000:60 -vl 25000:60 -vl 24000:60 -vl 23000:60 -vl 22000:60 -vl 21000:60 -vl 20000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 19000:60 -vl 18000:60 -vl 17000:60 -vl 16000:60 -vl 15000:60 -vl 14000:60 -vl 13000:60 -vl 12000:60 -vl 11000:60 -vl 10000:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vl 10000:3000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions---publish-rate-peak-exceeds-consumer-capacity">Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity<a href="#adverse-conditions---publish-rate-peak-exceeds-consumer-capacity" class="hash-link" aria-label="Direct link to Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity" title="Direct link to Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity">​</a></h2>
<p>Like the consumer slowdown, we end up with a situation where the publish rate exceeds the consume rate causing message backlogs. But this time caused by a large peak in the publish rate, one that our backend systems are unable to handle. Absorbing peaks in the publish rate is one of the reasons to choose a message queue. You don&#x27;t need to scale-out your backend systems to handle peak load, which might be expensive, instead you allow the message queue to absorb the extra traffic instead. Then you process the backlog over a time period.</p>
<p>In this test we keep the processing time at 10ms but increase the publish rate then decrease it:</p>
<ul>
<li>5 minutes at base rate</li>
<li>Grows from base rate to peak over a 20 minute period</li>
<li>5 minutes at peak.</li>
<li>Reduces from peak to base rate over a 20 minute period</li>
<li>50 minutes at base</li>
</ul>
<p>We&#x27;ll run three tests:</p>
<ul>
<li>10 k msg/s base publish rate, 20k msg/s peak. 200 consumers with 13k msg/s top consume rate.</li>
<li>20 k msg/s base publish rate, 30k msg/s peak. 300 consumers with 23k msg/s top consume rate.</li>
<li>30 k msg/s base publish rate, 40k msg/s peak. 400 consumers with 33k msg/s top consume rate.</li>
</ul>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 9. 10k msg/s base rate, 20k msg/s peak with up to 7k msg/s consumer rate deficit." src="/rabbitmq-website/assets/images/qq-publish-peak-all-10k-3026a0ef430a2e064eb162c7a987e2d0.png" width="912" height="389" class="img_ev3q"><figcaption>Fig 9. 10k msg/s base rate, 20k msg/s peak with up to 7k msg/s consumer rate deficit.</figcaption></figure><p></p>
<p>All the clusters managed to reach the 20k msg/s publish rate peak except for the 3x16 and 5x8 clusters.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 10. 20k msg/s base rate, 30k msg/s peak with up to 7k msg/s consumer rate deficit." src="/rabbitmq-website/assets/images/qq-publish-peak-all-20k-e4dffc4050c59da36adc9c3db6258b64.png" width="911" height="391" class="img_ev3q"><figcaption>Fig 10. 20k msg/s base rate, 30k msg/s peak with up to 7k msg/s consumer rate deficit.</figcaption></figure><p></p>
<p>Only the larger 5x16, 7x18 and 9x8 clusters manage to hit the 30k msg/s peak.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 11. 30k msg/s base rate, 40k msg/s peak with up to 7k msg/s consumer rate deficit." src="/rabbitmq-website/assets/images/qq-publish-peak-all-30k-1-ff5e7e137578b11826f8ebeb7f8b50e3.png" width="910" height="388" class="img_ev3q"><figcaption>Fig 11. 30k msg/s base rate, 40k msg/s peak with up to 7k msg/s consumer rate deficit.</figcaption></figure><p></p>
<p>The 7x16 cluster barely managed to hit the 40k msg/s peak and saw its message backlog reach close to 6 million messages but it still handled it.</p>
<p><img decoding="async" loading="lazy" src="/rabbitmq-website/assets/images/qq-publish-peak-30k-7x16-backlog-005f7de67ed152d4f707a28eac08056f.png" width="907" height="190" class="img_ev3q"></p>
<p>You can run a test like with PerfTest:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bin/runjava com.rabbitmq.perf.PerfTest \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-z 1800 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-f persistent \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-q 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ct -1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-ad false \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-c 1000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--size 1024 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern &#x27;perf-test-%d&#x27; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-from 1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--queue-pattern-to 100 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-qa auto-delete=false,durable=false,x-queue-type=quorum \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumers 200 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--producer-random-start-delay 30 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--consumer-latency 10000 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 100:300 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 102:60 -vr 104:60 -vr 106:60 -vr 108:60 -vr 110:60 -vr 112:60 -vr 114:60 -vr 116:60 -vr 118:60 -vr 120:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 122:60 -vr 124:60 -vr 126:60 -vr 128:60 -vr 130:60 -vr 132:60 -vr 134:60 -vr 136:60 -vr 138:60 -vr 140:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 142:60 -vr 144:60 -vr 146:60 -vr 148:60 -vr 150:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 148:60 -vr 146:60 -vr 144:60 -vr 142:60 -vr 140:60 -vr 138:60 -vr 136:60 -vr 134:60 -vr 132:60 -vr 130:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 128:60 -vr 126:60 -vr 124:60 -vr 122:60 -vr 120:60 -vr 118:60 -vr 116:60 -vr 114:60 -vr 112:60 -vr 110:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 108:60 -vr 106:60 -vr 104:60 -vr 102:60 -vr 100:60 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-vr 100:3000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions-tests---conclusions">Adverse Conditions Tests - Conclusions<a href="#adverse-conditions-tests---conclusions" class="hash-link" aria-label="Direct link to Adverse Conditions Tests - Conclusions" title="Direct link to Adverse Conditions Tests - Conclusions">​</a></h2>
<p>After performing the ideal conditions tests, we had many clusters that could handle the peak load so we ended up a top 5 leaderboard of clusters in terms of cost per 1000 msgs/s per month. Now after running the adverse conditions tests we&#x27;re down to two potentials from the original set. The 7x16 was the only cluster to handle all tests but if you are also sensitive to cost then the cheaper 9x8 was close to passing the backlog tests.</p>
<ul>
<li>Cluster: 7 nodes, 16 vCPUs, gp2 SSD. Cost: $104 per 1000 msg/s</li>
<li>Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $81 per 1000 msg/s</li>
</ul>
<p>Scaling out the smaller VMs gave us the best top throughput and cost effectiveness in the ideal conditions. But the 7x16 was the best all-rounder when taking into account the adverse conditions.</p>
<p>For this workload I would choose quorum queues (with gp2 volumes) over mirrored queues based on their superior ability to continue to handle the ingress rate in the event of message backlogs. Of course there are other reasons to choose quorum queues on top of that:</p>
<ul>
<li>better data safety</li>
<li>higher availability when handling rolling restarts</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="quorum-queue-case-study-takeaways">Quorum Queue Case Study Takeaways<a href="#quorum-queue-case-study-takeaways" class="hash-link" aria-label="Direct link to Quorum Queue Case Study Takeaways" title="Direct link to Quorum Queue Case Study Takeaways">​</a></h2>
<p>The takeaways are the same as the mirrored queue case study: don&#x27;t just run tests under ideal conditions. Make sure you include adverse conditions tests into your methodology or you may find that your cluster cannot handle your workload when you need it most. Systems are more likely to suffer these kinds of issues when under heavy load, so test at your expected peak load levels and beyond.</p>
<p>The bottom line is that RabbitMQ can handle broker loss pretty well, what it struggles with more are queue backlogs. Our top clusters, the 7x16 and 9x8 configurations hit 65-70k msg/s in ideal conditions but only 20-30k msg/s in the most adverse conditions we threw at it. I say only 20-30k msg/s, but that is 1.7-2.5 billion daily messages which is higher than most use cases for RabbitMQ.</p>
<p>Finally...this was a specific workload, check out the other recommendations in the <a href="/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations">first post</a> that can apply to other workloads and scenarios.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/performance">Performance</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/capacity-planning">Capacity Planning</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-22-cluster-sizing-case-study-quorum-queues-part-2/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/rabbitmq-website/blog/2020/06/23/quorum-queues-local-delivery"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">How quorum queues deliver locally while still offering ordering guarantees</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Cluster Sizing Case Study – Quorum Queues Part 1</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#adverse-conditions--coping-with-rolling-restarts-and-lost-brokers" class="table-of-contents__link toc-highlight">Adverse Conditions - Coping with rolling restarts and lost brokers</a></li><li><a href="#adverse-conditions--consumer-slowdown" class="table-of-contents__link toc-highlight">Adverse Conditions - Consumer Slowdown</a></li><li><a href="#adverse-conditions---publish-rate-peak-exceeds-consumer-capacity" class="table-of-contents__link toc-highlight">Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity</a></li><li><a href="#adverse-conditions-tests---conclusions" class="table-of-contents__link toc-highlight">Adverse Conditions Tests - Conclusions</a></li><li><a href="#quorum-queue-case-study-takeaways" class="table-of-contents__link toc-highlight">Quorum Queue Case Study Takeaways</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn about RabbitMQ</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/tutorials">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/docs">Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Reach out to the RabbitMQ team</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/rabbitmq" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/rabbitmq/rabbitmq-server/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact?utm_source=rmq_release-information_tableheader&amp;utm_medium=rmq_website&amp;utm_campaign=tanzu">Long Term Commercial Support</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact">Contact Us</a></li><li class="footer__item"><a href="https://www.rabbitmq.com/discord" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Broadcom</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://tanzu.vmware.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">VMware Tanzu<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/legal.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms of Use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/trademark-guidelines">Trademark Guidelines</a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy/california-privacy-rights.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Your California Privacy Rights<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item ot-sdk-show-settings">Cookie Settings</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2005-2025 Broadcom. All Rights Reserved. The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.</div></div></div></footer></div>
</body>
</html>
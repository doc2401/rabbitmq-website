<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Cluster Sizing and Other Considerations | RabbitMQ</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" name="twitter:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" property="og:url" content="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Cluster Sizing and Other Considerations | RabbitMQ"><meta data-rh="true" name="description" content="This is the start of a short series where we look at sizing your RabbitMQ clusters. The actual sizing wholly depends on your hardware and workload, so rather than tell you how many CPUs and how much RAM you should provision, we’ll create some general guidelines and use a case study to show what things you should consider."><meta data-rh="true" property="og:description" content="This is the start of a short series where we look at sizing your RabbitMQ clusters. The actual sizing wholly depends on your hardware and workload, so rather than tell you how many CPUs and how much RAM you should provision, we’ll create some general guidelines and use a case study to show what things you should consider."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-06-18T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Performance,Capacity Planning"><link data-rh="true" rel="icon" href="/rabbitmq-website/img/rabbitmq-logo.svg"><link data-rh="true" rel="canonical" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://H10VQIW16Y-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations","mainEntityOfPage":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations","url":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations","headline":"Cluster Sizing and Other Considerations","name":"Cluster Sizing and Other Considerations","description":"This is the start of a short series where we look at sizing your RabbitMQ clusters. The actual sizing wholly depends on your hardware and workload, so rather than tell you how many CPUs and how much RAM you should provision, we’ll create some general guidelines and use a case study to show what things you should consider.","datePublished":"2020-06-18T00:00:00.000Z","author":{"@type":"Person","name":"Jack Vanlightly"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://www.rabbitmq.com/rabbitmq-website/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/rabbitmq-website/blog/rss.xml" title="RabbitMQ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/rabbitmq-website/blog/atom.xml" title="RabbitMQ Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="RabbitMQ" href="/rabbitmq-website/opensearch.xml">







<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-domain-script="018ee308-473e-754f-b0c2-cbe82d25512f"></script>
<script>function OptanonWrapper(){}</script>
<script>function setGTM(e,t,o,n,r){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var i=t.getElementsByTagName(o)[0],a=t.createElement(o),s="dataLayer"!=n?"&l="+n:"";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+r+s,i.parentNode.insertBefore(a,i)}var timer;function waitForOnetrustActiveGroups(){document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?(clearTimeout(timer),setGTM(window,document,"script","dataLayer","GTM-TT84L8K")):timer=setTimeout(waitForOnetrustActiveGroups,250)}document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?setGTM(window,document,"script","dataLayer","GTM-TT84L8K"):waitForOnetrustActiveGroups()</script><link rel="stylesheet" href="/rabbitmq-website/styles.css">
<script src="/rabbitmq-website/runtime~main.js" defer="defer"></script>
<script src="/rabbitmq-website/main.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:var(--ifm-color-primary-contrast-background);color:var(--ifm-font-color-base)" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><strong style="font-size: var(--ifm-h4-font-size);"><a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0">RabbitMQ 4.1.0 is out</a></strong></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/rabbitmq-website/"><div class="navbar__logo"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/rabbitmq-website/tutorials">Getting Started</a><a class="navbar__item navbar__link" href="/rabbitmq-website/docs">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rabbitmq-website/blog">Blog</a><a class="navbar__item navbar__link" href="/rabbitmq-website/contact">Support</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/rabbitmq-website/docs">4.1</a><ul class="dropdown__menu"><li class=""><strong>Release series</strong></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/next">Next</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs">4.1</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/4.0">4.0</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/3.13">3.13</a></li><li><a href="https://v3-12.rabbitmq.com/documentation.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">3.12<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/rabbitmq-website/release-information">Release Information</a></li></ul></div><a href="https://github.com/rabbitmq/rabbitmq-website" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article class=""><header><h1 class="title_f1Hy">Cluster Sizing and Other Considerations</h1><div class="container_mt6G margin-vert--md"><time datetime="2020-06-18T00:00:00.000Z">June 18, 2020</time> · <!-- -->17 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><span class="authorName_yefp">Jack Vanlightly</span></div><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>This is the start of a short series where we look at sizing your RabbitMQ clusters. The actual sizing wholly depends on your hardware and workload, so rather than tell you how many CPUs and how much RAM you should provision, we’ll create some general guidelines and use a case study to show what things you should consider.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="common-questions">Common Questions<a href="#common-questions" class="hash-link" aria-label="Direct link to Common Questions" title="Direct link to Common Questions">​</a></h2>
<p>What is the best combination of VM size and VM count for your RabbitMQ cluster? Should you scale up and go for three nodes with 32 CPU threads? Or should you scale out and go for 9 nodes with 8 CPU threads? What type of disk offers the best value for money? How much memory do you need? Which hardware configuration is better for throughput, latency, cost of ownership?</p>
<p>First of all, there is no single answer. If you run in the cloud then there are fewer options but if you run on-premise then the sheer number of virtualisation, storage and networking products and configurations out there makes this an impossible question.</p>
<p>While there is no single sizing guide with hard numbers, we can go through a sizing analysis and hopefully that will help you with your own sizing.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="some-common-considerations">Some common considerations<a href="#some-common-considerations" class="hash-link" aria-label="Direct link to Some common considerations" title="Direct link to Some common considerations">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-number-of-queues-and-clients">The number of queues and clients<a href="#the-number-of-queues-and-clients" class="hash-link" aria-label="Direct link to The number of queues and clients" title="Direct link to The number of queues and clients">​</a></h3>
<p>Client connections and queues require compute time and memory. If you have thousands of queues and clients, then that will affect your sizing. The more you have, the more CPU cores and memory you&#x27;re likely to need. Having few queues and clients is more efficient for RabbitMQ to handle - there is less CPU context switching and less memory overhead. So if you have a workload with thousands of queues and clients, then you&#x27;ll need larger VMs or more VMs for the same total throughput compared to if you only had a handful of each.</p>
<p>Various types of churn can impact a cluster:</p>
<ul>
<li>Connection churn (the opening and closing of connections)</li>
<li>Queue and queue binding churn (the creation and deletion queues and bindings)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-high-throughput">What is high throughput?<a href="#what-is-high-throughput" class="hash-link" aria-label="Direct link to What is high throughput?" title="Direct link to What is high throughput?">​</a></h3>
<p>A million messages a day might sound like a lot, but when you calculate that as a per-second rate, it&#x27;s just down to just under 12 messages per second. When you have throughput anywhere under a 100 per second you&#x27;ll likely be able to size your VMs very small. It is unlikely you&#x27;ll see a resource bottleneck unless you have thousands of queues and clients. If you use a cluster, at this rate it will be purely for redundancy rather than performance.</p>
<p>Once you get past 1000 messages a second (86 million a day or 2.5 billion per month), that&#x27;s when you need to spend more time on your sizing analysis. For 1000 messages a second you can still go pretty small, but there may be some resource bottlenecks.</p>
<p>Beyond 10000 (860 million per day or 25 billion per month), I recommend you be even more thorough with your sizing analysis. We say <em>a happy Rabbit is an empty Rabbit</em>. RabbitMQ provides the best throughput and lowest latency when queues are empty. Messages are served from memory, often not written to disk at all. When you have a large backlog, messages are very likely read/written to disk, data structures are larger and less efficient and inevitably the maximum throughput a cluster can handle drops. When you have a high throughput cluster, backlogs can go from nothing to millions fast, and so you need to make sure you size for that. Don&#x27;t just size for the happy case, but also the unhappy case. We&#x27;ll look at this in more detail later on.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-workloads-require-more-memory">What workloads require more memory?<a href="#what-workloads-require-more-memory" class="hash-link" aria-label="Direct link to What workloads require more memory?" title="Direct link to What workloads require more memory?">​</a></h3>
<p>Classic and classic mirrored queues will keep messages in memory but start evicting them when memory gets low. Its hard to predict because it is a dynamic behaviour. One good practice is to use lazy queues if you have very large queues because lazy queues evict from memory very early and typically use far less memory.</p>
<p>Quorum queues store all messages in memory at all times by default, even under low memory conditions. This means unless you change the defaults, you are more likely to hit the memory alarms (which blocks all publishers) when queues grow longer. The good news is this can be configured using a couple of queue properties (such as x-max-in-memory-length) which will only keep this configured number of messages in memory at a time. This should probably be set on all your quorum queues. It does mean that more messages are read from disk so it doesn&#x27;t come for free.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-does-redundancy-affect-sizing">How does redundancy affect sizing?<a href="#how-does-redundancy-affect-sizing" class="hash-link" aria-label="Direct link to How does redundancy affect sizing?" title="Direct link to How does redundancy affect sizing?">​</a></h3>
<p>If you use quorum queues or mirrored queues, then each message will be delivered to multiple brokers. If you have a cluster of three brokers and quorum queues with a replicator factor of 3, then every broker will receive every message. In that case, we&#x27;ve created a cluster for redundancy only. But we can also create larger clusters for scalability. We could have a cluster of 9 brokers, with quorum queues with a rep factor of 3 and now we&#x27;ve spread that load out and can handle a much larger total throughput.</p>
<p>Adding more redundancy will reduce total throughput, so to counteract that you can add more brokers to your cluster to spread the load.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-does-message-size-affect-sizing">How does message size affect sizing?<a href="#how-does-message-size-affect-sizing" class="hash-link" aria-label="Direct link to How does message size affect sizing?" title="Direct link to How does message size affect sizing?">​</a></h3>
<p>Small messages, say under 1kb, are unlikely to saturate network or disk. If you hit a resource bottleneck it will likely be CPU. But we can easily saturate network and disk with larger message sizes. If you have 1Mb messages and a 5gbit network, then with a classic queue, you&#x27;re going to saturate the network at just over 300 msg/s. If you use quorum or mirrored queues, it will be even lower as the messages must not only be received/sent to clients, but replicated between brokers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="do-you-plan-to-use-federation">Do you plan to use Federation?<a href="#do-you-plan-to-use-federation" class="hash-link" aria-label="Direct link to Do you plan to use Federation?" title="Direct link to Do you plan to use Federation?">​</a></h3>
<p>Federation involves running AMQP clients on the RabbitMQ brokers. That means they contend for the same resources as channels and queues. This may mean you need to increase the size/number of your VMs. Also take into account that:</p>
<ul>
<li>if you use mirrored queues for the local queues (that act as an outbox), then you&#x27;ll be replicating those outgoing messages across your cluster. Redundancy is expensive.</li>
<li>messages will be transmitted across the network to another broker, this adds to your network sizing.</li>
</ul>
<p>Always include the federation setup in your sizing tests.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="sizing---an-aws-case-study">Sizing - An AWS Case Study<a href="#sizing---an-aws-case-study" class="hash-link" aria-label="Direct link to Sizing - An AWS Case Study" title="Direct link to Sizing - An AWS Case Study">​</a></h2>
<p>We&#x27;ll go through a case study now which will involve identifying the workload, defining our requirements regarding end-to-end latency and resiliency and finally a suite of tests that will measure different VM sizes and numbers against those requirements.</p>
<p>Remember, this is a case study, so your own requirements and workload may be very different to this. It is also a detailed analysis suitable for when RabbitMQ is a critical part of your infrastructure and is worth the time investment in doing a thorough sizing analysis.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-case-study-workload">The Case Study Workload<a href="#the-case-study-workload" class="hash-link" aria-label="Direct link to The Case Study Workload" title="Direct link to The Case Study Workload">​</a></h3>
<p>For the purposes of our case study, I have chosen a medium sized, high intensity workload. That means we have a moderate number of queues and clients, but pushing a large number of messages through them.</p>
<ul>
<li>200 publishers</li>
<li>100 queues</li>
<li>200 consumers</li>
<li>No fanout - using the default exchange to do point-to-point</li>
<li>1kb message sizes</li>
<li>10 millisecond processing time per message</li>
<li>Java client</li>
<li>Constant rate</li>
</ul>
<p>We have relatively stable throughput of 5000 msg/s most of the time but peaks of up to 20,000 msg/s that can last anything up to an hour or two hours per day. We project that traffic is likely to increase by 10% over the next year.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="our-requirements">Our Requirements<a href="#our-requirements" class="hash-link" aria-label="Direct link to Our Requirements" title="Direct link to Our Requirements">​</a></h3>
<p>We want to size our cluster according to the peak throughput plus an additional 10,000 msg/s just in case of unexpectedly high traffic which will also cover the expected 10% growth. We don&#x27;t need to size according to our expected growth beyond that as we can easily upgrade EC2 instances in the future.</p>
<p>We want to use a replicated queue as these messages have monetary value for the business. So we’ll run a sizing analysis for mirrored and the newer quorum queues.</p>
<p>In terms of latency, we’re happy as long as we’re below 1 second at 99th percentile end-to-end (time between publish and consumption of a message).</p>
<p>Finally we want to make sure we can hit our throughput peak even under adverse conditions such as losing a broker or there is a downstream outage that affects consumer throughput. If a queue backlog grows because consumers are running slowly, we want to absorb the message ingress (maintaining the publish rate). Slowing down publishing has a monetary cost for us.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-tests">The Tests<a href="#the-tests" class="hash-link" aria-label="Direct link to The Tests" title="Direct link to The Tests">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ideal-conditions--increasing-intensity-tests">Ideal Conditions - Increasing Intensity Tests<a href="#ideal-conditions--increasing-intensity-tests" class="hash-link" aria-label="Direct link to Ideal Conditions - Increasing Intensity Tests" title="Direct link to Ideal Conditions - Increasing Intensity Tests">​</a></h4>
<p>For the publish rate, we’ll actually run a series of benchmarks with different publish rates that cover the 5k to 30k msg/s and more. The idea is to identify up to what rate does a chosen sizing deliver the necessary results and when does it start to struggle and not meet the requirements. This is the happy scenario where RabbitMQ will likely remain empty (and fastest) because the consumers are keeping up at all times (until the cluster reaches its capacity).</p>
<p>We’ll use the rates (total across all publishers):</p>
<ul>
<li>1000 msg/s (hourly=3.6 million, daily=86.4 million, monthly=2.5 billion)</li>
<li>5000 msg/s (hourly=18 million, daily=432 million, monthly=12.9 billion)</li>
<li>10000 msg/s (hourly=36 million, daily=864 million, monthly=25.8 billion)</li>
<li>15000 msg/s (hourly=54 million, daily=1.3 billion, monthly=38.9 billion)</li>
<li>...</li>
<li>70000 msg/s (hourly=252 million, daily= 6 billion, monthly=181.4 billion)</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions--lose-a-broker-test">Adverse Conditions - Lose a Broker Test<a href="#adverse-conditions--lose-a-broker-test" class="hash-link" aria-label="Direct link to Adverse Conditions - Lose a Broker Test" title="Direct link to Adverse Conditions - Lose a Broker Test">​</a></h4>
<p>We&#x27;ll test that a chosen cluster size can handle the peak rate (30k msg/s) even when a broker is down. Brokers can go down because of multiple reasons: we reboot a machine as part of OS patch installations, a disk fails, a network partition etc. The worst case is this happens during peak load.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions---consume-rate-drops-creating-a-backlog-test">Adverse Conditions - Consume rate drops, creating a backlog test<a href="#adverse-conditions---consume-rate-drops-creating-a-backlog-test" class="hash-link" aria-label="Direct link to Adverse Conditions - Consume rate drops, creating a backlog test" title="Direct link to Adverse Conditions - Consume rate drops, creating a backlog test">​</a></h4>
<p>A database server is being overloaded, or there is a network slowdown in downstream systems or a third party API is running slowly. Either way, the time to process each message goes from 10ms to 30 ms, dropping the consume rate. Can we continue to accept the publish rate unaffected and absorb the backlog?</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="adverse-conditions--publish-rate-peaks-very-high-exceeding-consumers-capacity-test">Adverse Conditions - Publish rate peaks very high, exceeding consumers capacity test<a href="#adverse-conditions--publish-rate-peaks-very-high-exceeding-consumers-capacity-test" class="hash-link" aria-label="Direct link to Adverse Conditions - Publish rate peaks very high, exceeding consumers capacity test" title="Direct link to Adverse Conditions - Publish rate peaks very high, exceeding consumers capacity test">​</a></h4>
<p>A marketing campaign goes viral and we get way more traffic than expected, so much that our processing systems cannot handle the load. Can we absorb the traffic as large queue backlogs that can be processed later?</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-clusters">The Clusters<a href="#the-clusters" class="hash-link" aria-label="Direct link to The Clusters" title="Direct link to The Clusters">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-cluster-sizes-and-storage-volumes">The Cluster Sizes and Storage Volumes<a href="#the-cluster-sizes-and-storage-volumes" class="hash-link" aria-label="Direct link to The Cluster Sizes and Storage Volumes" title="Direct link to The Cluster Sizes and Storage Volumes">​</a></h4>
<p>We&#x27;re running on AWS ec2, and what is the cloud but one giant API? We can easily automate the creation of any cluster size or any ec2 instance type we want.</p>
<p>We&#x27;ll run all these tests on 7 different cluster configurations, with three different storage volume types (io1, gp2, st1).</p>
<p>The clusters:</p>
<ul>
<li>3 nodes, c5.9xlarge, 36 vCPUs, 72 GB RAM = 108 vCPUs</li>
<li>3 nodes, c5.4xlarge, 16 vCPUs, 32GB RAM = 48 vCPUs</li>
<li>5 nodes, c5.4xlarge, 16 vCPUs, 32GB RAM = 80 vCPUs</li>
<li>7 nodes, c5.4xlarge, 16 vCPUs, 32GB RAM = 112 vCPUs</li>
<li>5 nodes, c5.2xlarge, 8 vCPUs, 16 GB RAM = 40 vCPUs</li>
<li>7 nodes, c5.2xlarge, 8 vCPUs, 16 GB RAM = 56 vCPUs</li>
<li>9 nodes, c5.2xlarge, 8 vCPUs, 16 GB RAM = 72 vCPUs</li>
</ul>
<p>The c5.9xlarge can be considered a very large VM, it is definitely the biggest VM you would ever you go for. The c5.4xlarge could be considered large and the c5.2xlarge a medium sized instance. This is quite an intensive workload which is why we include these large instance types in the analysis. Many less intensive workloads would be suitable on a smaller instance type, such as the c5.xlarge with 4 vCPUs or c5.large. Larger memory instance types (m5, r5) are also an option if memory ever becomes an issue on these compute optimised instances.</p>
<p>The volumes:</p>
<ul>
<li>io1 (provisioned iops SSD), 200GB, 10000 IOPS, 500MiB/s max = $725 per month</li>
<li>gp2 (general purpose SSD), 1000GB, 3000 IOPS, 250 MiB/s max = $100 per month</li>
<li>st1 (high throughput HDD), 7000GB, 280 MB/s baseline, 500MiB/s max = $315 per month</li>
</ul>
<p>The io1 has a large number of IOPs for its size which is expensive. This choice was in part a way of showing how more expensive disks factor into a sizing analysis. You&#x27;ll see from the case studies that we could go with an io1 with less IOPs and it would be more cost effective.</p>
<p>We go for a large gp2 because smaller volumes get burst credits, which can surprise you. Likewise we went for 7TB HDD because of burst credits also. This size still has burst, but these workloads don’t dig into the burst much and are a balance of cost (this size will manage the 2 hour peaks). For the lower intensity workloads, we could go smaller and save ourselves some money.</p>
<p>This is a test with a 1TB HDD where the burst ran out.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 1. EBS volume burst credits run out." src="/rabbitmq-website/assets/images/burst-credits-1-d93c77f15e7df6b929aeadc690c1cf94.png" width="908" height="390" class="img_ev3q"><figcaption>Fig 1. EBS volume burst credits run out.</figcaption></figure><p></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="costs-per-month-on-demand-pricing">Costs Per Month (On-Demand pricing)<a href="#costs-per-month-on-demand-pricing" class="hash-link" aria-label="Direct link to Costs Per Month (On-Demand pricing)" title="Direct link to Costs Per Month (On-Demand pricing)">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="io1-ssd">io1 SSD<a href="#io1-ssd" class="hash-link" aria-label="Direct link to io1 SSD" title="Direct link to io1 SSD">​</a></h4>
<p>Costs are: VMs + Volumes = Total</p>
<ul>
<li>3 nodes, c5.9xlarge = 36 vCPUs, monthly cost of $3300 + $2175 = $5475</li>
<li>3 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $1468 + $2175 = $3643 </li>
<li>5 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $2445 + $3625 = $6070</li>
<li>7 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $4123 + $5075 = $9198</li>
<li>5 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1225 + $3625 = $4850</li>
<li>7 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1715 + $5075 = $6790</li>
<li>9 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $2205 + $6525 = $8730</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="gp2-ssd">gp2 SSD<a href="#gp2-ssd" class="hash-link" aria-label="Direct link to gp2 SSD" title="Direct link to gp2 SSD">​</a></h4>
<p>Costs are: VMs + Volumes = Total</p>
<ul>
<li>3 nodes, c5.9xlarge = 36 vCPUs, monthly cost of $3300 + $300 = $3600</li>
<li>3 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $1468 + $300 = $1768 </li>
<li>5 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $2445 + $500 = $2945</li>
<li>7 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $4123 + $700 = $4823</li>
<li>5 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1225 + $500 = $1725</li>
<li>7 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1715 + $700 = $2415</li>
<li>9 nodes, c5.2xlarge = 8 vCPUs,, monthly cost of $2205 + $900 = $3105</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="st1-hdd">st1 HDD<a href="#st1-hdd" class="hash-link" aria-label="Direct link to st1 HDD" title="Direct link to st1 HDD">​</a></h4>
<p>Costs are: VMs + Volumes = Total</p>
<ul>
<li>3 nodes, c5.9xlarge = 36 vCPUs, monthly cost of $3300 + $945 = $4245</li>
<li>3 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $1468 + $945 = $2413 </li>
<li>5 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $2445 + $1575 = $4020</li>
<li>7 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $4123 + $2205 = $6328</li>
<li>5 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1225 + $1575 = $2800</li>
<li>7 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1715 + $2205 = $3920</li>
<li>9 nodes, c5.2xlarge = 8 vCPUs,, monthly cost of $2205 + $2835 = $5040</li>
</ul>
<p>We are not including data transfer costs.</p>
<p>We see that choosing gp2 is actually the cheapest option for us. Of course the st1 HDD is half the cost per GB but if we go smaller we can’t achieve the higher intensity throughput. So it seems that for our needs, an SSD could be the most cost effective option. Of course, it can never handle more than 250 MiB/s, so if that is the limiting factor then you would be forced to choose either the expensive io1 or the st1.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="thecase-studies">The case studies<a href="#thecase-studies" class="hash-link" aria-label="Direct link to The case studies" title="Direct link to The case studies">​</a></h2>
<p>In the next posts we’ll perform this sizing analysis using both mirrored and quorum queues.</p>
<ul>
<li><a href="/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1">Cluster Sizing Case Study - Mirrored Queues Part 1</a></li>
<li><a href="/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2">Cluster Sizing Case Study - Mirrored Queues Part 2</a></li>
<li><a href="/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1">Cluster Sizing Case Study - Quorum Queues Part 1</a></li>
<li><a href="/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2">Cluster Sizing Case Study - Quorum Queues Part 2</a></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="other-tests-that-might-apply-to-your-workload">Other tests that might apply to your workload<a href="#other-tests-that-might-apply-to-your-workload" class="hash-link" aria-label="Direct link to Other tests that might apply to your workload" title="Direct link to Other tests that might apply to your workload">​</a></h2>
<p>There are some more tests that you may wish to run depending on your workload. For example:</p>
<ul>
<li>You might want to run long-running tests at peak load. The tests in these two case studies were short - between 10 minutes to 1hr 40 minutes. If you identify a specific intensity and cluster configuration, you can try running it for 24 hours to make sure of your choice. Obviously if you have burst network/disk then that may affect things if you test at peak for that long.</li>
<li>You might periodically get very large messages from a batch job that you want to test. <em>By the way, we recommend using an object store like s3 for large messages (passing its URI as the message).</em></li>
<li>You might want to test recovery time with a backlog by doing a full stop and start of your cluster. </li>
<li>You may have a variable number of clients connect to your cluster. Test your candidate cluster sizes with normal to worst case number of connected clients.</li>
<li><a href="/rabbitmq-website/docs/connections#high-connection-churn">Connection churn</a> (the opening and closing of connections) can also stress a cluster. If you have a variable amount of connection churn then test with normal and worst case. Also see <a href="/rabbitmq-website/docs/networking#tuning-for-large-number-of-connections-tcp-buffer-size">/docs/networking.html#tuning-for-large-number-of-connections-tcp-buffer-size</a>.</li>
<li>You may have a variable number of queues. Test your candidate cluster sizes with normal to worst case number of queues.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="final-thoughts">Final Thoughts<a href="#final-thoughts" class="hash-link" aria-label="Direct link to Final Thoughts" title="Direct link to Final Thoughts">​</a></h2>
<p>The amount of effort you put into sizing is probably going to relate to how much you rely on RabbitMQ in your system and what kind of costs are involved if it fails to deliver the necessary performance. If you have a small workload that is not critical then you may not wish to spend too much time on sizing. Try out a couple of small options and monitor.</p>
<p>If you have larger workloads or business critical workloads, then taking the time to do capacity planning and sizing right may save you more lost time and pain later.</p>
<p>Take the time to review the quorum and mirrored queue case studies, but if you don&#x27;t have time then here are some guidelines distilled into a single section.</p>
<p>High availability (HA) is a common requirement and is the reason we use replicated queues (quorum, mirrored). We don&#x27;t want to lose messages and we want to have continued availability even when failures occur. Don&#x27;t forget that capacity planning is also critical to get right in order to achieve those goals.</p>
<p>Sizing is about running your workload or workload simulations under both ideal and adverse conditions. Peak load is often when a business is making most money and when adverse conditions are also most likely to occur. Sizing according to the adverse conditions is a key part of getting sizing right.</p>
<p>Adverse conditions, where RabbitMQ can still operate effectively if appropriately sized are:</p>
<ul>
<li>loss of brokers (disk failing, VM reboots, network partitions)</li>
<li>queue backlogs (caused by consumer slowdown or publishing peaks)</li>
<li>huge numbers of TCP connections</li>
<li>huge numbers of queues</li>
</ul>
<p>Of those things, broker loss is probably the least stressful for RabbitMQ. One of the hardest things for RabbitMQ to handle is very large queue backlogs. In our case studies we saw that with appropriate sizing, RabbitMQ could handle this high throughput workload despite huge backlogs, but only with the largest clusters. Smaller clusters did fine under ideal conditions but quickly deteriorated when queues started backing up.</p>
<p>If you already have your production and QA environment deployments automated, then testing different VM sizes and counts should be simple enough to do. If you can run these sizing tests with your actual applications then that is likely to give you the most accurate results. If using your own applications to generate the load is too much, then look at designing a synthetic workload that matches the real-world as close as possible.</p>
<p>The case studies include PerfTest commands and there is also <a href="/rabbitmq-website/blog/2020/06/04/how-to-run-benchmarks">this post</a> that provides guidance and options for running performance tests.</p>
<p>I hope this sizing guidance has been helpful and helps RabbitMQ be a rock solid piece of your architecture.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/performance">Performance</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/capacity-planning">Capacity Planning</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-18-cluster-sizing-and-other-considerations/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">Cluster Sizing Case Study - Mirrored Queues Part 1</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rabbitmq-website/blog/2020/06/04/how-to-run-benchmarks"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">How to Run Benchmarks</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#common-questions" class="table-of-contents__link toc-highlight">Common Questions</a></li><li><a href="#some-common-considerations" class="table-of-contents__link toc-highlight">Some common considerations</a><ul><li><a href="#the-number-of-queues-and-clients" class="table-of-contents__link toc-highlight">The number of queues and clients</a></li><li><a href="#what-is-high-throughput" class="table-of-contents__link toc-highlight">What is high throughput?</a></li><li><a href="#what-workloads-require-more-memory" class="table-of-contents__link toc-highlight">What workloads require more memory?</a></li><li><a href="#how-does-redundancy-affect-sizing" class="table-of-contents__link toc-highlight">How does redundancy affect sizing?</a></li><li><a href="#how-does-message-size-affect-sizing" class="table-of-contents__link toc-highlight">How does message size affect sizing?</a></li><li><a href="#do-you-plan-to-use-federation" class="table-of-contents__link toc-highlight">Do you plan to use Federation?</a></li></ul></li><li><a href="#sizing---an-aws-case-study" class="table-of-contents__link toc-highlight">Sizing - An AWS Case Study</a><ul><li><a href="#the-case-study-workload" class="table-of-contents__link toc-highlight">The Case Study Workload</a></li><li><a href="#our-requirements" class="table-of-contents__link toc-highlight">Our Requirements</a></li><li><a href="#the-tests" class="table-of-contents__link toc-highlight">The Tests</a></li><li><a href="#the-clusters" class="table-of-contents__link toc-highlight">The Clusters</a></li><li><a href="#costs-per-month-on-demand-pricing" class="table-of-contents__link toc-highlight">Costs Per Month (On-Demand pricing)</a></li></ul></li><li><a href="#thecase-studies" class="table-of-contents__link toc-highlight">The case studies</a></li><li><a href="#other-tests-that-might-apply-to-your-workload" class="table-of-contents__link toc-highlight">Other tests that might apply to your workload</a></li><li><a href="#final-thoughts" class="table-of-contents__link toc-highlight">Final Thoughts</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn about RabbitMQ</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/tutorials">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/docs">Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Reach out to the RabbitMQ team</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/rabbitmq" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/rabbitmq/rabbitmq-server/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact?utm_source=rmq_release-information_tableheader&amp;utm_medium=rmq_website&amp;utm_campaign=tanzu">Long Term Commercial Support</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact">Contact Us</a></li><li class="footer__item"><a href="https://www.rabbitmq.com/discord" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Broadcom</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://tanzu.vmware.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">VMware Tanzu<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/legal.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms of Use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/trademark-guidelines">Trademark Guidelines</a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy/california-privacy-rights.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Your California Privacy Rights<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item ot-sdk-show-settings">Cookie Settings</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2005-2025 Broadcom. All Rights Reserved. The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.</div></div></div></footer></div>
</body>
</html>
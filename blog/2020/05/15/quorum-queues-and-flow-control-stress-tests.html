<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Quorum Queues and Flow Control - Stress Tests | RabbitMQ</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" name="twitter:image" content="https://www.rabbitmq.com/rabbitmq-website/img/rabbitmq-social-media-card.svg"><meta data-rh="true" property="og:url" content="https://www.rabbitmq.com/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Quorum Queues and Flow Control - Stress Tests | RabbitMQ"><meta data-rh="true" name="description" content="In the last post we ran some simple benchmarks on a single queue to see what effect pipelining publisher confirms and consumer acknowledgements had on flow control."><meta data-rh="true" property="og:description" content="In the last post we ran some simple benchmarks on a single queue to see what effect pipelining publisher confirms and consumer acknowledgements had on flow control."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2020-05-15T00:00:00.000Z"><meta data-rh="true" property="article:tag" content="Performance"><link data-rh="true" rel="icon" href="/rabbitmq-website/img/rabbitmq-logo.svg"><link data-rh="true" rel="canonical" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.rabbitmq.com/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://H10VQIW16Y-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests","mainEntityOfPage":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests","url":"https://www.rabbitmq.com/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests","headline":"Quorum Queues and Flow Control - Stress Tests","name":"Quorum Queues and Flow Control - Stress Tests","description":"In the last post we ran some simple benchmarks on a single queue to see what effect pipelining publisher confirms and consumer acknowledgements had on flow control.","datePublished":"2020-05-15T00:00:00.000Z","author":{"@type":"Person","name":"Jack Vanlightly"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://www.rabbitmq.com/rabbitmq-website/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/rabbitmq-website/blog/rss.xml" title="RabbitMQ RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/rabbitmq-website/blog/atom.xml" title="RabbitMQ Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="RabbitMQ" href="/rabbitmq-website/opensearch.xml">







<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-domain-script="018ee308-473e-754f-b0c2-cbe82d25512f"></script>
<script>function OptanonWrapper(){}</script>
<script>function setGTM(e,t,o,n,r){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var i=t.getElementsByTagName(o)[0],a=t.createElement(o),s="dataLayer"!=n?"&l="+n:"";a.async=!0,a.src="https://www.googletagmanager.com/gtm.js?id="+r+s,i.parentNode.insertBefore(a,i)}var timer;function waitForOnetrustActiveGroups(){document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?(clearTimeout(timer),setGTM(window,document,"script","dataLayer","GTM-TT84L8K")):timer=setTimeout(waitForOnetrustActiveGroups,250)}document.cookie.indexOf("OptanonConsent")>-1&&document.cookie.indexOf("groups=")>-1?setGTM(window,document,"script","dataLayer","GTM-TT84L8K"):waitForOnetrustActiveGroups()</script><link rel="stylesheet" href="/rabbitmq-website/styles.css">
<script src="/rabbitmq-website/runtime~main.js" defer="defer"></script>
<script src="/rabbitmq-website/main.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:var(--ifm-color-primary-contrast-background);color:var(--ifm-font-color-base)" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY"><strong style="font-size: var(--ifm-h4-font-size);"><a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0">RabbitMQ 4.1.0 is out</a></strong></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/rabbitmq-website/"><div class="navbar__logo"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/rabbitmq-website/img/rabbitmq-logo-with-name.svg" alt="RabbitMQ" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/rabbitmq-website/tutorials">Getting Started</a><a class="navbar__item navbar__link" href="/rabbitmq-website/docs">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/rabbitmq-website/blog">Blog</a><a class="navbar__item navbar__link" href="/rabbitmq-website/contact">Support</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/rabbitmq-website/docs">4.1</a><ul class="dropdown__menu"><li class=""><strong>Release series</strong></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/next">Next</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs">4.1</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/4.0">4.0</a></li><li><a class="dropdown__link" href="/rabbitmq-website/docs/3.13">3.13</a></li><li><a href="https://v3-12.rabbitmq.com/documentation.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">3.12<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a class="dropdown__link" href="/rabbitmq-website/release-information">Release Information</a></li></ul></div><a href="https://github.com/rabbitmq/rabbitmq-website" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><main class="col col--9 col--offset-1"><article class=""><header><h1 class="title_f1Hy">Quorum Queues and Flow Control - Stress Tests</h1><div class="container_mt6G margin-vert--md"><time datetime="2020-05-15T00:00:00.000Z">May 15, 2020</time> · <!-- -->23 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><span class="authorName_yefp">Jack Vanlightly</span></div><div class="authorSocials_rSDt"></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>In the <a href="/rabbitmq-website/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks">last post</a> we ran some simple benchmarks on a single queue to see what effect pipelining publisher confirms and consumer acknowledgements had on flow control. </p>
<p>Specifically we looked at:</p>
<ul>
<li>Publishers: Restricting the number of in-flight messages (messages sent but pending a confirm).</li>
<li>Consumers: Prefetch (the number in-flight messages the broker will allow on the channel)</li>
<li>Consumers: Ack Interval (multiple flag usage)</li>
</ul>
<p>Unsurprisingly, we saw when we restricted publishers and the brokers to a small number of in-flight messages at a time, that throughput was low. When we increased that limit, throughput increased, but only to a point, after which we saw no more throughput gains but instead just latency increases. We also saw that allowing consumers to use the multiple flag was beneficial to throughput.</p>
<p>In this post we’re going to look at those same three settings, but with many clients, many queues and different amounts of load, including stress tests. We’ll see that publisher confirms and consumer acknowledgements play a role in flow control to help prevent overload of a broker. </p>
<p>With data safety the clients play a role, they must use confirms and acks correctly to achieve at-least once processing. Likewise, thousands of clients shouldn’t expect to hammer a broker with load and accept no responsibility for how that goes. </p>
<p>Be warned, there is a fair amount of detail in this post so make sure you are comfortable with a beverage nearby before you begin.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mechanical-sympathy">Mechanical Sympathy<a href="#mechanical-sympathy" class="hash-link" aria-label="Direct link to Mechanical Sympathy" title="Direct link to Mechanical Sympathy">​</a></h2>
<p>I really like the term mechanical sympathy. When you drive a racing car slowly, you can get away with pretty much anything. It’s when you push the car to its limits that you need to start listening to it, feeling the vibrations and adjust accordingly else it will break down before the end of the race. </p>
<p>Likewise, with RabbitMQ, if you have a low load, then you can get away with a lot. You might not see much impact of changing these three settings, or using confirms at all (at least on performance). It’s when you stress a cluster to its limit that these settings really become important.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="degrading-gracefully">Degrading Gracefully<a href="#degrading-gracefully" class="hash-link" aria-label="Direct link to Degrading Gracefully" title="Direct link to Degrading Gracefully">​</a></h2>
<p>What should a system do when you throw more data at it than it can handle? </p>
<ul>
<li>Answer 1: accept all data only to burst into a flaming pile of bits.</li>
<li>Answer 2: deliver huge swings of high and low throughput, with hugely varying latencies.</li>
<li>Answer 3: rate limit data ingress and deliver steady throughput with low latencies.</li>
<li>Answer 4: favour ingress to egress, absorbing the data as if it were a peak in load causing high latencies but better keeping up with the ingress rate.</li>
</ul>
<p>At RabbitMQ we would argue that answers 3 and 4 are reasonable expectations whereas nobody wants 1 and 2.</p>
<p>When it comes to answer 4, when is a peak not a peak? At what point does a short peak become chronic? How should such a system favour publishers over consumers? This is a hard choice to make and a hard one to implement well. RabbitMQ goes more along with answer 3: rate limit publishers and try to balance the publish and consume rate as much as possible.</p>
<p>It comes down to flow control.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="choosing-the-right-in-flight-limit-and-prefetch">Choosing the right in-flight limit and prefetch<a href="#choosing-the-right-in-flight-limit-and-prefetch" class="hash-link" aria-label="Direct link to Choosing the right in-flight limit and prefetch" title="Direct link to Choosing the right in-flight limit and prefetch">​</a></h2>
<p>The decision is simple if you never expect heavy load. We saw in the last post with a single high throughput queue that you can set a high in-flight limit, high prefetch and optionally use the multiple flag with consumer acknowledgements and you’ll do ok. If you have low load then likely all settings look the same to the final throughput and latency numbers.</p>
<p>But if you expect periods of heavy load and have hundreds or even thousands of clients then is that still a good choice? The best way I know to answer these questions is to run tests, many, many tests with all kinds of parameters.</p>
<p>So we’ll run a series of benchmarks with different:</p>
<ul>
<li>numbers of publishers</li>
<li>numbers of  queues</li>
<li>numbers of  consumers</li>
<li>publish rates</li>
<li>in-flight limits</li>
<li>prefetch and ack intervals</li>
</ul>
<p>We’ll measure both throughput and latency. The in-flight limit will be a percentage of the target rate per publisher with the percentages anywhere between 1% to 200%. So for example with a per publisher target rate of 1000:</p>
<ul>
<li>1% in-flight limit = 10</li>
<li>5% in-flight limit = 50</li>
<li>10% in-flight limit = 100</li>
<li>20% in-flight limit = 200</li>
<li>100% in-flight limit = 1000</li>
<li>200% in-flight limit = 2000</li>
</ul>
<p>Like in the last post we’ll test both mirrored and quorum queues. Mirrored with one master plus one mirror (rep factor 2) and quorum queues with one leader and two followers (rep factor 3).</p>
<p>All tests use an alpha build of RabbitMQ 3.8.4 with improved quorum queue internals for handling high load. Additionally we’ll be conservative with memory use and set the quorum queue <em>x-max-in-memory-length</em> property to a low value, this makes a quorum queue act a little bit like a lazy queue, it will remove message bodies from memory as soon as it is safe to do so and the queue length has reached this limit. Without this limit, quorum queues maintain all messages in memory. It can be less performant if consumers are not keeping up as there are more disk reads, but it is a safer more conservative configuration. It will become important as we stress the system as it avoids large memory spikes. In these tests it is set to 0 which is the most aggressive setting.</p>
<p>All tests were on 3 node clusters with 16 vCPU (Cascade Lake/Skylake Xeon) machines with SSDs.</p>
<p>Benchmarks:</p>
<ol>
<li>20 publishers, 1000 msg/s, 10 queues, 20 consumers, 1kb messages</li>
<li>20 publishers, 2000 msg/s, 10 queues, 20 consumers, 1kb messages</li>
<li>500 publishers, 30 msg/s, 100 queues, 500 consumers, 1kb messages</li>
<li>500 publishers, 60 msg/s, 100 queues, 500 consumers, 1kb messages</li>
<li>1000 publishers, 100 msg/s, 200 queues, 1000 consumers, 1kb messages</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-1-20-publishers-1000-msgss-per-publisher-10-queues-20-consumers">Benchmark #1: 20 publishers, 1000 msgs/s per publisher, 10 queues, 20 consumers<a href="#benchmark-1-20-publishers-1000-msgss-per-publisher-10-queues-20-consumers" class="hash-link" aria-label="Direct link to Benchmark #1: 20 publishers, 1000 msgs/s per publisher, 10 queues, 20 consumers" title="Direct link to Benchmark #1: 20 publishers, 1000 msgs/s per publisher, 10 queues, 20 consumers">​</a></h2>
<p>With a  total target rate of 20000 msg/s this is within the total throughput limit of the cluster on the chosen hardware for this number of clients and queues. This kind of load is sustainable for this cluster.</p>
<p>We have two tests:</p>
<ol>
<li>No publisher confirms</li>
<li>Confirms with in-flight limit as a percentage of the target send rate: 1% (10), 2% (20), 5% (50), 10% (100), 20% (200), 100% (1000).</li>
</ol>
<p><strong>Mirrored queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 1. 20 publishers (1000 msg/s), 10 mirrored queues, 20 consumers without publisher confirms" src="/rabbitmq-website/assets/images/20-pub-queue-con-1000-sec-mirrored-no-confirms-94c331a797c8aee2e5f85dd8437dff8d.png" width="909" height="431" class="img_ev3q"><figcaption>Fig 1. 20 publishers (1000 msg/s), 10 mirrored queues, 20 consumers without publisher confirms</figcaption></figure><p></p>
<p>The cluster is not being driven harder by the publishers than it can handle. We get a smooth throughput that matches our target rate with sub-second latency.</p>
<p><strong>Mirrored queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 2. 20 publishers (1000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits" src="/rabbitmq-website/assets/images/20-pub-queue-con-1000-sec-mirrored-confirms-1-a41923268d2b6ad5f7210b5e32154f85.png" width="910" height="428" class="img_ev3q"><figcaption>Fig 2. 20 publishers (1000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits</figcaption></figure><p></p>
<p>With this load level, all in-flight settings behave the same. We are not anywhere near the broker’s limit.</p>
<p><strong>Quorum queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 3. 20 publishers (1000 msg/s), 10 quorum queues, 20 consumers without publisher confirms" src="/rabbitmq-website/assets/images/20-pub-queue-con-1000-sec-qq-no-confirms-3931d6594ec7ced39c73b3e6e00d390a.png" width="908" height="428" class="img_ev3q"><figcaption>Fig 3. 20 publishers (1000 msg/s), 10 quorum queues, 20 consumers without publisher confirms</figcaption></figure><p></p>
<p>Target rate matched, latency sub-second.</p>
<p><strong>Quorum queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 4. 20 publishers (1000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits" src="/rabbitmq-website/assets/images/20-pub-queue-con-1000-sec-qq-confirms-1-626ebf24e4c2b0f414d2078c3bcbcb0d.png" width="906" height="430" class="img_ev3q"><figcaption>Fig 4. 20 publishers (1000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits</figcaption></figure><p></p>
<p>With confirms, and a low in-flight limit, quorum queues are a tiny bit short of the target rate but are achieving &lt; 200ms at all percentiles. As we increase the in-flight limit, the target rate is reached, with a smooth line but latencies increase while still falling below 1 second.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3>
<p>When the publish rate is within a clusters capacity to deliver it to consumers, confirms with a low in-flight limit delivered the best end-to-end latency while no confirms or confirms with a high in-flight limit delivered the target throughput but at a higher latency (though still sub-second).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-2-20-publishers-2000-msgss-per-publisher-10-queues-20-consumers">Benchmark #2: 20 publishers, 2000 msgs/s per publisher, 10 queues, 20 consumers<a href="#benchmark-2-20-publishers-2000-msgss-per-publisher-10-queues-20-consumers" class="hash-link" aria-label="Direct link to Benchmark #2: 20 publishers, 2000 msgs/s per publisher, 10 queues, 20 consumers" title="Direct link to Benchmark #2: 20 publishers, 2000 msgs/s per publisher, 10 queues, 20 consumers">​</a></h2>
<p>With a total target rate of 40000 msg/s, this is around or above the throughput limit of the cluster on the chosen hardware. This kind of load is probably unsustainable for this cluster but could occur under peak load conditions. If it were sustained then bigger hardware would be advised.</p>
<p>We have three tests:</p>
<ol>
<li>No publisher confirms</li>
<li>Confirms with in-flight limit as a percentage of the target send rate: 1% (20), 2% (40), 5% (100), 10% (200), 20% (400), 100% (2000). Prefetch of 2000, ack interval of 1.</li>
<li>Same as 2, but with multiple flag usage by consumers, using an ack interval of 200 (10% of prefetch).</li>
</ol>
<p><strong>Mirrored queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 5. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers without publisher confirms" src="/rabbitmq-website/assets/images/20-pub-queue-con-2000-sec-mirrored-no-confirms-224abdd8b0acc1b1de6be75bd8d9e657.png" width="910" height="429" class="img_ev3q"><figcaption>Fig 5. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers without publisher confirms</figcaption></figure><p></p>
<p>Publishers briefly touch close to the target rate but both publisher and consumer rates stabilise at a lower rate, with the publish rate exceeding the consumer rate. This causes the queues to fill up and latencies to skyrocket. If this were sustained then the queue would grow huge and place increasing pressure on resource usage.</p>
<p><strong>Mirrored queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 6. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/20-pub-queue-con-2000-sec-mirrored-confirms-1-7eb0a508b6171b981cf68d2b3ca4c64c.png" width="910" height="431" class="img_ev3q"><figcaption>Fig 6. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p><strong>Mirrored queue with confirms and multiple flag usage</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 7. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits. Multiple flag usage by consumers." src="/rabbitmq-website/assets/images/20-pub-queue-con-2000-sec-mirrored-confirms-multiple-flag-990d682efef56d82b0074cfaff6f6072.png" width="912" height="433" class="img_ev3q"><figcaption>Fig 7. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits. Multiple flag usage by consumers.</figcaption></figure><p></p>
<p>Confirms really make a difference now, applying effective back pressure on the publishers. We hit the peak throughput (still way-off the target) with the lowest in-flight limit of 20 (1% of target rate). End-to-end latency is low, at around 20ms. But as we increase the in-flight limit, a minority of the queues start filling up, causing the 95th percentile latency to shoot up. </p>
<p>We see that using the multiple flag reduces the publish-to-consume rate imbalance when at the high in-flight limit and thereby reduces the worst of the latencies a bit. But the effect is not super strong in this case.</p>
<p><strong>Quorum queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 8. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers without publisher confirms." src="/rabbitmq-website/assets/images/20-pub-queue-con-2000-sec-qq-no-confirms-35763b0807fc926c9390e901548ff2ce.png" width="912" height="431" class="img_ev3q"><figcaption>Fig 8. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers without publisher confirms.</figcaption></figure><p></p>
<p>Quorum queues tend to outperform mirrored queues when the queue count is low. Here we see that 40000 msg/s was achieved and so back pressure on publishers was not needed.</p>
<p><strong>Quorum queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 9. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/20-pub-queue-con-2000-sec-qq-confirms-1-f2bdac5d5b1e22ba347e1c2f4eadc645.png" width="909" height="429" class="img_ev3q"><figcaption>Fig 9. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p><strong>Quorum queue with confirms and multiple flag usage</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 10. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits, with consumers using the multiple flag." src="/rabbitmq-website/assets/images/20-pub-queue-con-2000-sec-qq-confirms-multiple-flag-d118aaab9f0d05d018d29e08705b6f2f.png" width="909" height="431" class="img_ev3q"><figcaption>Fig 10. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits, with consumers using the multiple flag.</figcaption></figure><p></p>
<p>Quorum queues yet again deliver higher throughput and we even reached the target rate of 40000 msg/s with an in-flight limit of 2000. There was a mild benefit to using the multiple flag.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion-1">Conclusion<a href="#conclusion-1" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3>
<p>Without the back pressure of using publisher confirms and an in-flight limit, mirrored queues fell apart. When publishers used confirms they effectively put back pressure on the publishers, achieving low latency until the in-flight limit reached 100% of the target rate, where again latency started spiking again. The important thing to note is that this target rate exceeded the mirrored queues capacity, and we saw how important back pressure was.</p>
<p>Quorum queues can achieve higher throughput than mirrored queues when the number of queues and publishers is relatively low. They were capable of delivering 40000 msg/s and so using confirms or not using confirms was not critical to stable performance.</p>
<p>Multiple flag usage was beneficial, but not game changing.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-3-500-publishers-30-msgss-per-publisher-100-queues-500-consumers">Benchmark #3: 500 publishers, 30 msgs/s per publisher, 100 queues, 500 consumers<a href="#benchmark-3-500-publishers-30-msgss-per-publisher-100-queues-500-consumers" class="hash-link" aria-label="Direct link to Benchmark #3: 500 publishers, 30 msgs/s per publisher, 100 queues, 500 consumers" title="Direct link to Benchmark #3: 500 publishers, 30 msgs/s per publisher, 100 queues, 500 consumers">​</a></h2>
<p>With a total target rate of 15000 msg/s, this is within the total throughput limit of the cluster on the chosen hardware. </p>
<p>We have two tests:</p>
<ol>
<li>No publisher confirms</li>
<li>Confirms with in-flight limit as a percentage of the target send rate: 6% (2), 10% (3), 20% (6), 50% 12, 100% (30), 200% (60) and no multiple flag usage.</li>
</ol>
<p><strong>Mirrored queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 11. 500 publishers (30 msg/s), 100 mirrored queues, 500 consumers without publisher confirms." src="/rabbitmq-website/assets/images/500-pub-queue-con-30-sec-mirrored-no-confirms-9757b66864757318067b7bd6ce9804bb.png" width="913" height="430" class="img_ev3q"><figcaption>Fig 11. 500 publishers (30 msg/s), 100 mirrored queues, 500 consumers without publisher confirms.</figcaption></figure><p></p>
<p><strong>Mirrored queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 12. 500 publishers (30 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits" src="/rabbitmq-website/assets/images/500-pub-queue-con-30-sec-mirrored-confirms-1-345879c78ec42558dfe7153e4fc9c251.png" width="908" height="430" class="img_ev3q"><figcaption>Fig 12. 500 publishers (30 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits</figcaption></figure><p></p>
<p><strong>Quorum queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 13. 500 publishers (30 msg/s), 100 quorum queues, 500 consumers without publisher confirms." src="/rabbitmq-website/assets/images/500-pub-queue-con-30-sec-qq-no-confirms-6fe6b4cdaac364b6da24400f5f056df4.png" width="912" height="431" class="img_ev3q"><figcaption>Fig 13. 500 publishers (30 msg/s), 100 quorum queues, 500 consumers without publisher confirms.</figcaption></figure><p></p>
<p><strong>Quorum queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 14. 500 publishers (30 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits" src="/rabbitmq-website/assets/images/500-pub-queue-con-30-sec-qq-confirms-1-7772420ddef0e8181b180f993de88166.png" width="907" height="430" class="img_ev3q"><figcaption>Fig 14. 500 publishers (30 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits</figcaption></figure><p></p>
<p>In all cases we matched the target rate. With confirms and a low in-flight limit the throughput had a small amount of jitter that resolved at higher limits.</p>
<p>As we increased the in-flight limit, latency crept up. Mirrored queues passed 1 second while quorum queues remained below 1 second.</p>
<p>Again, we see that when the cluster is within its capacity, we don’t need confirms as a back pressure mechanism (just for data safety).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-4-500-publishers-60-msgss-per-publisher-100-queues-500-consumers">Benchmark #4: 500 publishers, 60 msgs/s per publisher, 100 queues, 500 consumers<a href="#benchmark-4-500-publishers-60-msgss-per-publisher-100-queues-500-consumers" class="hash-link" aria-label="Direct link to Benchmark #4: 500 publishers, 60 msgs/s per publisher, 100 queues, 500 consumers" title="Direct link to Benchmark #4: 500 publishers, 60 msgs/s per publisher, 100 queues, 500 consumers">​</a></h2>
<p>With a total target rate of 30000 msg/s, this is just above the total throughput limit of the cluster for this number of clients and queues (on the chosen hardware). This will stress the cluster and is not a sustainable load that this cluster should be exposed to.</p>
<p>We have three tests:</p>
<ol>
<li>No publisher confirms</li>
<li>Confirms with in-flight limit as a percentage of the target send rate: 5% (3), 10% (6), 20% (12), 50% (24), 100% (60), 200% (120) and a prefetch of 60.</li>
<li>Same as 2 but with multiple flag usage with an ack interval of 6 (10% of prefetch).</li>
</ol>
<p><strong>Mirrored queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 15. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers without publisher confirms." src="/rabbitmq-website/assets/images/500-pub-queue-con-60-sec-mirrored-no-confirms-27d340c1920479f9a49272ae3ded727a.png" width="909" height="430" class="img_ev3q"><figcaption>Fig 15. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers without publisher confirms.</figcaption></figure><p></p>
<p>Without confirms, publishers briefly manage the target rate but consumers can’t keep up. Throughput is pretty wild and latencies for half the queues get close to 1 minute and the rest reach over 2-3 minutes.</p>
<p><strong>Mirrored queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 16. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/500-pub-queue-con-60-sec-mirrored-confirms-2-19409f920f81dfb579178c1d8ace26cd.png" width="910" height="433" class="img_ev3q"><figcaption>Fig 16. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p><strong>Mirrored queue with confirms and multiple flag usage</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 17. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits with multiple fag usage." src="/rabbitmq-website/assets/images/500-pub-queue-con-60-sec-mirrored-confirms-multiple-flag-50c9609013a2c51b2f901ce70c07b7fa.png" width="911" height="430" class="img_ev3q"><figcaption>Fig 17. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits with multiple fag usage.</figcaption></figure><p></p>
<p>With confirms we get much more stable throughput where consumers keep up with the publish rate because the publishers are being rate limited by their in-flight limit. The multiple flag definitely helps this time, pushing us up to 5000 msg/s higher throughput. Notice that the in-flight limit of just 3% of the target rate delivers the best performance.</p>
<p><strong>Quorum queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 18. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers without publisher confirms." src="/rabbitmq-website/assets/images/500-pub-queue-con-60-sec-qq-no-confirms-4a68b92df370d72c31722efdbd6dea9a.png" width="911" height="428" class="img_ev3q"><figcaption>Fig 18. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers without publisher confirms.</figcaption></figure><p></p>
<p>The publishers hit their target, but consumers are not keeping up and the queues are filling. This is not a sustainable position to be in.</p>
<p><strong>Quorum queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 19. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/500-pub-queue-con-60-sec-qq-confirms-1-5bbb58afe4423a637e1081d307cd921f.png" width="909" height="428" class="img_ev3q"><figcaption>Fig 19. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p><strong>Quorum queue with confirms and multiple flag</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 20. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits and multiple flag usage." src="/rabbitmq-website/assets/images/500-pub-queue-con-60-sec-qq-confirms-multiple-flag-86ccbc1d05f584bd53270b5ec31e58dd.png" width="911" height="433" class="img_ev3q"><figcaption>Fig 20. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits and multiple flag usage.</figcaption></figure><p></p>
<p>With publisher confirms we see more stable throughput but there is a definitely a saw-tooth pattern. We can go all the way up to an in-flight limit of 100% of the target rate without things falling apart, though latencies are steadily rising. At 200%, the publish rate exceeds the consume rate and the queues start filling up.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion-2">Conclusion<a href="#conclusion-2" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3>
<p>When a cluster is past its limit, use of publisher confirms with an in-flight limit ensure a balanced publish and consume rate. Even though the publishers would go faster, they rate limit themselves and RabbitMQ can deliver sustainable performance for long periods.</p>
<p>With large numbers of publishers, consumers and queues, the maximum throughput of mirrored and quorum queues has converged to a similar number. Quorum queues no longer outperform mirrored queues. We saw a higher throughput with less clients and queues. Less means less context switching, less random IO which is all more efficient.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-5-1000-publishers-100-msgss-per-publisher-200-queues-1000-consumers">Benchmark #5: 1000 publishers, 100 msgs/s per publisher, 200 queues, 1000 consumers<a href="#benchmark-5-1000-publishers-100-msgss-per-publisher-200-queues-1000-consumers" class="hash-link" aria-label="Direct link to Benchmark #5: 1000 publishers, 100 msgs/s per publisher, 200 queues, 1000 consumers" title="Direct link to Benchmark #5: 1000 publishers, 100 msgs/s per publisher, 200 queues, 1000 consumers">​</a></h2>
<p>This load is way past what this cluster can handle at a total target rate of 100000 msg/s second over 200 queues. Beyond the low 10s of queues, expect maximum throughput of a cluster to fall as the number of queues increases.</p>
<p>If this cluster ever gets hit like this then it should only be for short periods of time.</p>
<p>We have three tests:</p>
<ol>
<li>No confirms</li>
<li>Confirms with in-flight limit as a percentage of the target send rate: 2% (2), 5% (5), 10% (10), 20% (20), 50% (50), 100% (100) and a prefetch of 100.</li>
<li>Same as 2 but with multiple flag usage and an ack interval of 10 (10% of prefetch).</li>
</ol>
<p><strong>Mirrored queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 21. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers without publisher confirms." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-mirrored-no-confirms-3297955c49cbacb2aee81212ec71ee03.png" width="908" height="430" class="img_ev3q"><figcaption>Fig 21. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers without publisher confirms.</figcaption></figure><p></p>
<p>Publishers almost reach the target rate, but then buffers inside the brokers start reaching capacity and throughput plummets like a stone. Relying on TCP back pressure, with default credit based flow control settings with 1000 publishers sending faster than the cluster could handle didn’t go very well. </p>
<p>The initial credit is 400 for each actor in the credit chain, so the reader process on each connection will accept at the least 400 messages before being blocked. With 1000 publishers, that’s 400,000 messages buffered just in the reader processes. Add to that the buffers of the channels and the queues, and all the outgoing port buffers etc and you can see how a broker can absorb and then get choked by a large number of messages from a large number of publishers, even before TCP back pressure kicks in.</p>
<p><strong>Mirrored queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 22. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-mirrored-confirms-1-b786df7f23f094497d474c624e4b026b.png" width="911" height="429" class="img_ev3q"><figcaption>Fig 22. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p><strong>Mirrored queue with confirms and multiple flag usage</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 23. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-mirrored-confirms-multiple-flag-0912bb4a1f98606da30de1ea2665b4bd.png" width="914" height="433" class="img_ev3q"><figcaption>Fig 23. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p>The publishers would love to reach the target rate but they are being rate limited effectively. As we increase the in-flight limit we see a slight increase in throughput and a larger increase in latency. In the end, when we reach an in-flight limit of 200% of the target rate, it’s too much, but publishers are still throttled. Queues back up a little and throughput drops, getting pretty choppy. Usage of the multiple flag helps, it lessens the drop and keeps latency below 25 seconds.</p>
<p>If we look at the <a href="https://grafana.com/grafana/dashboards/10991" target="_blank" rel="noopener noreferrer">RabbitMQ Overview</a> Grafana dashboard (slightly modified for show here), we see that when the in-flight limit is low, there are a low number of pending confirms and pending consumer acks, but as we reach 100% in-flight limit those numbers reach 100,000. So RabbitMQ has a lot more messages buffered internally. Consumers have not reached their prefetch limit though peaking at 55,000 of their total possible 100,000.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 24. RabbitMQ overview shows pending confirms and acks increasing inline with the in-flight limit." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-mirrored-confirms-overview-1-8438cef05152f91c6d6c6f7bf2ce9de7.png" width="908" height="710" class="img_ev3q"><figcaption>Fig 24. RabbitMQ overview shows pending confirms and acks increasing inline with the in-flight limit.</figcaption></figure><p></p>
<p><strong>Quorum queue without confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 25. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers without publisher confirms." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-qq-no-confirms-29f2bb67bfbed021b5dfabf962a81ff2.png" width="911" height="430" class="img_ev3q"><figcaption>Fig 25. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers without publisher confirms.</figcaption></figure><p></p>
<p>Same as mirrored queues. TCP back pressure was not enough to stop overload.</p>
<p><strong>Quorum queue with confirms</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 26. 1000 publishers (100 msg/s), 200 quorum queues, 1000 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-qq-confirms-1-907700be2932bd223e065c35071ae4c3.png" width="909" height="431" class="img_ev3q"><figcaption>Fig 26. 1000 publishers (100 msg/s), 200 quorum queues, 1000 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p><strong>Quorum queue with confirms and multiple flag usage</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 27. 1000 publishers (100 msg/s), 200 quorum queues, 1000 consumers with publisher confirms and different in-flight limits." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-qq-confirms-multiple-flag-ad1e4701c366225d7da1cf6841f4af61.png" width="909" height="430" class="img_ev3q"><figcaption>Fig 27. 1000 publishers (100 msg/s), 200 quorum queues, 1000 consumers with publisher confirms and different in-flight limits.</figcaption></figure><p></p>
<p>Quorum queues definitely benefited more than mirrored queues when switching from a low to a medium sized in-flight limit. With multiple flag usage we even hit close to 35000 msg/s. Things started to go wrong at the 100% of target rate limit and then really bad at 200%. The publishers pulled ahead causing the queues to fill up. This is when you really need that low value for the  <em>x-max-in-memory-length</em> quorum queue property. Without it, memory usage would spike very fast under these conditions causing huge swings in throughput as memory alarms turn on and off repeatedly.</p>
<p>We have made big improvements to quorum queue memory usage under stress in the upcoming 3.8.4 release. All these tests show the results of that work. Towards the end of this post we’ll show this same test with 3.8.3 and how it doesn’t deal so well with this stress test.</p>
<p>In the Overview dashboard we see how the queues are filling up. Consumers have reached their prefetch limit.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 28. RabbitMQ overview shows quorum queue pending confirms and acks increasing inline with the in-flight limit." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-qq-confirms-overview-1-73f7e3255d0d543ff557a6b88a753366.png" width="909" height="713" class="img_ev3q"><figcaption>Fig 28. RabbitMQ overview shows quorum queue pending confirms and acks increasing inline with the in-flight limit.</figcaption></figure><p></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion-3">Conclusion<a href="#conclusion-3" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h3>
<p>Neither queue type could handle this load without publisher confirms. Each cluster got totally overwhelmed.</p>
<p>With confirms, mirrored and quorum queues achieved the same ballpark throughput and latency numbers until the 100% and 200% in-flight limits, where quorum queues fared worse.</p>
<p>Mirrored queues handled the overload pretty well, even with high in-flight limits. Quorum queues needed the additional help of a low in-flight limit to achieve stable throughput with low latency.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-about-383-and-earlier">What about 3.8.3 and earlier?<a href="#what-about-383-and-earlier" class="hash-link" aria-label="Direct link to What about 3.8.3 and earlier?" title="Direct link to What about 3.8.3 and earlier?">​</a></h2>
<p>All the quorum queue tests were run on an alpha of 3.8.4, in order to show performance of the upcoming 3.8.4 release. But the rest of you will be on version 3.8.3 and earlier. So what can you expect?</p>
<p>The improvements landing in 3.8.4 are:</p>
<ul>
<li>High throughput capacity of segment writing. Messages are written first to the WAL and secondly to segment files. In 3.8.3 we saw that the segment writer was a bottleneck in high load, high queue count scenarios which would cause high memory usage. 3.8.4 comes with parallelised segment writing which completely solves this bottleneck.</li>
<li>Default configuration values for quorum queues were load tested and we found some changes resulted in more stable throughput under high load. Specifically we changed quorum_commands_soft_limit from 256 to 32 and raft.wal_max_batch_size from 32768 to 4096.</li>
</ul>
<p>If you are on 3.8.3 the good news is that rolling upgrades these days are easily performed, but if you can’t upgrade then try the above configurations. You’ll still have the possible bottleneck of the segment writer though.</p>
<p>Below is benchmark #5, with a longer running time, with 3.8.3 (with the configuration changes applied).</p>
<p><strong>3.8.3 benchmark #5</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 29. 3.8.3 sees large peaks and troughs caused by memory alarms." src="/rabbitmq-website/assets/images/1000-pub-queue-con-100-sec-qq-383-confirms-long-9432c3a514842db2c1d83f0bcc0e17f6.png" width="911" height="429" class="img_ev3q"><figcaption>Fig 29. 3.8.3 sees large peaks and troughs caused by memory alarms.</figcaption></figure><p></p>
<p>The main difference with 3.8.3 is that as we increase the in-flight limit, the segment writer falls behind and memory grows until memory alarms hit. Publishers get blocked and consumers are then unconstrained by competing with publishers to get their acks into the replicated log. The consume rate reaches short peaks of up to 90k msg/s until the queues are drained, memory falls and alarms deactivated, only to repeat again and again.</p>
<p>We can see that from the Overview dashboard. The 3.8.4 alpha has a slowly increasing memory growth as the in-flight limit rises.</p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 30. The 3.8.4 alpha sees stable memory growth as the in-flight limit increases." src="/rabbitmq-website/assets/images/custom-build-memory-f0b88d0cba0f5614361f332d490dd591.png" width="905" height="792" class="img_ev3q"><figcaption>Fig 30. The 3.8.4 alpha sees stable memory growth as the in-flight limit increases.</figcaption></figure><p></p>
<p><strong>3.8.3 hits the memory alarms repeatedly.</strong></p>
<p></p><figure><img decoding="async" loading="lazy" alt="Fig 31. 3.8.3 hits memory alarms repeatedly under heavy load from a 1000 publishers." src="/rabbitmq-website/assets/images/3.8.3-memory-be2f65f487975166e673ddef3cfa8ab2.png" width="908" height="789" class="img_ev3q"><figcaption>Fig 31. 3.8.3 hits memory alarms repeatedly under heavy load from a 1000 publishers.</figcaption></figure><p></p>
<p>Even with the low in-flight limit, this heavy workload with a 1000 publishers was too much for the segment writer and it reached close to the memory alarms early in the test.</p>
<p>So if you have large publisher and queue counts with regular peaks in load that exceed its limits, then consider upgrading to 3.8.4 when it is out.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="final-conclusions">Final Conclusions<a href="#final-conclusions" class="hash-link" aria-label="Direct link to Final Conclusions" title="Direct link to Final Conclusions">​</a></h2>
<p>First of all, if you are using a replicated queue (mirrored or quorum) then not using publisher confirms, from a data safety point of view, is highly inadvisable. Message delivery is not guaranteed, so please use them.</p>
<p>Data safety aside, these tests show that confirms also play a role in flow control.</p>
<p>Some key takeaways:</p>
<ul>
<li>Quorum queues can deliver higher throughput than mirrored queues when the queue count is in the region of 1-2 per core.</li>
<li>At low publisher and queue counts, you can pretty much do anything. TCP back pressure is probably enough for both mirrored and quorum queues (not using confirms).</li>
<li>At high publisher and queue counts and higher load, TCP back pressure is not enough. We must employ publisher confirms so that publishers rate limit themselves.</li>
<li>At high publisher and queue counts, performance was more or less similar for both queue types. But quorum queues needed a little extra help via a lower in-flight limit during the stress test.</li>
<li>Multiple flag usage was beneficial but not critical.</li>
<li>Whatever you do, don&#x27;t put your brokers under high load without publisher confirms!</li>
</ul>
<p>So what is the best in-flight limit? I hope I’ve managed to persuade you that <em>it depends</em>, but as a rule of thumb, with low network latency between publishers and the broker, using a limit between 1% and 10% of the target rate is optimal. With fewer publishers that have a high send rate, then we veer towards 10% but with hundreds of clients then we veer towards the 1% mark. These numbers are likely to increase with higher latency links between publishers and brokers.</p>
<p>Regarding consumer prefetch, all these tests used a prefetch of the target publish rate (per publisher, not total), but remember that in these tests, the number of publishers matched the number of consumers. When the multiple flag was used, the ack interval was 10% of the prefetch value. Multiple flag usage is beneficial but its not a big deal if you don&#x27;t use it.</p>
<p>If you are currently on mirrored queues and your workload more closely resembles benchmark #5 rather than any of the others, then it is recommended to make the jump after 3.8.4 is released. Improving flow control and resiliency under load is likely to be an ongoing effort, but is also workload specific in many cases. Hopefully you have seen that you have the power to tune throughput and latency via the use confirms, and get the behaviour that you need.</p>
<p>I would be amiss if I didn&#x27;t mention capacity planning. Ensuring that RabbitMQ has enough hardware to handle peak loads is the best way to ensure that it can deliver performance that is acceptable. But there are always surprise loads, limits in budget and so on.</p>
<p>Remember, as with all benchmarks like this, don&#x27;t fixate on these specific numbers. Your situation will be different. Different hardware, different message sizes, degrees of fanout, different versions of RabbitMQ, different clients, frameworks... the list goes on. The main takeaway is that you shouldn’t expect RabbitMQ to exert flow control by itself when under heavy load. It’s all about <em>mechanical sympathy</em>.</p>
<p>Next in the series is a look at migrating from mirrored to quorum queues.</p></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/rabbitmq-website/blog/tags/performance">Performance</a></li></ul></div></div><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><a href="https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-05-15-quorum-queues-and-flow-control-stress-tests/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/rabbitmq-website/blog/2020/06/01/this-month-in-rabbitmq-april-2020-recap"><div class="pagination-nav__sublabel">Newer post</div><div class="pagination-nav__label">This Month in RabbitMQ, April 2020 Recap</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/rabbitmq-website/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Quorum Queues and Flow Control - Single Queue Benchmarks</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#mechanical-sympathy" class="table-of-contents__link toc-highlight">Mechanical Sympathy</a></li><li><a href="#degrading-gracefully" class="table-of-contents__link toc-highlight">Degrading Gracefully</a></li><li><a href="#choosing-the-right-in-flight-limit-and-prefetch" class="table-of-contents__link toc-highlight">Choosing the right in-flight limit and prefetch</a></li><li><a href="#benchmark-1-20-publishers-1000-msgss-per-publisher-10-queues-20-consumers" class="table-of-contents__link toc-highlight">Benchmark #1: 20 publishers, 1000 msgs/s per publisher, 10 queues, 20 consumers</a><ul><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li><li><a href="#benchmark-2-20-publishers-2000-msgss-per-publisher-10-queues-20-consumers" class="table-of-contents__link toc-highlight">Benchmark #2: 20 publishers, 2000 msgs/s per publisher, 10 queues, 20 consumers</a><ul><li><a href="#conclusion-1" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li><li><a href="#benchmark-3-500-publishers-30-msgss-per-publisher-100-queues-500-consumers" class="table-of-contents__link toc-highlight">Benchmark #3: 500 publishers, 30 msgs/s per publisher, 100 queues, 500 consumers</a></li><li><a href="#benchmark-4-500-publishers-60-msgss-per-publisher-100-queues-500-consumers" class="table-of-contents__link toc-highlight">Benchmark #4: 500 publishers, 60 msgs/s per publisher, 100 queues, 500 consumers</a><ul><li><a href="#conclusion-2" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li><li><a href="#benchmark-5-1000-publishers-100-msgss-per-publisher-200-queues-1000-consumers" class="table-of-contents__link toc-highlight">Benchmark #5: 1000 publishers, 100 msgs/s per publisher, 200 queues, 1000 consumers</a><ul><li><a href="#conclusion-3" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li><li><a href="#what-about-383-and-earlier" class="table-of-contents__link toc-highlight">What about 3.8.3 and earlier?</a></li><li><a href="#final-conclusions" class="table-of-contents__link toc-highlight">Final Conclusions</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn about RabbitMQ</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/tutorials">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/docs">Documentation</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Reach out to the RabbitMQ team</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/rabbitmq" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/rabbitmq/rabbitmq-server/discussions" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Discussions<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact?utm_source=rmq_release-information_tableheader&amp;utm_medium=rmq_website&amp;utm_campaign=tanzu">Long Term Commercial Support</a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/contact">Contact Us</a></li><li class="footer__item"><a href="https://www.rabbitmq.com/discord" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Broadcom</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://tanzu.vmware.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">VMware Tanzu<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/legal.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Terms of Use<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Privacy<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/rabbitmq-website/trademark-guidelines">Trademark Guidelines</a></li><li class="footer__item"><a href="https://www.vmware.com/help/privacy/california-privacy-rights.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Your California Privacy Rights<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item ot-sdk-show-settings">Cookie Settings</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2005-2025 Broadcom. All Rights Reserved. The term "Broadcom" refers to Broadcom Inc. and/or its subsidiaries.</div></div></div></footer></div>
</body>
</html>
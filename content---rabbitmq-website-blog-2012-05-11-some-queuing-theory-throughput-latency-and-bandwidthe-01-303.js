"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(globalThis["webpackChunkrabbitmq_website"] = globalThis["webpackChunkrabbitmq_website"] || []).push([["content---rabbitmq-website-blog-2012-05-11-some-queuing-theory-throughput-latency-and-bandwidthe-01-303"],{

/***/ "./.docusaurus/docusaurus-plugin-content-blog/default/site-blog-2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth-index-md-e01.json":
/***/ ((module) => {

module.exports = /*#__PURE__*/JSON.parse('{"permalink":"/rabbitmq-website/blog/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md","source":"@site/blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md","title":"Some queuing theory: throughput, latency and bandwidth","description":"You have a queue in Rabbit. You have some clients consuming from that","date":"2012-05-11T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":11.775,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"Some queuing theory: throughput, latency and bandwidth","tags":["HowTo","New Features"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"Introducing RabbitMQ-Web-Stomp","permalink":"/rabbitmq-website/blog/2012/05/14/introducing-rabbitmq-web-stomp"},"nextItem":{"title":"RabbitMQ Performance Measurements, part 2","permalink":"/rabbitmq-website/blog/2012/04/25/rabbitmq-performance-measurements-part-2"}}');

/***/ }),

/***/ "./blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md":
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   assets: () => (/* binding */ assets),\n/* harmony export */   contentTitle: () => (/* binding */ contentTitle),\n/* harmony export */   \"default\": () => (/* binding */ MDXContent),\n/* harmony export */   frontMatter: () => (/* binding */ frontMatter),\n/* harmony export */   metadata: () => (/* reexport default export from named module */ _site_docusaurus_docusaurus_plugin_content_blog_default_site_blog_2012_05_11_some_queuing_theory_throughput_latency_and_bandwidth_index_md_e01_json__WEBPACK_IMPORTED_MODULE_0__),\n/* harmony export */   toc: () => (/* binding */ toc)\n/* harmony export */ });\n/* harmony import */ var _site_docusaurus_docusaurus_plugin_content_blog_default_site_blog_2012_05_11_some_queuing_theory_throughput_latency_and_bandwidth_index_md_e01_json__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(\"./.docusaurus/docusaurus-plugin-content-blog/default/site-blog-2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth-index-md-e01.json\");\n/* harmony import */ var react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(\"./node_modules/react/jsx-runtime.js\");\n/* harmony import */ var _mdx_js_react__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(\"./node_modules/@mdx-js/react/lib/index.js\");\n\n\nconst frontMatter = {\n\ttitle: 'Some queuing theory: throughput, latency and bandwidth',\n\ttags: [\n\t\t'HowTo',\n\t\t'New Features'\n\t],\n\tauthors: [\n\t\t'matthew'\n\t]\n};\nconst contentTitle = undefined;\n\nconst assets = {\n\"authorsImageUrls\": [undefined],\n};\n\n\n\nconst toc = [];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    code: \"code\",\n    em: \"em\",\n    img: \"img\",\n    li: \"li\",\n    ol: \"ol\",\n    p: \"p\",\n    ...(0,_mdx_js_react__WEBPACK_IMPORTED_MODULE_2__.useMDXComponents)(),\n    ...props.components\n  };\n  return (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.Fragment, {\n    children: [(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"You have a queue in Rabbit. You have some clients consuming from that\\r\\nqueue. If you don't set a QoS setting at all (\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"basic.qos\"\n      }), \"), then\\r\\nRabbit will push all the queue's messages to the clients as fast as\\r\\nthe network and the clients will allow. The consumers will balloon in\\r\\nmemory as they buffer all the messages in their own RAM. The queue may\\r\\nappear empty if you ask Rabbit, but there may be millions of messages\\r\\nunacknowledged as they sit in the clients, ready for processing by the\\r\\nclient application. If you add a new consumer, there are no messages\\r\\nleft in the queue to be sent to the new consumer. Messages are just\\r\\nbeing buffered in the existing clients, and may be there for a long\\r\\ntime, even if there are other consumers that become available to\\r\\nprocess such messages sooner. This is rather sub optimal.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"So, the default QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" setting gives clients an \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.em, {\n        children: \"unlimited\"\n      }), \"\\r\\nbuffer, and that can result in poor behaviour and performance. But\\r\\nwhat should you set the QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" buffer size to? The goal is to\\r\\nkeep the consumers saturated with work, but to minimise the client's\\r\\nbuffer size so that more messages stay in Rabbit's queue and are thus\\r\\navailable for new consumers or to just be sent out to consumers as\\r\\nthey become free.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"Let's say it takes 50ms for Rabbit to take a message from this queue,\\r\\nput it on the network and for it to arrive at the consumer. It takes\\r\\n4ms for the client to process the message. Once the consumer has\\r\\nprocessed the message, it sends an \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"ack\"\n      }), \" back to Rabbit, which takes a\\r\\nfurther 50ms to be sent to and processed by Rabbit. So we have a total\\r\\nround trip time of 104ms. If we have a QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" setting of 1\\r\\nmessage then Rabbit won't sent out the next message until after this\\r\\nround trip completes. Thus the client will be busy for only 4ms of\\r\\nevery 104ms, or 3.8% of the time. We want it to be busy 100% of the\\r\\ntime.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.p, {\n      children: (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.img, {\n        src: (__webpack_require__(\"./node_modules/url-loader/dist/cjs.js?limit=10000&name=assets/images/[name]-[contenthash].[ext]&fallback=/mnt/d/xy2401/codeDoc/rabbitmq-website/node_modules/file-loader/dist/cjs.js!./blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/qos.svg\")[\"default\"]) + \"\",\n        width: \"693\",\n        height: \"178\"\n      })\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"If we do \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.em, {\n        children: \"total round trip time\"\n      }), \" / \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.em, {\n        children: \"processing time on the client for\\r\\neach message\"\n      }), \", we get \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"104 / 4 = 26\"\n      }), \". If we have a QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" of\\r\\n26 messages this solves our problem: assume that the client has 26\\r\\nmessages buffered, ready and waiting for processing. (This is a\\r\\nsensible assumption: once you set \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"basic.qos\"\n      }), \" and then \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"consume\"\n      }), \" from\\r\\na queue, Rabbit will send as many messages as it can from the queue\\r\\nyou've subscribed to to the client, up to the QoS limit. If you assume\\r\\nmessages aren't very big and bandwidth is high, it's likely Rabbit\\r\\nwill be able to send messages to your consuming client faster than\\r\\nyour client can process them. Thus it's reasonable (and simpler) to do\\r\\nall the maths from the assumption of a full client-side buffer.) If\\r\\neach message takes 4ms of processing to deal with then it'll take a\\r\\ntotal of \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"26 * 4 = 104ms\"\n      }), \" to deal with the entire buffer. The first\\r\\n4ms is the client processing of the first message. The client then\\r\\nissues an \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"ack\"\n      }), \" and goes on to process the next message from the\\r\\nbuffer. That ack takes 50ms to get to the broker. The broker than\\r\\nissues a new message to the client, which takes 50ms to get there, so\\r\\nby the time 104ms has passed and the client has finished processing\\r\\nits buffer, the next message from the broker has already arrived and\\r\\nis ready and waiting for the client to process it. Thus the client\\r\\nremains busy all the time: having a bigger QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" will not\\r\\nmake it go faster; but we minimise the buffer size and thus latency of\\r\\nmessages in the client: messages are buffered by the client for no\\r\\nlonger than they need to be in order to keep the client saturated with\\r\\nwork. In fact, the client is able to fully drain the buffer before the\\r\\nnext message arrives, thus the buffer actually stays empty.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"This solution is absolutely fine, provided processing time and network\\r\\nbehaviour remains the same. But consider what happens if suddenly the\\r\\nnetwork halves in speed: your \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" buffer is no longer big\\r\\nenough and now the client will sit idle, waiting for new messages to\\r\\narrive as the client is able to process messages faster than Rabbit\\r\\ncan supply fresh messages.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"To address this problem, we might just decide to double (or nearly\\r\\ndouble) the QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" size. If we push it to 51 from 26, then if\\r\\nthe client processing remains at 4ms per message, we now have \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"51 * 4 = 204ms\"\n      }), \" of messages in the buffer, of which 4ms will be spent\\r\\nprocessing a message, leaving 200ms for the sending an ack back to\\r\\nRabbit and receiving the next message. Thus we can now cope with the\\r\\nnetwork halving in speed.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"But if the network's performing normally, doubling our QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \"\\r\\nnow means each message will sit in the client side buffer for a while,\\r\\ninstead of being processed immediately upon arrival at the\\r\\nclient. Again, starting from a full buffer of now 51 messages we know\\r\\nthat new messages will start appearing at the client 100ms after the\\r\\nclient finishes processing the first message. But in those 100ms, the\\r\\nclient will have processed \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"100 / 4 = 25\"\n      }), \" messages out of the 50\\r\\navailable. Which means as a new message arrives at the client, it'll\\r\\nbe added to the end of the buffer as the client removes from the head\\r\\nof the buffer. The buffer will thus always stay \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"50 - 25 = 25\"\n      }), \"\\r\\nmessages long and every message will thus sit in the buffer for \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"25 * 4 = 100ms\"\n      }), \", increasing the latency between Rabbit sending it to the\\r\\nclient and the client starting to process it from 50ms to 150ms.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"Thus we see that increasing the \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" buffer so that the client\\r\\ncan cope with deteriorated network performance whilst keeping the\\r\\nclient busy, substantially increases the latency when the network is\\r\\nperforming normally.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"Equally, rather than the network's performance deteriorating, what\\r\\nhappens if the client starts taking 40ms to process each message\\r\\nrather than 4ms? If the queue in Rabbit was previously at a steady\\r\\nlength (i.e. ingress and egress rates were the same), it'll now start\\r\\ngrowing rapidly, as the egress rate has dropped to a tenth of what it\\r\\nwas. You might decide to try and work through this growing backlog by\\r\\nadding more consumers, but there are messages now being buffered by\\r\\nthe existing clients. Assuming the original buffer size of 26\\r\\nmessages, the client will spend 40ms processing the first message,\\r\\nwill then send the ack back to Rabbit and move onto the next\\r\\nmessage. The ack still takes 50ms to get to Rabbit and a further 50ms\\r\\nfor Rabbit to send out a new message, but in that 100ms, the client\\r\\nhas only worked through \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"100 / 40 = 2.5\"\n      }), \" further messages rather than\\r\\nthe remaining 25 messages. Thus the buffer is at this point \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"25 - 3 = 22\"\n      }), \" messages long. The new message arriving from Rabbit, rather than\\r\\nbeing processed immediately, now sits in 23rd place, behind 22 other\\r\\nmessages still waiting to be processed, and will not be touched by the\\r\\nclient for a further \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"22 * 40 = 880ms\"\n      }), \". Given the network delay from\\r\\nRabbit to the client is only 50ms, this additional 880ms delay is now\\r\\n95% of the latency (\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"880 / (880 + 50) = 0.946\"\n      }), \").\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"Even worse, what happens if we doubled the buffer size to 51 messages\\r\\nin order to cope with network performance degradation? After the first\\r\\nmessage has been processed, there will be 50 further messages buffered\\r\\nin the client. 100ms later (assuming the network is running normally),\\r\\na new message will arrive from Rabbit, and the client will be half way\\r\\nthrough processing the 3rd of those 50 messages (the buffer will now\\r\\nbe 47 messages long), thus the new message will be 48th in the buffer,\\r\\nand will not be touched for a further \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"47 * 40 = 1880ms\"\n      }), \". Again, given\\r\\nthe network delay of getting the message to the client is only 50ms,\\r\\nthis further 1880ms delay now means client side buffering is\\r\\nresponsible for over 97% of the latency (\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"1880 / (1880 + 50) = 0.974\"\n      }), \"). This may very well be unacceptable: the data may only be\\r\\nvalid and useful if it's processed promptly, not some 2 seconds after\\r\\nthe client received it! If other consuming clients are idle, there's\\r\\nnothing they can do: once Rabbit has sent a message to a client, the\\r\\nmessage is the client's responsibility until it acks or rejects the\\r\\nmessage. Clients can't steal messages from each other once the message\\r\\nhas been sent to a client. What you want is for clients to be kept\\r\\nbusy, but for clients to buffer as few messages as possible so that\\r\\nmessages are not delayed by client-side buffers and thus new consuming\\r\\nclients can be quickly fed with messages from Rabbit's queue.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"So, too small a buffer results in clients going idle if the network\\r\\ngets slower, but too big a buffer results in lots of extra latency if\\r\\nthe network performs normally, and huge amounts of extra latency if\\r\\nthe client suddenly starts taking longer to process each message than\\r\\nnormal. It's clear that what you really want is a varying buffer\\r\\nsize. These problems are common across network devices and have been\\r\\nthe subject of much study. \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.em, {\n        children: \"Active Queue Management\"\n      }), \" algorithms seek\\r\\nto try and drop or reject messages so that you avoid messages sitting\\r\\nin buffers for long periods of time. The lowest latency is achieved\\r\\nwhen the buffer is kept empty (each message suffers network latency\\r\\nonly and does not sit around in a buffer at all) and buffers are there\\r\\nto absorb spikes. \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.a, {\n        href: \"http://gettys.wordpress.com/\",\n        children: \"Jim Gettys\"\n      }), \" has been\\r\\nworking on this problem from the point of view of network routers:\\r\\ndifferences between performance of the LAN and the WAN suffer exactly\\r\\nthe same sorts of problems. Indeed whenever you have a buffer between\\r\\na producer (in our case Rabbit) and a consumer (the client-side\\r\\napplication logic) where the performance of both sides can vary\\r\\ndynamically, you will suffer these sorts of problems. Recently a new\\r\\nalgorithm called\\r\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.a, {\n        href: \"https://queue.acm.org/detail.cfm?id=2209336\",\n        children: \"Controlled Delay\"\n      }), \" has\\r\\nbeen published which\\r\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.a, {\n        href: \"http://arstechnica.com/information-technology/2012/05/codel-buffer-management-could-solve-the-internets-bufferbloat-jams/\",\n        children: \"appears to work well\"\n      }), \"\\r\\nin solving these problems.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"The authors claim that their \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.em, {\n        children: \"CoDel\"\n      }), \" (\\\"coddle\\\") algorithm is a \\\"knob\\r\\nfree\\\" algorithm. This is a bit of a lie really: there are two knobs\\r\\nand they do need setting appropriately. But they don't need changing\\r\\nevery time performance changes, which is a massive benefit. I have\\r\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.a, {\n        href: \"https://gist.github.com/2658712\",\n        children: \"implemented this algorithm\"\n      }), \" for our\\r\\nAMQP Java Client as a variant of the QueueingConsumer. Whilst the\\r\\noriginal algorithm is aimed at the TCP layer, where it's valid to just\\r\\ndrop packets (TCP itself will take care\\r\\nof re-transmission of lost packets), in AMQP that's not so polite! As a result,\\r\\nmy implementation uses Rabbit's \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"basic.nack\"\n      }), \" extension to explicitly\\r\\nreturn messages to the queue so they can be processed by others.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [(0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.a, {\n        href: \"https://gist.github.com/2658727\",\n        children: \"Using it is pretty much the same\"\n      }), \" as\\r\\nthe normal QueueingConsumer except that you should provide three extra\\r\\nparameters to the constructor to get the best performance.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.ol, {\n      children: [\"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.li, {\n        children: [\"The first is \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n          children: \"requeue\"\n        }), \" which says whether, when messages are\\r\\nnacked, should they be requeued or discarded. If false, they will\\r\\nbe discarded which may trigger the dead letter exchange mechanisms\\r\\nif they're set up.\"]\n      }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.li, {\n        children: [\"The second is the \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n          children: \"targetDelay\"\n        }), \" which is the acceptable time in\\r\\nmilliseconds for messages to wait in the client-side QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n          children: \"prefetch\"\n        }), \"\\r\\nbuffer.\"]\n      }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.li, {\n        children: [\"The third is the \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n          children: \"interval\"\n        }), \" and is the expected worst case\\r\\nprocessing time of one message in milliseconds. This doesn't have\\r\\nto be spot on, but within an order of magnitude certainly helps.\"]\n      }), \"\\n\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"You should still set a QoS \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"prefetch\"\n      }), \" size appropriately. If you do\\r\\nnot, what is likely is that the client will be sent a lot of messages,\\r\\nand the algorithm will then have to return them to Rabbit if they sit\\r\\nin the buffer for too long. It's easy to end up with a lot of extra\\r\\nnetwork traffic as messages are returned to Rabbit. The CoDel\\r\\nalgorithm is meant to only start dropping (or rejecting) messages once\\r\\nperformance diverges from the norm, thus a worked example might help.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsxs)(_components.p, {\n      children: [\"Again, assume network traversal time in each direction of 50ms, and we\\r\\nexpect the client to spend 4ms on average processing each message, but\\r\\nthis can spike to 20ms. We thus set the \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"interval\"\n      }), \" parameter of CoDel\\r\\nto 20. Sometimes the network halves in speed, so the traversal time\\r\\ncan be 100ms in each direction. To cater for that, we set the\\r\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"basic.qos prefetch\"\n      }), \" to \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"204 / 4 = 51\"\n      }), \". Yes, this means that the\\r\\nbuffer will remain 25 messages long most of the time when the network\\r\\nis running normally (see workings earlier), but we decide that's\\r\\nOK. Each message will thus sit in the buffer for an expected \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"25 * 4 = 100ms\"\n      }), \", so we set the \", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.code, {\n        children: \"targetDelay\"\n      }), \" of CoDel to 100.\"]\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.p, {\n      children: \"When things are running normally, CoDel should not get in the way, and\\r\\nfew if any messages should be being nacked. But should the client\\r\\nstart processing messages more slowly than normal, CoDel will spot\\r\\nthat messages have been buffered by the client for too long, and will\\r\\nreturn those messages to the queue. If those messages are requeued\\r\\nthen they will become available for delivery to other clients.\"\n    }), \"\\n\", (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_components.p, {\n      children: \"This is very much experimental at the moment, and it's possible to see\\r\\nreasons why CoDel isn't as appropriate for dealing with AMQP messages\\r\\nas it is for plain IP. It's also worth remembering that requeuing\\r\\nmessages via nacks is a fairly expensive operation, so it's a good\\r\\nidea to set the parameters of CoDel to ensure in normal operation very\\r\\nfew if any messages are being nacked. The management plugin is an easy\\r\\nway to inspect how many messages are being nacked. As ever, comments,\\r\\nfeedback and improvements are most welcome!\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = {\n    ...(0,_mdx_js_react__WEBPACK_IMPORTED_MODULE_2__.useMDXComponents)(),\n    ...props.components\n  };\n  return MDXLayout ? (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(MDXLayout, {\n    ...props,\n    children: (0,react_jsx_runtime__WEBPACK_IMPORTED_MODULE_1__.jsx)(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\n\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"file":"./blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md","mappings":";;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://rabbitmq-website/./blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md?4ee6"],"sourcesContent":["\n\nexport const frontMatter = {\n\ttitle: 'Some queuing theory: throughput, latency and bandwidth',\n\ttags: [\n\t\t'HowTo',\n\t\t'New Features'\n\t],\n\tauthors: [\n\t\t'matthew'\n\t]\n};\nexport const contentTitle = undefined;\nexport {default as metadata} from '@site/.docusaurus/docusaurus-plugin-content-blog/default/site-blog-2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth-index-md-e01.json'\nexport const assets = {\n\"authorsImageUrls\": [undefined],\n};\n\nimport {Fragment as _Fragment, jsx as _jsx, jsxs as _jsxs} from \"react/jsx-runtime\";\nimport {useMDXComponents as _provideComponents} from \"@mdx-js/react\";\nexport const toc = [];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    code: \"code\",\n    em: \"em\",\n    img: \"img\",\n    li: \"li\",\n    ol: \"ol\",\n    p: \"p\",\n    ..._provideComponents(),\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsxs(_components.p, {\n      children: [\"You have a queue in Rabbit. You have some clients consuming from that\\r\\nqueue. If you don't set a QoS setting at all (\", _jsx(_components.code, {\n        children: \"basic.qos\"\n      }), \"), then\\r\\nRabbit will push all the queue's messages to the clients as fast as\\r\\nthe network and the clients will allow. The consumers will balloon in\\r\\nmemory as they buffer all the messages in their own RAM. The queue may\\r\\nappear empty if you ask Rabbit, but there may be millions of messages\\r\\nunacknowledged as they sit in the clients, ready for processing by the\\r\\nclient application. If you add a new consumer, there are no messages\\r\\nleft in the queue to be sent to the new consumer. Messages are just\\r\\nbeing buffered in the existing clients, and may be there for a long\\r\\ntime, even if there are other consumers that become available to\\r\\nprocess such messages sooner. This is rather sub optimal.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"So, the default QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" setting gives clients an \", _jsx(_components.em, {\n        children: \"unlimited\"\n      }), \"\\r\\nbuffer, and that can result in poor behaviour and performance. But\\r\\nwhat should you set the QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" buffer size to? The goal is to\\r\\nkeep the consumers saturated with work, but to minimise the client's\\r\\nbuffer size so that more messages stay in Rabbit's queue and are thus\\r\\navailable for new consumers or to just be sent out to consumers as\\r\\nthey become free.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Let's say it takes 50ms for Rabbit to take a message from this queue,\\r\\nput it on the network and for it to arrive at the consumer. It takes\\r\\n4ms for the client to process the message. Once the consumer has\\r\\nprocessed the message, it sends an \", _jsx(_components.code, {\n        children: \"ack\"\n      }), \" back to Rabbit, which takes a\\r\\nfurther 50ms to be sent to and processed by Rabbit. So we have a total\\r\\nround trip time of 104ms. If we have a QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" setting of 1\\r\\nmessage then Rabbit won't sent out the next message until after this\\r\\nround trip completes. Thus the client will be busy for only 4ms of\\r\\nevery 104ms, or 3.8% of the time. We want it to be busy 100% of the\\r\\ntime.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: require(\"!/mnt/d/xy2401/codeDoc/rabbitmq-website/node_modules/url-loader/dist/cjs.js?limit=10000&name=assets/images/[name]-[contenthash].[ext]&fallback=/mnt/d/xy2401/codeDoc/rabbitmq-website/node_modules/file-loader/dist/cjs.js!./qos.svg\").default + \"\",\n        width: \"693\",\n        height: \"178\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"If we do \", _jsx(_components.em, {\n        children: \"total round trip time\"\n      }), \" / \", _jsx(_components.em, {\n        children: \"processing time on the client for\\r\\neach message\"\n      }), \", we get \", _jsx(_components.code, {\n        children: \"104 / 4 = 26\"\n      }), \". If we have a QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" of\\r\\n26 messages this solves our problem: assume that the client has 26\\r\\nmessages buffered, ready and waiting for processing. (This is a\\r\\nsensible assumption: once you set \", _jsx(_components.code, {\n        children: \"basic.qos\"\n      }), \" and then \", _jsx(_components.code, {\n        children: \"consume\"\n      }), \" from\\r\\na queue, Rabbit will send as many messages as it can from the queue\\r\\nyou've subscribed to to the client, up to the QoS limit. If you assume\\r\\nmessages aren't very big and bandwidth is high, it's likely Rabbit\\r\\nwill be able to send messages to your consuming client faster than\\r\\nyour client can process them. Thus it's reasonable (and simpler) to do\\r\\nall the maths from the assumption of a full client-side buffer.) If\\r\\neach message takes 4ms of processing to deal with then it'll take a\\r\\ntotal of \", _jsx(_components.code, {\n        children: \"26 * 4 = 104ms\"\n      }), \" to deal with the entire buffer. The first\\r\\n4ms is the client processing of the first message. The client then\\r\\nissues an \", _jsx(_components.code, {\n        children: \"ack\"\n      }), \" and goes on to process the next message from the\\r\\nbuffer. That ack takes 50ms to get to the broker. The broker than\\r\\nissues a new message to the client, which takes 50ms to get there, so\\r\\nby the time 104ms has passed and the client has finished processing\\r\\nits buffer, the next message from the broker has already arrived and\\r\\nis ready and waiting for the client to process it. Thus the client\\r\\nremains busy all the time: having a bigger QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" will not\\r\\nmake it go faster; but we minimise the buffer size and thus latency of\\r\\nmessages in the client: messages are buffered by the client for no\\r\\nlonger than they need to be in order to keep the client saturated with\\r\\nwork. In fact, the client is able to fully drain the buffer before the\\r\\nnext message arrives, thus the buffer actually stays empty.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"This solution is absolutely fine, provided processing time and network\\r\\nbehaviour remains the same. But consider what happens if suddenly the\\r\\nnetwork halves in speed: your \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" buffer is no longer big\\r\\nenough and now the client will sit idle, waiting for new messages to\\r\\narrive as the client is able to process messages faster than Rabbit\\r\\ncan supply fresh messages.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"To address this problem, we might just decide to double (or nearly\\r\\ndouble) the QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" size. If we push it to 51 from 26, then if\\r\\nthe client processing remains at 4ms per message, we now have \", _jsx(_components.code, {\n        children: \"51 * 4 = 204ms\"\n      }), \" of messages in the buffer, of which 4ms will be spent\\r\\nprocessing a message, leaving 200ms for the sending an ack back to\\r\\nRabbit and receiving the next message. Thus we can now cope with the\\r\\nnetwork halving in speed.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"But if the network's performing normally, doubling our QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \"\\r\\nnow means each message will sit in the client side buffer for a while,\\r\\ninstead of being processed immediately upon arrival at the\\r\\nclient. Again, starting from a full buffer of now 51 messages we know\\r\\nthat new messages will start appearing at the client 100ms after the\\r\\nclient finishes processing the first message. But in those 100ms, the\\r\\nclient will have processed \", _jsx(_components.code, {\n        children: \"100 / 4 = 25\"\n      }), \" messages out of the 50\\r\\navailable. Which means as a new message arrives at the client, it'll\\r\\nbe added to the end of the buffer as the client removes from the head\\r\\nof the buffer. The buffer will thus always stay \", _jsx(_components.code, {\n        children: \"50 - 25 = 25\"\n      }), \"\\r\\nmessages long and every message will thus sit in the buffer for \", _jsx(_components.code, {\n        children: \"25 * 4 = 100ms\"\n      }), \", increasing the latency between Rabbit sending it to the\\r\\nclient and the client starting to process it from 50ms to 150ms.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Thus we see that increasing the \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" buffer so that the client\\r\\ncan cope with deteriorated network performance whilst keeping the\\r\\nclient busy, substantially increases the latency when the network is\\r\\nperforming normally.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Equally, rather than the network's performance deteriorating, what\\r\\nhappens if the client starts taking 40ms to process each message\\r\\nrather than 4ms? If the queue in Rabbit was previously at a steady\\r\\nlength (i.e. ingress and egress rates were the same), it'll now start\\r\\ngrowing rapidly, as the egress rate has dropped to a tenth of what it\\r\\nwas. You might decide to try and work through this growing backlog by\\r\\nadding more consumers, but there are messages now being buffered by\\r\\nthe existing clients. Assuming the original buffer size of 26\\r\\nmessages, the client will spend 40ms processing the first message,\\r\\nwill then send the ack back to Rabbit and move onto the next\\r\\nmessage. The ack still takes 50ms to get to Rabbit and a further 50ms\\r\\nfor Rabbit to send out a new message, but in that 100ms, the client\\r\\nhas only worked through \", _jsx(_components.code, {\n        children: \"100 / 40 = 2.5\"\n      }), \" further messages rather than\\r\\nthe remaining 25 messages. Thus the buffer is at this point \", _jsx(_components.code, {\n        children: \"25 - 3 = 22\"\n      }), \" messages long. The new message arriving from Rabbit, rather than\\r\\nbeing processed immediately, now sits in 23rd place, behind 22 other\\r\\nmessages still waiting to be processed, and will not be touched by the\\r\\nclient for a further \", _jsx(_components.code, {\n        children: \"22 * 40 = 880ms\"\n      }), \". Given the network delay from\\r\\nRabbit to the client is only 50ms, this additional 880ms delay is now\\r\\n95% of the latency (\", _jsx(_components.code, {\n        children: \"880 / (880 + 50) = 0.946\"\n      }), \").\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Even worse, what happens if we doubled the buffer size to 51 messages\\r\\nin order to cope with network performance degradation? After the first\\r\\nmessage has been processed, there will be 50 further messages buffered\\r\\nin the client. 100ms later (assuming the network is running normally),\\r\\na new message will arrive from Rabbit, and the client will be half way\\r\\nthrough processing the 3rd of those 50 messages (the buffer will now\\r\\nbe 47 messages long), thus the new message will be 48th in the buffer,\\r\\nand will not be touched for a further \", _jsx(_components.code, {\n        children: \"47 * 40 = 1880ms\"\n      }), \". Again, given\\r\\nthe network delay of getting the message to the client is only 50ms,\\r\\nthis further 1880ms delay now means client side buffering is\\r\\nresponsible for over 97% of the latency (\", _jsx(_components.code, {\n        children: \"1880 / (1880 + 50) = 0.974\"\n      }), \"). This may very well be unacceptable: the data may only be\\r\\nvalid and useful if it's processed promptly, not some 2 seconds after\\r\\nthe client received it! If other consuming clients are idle, there's\\r\\nnothing they can do: once Rabbit has sent a message to a client, the\\r\\nmessage is the client's responsibility until it acks or rejects the\\r\\nmessage. Clients can't steal messages from each other once the message\\r\\nhas been sent to a client. What you want is for clients to be kept\\r\\nbusy, but for clients to buffer as few messages as possible so that\\r\\nmessages are not delayed by client-side buffers and thus new consuming\\r\\nclients can be quickly fed with messages from Rabbit's queue.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"So, too small a buffer results in clients going idle if the network\\r\\ngets slower, but too big a buffer results in lots of extra latency if\\r\\nthe network performs normally, and huge amounts of extra latency if\\r\\nthe client suddenly starts taking longer to process each message than\\r\\nnormal. It's clear that what you really want is a varying buffer\\r\\nsize. These problems are common across network devices and have been\\r\\nthe subject of much study. \", _jsx(_components.em, {\n        children: \"Active Queue Management\"\n      }), \" algorithms seek\\r\\nto try and drop or reject messages so that you avoid messages sitting\\r\\nin buffers for long periods of time. The lowest latency is achieved\\r\\nwhen the buffer is kept empty (each message suffers network latency\\r\\nonly and does not sit around in a buffer at all) and buffers are there\\r\\nto absorb spikes. \", _jsx(_components.a, {\n        href: \"http://gettys.wordpress.com/\",\n        children: \"Jim Gettys\"\n      }), \" has been\\r\\nworking on this problem from the point of view of network routers:\\r\\ndifferences between performance of the LAN and the WAN suffer exactly\\r\\nthe same sorts of problems. Indeed whenever you have a buffer between\\r\\na producer (in our case Rabbit) and a consumer (the client-side\\r\\napplication logic) where the performance of both sides can vary\\r\\ndynamically, you will suffer these sorts of problems. Recently a new\\r\\nalgorithm called\\r\\n\", _jsx(_components.a, {\n        href: \"https://queue.acm.org/detail.cfm?id=2209336\",\n        children: \"Controlled Delay\"\n      }), \" has\\r\\nbeen published which\\r\\n\", _jsx(_components.a, {\n        href: \"http://arstechnica.com/information-technology/2012/05/codel-buffer-management-could-solve-the-internets-bufferbloat-jams/\",\n        children: \"appears to work well\"\n      }), \"\\r\\nin solving these problems.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The authors claim that their \", _jsx(_components.em, {\n        children: \"CoDel\"\n      }), \" (\\\"coddle\\\") algorithm is a \\\"knob\\r\\nfree\\\" algorithm. This is a bit of a lie really: there are two knobs\\r\\nand they do need setting appropriately. But they don't need changing\\r\\nevery time performance changes, which is a massive benefit. I have\\r\\n\", _jsx(_components.a, {\n        href: \"https://gist.github.com/2658712\",\n        children: \"implemented this algorithm\"\n      }), \" for our\\r\\nAMQP Java Client as a variant of the QueueingConsumer. Whilst the\\r\\noriginal algorithm is aimed at the TCP layer, where it's valid to just\\r\\ndrop packets (TCP itself will take care\\r\\nof re-transmission of lost packets), in AMQP that's not so polite! As a result,\\r\\nmy implementation uses Rabbit's \", _jsx(_components.code, {\n        children: \"basic.nack\"\n      }), \" extension to explicitly\\r\\nreturn messages to the queue so they can be processed by others.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.a, {\n        href: \"https://gist.github.com/2658727\",\n        children: \"Using it is pretty much the same\"\n      }), \" as\\r\\nthe normal QueueingConsumer except that you should provide three extra\\r\\nparameters to the constructor to get the best performance.\"]\n    }), \"\\n\", _jsxs(_components.ol, {\n      children: [\"\\n\", _jsxs(_components.li, {\n        children: [\"The first is \", _jsx(_components.code, {\n          children: \"requeue\"\n        }), \" which says whether, when messages are\\r\\nnacked, should they be requeued or discarded. If false, they will\\r\\nbe discarded which may trigger the dead letter exchange mechanisms\\r\\nif they're set up.\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"The second is the \", _jsx(_components.code, {\n          children: \"targetDelay\"\n        }), \" which is the acceptable time in\\r\\nmilliseconds for messages to wait in the client-side QoS \", _jsx(_components.code, {\n          children: \"prefetch\"\n        }), \"\\r\\nbuffer.\"]\n      }), \"\\n\", _jsxs(_components.li, {\n        children: [\"The third is the \", _jsx(_components.code, {\n          children: \"interval\"\n        }), \" and is the expected worst case\\r\\nprocessing time of one message in milliseconds. This doesn't have\\r\\nto be spot on, but within an order of magnitude certainly helps.\"]\n      }), \"\\n\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"You should still set a QoS \", _jsx(_components.code, {\n        children: \"prefetch\"\n      }), \" size appropriately. If you do\\r\\nnot, what is likely is that the client will be sent a lot of messages,\\r\\nand the algorithm will then have to return them to Rabbit if they sit\\r\\nin the buffer for too long. It's easy to end up with a lot of extra\\r\\nnetwork traffic as messages are returned to Rabbit. The CoDel\\r\\nalgorithm is meant to only start dropping (or rejecting) messages once\\r\\nperformance diverges from the norm, thus a worked example might help.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Again, assume network traversal time in each direction of 50ms, and we\\r\\nexpect the client to spend 4ms on average processing each message, but\\r\\nthis can spike to 20ms. We thus set the \", _jsx(_components.code, {\n        children: \"interval\"\n      }), \" parameter of CoDel\\r\\nto 20. Sometimes the network halves in speed, so the traversal time\\r\\ncan be 100ms in each direction. To cater for that, we set the\\r\\n\", _jsx(_components.code, {\n        children: \"basic.qos prefetch\"\n      }), \" to \", _jsx(_components.code, {\n        children: \"204 / 4 = 51\"\n      }), \". Yes, this means that the\\r\\nbuffer will remain 25 messages long most of the time when the network\\r\\nis running normally (see workings earlier), but we decide that's\\r\\nOK. Each message will thus sit in the buffer for an expected \", _jsx(_components.code, {\n        children: \"25 * 4 = 100ms\"\n      }), \", so we set the \", _jsx(_components.code, {\n        children: \"targetDelay\"\n      }), \" of CoDel to 100.\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"When things are running normally, CoDel should not get in the way, and\\r\\nfew if any messages should be being nacked. But should the client\\r\\nstart processing messages more slowly than normal, CoDel will spot\\r\\nthat messages have been buffered by the client for too long, and will\\r\\nreturn those messages to the queue. If those messages are requeued\\r\\nthen they will become available for delivery to other clients.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"This is very much experimental at the moment, and it's possible to see\\r\\nreasons why CoDel isn't as appropriate for dealing with AMQP messages\\r\\nas it is for plain IP. It's also worth remembering that requeuing\\r\\nmessages via nacks is a fairly expensive operation, so it's a good\\r\\nidea to set the parameters of CoDel to ensure in normal operation very\\r\\nfew if any messages are being nacked. The management plugin is an easy\\r\\nway to inspect how many messages are being nacked. As ever, comments,\\r\\nfeedback and improvements are most welcome!\"\n    })]\n  });\n}\nexport default function MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = {\n    ..._provideComponents(),\n    ...props.components\n  };\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\n\n"],"names":[],"sourceRoot":""}\n//# sourceURL=webpack-internal:///./blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md\n");

/***/ }),

/***/ "./node_modules/@mdx-js/react/lib/index.js":
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   MDXProvider: () => (/* binding */ MDXProvider),\n/* harmony export */   useMDXComponents: () => (/* binding */ useMDXComponents)\n/* harmony export */ });\n/* harmony import */ var react__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(\"./node_modules/react/index.js\");\n/**\n * @import {MDXComponents} from 'mdx/types.js'\n * @import {Component, ReactElement, ReactNode} from 'react'\n */\n\n/**\n * @callback MergeComponents\n *   Custom merge function.\n * @param {Readonly<MDXComponents>} currentComponents\n *   Current components from the context.\n * @returns {MDXComponents}\n *   Additional components.\n *\n * @typedef Props\n *   Configuration for `MDXProvider`.\n * @property {ReactNode | null | undefined} [children]\n *   Children (optional).\n * @property {Readonly<MDXComponents> | MergeComponents | null | undefined} [components]\n *   Additional components to use or a function that creates them (optional).\n * @property {boolean | null | undefined} [disableParentContext=false]\n *   Turn off outer component context (default: `false`).\n */\n\n\n\n/** @type {Readonly<MDXComponents>} */\nconst emptyComponents = {}\n\nconst MDXContext = react__WEBPACK_IMPORTED_MODULE_0__.createContext(emptyComponents)\n\n/**\n * Get current components from the MDX Context.\n *\n * @param {Readonly<MDXComponents> | MergeComponents | null | undefined} [components]\n *   Additional components to use or a function that creates them (optional).\n * @returns {MDXComponents}\n *   Current components.\n */\nfunction useMDXComponents(components) {\n  const contextComponents = react__WEBPACK_IMPORTED_MODULE_0__.useContext(MDXContext)\n\n  // Memoize to avoid unnecessary top-level context changes\n  return react__WEBPACK_IMPORTED_MODULE_0__.useMemo(\n    function () {\n      // Custom merge via a function prop\n      if (typeof components === 'function') {\n        return components(contextComponents)\n      }\n\n      return {...contextComponents, ...components}\n    },\n    [contextComponents, components]\n  )\n}\n\n/**\n * Provider for MDX context.\n *\n * @param {Readonly<Props>} properties\n *   Properties.\n * @returns {ReactElement}\n *   Element.\n * @satisfies {Component}\n */\nfunction MDXProvider(properties) {\n  /** @type {Readonly<MDXComponents>} */\n  let allComponents\n\n  if (properties.disableParentContext) {\n    allComponents =\n      typeof properties.components === 'function'\n        ? properties.components(emptyComponents)\n        : properties.components || emptyComponents\n  } else {\n    allComponents = useMDXComponents(properties.components)\n  }\n\n  return react__WEBPACK_IMPORTED_MODULE_0__.createElement(\n    MDXContext.Provider,\n    {value: allComponents},\n    properties.children\n  )\n}\n//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,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\n//# sourceURL=webpack-internal:///./node_modules/@mdx-js/react/lib/index.js\n");

/***/ }),

/***/ "./node_modules/url-loader/dist/cjs.js?limit=10000&name=assets/images/[name]-[contenthash].[ext]&fallback=/mnt/d/xy2401/codeDoc/rabbitmq-website/node_modules/file-loader/dist/cjs.js!./blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/qos.svg":
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (__webpack_require__.p + \"assets/images/qos-795ea277e045793fafb2110f19e34633.svg\");//# sourceURL=[module]\n//# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiLi9ub2RlX21vZHVsZXMvdXJsLWxvYWRlci9kaXN0L2Nqcy5qcz9saW1pdD0xMDAwMCZuYW1lPWFzc2V0cy9pbWFnZXMvW25hbWVdLVtjb250ZW50aGFzaF0uW2V4dF0mZmFsbGJhY2s9L21udC9kL3h5MjQwMS9jb2RlRG9jL3JhYmJpdG1xLXdlYnNpdGUvbm9kZV9tb2R1bGVzL2ZpbGUtbG9hZGVyL2Rpc3QvY2pzLmpzIS4vYmxvZy8yMDEyLTA1LTExLXNvbWUtcXVldWluZy10aGVvcnktdGhyb3VnaHB1dC1sYXRlbmN5LWFuZC1iYW5kd2lkdGgvcW9zLnN2ZyIsIm1hcHBpbmdzIjoiOzs7O0FBQUEiLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly9yYWJiaXRtcS13ZWJzaXRlLy4vYmxvZy8yMDEyLTA1LTExLXNvbWUtcXVldWluZy10aGVvcnktdGhyb3VnaHB1dC1sYXRlbmN5LWFuZC1iYW5kd2lkdGgvcW9zLnN2Zz81MTRjIl0sInNvdXJjZXNDb250ZW50IjpbImV4cG9ydCBkZWZhdWx0IF9fd2VicGFja19wdWJsaWNfcGF0aF9fICsgXCJhc3NldHMvaW1hZ2VzL3Fvcy03OTVlYTI3N2UwNDU3OTNmYWZiMjExMGYxOWUzNDYzMy5zdmdcIjsiXSwibmFtZXMiOltdLCJzb3VyY2VSb290IjoiIn0=\n//# sourceURL=webpack-internal:///./node_modules/url-loader/dist/cjs.js?limit=10000&name=assets/images/[name]-[contenthash].[ext]&fallback=/mnt/d/xy2401/codeDoc/rabbitmq-website/node_modules/file-loader/dist/cjs.js!./blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/qos.svg\n");

/***/ })

}]);
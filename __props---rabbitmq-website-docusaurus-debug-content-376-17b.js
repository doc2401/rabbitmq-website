"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(globalThis["webpackChunkrabbitmq_website"] = globalThis["webpackChunkrabbitmq_website"] || []).push([["__props---rabbitmq-website-docusaurus-debug-content-376-17b"],{

/***/ "./.docusaurus/docusaurus-plugin-debug/default/p/rabbitmq-website-docusaurus-debug-content-525.json":
/***/ ((module) => {

module.exports = /*#__PURE__*/JSON.parse('{"allContent":{"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":"unreleased","badge":true,"noIndex":false,"className":"docs-version-current","path":"/rabbitmq-website/docs/next","tagsPath":"/rabbitmq-website/docs/next/tags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs","editUrlLocalized":"https://github.com/rabbitmq/rabbitmq-website/tree/main/i18n/en/docusaurus-plugin-content-docs/current","isLast":false,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/sidebarsDocs.js","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/docs","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs/current","docs":[{"id":"access-control","title":"Authentication, Authorisation, Access Control","description":"<!--","source":"@site/docs/access-control.md","sourceDirName":".","slug":"/access-control","permalink":"/rabbitmq-website/docs/next/access-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/access-control.md","tags":[],"version":"current","frontMatter":{"title":"Authentication, Authorisation, Access Control"},"sidebar":"docsSidebar","previous":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/next/vhosts"},"next":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/next/authentication"}},{"id":"ae","title":"Alternate Exchanges","description":"<!--","source":"@site/docs/ae.md","sourceDirName":".","slug":"/ae","permalink":"/rabbitmq-website/docs/next/ae","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/ae.md","tags":[],"version":"current","frontMatter":{"title":"Alternate Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/next/e2e"},"next":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/next/sender-selected"}},{"id":"alarms","title":"Memory and Disk Alarms","description":"<!--","source":"@site/docs/alarms.md","sourceDirName":".","slug":"/alarms","permalink":"/rabbitmq-website/docs/next/alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/alarms.md","tags":[],"version":"current","frontMatter":{"title":"Memory and Disk Alarms"},"sidebar":"docsSidebar","previous":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/next/memory-use/"},"next":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/next/memory"}},{"id":"amqp","title":"AMQP 1.0","description":"<!--","source":"@site/docs/amqp.md","sourceDirName":".","slug":"/amqp","permalink":"/rabbitmq-website/docs/next/amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/amqp.md","tags":[],"version":"current","frontMatter":{"title":"AMQP 1.0"},"sidebar":"docsSidebar","previous":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/next/protocols"},"next":{"title":"Connections","permalink":"/rabbitmq-website/docs/next/connections/"}},{"id":"auth-cache-backend","title":"RabbitMQ Access Control Cache Plugin","description":"<!--","source":"@site/docs/auth-cache-backend.md","sourceDirName":".","slug":"/auth-cache-backend","permalink":"/rabbitmq-website/docs/next/auth-cache-backend","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/auth-cache-backend.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Access Control Cache Plugin"},"sidebar":"docsSidebar","previous":{"title":"LDAP","permalink":"/rabbitmq-website/docs/next/ldap"},"next":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/next/auth-notification"}},{"id":"auth-notification","title":"Authentication Failure Notifications","description":"<!--","source":"@site/docs/auth-notification.md","sourceDirName":".","slug":"/auth-notification","permalink":"/rabbitmq-website/docs/next/auth-notification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/auth-notification.md","tags":[],"version":"current","frontMatter":{"title":"Authentication Failure Notifications"},"sidebar":"docsSidebar","previous":{"title":"Cache","permalink":"/rabbitmq-website/docs/next/auth-cache-backend"},"next":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/next/user-limits"}},{"id":"authentication","title":"Authentication Mechanisms","description":"<!--","source":"@site/docs/authentication.md","sourceDirName":".","slug":"/authentication","permalink":"/rabbitmq-website/docs/next/authentication","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/authentication.md","tags":[],"version":"current","frontMatter":{"title":"Authentication Mechanisms"},"sidebar":"docsSidebar","previous":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/next/access-control"},"next":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/next/passwords"}},{"id":"backup","title":"Backup and Restore","description":"<!--","source":"@site/docs/backup.md","sourceDirName":".","slug":"/backup","permalink":"/rabbitmq-website/docs/next/backup","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/backup.md","tags":[],"version":"current","frontMatter":{"title":"Backup and Restore"},"sidebar":"docsSidebar","previous":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/next/flow-control"},"next":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/next/runtime"}},{"id":"blue-green-upgrade","title":"Blue-Green Deployment","description":"<!--","source":"@site/docs/blue-green-upgrade.md","sourceDirName":".","slug":"/blue-green-upgrade","permalink":"/rabbitmq-website/docs/next/blue-green-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/blue-green-upgrade.md","tags":[],"version":"current","frontMatter":{"title":"Blue-Green Deployment"},"sidebar":"docsSidebar","previous":{"title":"Rolling Upgrade","permalink":"/rabbitmq-website/docs/next/rolling-upgrade"},"next":{"title":"Grow-Then-Shrink Upgrade","permalink":"/rabbitmq-website/docs/next/grow-then-shrink-upgrade"}},{"id":"build-server","title":"Server Build Instructions","description":"<!--","source":"@site/docs/build-server.md","sourceDirName":".","slug":"/build-server","permalink":"/rabbitmq-website/docs/next/build-server","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/build-server.md","tags":[],"version":"current","frontMatter":{"title":"Server Build Instructions","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"channels/index","title":"Channels","description":"<!--","source":"@site/docs/channels/index.md","sourceDirName":"channels","slug":"/channels/","permalink":"/rabbitmq-website/docs/next/channels/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/channels/index.md","tags":[],"version":"current","frontMatter":{"title":"Channels","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Streams","permalink":"/rabbitmq-website/docs/next/streams"},"next":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/next/reliability"}},{"id":"classic-queues","title":"Classic Queues","description":"<!--","source":"@site/docs/classic-queues.md","sourceDirName":".","slug":"/classic-queues","permalink":"/rabbitmq-website/docs/next/classic-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/classic-queues.md","tags":[],"version":"current","frontMatter":{"title":"Classic Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/next/quorum-queues/"},"next":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/next/ttl"}},{"id":"cli","title":"Command Line Tools","description":"<!--","source":"@site/docs/cli.md","sourceDirName":".","slug":"/cli","permalink":"/rabbitmq-website/docs/next/cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/cli.md","tags":[],"version":"current","frontMatter":{"title":"Command Line Tools"},"sidebar":"docsSidebar","previous":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/next/manage-rabbitmq"},"next":{"title":"Configuration","permalink":"/rabbitmq-website/docs/next/configure"}},{"id":"cluster-formation","title":"Cluster Formation and Peer Discovery","description":"<!--","source":"@site/docs/cluster-formation.md","sourceDirName":".","slug":"/cluster-formation","permalink":"/rabbitmq-website/docs/next/cluster-formation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/cluster-formation.md","tags":[],"version":"current","frontMatter":{"title":"Cluster Formation and Peer Discovery"},"sidebar":"docsSidebar","previous":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/next/clustering"},"next":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/next/partitions"}},{"id":"clustering","title":"Clustering Guide","description":"<!--","source":"@site/docs/clustering.md","sourceDirName":".","slug":"/clustering","permalink":"/rabbitmq-website/docs/next/clustering","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/clustering.md","tags":[],"version":"current","frontMatter":{"title":"Clustering Guide"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/next/troubleshooting-ssl"},"next":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/next/cluster-formation"}},{"id":"clustering-ssl","title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS","description":"<!--","source":"@site/docs/clustering-ssl.md","sourceDirName":".","slug":"/clustering-ssl","permalink":"/rabbitmq-website/docs/next/clustering-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/clustering-ssl.md","tags":[],"version":"current","frontMatter":{"title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS"},"sidebar":"docsSidebar","previous":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/next/partitions"},"next":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/next/ec2"}},{"id":"configure","title":"Configuration","description":"<!--","source":"@site/docs/configure.md","sourceDirName":".","slug":"/configure","permalink":"/rabbitmq-website/docs/next/configure","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/configure.md","tags":[],"version":"current","frontMatter":{"title":"Configuration"},"sidebar":"docsSidebar","previous":{"title":"CLI","permalink":"/rabbitmq-website/docs/next/cli"},"next":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/next/relocate"}},{"id":"confirms","title":"Consumer Acknowledgements and Publisher Confirms","description":"<!--","source":"@site/docs/confirms.md","sourceDirName":".","slug":"/confirms","permalink":"/rabbitmq-website/docs/next/confirms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/confirms.md","tags":[],"version":"current","frontMatter":{"title":"Consumer Acknowledgements and Publisher Confirms"},"sidebar":"docsSidebar","previous":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/next/reliability"},"next":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/next/distributed"}},{"id":"connection-blocked","title":"Blocked Connection Notifications","description":"<!--","source":"@site/docs/connection-blocked.md","sourceDirName":".","slug":"/connection-blocked","permalink":"/rabbitmq-website/docs/next/connection-blocked","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/connection-blocked.md","tags":[],"version":"current","frontMatter":{"title":"Blocked Connection Notifications"},"sidebar":"docsSidebar","previous":{"title":"Local random exchange","permalink":"/rabbitmq-website/docs/next/local-random-exchange"},"next":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/next/e2e"}},{"id":"connections/index","title":"Connections","description":"<!--","source":"@site/docs/connections/index.md","sourceDirName":"connections","slug":"/connections/","permalink":"/rabbitmq-website/docs/next/connections/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/connections/index.md","tags":[],"version":"current","frontMatter":{"title":"Connections"},"sidebar":"docsSidebar","previous":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/docs/next/amqp"},"next":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/next/conversions"}},{"id":"consumer-cancel","title":"Consumer Cancel Notification","description":"<!--","source":"@site/docs/consumer-cancel.md","sourceDirName":".","slug":"/consumer-cancel","permalink":"/rabbitmq-website/docs/next/consumer-cancel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/consumer-cancel.md","tags":[],"version":"current","frontMatter":{"title":"Consumer Cancel Notification"},"sidebar":"docsSidebar","previous":{"title":"Consumers","permalink":"/rabbitmq-website/docs/next/consumers"},"next":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/next/consumer-prefetch"}},{"id":"consumer-prefetch","title":"Consumer Prefetch","description":"<!--","source":"@site/docs/consumer-prefetch.md","sourceDirName":".","slug":"/consumer-prefetch","permalink":"/rabbitmq-website/docs/next/consumer-prefetch","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/consumer-prefetch.md","tags":[],"version":"current","frontMatter":{"title":"Consumer Prefetch"},"sidebar":"docsSidebar","previous":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/next/consumer-cancel"},"next":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/next/consumer-priority"}},{"id":"consumer-priority","title":"Consumer Priorities","description":"<!--","source":"@site/docs/consumer-priority.md","sourceDirName":".","slug":"/consumer-priority","permalink":"/rabbitmq-website/docs/next/consumer-priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/consumer-priority.md","tags":[],"version":"current","frontMatter":{"title":"Consumer Priorities"},"sidebar":"docsSidebar","previous":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/next/consumer-prefetch"},"next":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/next/nack"}},{"id":"consumers","title":"Consumers","description":"<!--","source":"@site/docs/consumers.md","sourceDirName":".","slug":"/consumers","permalink":"/rabbitmq-website/docs/next/consumers","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/consumers.md","tags":[],"version":"current","frontMatter":{"title":"Consumers","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/next/exchanges"},"next":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/next/consumer-cancel"}},{"id":"conversions","title":"Inter-Protocol Property Conversions","description":"<!--","source":"@site/docs/conversions.md","sourceDirName":".","slug":"/conversions","permalink":"/rabbitmq-website/docs/next/conversions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/conversions.md","tags":[],"version":"current","frontMatter":{"title":"Inter-Protocol Property Conversions"},"sidebar":"docsSidebar","previous":{"title":"Connections","permalink":"/rabbitmq-website/docs/next/connections/"},"next":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/next/heartbeats"}},{"id":"definitions","title":"Schema Definition Export and Import","description":"<!--","source":"@site/docs/definitions.md","sourceDirName":".","slug":"/definitions","permalink":"/rabbitmq-website/docs/next/definitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/definitions.md","tags":[],"version":"current","frontMatter":{"title":"Schema Definition Export and Import"},"sidebar":"docsSidebar","previous":{"title":"Khepri FAQ","permalink":"/rabbitmq-website/docs/next/metadata-store/khepri-faq"},"next":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/next/networking"}},{"id":"deprecated-features/index","title":"Deprecated Features","description":"<!--","source":"@site/docs/deprecated-features/index.md","sourceDirName":"deprecated-features","slug":"/deprecated-features/","permalink":"/rabbitmq-website/docs/next/deprecated-features/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/deprecated-features/index.md","tags":[],"version":"current","frontMatter":{"title":"Deprecated Features"},"sidebar":"docsSidebar","previous":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/next/feature-flags/"},"next":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/next/snapshots"}},{"id":"direct-reply-to","title":"Direct Reply-to","description":"<!--","source":"@site/docs/direct-reply-to.md","sourceDirName":".","slug":"/direct-reply-to","permalink":"/rabbitmq-website/docs/next/direct-reply-to","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/direct-reply-to.md","tags":[],"version":"current","frontMatter":{"title":"Direct Reply-to"},"sidebar":"docsSidebar","previous":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/next/exchanges"},"next":{"title":"Local random exchange","permalink":"/rabbitmq-website/docs/next/local-random-exchange"}},{"id":"disk-alarms","title":"Free Disk Space Alarms","description":"<!--","source":"@site/docs/disk-alarms.md","sourceDirName":".","slug":"/disk-alarms","permalink":"/rabbitmq-website/docs/next/disk-alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/disk-alarms.md","tags":[],"version":"current","frontMatter":{"title":"Free Disk Space Alarms"},"sidebar":"docsSidebar","previous":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/next/memory"},"next":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/next/flow-control"}},{"id":"distributed","title":"Distributed RabbitMQ","description":"<!--","source":"@site/docs/distributed.md","sourceDirName":".","slug":"/distributed","permalink":"/rabbitmq-website/docs/next/distributed","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/distributed.md","tags":[],"version":"current","frontMatter":{"title":"Distributed RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/next/confirms"},"next":{"title":"Plugins","permalink":"/rabbitmq-website/docs/next/plugins"}},{"id":"dlx","title":"Dead Letter Exchanges","description":"<!--","source":"@site/docs/dlx.md","sourceDirName":".","slug":"/dlx","permalink":"/rabbitmq-website/docs/next/dlx","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/dlx.md","tags":[],"version":"current","frontMatter":{"title":"Dead Letter Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/next/lazy-queues"},"next":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/next/priority"}},{"id":"download","title":"Installing RabbitMQ","description":"<!--","source":"@site/docs/download.md","sourceDirName":".","slug":"/download","permalink":"/rabbitmq-website/docs/next/download","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/download.md","tags":[],"version":"current","frontMatter":{"title":"Installing RabbitMQ","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Introduction","permalink":"/rabbitmq-website/docs/next/"},"next":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/next/which-erlang"}},{"id":"e2e","title":"Exchange to Exchange Bindings","description":"<!--","source":"@site/docs/e2e.md","sourceDirName":".","slug":"/e2e","permalink":"/rabbitmq-website/docs/next/e2e","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/e2e.md","tags":[],"version":"current","frontMatter":{"title":"Exchange to Exchange Bindings"},"sidebar":"docsSidebar","previous":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/next/connection-blocked"},"next":{"title":"Alternate Exchanges","permalink":"/rabbitmq-website/docs/next/ae"}},{"id":"ec2","title":"Running RabbitMQ on Amazon EC2","description":"<!--","source":"@site/docs/ec2.md","sourceDirName":".","slug":"/ec2","permalink":"/rabbitmq-website/docs/next/ec2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/ec2.md","tags":[],"version":"current","frontMatter":{"title":"Running RabbitMQ on Amazon EC2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/next/clustering-ssl"},"next":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/next/memory-use/"}},{"id":"event-exchange","title":"Event Exchange Plugin","description":"<!--","source":"@site/docs/event-exchange.md","sourceDirName":".","slug":"/event-exchange","permalink":"/rabbitmq-website/docs/next/event-exchange","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/event-exchange.md","tags":[],"version":"current","frontMatter":{"title":"Event Exchange Plugin"},"sidebar":"docsSidebar","previous":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/next/prometheus/"},"next":{"title":"Firehose Tracing","permalink":"/rabbitmq-website/docs/next/firehose"}},{"id":"exchanges","title":"Exchanges","description":"<!--","source":"@site/docs/exchanges.md","sourceDirName":".","slug":"/exchanges","permalink":"/rabbitmq-website/docs/next/exchanges","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/exchanges.md","tags":[],"version":"current","frontMatter":{"title":"Exchanges","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Publishers","permalink":"/rabbitmq-website/docs/next/publishers/"},"next":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/next/direct-reply-to"}},{"id":"extensions","title":"AMQP 0-9-1 Protocol Extensions","description":"<!--","source":"@site/docs/extensions.md","sourceDirName":".","slug":"/extensions","permalink":"/rabbitmq-website/docs/next/extensions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/extensions.md","tags":[],"version":"current","frontMatter":{"title":"AMQP 0-9-1 Protocol Extensions"},"sidebar":"docsSidebar","previous":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/next/heartbeats"},"next":{"title":"Intercepting Messages","permalink":"/rabbitmq-website/docs/next/message-interceptors"}},{"id":"feature-flags/index","title":"Feature Flags","description":"<!--","source":"@site/docs/feature-flags/index.md","sourceDirName":"feature-flags","slug":"/feature-flags/","permalink":"/rabbitmq-website/docs/next/feature-flags/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/feature-flags/index.md","tags":[],"version":"current","frontMatter":{"title":"Feature Flags"},"sidebar":"docsSidebar","previous":{"title":"Grow-Then-Shrink Upgrade","permalink":"/rabbitmq-website/docs/next/grow-then-shrink-upgrade"},"next":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/next/deprecated-features/"}},{"id":"federated-exchanges/index","title":"Federated Exchanges","description":"<!--","source":"@site/docs/federated-exchanges/index.md","sourceDirName":"federated-exchanges","slug":"/federated-exchanges/","permalink":"/rabbitmq-website/docs/next/federated-exchanges/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/federated-exchanges/index.md","tags":[],"version":"current","frontMatter":{"title":"Federated Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/next/federation"},"next":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/next/federated-queues/"}},{"id":"federated-queues/index","title":"Federated Queues","description":"<!--","source":"@site/docs/federated-queues/index.md","sourceDirName":"federated-queues","slug":"/federated-queues/","permalink":"/rabbitmq-website/docs/next/federated-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/federated-queues/index.md","tags":[],"version":"current","frontMatter":{"title":"Federated Queues"},"sidebar":"docsSidebar","previous":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/next/federated-exchanges/"},"next":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/next/federation-reference"}},{"id":"federation","title":"Federation Plugin","description":"<!--","source":"@site/docs/federation.md","sourceDirName":".","slug":"/federation","permalink":"/rabbitmq-website/docs/next/federation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/federation.md","tags":[],"version":"current","frontMatter":{"title":"Federation Plugin"},"sidebar":"docsSidebar","previous":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/next/management/"},"next":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/next/federated-exchanges/"}},{"id":"federation-reference","title":"Federation Reference","description":"<!--","source":"@site/docs/federation-reference.md","sourceDirName":".","slug":"/federation-reference","permalink":"/rabbitmq-website/docs/next/federation-reference","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/federation-reference.md","tags":[],"version":"current","frontMatter":{"title":"Federation Reference"},"sidebar":"docsSidebar","previous":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/next/federated-queues/"},"next":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/next/shovel"}},{"id":"firehose","title":"Firehose Tracer","description":"<!--","source":"@site/docs/firehose.md","sourceDirName":".","slug":"/firehose","permalink":"/rabbitmq-website/docs/next/firehose","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/firehose.md","tags":[],"version":"current","frontMatter":{"title":"Firehose Tracer"},"sidebar":"docsSidebar","previous":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/next/event-exchange"}},{"id":"flow-control","title":"Flow Control","description":"<!--","source":"@site/docs/flow-control.md","sourceDirName":".","slug":"/flow-control","permalink":"/rabbitmq-website/docs/next/flow-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/flow-control.md","tags":[],"version":"current","frontMatter":{"title":"Flow Control"},"sidebar":"docsSidebar","previous":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/next/disk-alarms"},"next":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/next/backup"}},{"id":"grow-then-shrink-upgrade","title":"Grow-then-Shrink Upgrade","description":"<!--","source":"@site/docs/grow-then-shrink-upgrade.md","sourceDirName":".","slug":"/grow-then-shrink-upgrade","permalink":"/rabbitmq-website/docs/next/grow-then-shrink-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/grow-then-shrink-upgrade.md","tags":[],"version":"current","frontMatter":{"title":"Grow-then-Shrink Upgrade"},"sidebar":"docsSidebar","previous":{"title":"Blue-Green Deployment","permalink":"/rabbitmq-website/docs/next/blue-green-upgrade"},"next":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/next/feature-flags/"}},{"id":"heartbeats","title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives","description":"<!--","source":"@site/docs/heartbeats.md","sourceDirName":".","slug":"/heartbeats","permalink":"/rabbitmq-website/docs/next/heartbeats","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/heartbeats.md","tags":[],"version":"current","frontMatter":{"title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives"},"sidebar":"docsSidebar","previous":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/next/conversions"},"next":{"title":"AMQP 0-9-1 Extensions","permalink":"/rabbitmq-website/docs/next/extensions"}},{"id":"http-api-reference","title":"HTTP API Reference","description":"<!--","source":"@site/docs/http-api-reference.md","sourceDirName":".","slug":"/http-api-reference","permalink":"/rabbitmq-website/docs/next/http-api-reference","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/http-api-reference.md","tags":[],"version":"current","frontMatter":{"title":"HTTP API Reference"}},{"id":"index","title":"RabbitMQ Documentation","description":"<!--","source":"@site/docs/index.md","sourceDirName":".","slug":"/","permalink":"/rabbitmq-website/docs/next/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/index.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Documentation"},"sidebar":"docsSidebar","next":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/next/download"}},{"id":"install-debian","title":"Installing on Debian and Ubuntu","description":"<!--","source":"@site/docs/install-debian.md","sourceDirName":".","slug":"/install-debian","permalink":"/rabbitmq-website/docs/next/install-debian","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-debian.md","tags":[],"version":"current","frontMatter":{"title":"Installing on Debian and Ubuntu","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/next/platforms"},"next":{"title":"RedHat","permalink":"/rabbitmq-website/docs/next/install-rpm"}},{"id":"install-generic-unix","title":"Generic Binary Build","description":"<!--","source":"@site/docs/install-generic-unix.md","sourceDirName":".","slug":"/install-generic-unix","permalink":"/rabbitmq-website/docs/next/install-generic-unix","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-generic-unix.md","tags":[],"version":"current","frontMatter":{"title":"Generic Binary Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"RedHat","permalink":"/rabbitmq-website/docs/next/install-rpm"},"next":{"title":"Windows","permalink":"/rabbitmq-website/docs/next/install-windows"}},{"id":"install-homebrew","title":"The Homebrew RabbitMQ Formula","description":"<!--","source":"@site/docs/install-homebrew.md","sourceDirName":".","slug":"/install-homebrew","permalink":"/rabbitmq-website/docs/next/install-homebrew","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-homebrew.md","tags":[],"version":"current","frontMatter":{"title":"The Homebrew RabbitMQ Formula","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/next/install-standalone-mac"},"next":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/next/upgrade"}},{"id":"install-rpm","title":"Installing on RPM-based Linux","description":"<!--","source":"@site/docs/install-rpm.md","sourceDirName":".","slug":"/install-rpm","permalink":"/rabbitmq-website/docs/next/install-rpm","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-rpm.md","tags":[],"version":"current","frontMatter":{"title":"Installing on RPM-based Linux","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/next/install-debian"},"next":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/next/install-generic-unix"}},{"id":"install-solaris","title":"Installing on Solaris","description":"<!--","source":"@site/docs/install-solaris.md","sourceDirName":".","slug":"/install-solaris","permalink":"/rabbitmq-website/docs/next/install-solaris","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-solaris.md","tags":[],"version":"current","frontMatter":{"title":"Installing on Solaris","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"install-standalone-mac","title":"Standalone MacOS Build","description":"<!--","source":"@site/docs/install-standalone-mac.md","sourceDirName":".","slug":"/install-standalone-mac","permalink":"/rabbitmq-website/docs/next/install-standalone-mac","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-standalone-mac.md","tags":[],"version":"current","frontMatter":{"title":"Standalone MacOS Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Windows","permalink":"/rabbitmq-website/docs/next/install-windows"},"next":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/next/install-homebrew"}},{"id":"install-windows","title":"Installing on Windows","description":"<!--","source":"@site/docs/install-windows.md","sourceDirName":".","slug":"/install-windows","permalink":"/rabbitmq-website/docs/next/install-windows","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-windows.md","tags":[],"version":"current","frontMatter":{"title":"Installing on Windows","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/next/install-generic-unix"},"next":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/next/install-standalone-mac"}},{"id":"install-windows-manual","title":"Installing on Windows manually","description":"<!--","source":"@site/docs/install-windows-manual.md","sourceDirName":".","slug":"/install-windows-manual","permalink":"/rabbitmq-website/docs/next/install-windows-manual","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/install-windows-manual.md","tags":[],"version":"current","frontMatter":{"title":"Installing on Windows manually","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"installing-plugins","title":"installing Additional Plugins","description":"<!--","source":"@site/docs/installing-plugins.md","sourceDirName":".","slug":"/installing-plugins","permalink":"/rabbitmq-website/docs/next/installing-plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/installing-plugins.md","tags":[],"version":"current","frontMatter":{"title":"installing Additional Plugins"},"sidebar":"docsSidebar","previous":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/next/stream"},"next":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/next/protocols"}},{"id":"lazy-queues","title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)","description":"<!--","source":"@site/docs/lazy-queues.md","sourceDirName":".","slug":"/lazy-queues","permalink":"/rabbitmq-website/docs/next/lazy-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/lazy-queues.md","tags":[],"version":"current","frontMatter":{"title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)"},"sidebar":"docsSidebar","previous":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/next/maxlength/"},"next":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/next/dlx"}},{"id":"ldap","title":"LDAP Support","description":"<!--","source":"@site/docs/ldap.md","sourceDirName":".","slug":"/ldap","permalink":"/rabbitmq-website/docs/next/ldap","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/ldap.md","tags":[],"version":"current","frontMatter":{"title":"LDAP Support"},"sidebar":"docsSidebar","previous":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/next/oauth2"},"next":{"title":"Cache","permalink":"/rabbitmq-website/docs/next/auth-cache-backend"}},{"id":"local-random-exchange","title":"Local Random Exchange","description":"<!--","source":"@site/docs/local-random-exchange.md","sourceDirName":".","slug":"/local-random-exchange","permalink":"/rabbitmq-website/docs/next/local-random-exchange","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/local-random-exchange.md","tags":[],"version":"current","frontMatter":{"title":"Local Random Exchange"},"sidebar":"docsSidebar","previous":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/next/direct-reply-to"},"next":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/next/connection-blocked"}},{"id":"logging","title":"Logging","description":"<!--","source":"@site/docs/logging.md","sourceDirName":".","slug":"/logging","permalink":"/rabbitmq-website/docs/next/logging","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/logging.md","tags":[],"version":"current","frontMatter":{"title":"Logging"},"sidebar":"docsSidebar","previous":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/next/relocate"},"next":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/next/vhosts"}},{"id":"man/rabbitmq-diagnostics.8","title":"rabbitmq-diagnostics.8","description":"NAME","source":"@site/docs/man/rabbitmq-diagnostics.8.md","sourceDirName":"man","slug":"/man/rabbitmq-diagnostics.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-diagnostics.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-diagnostics.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-echopid.8","title":"rabbitmq-echopid.8","description":"NAME","source":"@site/docs/man/rabbitmq-echopid.8.md","sourceDirName":"man","slug":"/man/rabbitmq-echopid.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-echopid.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-echopid.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-env.conf.5","title":"rabbitmq-env.conf.5","description":"NAME","source":"@site/docs/man/rabbitmq-env.conf.5.md","sourceDirName":"man","slug":"/man/rabbitmq-env.conf.5","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-env.conf.5","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-env.conf.5.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-plugins.8","title":"rabbitmq-plugins.8","description":"NAME","source":"@site/docs/man/rabbitmq-plugins.8.md","sourceDirName":"man","slug":"/man/rabbitmq-plugins.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-plugins.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-plugins.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-queues.8","title":"rabbitmq-queues.8","description":"NAME","source":"@site/docs/man/rabbitmq-queues.8.md","sourceDirName":"man","slug":"/man/rabbitmq-queues.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-queues.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-queues.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-server.8","title":"rabbitmq-server.8","description":"NAME","source":"@site/docs/man/rabbitmq-server.8.md","sourceDirName":"man","slug":"/man/rabbitmq-server.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-server.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-server.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-service.8","title":"rabbitmq-service.8","description":"NAME","source":"@site/docs/man/rabbitmq-service.8.md","sourceDirName":"man","slug":"/man/rabbitmq-service.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-service.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-service.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-streams.8","title":"rabbitmq-streams.8","description":"NAME","source":"@site/docs/man/rabbitmq-streams.8.md","sourceDirName":"man","slug":"/man/rabbitmq-streams.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-streams.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-streams.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmq-upgrade.8","title":"rabbitmq-upgrade.8","description":"NAME","source":"@site/docs/man/rabbitmq-upgrade.8.md","sourceDirName":"man","slug":"/man/rabbitmq-upgrade.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmq-upgrade.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmq-upgrade.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/rabbitmqctl.8","title":"rabbitmqctl.8","description":"NAME","source":"@site/docs/man/rabbitmqctl.8.md","sourceDirName":"man","slug":"/man/rabbitmqctl.8","permalink":"/rabbitmq-website/docs/next/man/rabbitmqctl.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/rabbitmqctl.8.md","tags":[],"version":"current","frontMatter":{}},{"id":"man/README","title":"RabbitMQ man Pages","description":"Source Files","source":"@site/docs/man/README.md","sourceDirName":"man","slug":"/man/","permalink":"/rabbitmq-website/docs/next/man/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/man/README.md","tags":[],"version":"current","frontMatter":{}},{"id":"manage-rabbitmq","title":"How to Manage RabbitMQ","description":"<!--","source":"@site/docs/manage-rabbitmq.md","sourceDirName":".","slug":"/manage-rabbitmq","permalink":"/rabbitmq-website/docs/next/manage-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/manage-rabbitmq.md","tags":[],"version":"current","frontMatter":{"title":"How to Manage RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Intercepting Messages","permalink":"/rabbitmq-website/docs/next/message-interceptors"},"next":{"title":"CLI","permalink":"/rabbitmq-website/docs/next/cli"}},{"id":"management-cli","title":"rabbitmqadmin v2, a Command Line Tool for the HTTP API","description":"<!--","source":"@site/docs/management-cli.md","sourceDirName":".","slug":"/management-cli","permalink":"/rabbitmq-website/docs/next/management-cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/management-cli.md","tags":[],"version":"current","frontMatter":{"title":"rabbitmqadmin v2, a Command Line Tool for the HTTP API","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"management/index","title":"Management Plugin","description":"<!--","source":"@site/docs/management/index.md","sourceDirName":"management","slug":"/management/","permalink":"/rabbitmq-website/docs/next/management/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/management/index.md","tags":[],"version":"current","frontMatter":{"title":"Management Plugin"},"sidebar":"docsSidebar","previous":{"title":"Plugins","permalink":"/rabbitmq-website/docs/next/plugins"},"next":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/next/federation"}},{"id":"manpages","title":"Manual Pages","description":"<!--","source":"@site/docs/manpages.md","sourceDirName":".","slug":"/manpages","permalink":"/rabbitmq-website/docs/next/manpages","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/manpages.md","tags":[],"version":"current","frontMatter":{"title":"Manual Pages","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"maxlength/index","title":"Queue Length Limit","description":"<!--","source":"@site/docs/maxlength/index.md","sourceDirName":"maxlength","slug":"/maxlength/","permalink":"/rabbitmq-website/docs/next/maxlength/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/maxlength/index.md","tags":[],"version":"current","frontMatter":{"title":"Queue Length Limit"},"sidebar":"docsSidebar","previous":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/next/ttl"},"next":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/next/lazy-queues"}},{"id":"memory","title":"Memory Threshold and Limit","description":"<!--","source":"@site/docs/memory.md","sourceDirName":".","slug":"/memory","permalink":"/rabbitmq-website/docs/next/memory","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/memory.md","tags":[],"version":"current","frontMatter":{"title":"Memory Threshold and Limit"},"sidebar":"docsSidebar","previous":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/next/alarms"},"next":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/next/disk-alarms"}},{"id":"memory-use/index","title":"Reasoning About Memory Use","description":"<!--","source":"@site/docs/memory-use/index.md","sourceDirName":"memory-use","slug":"/memory-use/","permalink":"/rabbitmq-website/docs/next/memory-use/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/memory-use/index.md","tags":[],"version":"current","frontMatter":{"title":"Reasoning About Memory Use"},"sidebar":"docsSidebar","previous":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/next/ec2"},"next":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/next/alarms"}},{"id":"message-interceptors","title":"Intercepting Messages","description":"<!--","source":"@site/docs/message-interceptors.md","sourceDirName":".","slug":"/message-interceptors","permalink":"/rabbitmq-website/docs/next/message-interceptors","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/message-interceptors.md","tags":[],"version":"current","frontMatter":{"title":"Intercepting Messages","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"AMQP 0-9-1 Extensions","permalink":"/rabbitmq-website/docs/next/extensions"},"next":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/next/manage-rabbitmq"}},{"id":"metadata-store/clustering","title":"Clustering and Khepri","description":"When RabbitMQ nodes are clustered, they call the metadata","source":"@site/docs/metadata-store/clustering.md","sourceDirName":"metadata-store","slug":"/metadata-store/clustering","permalink":"/rabbitmq-website/docs/next/metadata-store/clustering","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/metadata-store/clustering.md","tags":[],"version":"current","frontMatter":{"title":"Clustering and Khepri"},"sidebar":"docsSidebar","previous":{"title":"How to enable Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/how-to-enable-khepri"},"next":{"title":"Everyday Operations with Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/everyday-operations"}},{"id":"metadata-store/everyday-operations","title":"Everyday Operations with Khepri","description":"Even though the metadata store doesn’t store messages, its behavior will affect","source":"@site/docs/metadata-store/everyday-operations.md","sourceDirName":"metadata-store","slug":"/metadata-store/everyday-operations","permalink":"/rabbitmq-website/docs/next/metadata-store/everyday-operations","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/metadata-store/everyday-operations.md","tags":[],"version":"current","frontMatter":{"title":"Everyday Operations with Khepri"},"sidebar":"docsSidebar","previous":{"title":"Clustering and Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/clustering"},"next":{"title":"Failure recovery with Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/failure-recovery"}},{"id":"metadata-store/failure-recovery","title":"How Khepri Approaches Failure Recovery","description":"This section describes Khepri’s Raft-based approach to failure handling and","source":"@site/docs/metadata-store/failure-recovery.md","sourceDirName":"metadata-store","slug":"/metadata-store/failure-recovery","permalink":"/rabbitmq-website/docs/next/metadata-store/failure-recovery","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/metadata-store/failure-recovery.md","tags":[],"version":"current","frontMatter":{"title":"How Khepri Approaches Failure Recovery"},"sidebar":"docsSidebar","previous":{"title":"Everyday Operations with Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/everyday-operations"},"next":{"title":"Known issues with Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/known-issues"}},{"id":"metadata-store/how-to-enable-khepri","title":"How to Enable Khepri","description":"As of RabbitMQ 4.2.0, Khepri became the default metadata store backend for all","source":"@site/docs/metadata-store/how-to-enable-khepri.md","sourceDirName":"metadata-store","slug":"/metadata-store/how-to-enable-khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/how-to-enable-khepri","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/metadata-store/how-to-enable-khepri.md","tags":[],"version":"current","frontMatter":{"title":"How to Enable Khepri"},"sidebar":"docsSidebar","previous":{"title":"Metadata store","permalink":"/rabbitmq-website/docs/next/metadata-store/"},"next":{"title":"Clustering and Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/clustering"}},{"id":"metadata-store/index","title":"Metadata store","description":"Role of the metadata store","source":"@site/docs/metadata-store/index.md","sourceDirName":"metadata-store","slug":"/metadata-store/","permalink":"/rabbitmq-website/docs/next/metadata-store/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/metadata-store/index.md","tags":[],"version":"current","frontMatter":{"title":"Metadata store"},"sidebar":"docsSidebar","previous":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/next/parameters"},"next":{"title":"How to enable Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/how-to-enable-khepri"}},{"id":"metadata-store/khepri-faq","title":"Khepri FAQ","description":"I see the khepri_db feature flag is marked as experimental in the RabbitMQ code. Is it supported?","source":"@site/docs/metadata-store/khepri-faq.md","sourceDirName":"metadata-store","slug":"/metadata-store/khepri-faq","permalink":"/rabbitmq-website/docs/next/metadata-store/khepri-faq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/metadata-store/khepri-faq.md","tags":[],"version":"current","frontMatter":{"title":"Khepri FAQ"},"sidebar":"docsSidebar","previous":{"title":"Known issues with Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/known-issues"},"next":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/next/definitions"}},{"id":"metadata-store/known-issues","title":"Known issues with Khepri","description":"This document lists the most common known issues with Khepri that may affect","source":"@site/docs/metadata-store/known-issues.md","sourceDirName":"metadata-store","slug":"/metadata-store/known-issues","permalink":"/rabbitmq-website/docs/next/metadata-store/known-issues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/metadata-store/known-issues.md","tags":[],"version":"current","frontMatter":{"title":"Known issues with Khepri"},"sidebar":"docsSidebar","previous":{"title":"Failure recovery with Khepri","permalink":"/rabbitmq-website/docs/next/metadata-store/failure-recovery"},"next":{"title":"Khepri FAQ","permalink":"/rabbitmq-website/docs/next/metadata-store/khepri-faq"}},{"id":"monitoring/index","title":"Monitoring","description":"<!--","source":"@site/docs/monitoring/index.md","sourceDirName":"monitoring","slug":"/monitoring/","permalink":"/rabbitmq-website/docs/next/monitoring/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/monitoring/index.md","tags":[],"version":"current","frontMatter":{"title":"Monitoring"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/next/troubleshooting/"},"next":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/next/prometheus/"}},{"id":"mqtt","title":"MQTT Plugin","description":"<!--","source":"@site/docs/mqtt.md","sourceDirName":".","slug":"/mqtt","permalink":"/rabbitmq-website/docs/next/mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/mqtt.md","tags":[],"version":"current","frontMatter":{"title":"MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/next/web-stomp"},"next":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/next/web-mqtt"}},{"id":"nack","title":"Negative Acknowledgements","description":"<!--","source":"@site/docs/nack.md","sourceDirName":".","slug":"/nack","permalink":"/rabbitmq-website/docs/next/nack","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/nack.md","tags":[],"version":"current","frontMatter":{"title":"Negative Acknowledgements"},"sidebar":"docsSidebar","previous":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/next/consumer-priority"},"next":{"title":"Queues","permalink":"/rabbitmq-website/docs/next/queues"}},{"id":"nettick","title":"Net Tick Time (Inter-node Communication Heartbeats)","description":"<!--","source":"@site/docs/nettick.md","sourceDirName":".","slug":"/nettick","permalink":"/rabbitmq-website/docs/next/nettick","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/nettick.md","tags":[],"version":"current","frontMatter":{"title":"Net Tick Time (Inter-node Communication Heartbeats)"},"sidebar":"docsSidebar","previous":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/next/networking"},"next":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/next/ssl/"}},{"id":"networking","title":"Networking and RabbitMQ","description":"<!--","source":"@site/docs/networking.md","sourceDirName":".","slug":"/networking","permalink":"/rabbitmq-website/docs/next/networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/networking.md","tags":[],"version":"current","frontMatter":{"title":"Networking and RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/next/definitions"},"next":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/next/nettick"}},{"id":"oauth2","title":"OAuth 2.0 Authentication Backend","description":"<!--","source":"@site/docs/oauth2.md","sourceDirName":".","slug":"/oauth2","permalink":"/rabbitmq-website/docs/next/oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2.md","tags":[],"version":"current","frontMatter":{"title":"OAuth 2.0 Authentication Backend"},"sidebar":"docsSidebar","previous":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/next/passwords"},"next":{"title":"LDAP","permalink":"/rabbitmq-website/docs/next/ldap"}},{"id":"oauth2-examples-auth0","title":"Use auth0.com as OAuth 2.0 Server","description":"<!--","source":"@site/docs/oauth2-examples-auth0.md","sourceDirName":".","slug":"/oauth2-examples-auth0","permalink":"/rabbitmq-website/docs/next/oauth2-examples-auth0","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-auth0.md","tags":[],"version":"current","frontMatter":{"title":"Use auth0.com as OAuth 2.0 Server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-entra-id/index","title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","description":"<!--","source":"@site/docs/oauth2-examples-entra-id/index.md","sourceDirName":"oauth2-examples-entra-id","slug":"/oauth2-examples-entra-id/","permalink":"/rabbitmq-website/docs/next/oauth2-examples-entra-id/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-entra-id/index.md","tags":[],"version":"current","frontMatter":{"title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-forward-proxy","title":"Use an explicit forward proxy and Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/docs/oauth2-examples-forward-proxy.md","sourceDirName":".","slug":"/oauth2-examples-forward-proxy","permalink":"/rabbitmq-website/docs/next/oauth2-examples-forward-proxy","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-forward-proxy.md","tags":[],"version":"current","frontMatter":{"title":"Use an explicit forward proxy and Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-google","title":"Use Google as OAuth 2.0 server","description":"<!--","source":"@site/docs/oauth2-examples-google.md","sourceDirName":".","slug":"/oauth2-examples-google","permalink":"/rabbitmq-website/docs/next/oauth2-examples-google","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-google.md","tags":[],"version":"current","frontMatter":{"title":"Use Google as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-idp-initiated","title":"Use Identity Provider Initiated Logon","description":"<!--","source":"@site/docs/oauth2-examples-idp-initiated.md","sourceDirName":".","slug":"/oauth2-examples-idp-initiated","permalink":"/rabbitmq-website/docs/next/oauth2-examples-idp-initiated","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-idp-initiated.md","tags":[],"version":"current","frontMatter":{"title":"Use Identity Provider Initiated Logon","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-keycloak","title":"Use Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/docs/oauth2-examples-keycloak.md","sourceDirName":".","slug":"/oauth2-examples-keycloak","permalink":"/rabbitmq-website/docs/next/oauth2-examples-keycloak","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-keycloak.md","tags":[],"version":"current","frontMatter":{"title":"Use Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-multiresource","title":"Using Multiple OAuth 2.0 Servers and/or Audiences","description":"<!--","source":"@site/docs/oauth2-examples-multiresource.md","sourceDirName":".","slug":"/oauth2-examples-multiresource","permalink":"/rabbitmq-website/docs/next/oauth2-examples-multiresource","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-multiresource.md","tags":[],"version":"current","frontMatter":{"title":"Using Multiple OAuth 2.0 Servers and/or Audiences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-okta","title":"Use Okta as OAuth 2.0 server","description":"<!--","source":"@site/docs/oauth2-examples-okta.md","sourceDirName":".","slug":"/oauth2-examples-okta","permalink":"/rabbitmq-website/docs/next/oauth2-examples-okta","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-okta.md","tags":[],"version":"current","frontMatter":{"title":"Use Okta as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-proxy","title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/docs/oauth2-examples-proxy.md","sourceDirName":".","slug":"/oauth2-examples-proxy","permalink":"/rabbitmq-website/docs/next/oauth2-examples-proxy","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples-proxy.md","tags":[],"version":"current","frontMatter":{"title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples/index","title":"OAuth 2.0 Authentication Examples","description":"<!--","source":"@site/docs/oauth2-examples/index.md","sourceDirName":"oauth2-examples","slug":"/oauth2-examples/","permalink":"/rabbitmq-website/docs/next/oauth2-examples/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/oauth2-examples/index.md","tags":[],"version":"current","frontMatter":{"title":"OAuth 2.0 Authentication Examples","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"parameters","title":"Runtime Parameters","description":"<!--","source":"@site/docs/parameters.md","sourceDirName":".","slug":"/parameters","permalink":"/rabbitmq-website/docs/next/parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/parameters.md","tags":[],"version":"current","frontMatter":{"title":"Runtime Parameters"},"sidebar":"docsSidebar","previous":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/next/user-limits"},"next":{"title":"Metadata store","permalink":"/rabbitmq-website/docs/next/metadata-store/"}},{"id":"partitions","title":"Clustering and Network Partitions","description":"<!--","source":"@site/docs/partitions.md","sourceDirName":".","slug":"/partitions","permalink":"/rabbitmq-website/docs/next/partitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/partitions.md","tags":[],"version":"current","frontMatter":{"title":"Clustering and Network Partitions"},"sidebar":"docsSidebar","previous":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/next/cluster-formation"},"next":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/next/clustering-ssl"}},{"id":"passwords","title":"Credentials and Passwords","description":"<!--","source":"@site/docs/passwords.md","sourceDirName":".","slug":"/passwords","permalink":"/rabbitmq-website/docs/next/passwords","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/passwords.md","tags":[],"version":"current","frontMatter":{"title":"Credentials and Passwords","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/next/authentication"},"next":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/next/oauth2"}},{"id":"persistence-conf","title":"Persistence Configuration","description":"<!--","source":"@site/docs/persistence-conf.md","sourceDirName":".","slug":"/persistence-conf","permalink":"/rabbitmq-website/docs/next/persistence-conf","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/persistence-conf.md","tags":[],"version":"current","frontMatter":{"title":"Persistence Configuration"},"sidebar":"docsSidebar","previous":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/next/runtime"},"next":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/next/production-checklist"}},{"id":"platforms","title":"Supported Platforms","description":"<!--","source":"@site/docs/platforms.md","sourceDirName":".","slug":"/platforms","permalink":"/rabbitmq-website/docs/next/platforms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/platforms.md","tags":[],"version":"current","frontMatter":{"title":"Supported Platforms"},"sidebar":"docsSidebar","previous":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/next/signatures"},"next":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/next/install-debian"}},{"id":"plugins","title":"Plugins","description":"<!--","source":"@site/docs/plugins.md","sourceDirName":".","slug":"/plugins","permalink":"/rabbitmq-website/docs/next/plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/plugins.md","tags":[],"version":"current","frontMatter":{"title":"Plugins","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/next/distributed"},"next":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/next/management/"}},{"id":"policies","title":"Policies","description":"<!--","source":"@site/docs/policies.md","sourceDirName":".","slug":"/policies","permalink":"/rabbitmq-website/docs/next/policies","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/policies.md","tags":[],"version":"current","frontMatter":{"title":"Policies"}},{"id":"priority","title":"Classic Queues Support Priorities","description":"<!--","source":"@site/docs/priority.md","sourceDirName":".","slug":"/priority","permalink":"/rabbitmq-website/docs/next/priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/priority.md","tags":[],"version":"current","frontMatter":{"title":"Classic Queues Support Priorities"},"sidebar":"docsSidebar","previous":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/next/dlx"},"next":{"title":"Streams","permalink":"/rabbitmq-website/docs/next/streams"}},{"id":"production-checklist","title":"Production Deployment Guidelines","description":"<!--","source":"@site/docs/production-checklist.md","sourceDirName":".","slug":"/production-checklist","permalink":"/rabbitmq-website/docs/next/production-checklist","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/production-checklist.md","tags":[],"version":"current","frontMatter":{"title":"Production Deployment Guidelines"},"sidebar":"docsSidebar","previous":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/next/persistence-conf"},"next":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/next/troubleshooting/"}},{"id":"prometheus/index","title":"Monitoring with Prometheus and Grafana","description":"Overview","source":"@site/docs/prometheus/index.md","sourceDirName":"prometheus","slug":"/prometheus/","permalink":"/rabbitmq-website/docs/next/prometheus/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/prometheus/index.md","tags":[],"version":"current","frontMatter":{"title":"Monitoring with Prometheus and Grafana","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/next/monitoring/"},"next":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/next/event-exchange"}},{"id":"protocols","title":"Which protocols does RabbitMQ support?","description":"<!--","source":"@site/docs/protocols.md","sourceDirName":".","slug":"/protocols","permalink":"/rabbitmq-website/docs/next/protocols","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/protocols.md","tags":[],"version":"current","frontMatter":{"title":"Which protocols does RabbitMQ support?","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/next/installing-plugins"},"next":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/docs/next/amqp"}},{"id":"publishers/index","title":"Publishers","description":"<!--","source":"@site/docs/publishers/index.md","sourceDirName":"publishers","slug":"/publishers/","permalink":"/rabbitmq-website/docs/next/publishers/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/publishers/index.md","tags":[],"version":"current","frontMatter":{"title":"Publishers"},"sidebar":"docsSidebar","previous":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/next/use-rabbitmq"},"next":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/next/exchanges"}},{"id":"queues","title":"Queues","description":"<!--","source":"@site/docs/queues.md","sourceDirName":".","slug":"/queues","permalink":"/rabbitmq-website/docs/next/queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/queues.md","tags":[],"version":"current","frontMatter":{"title":"Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/next/nack"},"next":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/next/quorum-queues/"}},{"id":"quorum-queues/index","title":"Quorum Queues","description":"<!--","source":"@site/docs/quorum-queues/index.md","sourceDirName":"quorum-queues","slug":"/quorum-queues/","permalink":"/rabbitmq-website/docs/next/quorum-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/quorum-queues/index.md","tags":[],"version":"current","frontMatter":{"title":"Quorum Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Queues","permalink":"/rabbitmq-website/docs/next/queues"},"next":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/next/classic-queues"}},{"id":"reliability","title":"Reliability Guide","description":"<!--","source":"@site/docs/reliability.md","sourceDirName":".","slug":"/reliability","permalink":"/rabbitmq-website/docs/next/reliability","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/reliability.md","tags":[],"version":"current","frontMatter":{"title":"Reliability Guide"},"sidebar":"docsSidebar","previous":{"title":"Channels","permalink":"/rabbitmq-website/docs/next/channels/"},"next":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/next/confirms"}},{"id":"relocate","title":"File and Directory Locations","description":"<!--","source":"@site/docs/relocate.md","sourceDirName":".","slug":"/relocate","permalink":"/rabbitmq-website/docs/next/relocate","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/relocate.md","tags":[],"version":"current","frontMatter":{"title":"File and Directory Locations"},"sidebar":"docsSidebar","previous":{"title":"Configuration","permalink":"/rabbitmq-website/docs/next/configure"},"next":{"title":"Logging","permalink":"/rabbitmq-website/docs/next/logging"}},{"id":"rolling-upgrade","title":"Rolling (in-place) Upgrade","description":"<!--","source":"@site/docs/rolling-upgrade.md","sourceDirName":".","slug":"/rolling-upgrade","permalink":"/rabbitmq-website/docs/next/rolling-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/rolling-upgrade.md","tags":[],"version":"current","frontMatter":{"title":"Rolling (in-place) Upgrade"},"sidebar":"docsSidebar","previous":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/next/upgrade"},"next":{"title":"Blue-Green Deployment","permalink":"/rabbitmq-website/docs/next/blue-green-upgrade"}},{"id":"runtime","title":"Runtime Tuning","description":"<!--","source":"@site/docs/runtime.md","sourceDirName":".","slug":"/runtime","permalink":"/rabbitmq-website/docs/next/runtime","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/runtime.md","tags":[],"version":"current","frontMatter":{"title":"Runtime Tuning","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/next/backup"},"next":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/next/persistence-conf"}},{"id":"semantics","title":"Broker Semantics","description":"Here we describe the broker semantics. This should be read together with the AMQP specification.","source":"@site/docs/semantics.md","sourceDirName":".","slug":"/semantics","permalink":"/rabbitmq-website/docs/next/semantics","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/semantics.md","tags":[],"version":"current","frontMatter":{"title":"Broker Semantics","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"sender-selected","title":"Sender-selected Distribution","description":"<!--","source":"@site/docs/sender-selected.md","sourceDirName":".","slug":"/sender-selected","permalink":"/rabbitmq-website/docs/next/sender-selected","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/sender-selected.md","tags":[],"version":"current","frontMatter":{"title":"Sender-selected Distribution"},"sidebar":"docsSidebar","previous":{"title":"Alternate Exchanges","permalink":"/rabbitmq-website/docs/next/ae"},"next":{"title":"Validated User ID","permalink":"/rabbitmq-website/docs/next/validated-user-id"}},{"id":"shovel","title":"Shovel Plugin","description":"<!--","source":"@site/docs/shovel.md","sourceDirName":".","slug":"/shovel","permalink":"/rabbitmq-website/docs/next/shovel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/shovel.md","tags":[],"version":"current","frontMatter":{"title":"Shovel Plugin"},"sidebar":"docsSidebar","previous":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/next/federation-reference"},"next":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/next/shovel-static"}},{"id":"shovel-dynamic","title":"Configuring Dynamic Shovels","description":"<!--","source":"@site/docs/shovel-dynamic.md","sourceDirName":".","slug":"/shovel-dynamic","permalink":"/rabbitmq-website/docs/next/shovel-dynamic","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/shovel-dynamic.md","tags":[],"version":"current","frontMatter":{"title":"Configuring Dynamic Shovels"},"sidebar":"docsSidebar","previous":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/next/shovel-static"},"next":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/next/stomp"}},{"id":"shovel-static","title":"Configuring Static Shovels","description":"<!--","source":"@site/docs/shovel-static.md","sourceDirName":".","slug":"/shovel-static","permalink":"/rabbitmq-website/docs/next/shovel-static","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/shovel-static.md","tags":[],"version":"current","frontMatter":{"title":"Configuring Static Shovels"},"sidebar":"docsSidebar","previous":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/next/shovel"},"next":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/next/shovel-dynamic"}},{"id":"signatures","title":"Package Signatures","description":"<!--","source":"@site/docs/signatures.md","sourceDirName":".","slug":"/signatures","permalink":"/rabbitmq-website/docs/next/signatures","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/signatures.md","tags":[],"version":"current","frontMatter":{"title":"Package Signatures","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/next/which-erlang"},"next":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/next/platforms"}},{"id":"snapshots","title":"Snapshots Releases","description":"<!--","source":"@site/docs/snapshots.md","sourceDirName":".","slug":"/snapshots","permalink":"/rabbitmq-website/docs/next/snapshots","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/snapshots.md","tags":[],"version":"current","frontMatter":{"title":"Snapshots Releases"},"sidebar":"docsSidebar","previous":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/next/deprecated-features/"},"next":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/next/use-rabbitmq"}},{"id":"spec-differences","title":"Spec Differences","description":"Undeprecated Features","source":"@site/docs/spec-differences.md","sourceDirName":".","slug":"/spec-differences","permalink":"/rabbitmq-website/docs/next/spec-differences","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/spec-differences.md","tags":[],"version":"current","frontMatter":{"title":"Spec Differences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"specification","title":"Compatibility and Conformance","description":"RabbitMQ core broker implements the AMQP 1.0 specification and AMQP 0-9-1 specification with a number of AMQP 0-9-1 extensions.","source":"@site/docs/specification.md","sourceDirName":".","slug":"/specification","permalink":"/rabbitmq-website/docs/next/specification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/specification.md","tags":[],"version":"current","frontMatter":{"title":"Compatibility and Conformance","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"ssl/index","title":"TLS Support","description":"<!--","source":"@site/docs/ssl/index.md","sourceDirName":"ssl","slug":"/ssl/","permalink":"/rabbitmq-website/docs/next/ssl/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/ssl/index.md","tags":[],"version":"current","frontMatter":{"title":"TLS Support"},"sidebar":"docsSidebar","previous":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/next/nettick"},"next":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/next/troubleshooting-networking"}},{"id":"stomp","title":"STOMP Plugin","description":"<!--","source":"@site/docs/stomp.md","sourceDirName":".","slug":"/stomp","permalink":"/rabbitmq-website/docs/next/stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/stomp.md","tags":[],"version":"current","frontMatter":{"title":"STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/next/shovel-dynamic"},"next":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/next/web-stomp"}},{"id":"stream","title":"Stream Plugin","description":"<!--","source":"@site/docs/stream.md","sourceDirName":".","slug":"/stream","permalink":"/rabbitmq-website/docs/next/stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/stream.md","tags":[],"version":"current","frontMatter":{"title":"Stream Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/next/web-mqtt"},"next":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/next/installing-plugins"}},{"id":"stream-core-plugin-comparison","title":"Stream Core vs Stream Plugin","description":"<!--","source":"@site/docs/stream-core-plugin-comparison.md","sourceDirName":".","slug":"/stream-core-plugin-comparison","permalink":"/rabbitmq-website/docs/next/stream-core-plugin-comparison","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/stream-core-plugin-comparison.md","tags":[],"version":"current","frontMatter":{"title":"Stream Core vs Stream Plugin","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"streams","title":"Streams and Superstreams (Partitioned Streams)","description":"<!--","source":"@site/docs/streams.md","sourceDirName":".","slug":"/streams","permalink":"/rabbitmq-website/docs/next/streams","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/streams.md","tags":[],"version":"current","frontMatter":{"title":"Streams and Superstreams (Partitioned Streams)"},"sidebar":"docsSidebar","previous":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/next/priority"},"next":{"title":"Channels","permalink":"/rabbitmq-website/docs/next/channels/"}},{"id":"troubleshooting-networking","title":"Troubleshooting Network Connectivity","description":"<!--","source":"@site/docs/troubleshooting-networking.md","sourceDirName":".","slug":"/troubleshooting-networking","permalink":"/rabbitmq-website/docs/next/troubleshooting-networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/troubleshooting-networking.md","tags":[],"version":"current","frontMatter":{"title":"Troubleshooting Network Connectivity"},"sidebar":"docsSidebar","previous":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/next/ssl/"},"next":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/next/troubleshooting-ssl"}},{"id":"troubleshooting-oauth2","title":"Troubleshooting OAuth 2","description":"<!--","source":"@site/docs/troubleshooting-oauth2.md","sourceDirName":".","slug":"/troubleshooting-oauth2","permalink":"/rabbitmq-website/docs/next/troubleshooting-oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/troubleshooting-oauth2.md","tags":[],"version":"current","frontMatter":{"title":"Troubleshooting OAuth 2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"troubleshooting-ssl","title":"Troubleshooting TLS-enabled Connections","description":"<!--","source":"@site/docs/troubleshooting-ssl.md","sourceDirName":".","slug":"/troubleshooting-ssl","permalink":"/rabbitmq-website/docs/next/troubleshooting-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/troubleshooting-ssl.md","tags":[],"version":"current","frontMatter":{"title":"Troubleshooting TLS-enabled Connections"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/next/troubleshooting-networking"},"next":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/next/clustering"}},{"id":"troubleshooting/index","title":"Troubleshooting Guidance","description":"<!--","source":"@site/docs/troubleshooting/index.md","sourceDirName":"troubleshooting","slug":"/troubleshooting/","permalink":"/rabbitmq-website/docs/next/troubleshooting/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/troubleshooting/index.md","tags":[],"version":"current","frontMatter":{"title":"Troubleshooting Guidance"},"sidebar":"docsSidebar","previous":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/next/production-checklist"},"next":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/next/monitoring/"}},{"id":"ttl","title":"Time-To-Live and Expiration","description":"<!--","source":"@site/docs/ttl.md","sourceDirName":".","slug":"/ttl","permalink":"/rabbitmq-website/docs/next/ttl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/ttl.md","tags":[],"version":"current","frontMatter":{"title":"Time-To-Live and Expiration"},"sidebar":"docsSidebar","previous":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/next/classic-queues"},"next":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/next/maxlength/"}},{"id":"upgrade","title":"Upgrading RabbitMQ","description":"<!--","source":"@site/docs/upgrade.md","sourceDirName":".","slug":"/upgrade","permalink":"/rabbitmq-website/docs/next/upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/upgrade.md","tags":[],"version":"current","frontMatter":{"title":"Upgrading RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/next/install-homebrew"},"next":{"title":"Rolling Upgrade","permalink":"/rabbitmq-website/docs/next/rolling-upgrade"}},{"id":"uri-query-parameters","title":"URI Query Parameters","description":"<!--","source":"@site/docs/uri-query-parameters.md","sourceDirName":".","slug":"/uri-query-parameters","permalink":"/rabbitmq-website/docs/next/uri-query-parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/uri-query-parameters.md","tags":[],"version":"current","frontMatter":{"title":"URI Query Parameters","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"uri-spec","title":"RabbitMQ URI Specification","description":"<!--","source":"@site/docs/uri-spec.md","sourceDirName":".","slug":"/uri-spec","permalink":"/rabbitmq-website/docs/next/uri-spec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/uri-spec.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ URI Specification","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"use-rabbitmq","title":"How to Use RabbitMQ","description":"<!--","source":"@site/docs/use-rabbitmq.md","sourceDirName":".","slug":"/use-rabbitmq","permalink":"/rabbitmq-website/docs/next/use-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/use-rabbitmq.md","tags":[],"version":"current","frontMatter":{"title":"How to Use RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/next/snapshots"},"next":{"title":"Publishers","permalink":"/rabbitmq-website/docs/next/publishers/"}},{"id":"user-limits","title":"Per-user Resource Limits","description":"<!--","source":"@site/docs/user-limits.md","sourceDirName":".","slug":"/user-limits","permalink":"/rabbitmq-website/docs/next/user-limits","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/user-limits.md","tags":[],"version":"current","frontMatter":{"title":"Per-user Resource Limits","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/next/auth-notification"},"next":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/next/parameters"}},{"id":"validated-user-id","title":"Validated User-ID","description":"<!--","source":"@site/docs/validated-user-id.md","sourceDirName":".","slug":"/validated-user-id","permalink":"/rabbitmq-website/docs/next/validated-user-id","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/validated-user-id.md","tags":[],"version":"current","frontMatter":{"title":"Validated User-ID"},"sidebar":"docsSidebar","previous":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/next/sender-selected"},"next":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/next/exchanges"}},{"id":"vhosts","title":"Virtual Hosts","description":"<!--","source":"@site/docs/vhosts.md","sourceDirName":".","slug":"/vhosts","permalink":"/rabbitmq-website/docs/next/vhosts","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/vhosts.md","tags":[],"version":"current","frontMatter":{"title":"Virtual Hosts"},"sidebar":"docsSidebar","previous":{"title":"Logging","permalink":"/rabbitmq-website/docs/next/logging"},"next":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/next/access-control"}},{"id":"web-mqtt","title":"RabbitMQ Web MQTT Plugin","description":"<!--","source":"@site/docs/web-mqtt.md","sourceDirName":".","slug":"/web-mqtt","permalink":"/rabbitmq-website/docs/next/web-mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/web-mqtt.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Web MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/next/mqtt"},"next":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/next/stream"}},{"id":"web-stomp","title":"RabbitMQ Web STOMP Plugin","description":"<!--","source":"@site/docs/web-stomp.md","sourceDirName":".","slug":"/web-stomp","permalink":"/rabbitmq-website/docs/next/web-stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/web-stomp.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Web STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/next/stomp"},"next":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/next/mqtt"}},{"id":"which-erlang","title":"Erlang Version Requirements","description":"<!--","source":"@site/docs/which-erlang.md","sourceDirName":".","slug":"/which-erlang","permalink":"/rabbitmq-website/docs/next/which-erlang","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/which-erlang.md","tags":[],"version":"current","frontMatter":{"title":"Erlang Version Requirements","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/next/download"},"next":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/next/signatures"}},{"id":"windows-configuration","title":"Windows Configuration","description":"<!--","source":"@site/docs/windows-configuration.md","sourceDirName":".","slug":"/windows-configuration","permalink":"/rabbitmq-website/docs/next/windows-configuration","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/docs/windows-configuration.md","tags":[],"version":"current","frontMatter":{"title":"Windows Configuration","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"}],"drafts":[],"sidebars":{"docsSidebar":[{"type":"doc","id":"index","label":"Introduction","translatable":true},{"type":"link","label":"Release Information","href":"/release-information"},{"type":"link","label":"Getting Started","href":"/tutorials"},{"type":"category","label":"Install and Upgrade","link":{"type":"doc","id":"download"},"items":[{"type":"doc","id":"which-erlang","label":"Erlang Version Requirements","translatable":true},{"type":"doc","id":"signatures","label":"Package Signatures","translatable":true},{"type":"category","label":"Supported Operating Systems","link":{"type":"doc","id":"platforms"},"items":[{"type":"category","label":"Linux/Unix","items":[{"type":"doc","id":"install-debian","label":"Debian and Ubuntu","translatable":true},{"type":"doc","id":"install-rpm","label":"RedHat","translatable":true},{"type":"doc","id":"install-generic-unix","label":"Generic Unix","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"install-windows","label":"Windows","translatable":true},{"type":"category","label":"MacOS","items":[{"type":"doc","id":"install-standalone-mac","label":"MacOS using Standalone Binary Build","translatable":true},{"type":"doc","id":"install-homebrew","label":"MacOs using Homebrew","translatable":true}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Kubernetes Operator","href":"/kubernetes/operator/install-operator"},{"type":"category","label":"Upgrade","link":{"type":"doc","id":"upgrade"},"items":[{"type":"doc","id":"rolling-upgrade","label":"Rolling Upgrade","translatable":true},{"type":"doc","id":"blue-green-upgrade","label":"Blue-Green Deployment","translatable":true},{"type":"doc","id":"grow-then-shrink-upgrade","label":"Grow-Then-Shrink Upgrade","translatable":true},{"type":"doc","id":"feature-flags/index","label":"Feature Flags","translatable":true},{"type":"doc","id":"deprecated-features/index","label":"Deprecated Features","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"snapshots","label":"Snapshots","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Use RabbitMQ","link":{"type":"doc","id":"use-rabbitmq"},"items":[{"type":"category","label":"Publishing Messages","link":{"type":"doc","id":"publishers/index"},"items":[{"type":"doc","id":"exchanges","label":"Exchanges","translatable":true},{"type":"doc","id":"direct-reply-to","label":"Direct reply-to","translatable":true},{"type":"doc","id":"local-random-exchange","label":"Local random exchange","translatable":true},{"type":"doc","id":"connection-blocked","label":"Blocked Connection Notifications","translatable":true},{"type":"doc","id":"e2e","label":"Exchange to Exchange Bindings","translatable":true},{"type":"doc","id":"ae","label":"Alternate Exchanges","translatable":true},{"type":"doc","id":"sender-selected","label":"Sender-selected Distribution","translatable":true},{"type":"doc","id":"validated-user-id","label":"Validated User ID","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"exchanges","label":"Exchanges","translatable":true},{"type":"category","label":"Consuming Messages","link":{"type":"doc","id":"consumers"},"items":[{"type":"doc","id":"consumer-cancel","label":"Consumer Cancellation Notifications","translatable":true},{"type":"doc","id":"consumer-prefetch","label":"Consumer Prefetch","translatable":true},{"type":"doc","id":"consumer-priority","label":"Consumer Priorites","translatable":true},{"type":"doc","id":"nack","label":"Negative Acknowledgements","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Queues","link":{"type":"doc","id":"queues"},"items":[{"type":"doc","id":"quorum-queues/index","label":"Quorum Queues","translatable":true},{"type":"doc","id":"classic-queues","label":"Classic Queues","translatable":true},{"type":"doc","id":"ttl","label":"Time-to-Live and Expiration","translatable":true},{"type":"doc","id":"maxlength/index","label":"Queue Length","translatable":true},{"type":"doc","id":"lazy-queues","label":"Lazy Queues","translatable":true},{"type":"doc","id":"dlx","label":"Dead Lettering","translatable":true},{"type":"doc","id":"priority","label":"Priority Queues","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"streams","label":"Streams","translatable":true},{"type":"doc","id":"channels/index","label":"Channels","translatable":true},{"type":"doc","id":"reliability","label":"Reliability and Data Safety","translatable":true},{"type":"doc","id":"confirms","label":"Consumer Acknowledgements and Publisher Confirms","translatable":true},{"type":"doc","id":"distributed","label":"Network Distribution","translatable":true},{"type":"category","label":"Plugins","link":{"type":"doc","id":"plugins"},"items":[{"type":"doc","id":"management/index","label":"Management Plugin","translatable":true},{"type":"category","label":"Federation Plugin","link":{"type":"doc","id":"federation"},"items":[{"type":"doc","id":"federated-exchanges/index","label":"Federated Exchanges","translatable":true},{"type":"doc","id":"federated-queues/index","label":"Federated Queues","translatable":true},{"type":"doc","id":"federation-reference","label":"Federation Reference","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Shovel Plugin","link":{"type":"doc","id":"shovel"},"items":[{"type":"doc","id":"shovel-static","label":"Static Shovels","translatable":true},{"type":"doc","id":"shovel-dynamic","label":"Dynamic Shovels","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"stomp","label":"STOMP Plugin","translatable":true},{"type":"doc","id":"web-stomp","label":"Web STOMP Plugin","translatable":true},{"type":"doc","id":"mqtt","label":"MQTT Plugin","translatable":true},{"type":"doc","id":"web-mqtt","label":"Web MQTT Plugin","translatable":true},{"type":"doc","id":"stream","label":"Stream Plugin","translatable":true},{"type":"doc","id":"installing-plugins","label":"Installing 3rd-party Plugins","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Protocols","link":{"type":"doc","id":"protocols"},"items":[{"type":"doc","id":"amqp","label":"AMQP 1.0","translatable":true},{"type":"doc","id":"connections/index","label":"Connections","translatable":true},{"type":"doc","id":"conversions","label":"Inter-Protocol Property Conversion","translatable":true},{"type":"doc","id":"heartbeats","label":"Heartbeats","translatable":true},{"type":"doc","id":"extensions","label":"AMQP 0-9-1 Extensions","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"message-interceptors","label":"Intercepting Messages","translatable":true},{"type":"link","label":"Client Libraries","href":"/client-libraries"}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Manage RabbitMQ","link":{"type":"doc","id":"manage-rabbitmq"},"items":[{"type":"doc","id":"cli","label":"CLI","translatable":true},{"type":"doc","id":"configure","label":"Configuration","translatable":true},{"type":"doc","id":"relocate","label":"File and Directory Locations","translatable":true},{"type":"doc","id":"logging","label":"Logging","translatable":true},{"type":"doc","id":"vhosts","label":"Virtual Hosts","translatable":true},{"type":"category","label":" Authentication and Authorization","link":{"type":"doc","id":"access-control"},"items":[{"type":"doc","id":"authentication","label":"AMQP 0-9-1 Authentication Mechanisms","translatable":true},{"type":"doc","id":"passwords","label":"Credentials and Passwords","translatable":true},{"type":"doc","id":"oauth2","label":"OAuth 2","translatable":true},{"type":"doc","id":"ldap","label":"LDAP","translatable":true},{"type":"doc","id":"auth-cache-backend","label":"Cache","translatable":true},{"type":"doc","id":"auth-notification","label":"Authentication Failure Notifications","translatable":true},{"type":"doc","id":"user-limits","label":"Per User Resource Limits","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"parameters","label":"Policies and Runtime Parameters","translatable":true},{"type":"category","label":"Metadata store","link":{"type":"doc","id":"metadata-store/index"},"items":[{"type":"doc","id":"metadata-store/how-to-enable-khepri","label":"How to enable Khepri","translatable":true},{"type":"doc","id":"metadata-store/clustering","label":"Clustering and Khepri","translatable":true},{"type":"doc","id":"metadata-store/everyday-operations","label":"Everyday Operations with Khepri","translatable":true},{"type":"doc","id":"metadata-store/failure-recovery","label":"Failure recovery with Khepri","translatable":true},{"type":"doc","id":"metadata-store/known-issues","label":"Known issues with Khepri","translatable":true},{"type":"doc","id":"metadata-store/khepri-faq","label":"Khepri FAQ","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"definitions","label":"Schema Definitions","translatable":true},{"type":"category","label":"Networking","link":{"type":"doc","id":"networking"},"items":[{"type":"doc","id":"nettick","label":"Net Tick Time","translatable":true},{"type":"doc","id":"ssl/index","label":"TLS Support","translatable":true},{"type":"doc","id":"troubleshooting-networking","label":"Troubleshooting Connectivity","translatable":true},{"type":"doc","id":"troubleshooting-ssl","label":"Troubleshooting TLS","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Clustering","link":{"type":"doc","id":"clustering"},"items":[{"type":"doc","id":"cluster-formation","label":"Cluster Formation","translatable":true},{"type":"doc","id":"partitions","label":"Network Partitions","translatable":true},{"type":"doc","id":"clustering-ssl","label":"Using TLS for Inter-node Traffic","translatable":true},{"type":"doc","id":"ec2","label":"RabbitMQ on Amazon EC2","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Resource Management","items":[{"type":"doc","id":"memory-use/index","label":"Analyzing how Memory is Used","translatable":true},{"type":"category","label":"Memory and Disk Alarms","link":{"type":"doc","id":"alarms"},"items":[{"type":"doc","id":"memory","label":"Memory Alarms","translatable":true},{"type":"doc","id":"disk-alarms","label":"Disk Alarms","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"flow-control","label":"Flow Control","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"backup","label":"Backup and Restore","translatable":true},{"type":"category","label":"Tuning","items":[{"type":"doc","id":"runtime","label":"Runtime Tuning","translatable":true},{"type":"doc","id":"persistence-conf","label":"Persistence Configuration","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"production-checklist","label":"Deployment Guidelines","translatable":true},{"type":"link","label":"RabbitMQ on Kubernetes","href":"/kubernetes/operator/operator-overview"},{"type":"doc","id":"troubleshooting/index","label":"Troubleshooting RabbitMQ","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Monitor RabbitMQ","link":{"type":"doc","id":"monitoring/index"},"items":[{"type":"doc","id":"prometheus/index","label":"Prometheus and Grafana","translatable":true},{"type":"doc","id":"event-exchange","label":"Event Exchange Plugin","translatable":true},{"type":"doc","id":"firehose","label":"Firehose Tracing","translatable":true}],"collapsed":true,"collapsible":true}]}},{"versionName":"4.1","label":"4.1","banner":null,"badge":true,"noIndex":false,"className":"docs-version-4.1","path":"/rabbitmq-website/docs","tagsPath":"/rabbitmq-website/docs/tags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1","editUrlLocalized":"https://github.com/rabbitmq/rabbitmq-website/tree/main/i18n/en/docusaurus-plugin-content-docs/version-4.1","isLast":true,"routePriority":-1,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/versioned_sidebars/version-4.1-sidebars.json","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/versioned_docs/version-4.1","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs/version-4.1","docs":[{"id":"access-control","title":"Authentication, Authorisation, Access Control","description":"<!--","source":"@site/versioned_docs/version-4.1/access-control.md","sourceDirName":".","slug":"/access-control","permalink":"/rabbitmq-website/docs/access-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/access-control.md","tags":[],"version":"4.1","frontMatter":{"title":"Authentication, Authorisation, Access Control"},"sidebar":"docsSidebar","previous":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/vhosts"},"next":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/authentication"}},{"id":"ae","title":"Alternate Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.1/ae.md","sourceDirName":".","slug":"/ae","permalink":"/rabbitmq-website/docs/ae","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/ae.md","tags":[],"version":"4.1","frontMatter":{"title":"Alternate Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/e2e"},"next":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/sender-selected"}},{"id":"alarms","title":"Memory and Disk Alarms","description":"<!--","source":"@site/versioned_docs/version-4.1/alarms.md","sourceDirName":".","slug":"/alarms","permalink":"/rabbitmq-website/docs/alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/alarms.md","tags":[],"version":"4.1","frontMatter":{"title":"Memory and Disk Alarms"},"sidebar":"docsSidebar","previous":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/memory-use/"},"next":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/memory"}},{"id":"amqp","title":"AMQP 1.0","description":"<!--","source":"@site/versioned_docs/version-4.1/amqp.md","sourceDirName":".","slug":"/amqp","permalink":"/rabbitmq-website/docs/amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/amqp.md","tags":[],"version":"4.1","frontMatter":{"title":"AMQP 1.0"},"sidebar":"docsSidebar","previous":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/protocols"},"next":{"title":"Connections","permalink":"/rabbitmq-website/docs/connections/"}},{"id":"auth-cache-backend","title":"RabbitMQ Access Control Cache Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/auth-cache-backend.md","sourceDirName":".","slug":"/auth-cache-backend","permalink":"/rabbitmq-website/docs/auth-cache-backend","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/auth-cache-backend.md","tags":[],"version":"4.1","frontMatter":{"title":"RabbitMQ Access Control Cache Plugin"},"sidebar":"docsSidebar","previous":{"title":"LDAP","permalink":"/rabbitmq-website/docs/ldap"},"next":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/auth-notification"}},{"id":"auth-notification","title":"Authentication Failure Notifications","description":"<!--","source":"@site/versioned_docs/version-4.1/auth-notification.md","sourceDirName":".","slug":"/auth-notification","permalink":"/rabbitmq-website/docs/auth-notification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/auth-notification.md","tags":[],"version":"4.1","frontMatter":{"title":"Authentication Failure Notifications"},"sidebar":"docsSidebar","previous":{"title":"Cache","permalink":"/rabbitmq-website/docs/auth-cache-backend"},"next":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/user-limits"}},{"id":"authentication","title":"Authentication Mechanisms","description":"<!--","source":"@site/versioned_docs/version-4.1/authentication.md","sourceDirName":".","slug":"/authentication","permalink":"/rabbitmq-website/docs/authentication","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/authentication.md","tags":[],"version":"4.1","frontMatter":{"title":"Authentication Mechanisms"},"sidebar":"docsSidebar","previous":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/access-control"},"next":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/passwords"}},{"id":"backup","title":"Backup and Restore","description":"<!--","source":"@site/versioned_docs/version-4.1/backup.md","sourceDirName":".","slug":"/backup","permalink":"/rabbitmq-website/docs/backup","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/backup.md","tags":[],"version":"4.1","frontMatter":{"title":"Backup and Restore"},"sidebar":"docsSidebar","previous":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/flow-control"},"next":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/runtime"}},{"id":"blue-green-upgrade","title":"Blue-Green Deployment","description":"<!--","source":"@site/versioned_docs/version-4.1/blue-green-upgrade.md","sourceDirName":".","slug":"/blue-green-upgrade","permalink":"/rabbitmq-website/docs/blue-green-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/blue-green-upgrade.md","tags":[],"version":"4.1","frontMatter":{"title":"Blue-Green Deployment"},"sidebar":"docsSidebar","previous":{"title":"Rolling Upgrade","permalink":"/rabbitmq-website/docs/rolling-upgrade"},"next":{"title":"Grow-Then-Shrink Upgrade","permalink":"/rabbitmq-website/docs/grow-then-shrink-upgrade"}},{"id":"build-server","title":"Server Build Instructions","description":"<!--","source":"@site/versioned_docs/version-4.1/build-server.md","sourceDirName":".","slug":"/build-server","permalink":"/rabbitmq-website/docs/build-server","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/build-server.md","tags":[],"version":"4.1","frontMatter":{"title":"Server Build Instructions","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"channels/index","title":"Channels","description":"<!--","source":"@site/versioned_docs/version-4.1/channels/index.md","sourceDirName":"channels","slug":"/channels/","permalink":"/rabbitmq-website/docs/channels/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/channels/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Channels","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Streams","permalink":"/rabbitmq-website/docs/streams"},"next":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/reliability"}},{"id":"classic-queues","title":"Classic Queues","description":"<!--","source":"@site/versioned_docs/version-4.1/classic-queues.md","sourceDirName":".","slug":"/classic-queues","permalink":"/rabbitmq-website/docs/classic-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/classic-queues.md","tags":[],"version":"4.1","frontMatter":{"title":"Classic Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/quorum-queues/"},"next":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/ttl"}},{"id":"cli","title":"Command Line Tools","description":"<!--","source":"@site/versioned_docs/version-4.1/cli.md","sourceDirName":".","slug":"/cli","permalink":"/rabbitmq-website/docs/cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/cli.md","tags":[],"version":"4.1","frontMatter":{"title":"Command Line Tools"},"sidebar":"docsSidebar","previous":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/manage-rabbitmq"},"next":{"title":"Configuration","permalink":"/rabbitmq-website/docs/configure"}},{"id":"cluster-formation","title":"Cluster Formation and Peer Discovery","description":"<!--","source":"@site/versioned_docs/version-4.1/cluster-formation.md","sourceDirName":".","slug":"/cluster-formation","permalink":"/rabbitmq-website/docs/cluster-formation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/cluster-formation.md","tags":[],"version":"4.1","frontMatter":{"title":"Cluster Formation and Peer Discovery"},"sidebar":"docsSidebar","previous":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/clustering"},"next":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/partitions"}},{"id":"clustering","title":"Clustering Guide","description":"<!--","source":"@site/versioned_docs/version-4.1/clustering.md","sourceDirName":".","slug":"/clustering","permalink":"/rabbitmq-website/docs/clustering","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/clustering.md","tags":[],"version":"4.1","frontMatter":{"title":"Clustering Guide"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/troubleshooting-ssl"},"next":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/cluster-formation"}},{"id":"clustering-ssl","title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS","description":"<!--","source":"@site/versioned_docs/version-4.1/clustering-ssl.md","sourceDirName":".","slug":"/clustering-ssl","permalink":"/rabbitmq-website/docs/clustering-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/clustering-ssl.md","tags":[],"version":"4.1","frontMatter":{"title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS"},"sidebar":"docsSidebar","previous":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/partitions"},"next":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/ec2"}},{"id":"configure","title":"Configuration","description":"<!--","source":"@site/versioned_docs/version-4.1/configure.md","sourceDirName":".","slug":"/configure","permalink":"/rabbitmq-website/docs/configure","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/configure.md","tags":[],"version":"4.1","frontMatter":{"title":"Configuration"},"sidebar":"docsSidebar","previous":{"title":"CLI","permalink":"/rabbitmq-website/docs/cli"},"next":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/relocate"}},{"id":"confirms","title":"Consumer Acknowledgements and Publisher Confirms","description":"<!--","source":"@site/versioned_docs/version-4.1/confirms.md","sourceDirName":".","slug":"/confirms","permalink":"/rabbitmq-website/docs/confirms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/confirms.md","tags":[],"version":"4.1","frontMatter":{"title":"Consumer Acknowledgements and Publisher Confirms"},"sidebar":"docsSidebar","previous":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/reliability"},"next":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/distributed"}},{"id":"connection-blocked","title":"Blocked Connection Notifications","description":"<!--","source":"@site/versioned_docs/version-4.1/connection-blocked.md","sourceDirName":".","slug":"/connection-blocked","permalink":"/rabbitmq-website/docs/connection-blocked","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/connection-blocked.md","tags":[],"version":"4.1","frontMatter":{"title":"Blocked Connection Notifications"},"sidebar":"docsSidebar","previous":{"title":"Local random exchange","permalink":"/rabbitmq-website/docs/local-random-exchange"},"next":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/e2e"}},{"id":"connections/index","title":"Connections","description":"<!--","source":"@site/versioned_docs/version-4.1/connections/index.md","sourceDirName":"connections","slug":"/connections/","permalink":"/rabbitmq-website/docs/connections/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/connections/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Connections"},"sidebar":"docsSidebar","previous":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/docs/amqp"},"next":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/conversions"}},{"id":"consumer-cancel","title":"Consumer Cancel Notification","description":"<!--","source":"@site/versioned_docs/version-4.1/consumer-cancel.md","sourceDirName":".","slug":"/consumer-cancel","permalink":"/rabbitmq-website/docs/consumer-cancel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/consumer-cancel.md","tags":[],"version":"4.1","frontMatter":{"title":"Consumer Cancel Notification"},"sidebar":"docsSidebar","previous":{"title":"Consumers","permalink":"/rabbitmq-website/docs/consumers"},"next":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/consumer-prefetch"}},{"id":"consumer-prefetch","title":"Consumer Prefetch","description":"<!--","source":"@site/versioned_docs/version-4.1/consumer-prefetch.md","sourceDirName":".","slug":"/consumer-prefetch","permalink":"/rabbitmq-website/docs/consumer-prefetch","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/consumer-prefetch.md","tags":[],"version":"4.1","frontMatter":{"title":"Consumer Prefetch"},"sidebar":"docsSidebar","previous":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/consumer-cancel"},"next":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/consumer-priority"}},{"id":"consumer-priority","title":"Consumer Priorities","description":"<!--","source":"@site/versioned_docs/version-4.1/consumer-priority.md","sourceDirName":".","slug":"/consumer-priority","permalink":"/rabbitmq-website/docs/consumer-priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/consumer-priority.md","tags":[],"version":"4.1","frontMatter":{"title":"Consumer Priorities"},"sidebar":"docsSidebar","previous":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/consumer-prefetch"},"next":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/nack"}},{"id":"consumers","title":"Consumers","description":"<!--","source":"@site/versioned_docs/version-4.1/consumers.md","sourceDirName":".","slug":"/consumers","permalink":"/rabbitmq-website/docs/consumers","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/consumers.md","tags":[],"version":"4.1","frontMatter":{"title":"Consumers","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/exchanges"},"next":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/consumer-cancel"}},{"id":"conversions","title":"Inter-Protocol Property Conversions","description":"<!--","source":"@site/versioned_docs/version-4.1/conversions.md","sourceDirName":".","slug":"/conversions","permalink":"/rabbitmq-website/docs/conversions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/conversions.md","tags":[],"version":"4.1","frontMatter":{"title":"Inter-Protocol Property Conversions"},"sidebar":"docsSidebar","previous":{"title":"Connections","permalink":"/rabbitmq-website/docs/connections/"},"next":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/heartbeats"}},{"id":"definitions","title":"Schema Definition Export and Import","description":"<!--","source":"@site/versioned_docs/version-4.1/definitions.md","sourceDirName":".","slug":"/definitions","permalink":"/rabbitmq-website/docs/definitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/definitions.md","tags":[],"version":"4.1","frontMatter":{"title":"Schema Definition Export and Import"},"sidebar":"docsSidebar","previous":{"title":"Khepri FAQ","permalink":"/rabbitmq-website/docs/metadata-store/khepri-faq"},"next":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/networking"}},{"id":"deprecated-features/index","title":"Deprecated Features","description":"<!--","source":"@site/versioned_docs/version-4.1/deprecated-features/index.md","sourceDirName":"deprecated-features","slug":"/deprecated-features/","permalink":"/rabbitmq-website/docs/deprecated-features/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/deprecated-features/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Deprecated Features"},"sidebar":"docsSidebar","previous":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/feature-flags/"},"next":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/snapshots"}},{"id":"direct-reply-to","title":"Direct Reply-to","description":"<!--","source":"@site/versioned_docs/version-4.1/direct-reply-to.md","sourceDirName":".","slug":"/direct-reply-to","permalink":"/rabbitmq-website/docs/direct-reply-to","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/direct-reply-to.md","tags":[],"version":"4.1","frontMatter":{"title":"Direct Reply-to"},"sidebar":"docsSidebar","previous":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/exchanges"},"next":{"title":"Local random exchange","permalink":"/rabbitmq-website/docs/local-random-exchange"}},{"id":"disk-alarms","title":"Free Disk Space Alarms","description":"<!--","source":"@site/versioned_docs/version-4.1/disk-alarms.md","sourceDirName":".","slug":"/disk-alarms","permalink":"/rabbitmq-website/docs/disk-alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/disk-alarms.md","tags":[],"version":"4.1","frontMatter":{"title":"Free Disk Space Alarms"},"sidebar":"docsSidebar","previous":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/memory"},"next":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/flow-control"}},{"id":"distributed","title":"Distributed RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.1/distributed.md","sourceDirName":".","slug":"/distributed","permalink":"/rabbitmq-website/docs/distributed","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/distributed.md","tags":[],"version":"4.1","frontMatter":{"title":"Distributed RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/confirms"},"next":{"title":"Plugins","permalink":"/rabbitmq-website/docs/plugins"}},{"id":"dlx","title":"Dead Letter Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.1/dlx.md","sourceDirName":".","slug":"/dlx","permalink":"/rabbitmq-website/docs/dlx","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/dlx.md","tags":[],"version":"4.1","frontMatter":{"title":"Dead Letter Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/lazy-queues"},"next":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/priority"}},{"id":"download","title":"Installing RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.1/download.md","sourceDirName":".","slug":"/download","permalink":"/rabbitmq-website/docs/download","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/download.md","tags":[],"version":"4.1","frontMatter":{"title":"Installing RabbitMQ","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Introduction","permalink":"/rabbitmq-website/docs/"},"next":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/which-erlang"}},{"id":"e2e","title":"Exchange to Exchange Bindings","description":"<!--","source":"@site/versioned_docs/version-4.1/e2e.md","sourceDirName":".","slug":"/e2e","permalink":"/rabbitmq-website/docs/e2e","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/e2e.md","tags":[],"version":"4.1","frontMatter":{"title":"Exchange to Exchange Bindings"},"sidebar":"docsSidebar","previous":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/connection-blocked"},"next":{"title":"Alternate Exchanges","permalink":"/rabbitmq-website/docs/ae"}},{"id":"ec2","title":"Running RabbitMQ on Amazon EC2","description":"<!--","source":"@site/versioned_docs/version-4.1/ec2.md","sourceDirName":".","slug":"/ec2","permalink":"/rabbitmq-website/docs/ec2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/ec2.md","tags":[],"version":"4.1","frontMatter":{"title":"Running RabbitMQ on Amazon EC2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/clustering-ssl"},"next":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/memory-use/"}},{"id":"event-exchange","title":"Event Exchange Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/event-exchange.md","sourceDirName":".","slug":"/event-exchange","permalink":"/rabbitmq-website/docs/event-exchange","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/event-exchange.md","tags":[],"version":"4.1","frontMatter":{"title":"Event Exchange Plugin"},"sidebar":"docsSidebar","previous":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/prometheus/"},"next":{"title":"Firehose Tracing","permalink":"/rabbitmq-website/docs/firehose"}},{"id":"exchanges","title":"Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.1/exchanges.md","sourceDirName":".","slug":"/exchanges","permalink":"/rabbitmq-website/docs/exchanges","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/exchanges.md","tags":[],"version":"4.1","frontMatter":{"title":"Exchanges","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Publishers","permalink":"/rabbitmq-website/docs/publishers/"},"next":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/direct-reply-to"}},{"id":"extensions","title":"AMQP 0-9-1 Protocol Extensions","description":"<!--","source":"@site/versioned_docs/version-4.1/extensions.md","sourceDirName":".","slug":"/extensions","permalink":"/rabbitmq-website/docs/extensions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/extensions.md","tags":[],"version":"4.1","frontMatter":{"title":"AMQP 0-9-1 Protocol Extensions"},"sidebar":"docsSidebar","previous":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/heartbeats"},"next":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/manage-rabbitmq"}},{"id":"feature-flags/index","title":"Feature Flags","description":"<!--","source":"@site/versioned_docs/version-4.1/feature-flags/index.md","sourceDirName":"feature-flags","slug":"/feature-flags/","permalink":"/rabbitmq-website/docs/feature-flags/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/feature-flags/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Feature Flags"},"sidebar":"docsSidebar","previous":{"title":"Grow-Then-Shrink Upgrade","permalink":"/rabbitmq-website/docs/grow-then-shrink-upgrade"},"next":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/deprecated-features/"}},{"id":"federated-exchanges/index","title":"Federated Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.1/federated-exchanges/index.md","sourceDirName":"federated-exchanges","slug":"/federated-exchanges/","permalink":"/rabbitmq-website/docs/federated-exchanges/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/federated-exchanges/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Federated Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/federation"},"next":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/federated-queues/"}},{"id":"federated-queues/index","title":"Federated Queues","description":"<!--","source":"@site/versioned_docs/version-4.1/federated-queues/index.md","sourceDirName":"federated-queues","slug":"/federated-queues/","permalink":"/rabbitmq-website/docs/federated-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/federated-queues/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Federated Queues"},"sidebar":"docsSidebar","previous":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/federated-exchanges/"},"next":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/federation-reference"}},{"id":"federation","title":"Federation Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/federation.md","sourceDirName":".","slug":"/federation","permalink":"/rabbitmq-website/docs/federation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/federation.md","tags":[],"version":"4.1","frontMatter":{"title":"Federation Plugin"},"sidebar":"docsSidebar","previous":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/management/"},"next":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/federated-exchanges/"}},{"id":"federation-reference","title":"Federation Reference","description":"<!--","source":"@site/versioned_docs/version-4.1/federation-reference.md","sourceDirName":".","slug":"/federation-reference","permalink":"/rabbitmq-website/docs/federation-reference","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/federation-reference.md","tags":[],"version":"4.1","frontMatter":{"title":"Federation Reference"},"sidebar":"docsSidebar","previous":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/federated-queues/"},"next":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/shovel"}},{"id":"firehose","title":"Firehose Tracer","description":"<!--","source":"@site/versioned_docs/version-4.1/firehose.md","sourceDirName":".","slug":"/firehose","permalink":"/rabbitmq-website/docs/firehose","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/firehose.md","tags":[],"version":"4.1","frontMatter":{"title":"Firehose Tracer"},"sidebar":"docsSidebar","previous":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/event-exchange"}},{"id":"flow-control","title":"Flow Control","description":"<!--","source":"@site/versioned_docs/version-4.1/flow-control.md","sourceDirName":".","slug":"/flow-control","permalink":"/rabbitmq-website/docs/flow-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/flow-control.md","tags":[],"version":"4.1","frontMatter":{"title":"Flow Control"},"sidebar":"docsSidebar","previous":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/disk-alarms"},"next":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/backup"}},{"id":"grow-then-shrink-upgrade","title":"Grow-then-Shrink Upgrade","description":"<!--","source":"@site/versioned_docs/version-4.1/grow-then-shrink-upgrade.md","sourceDirName":".","slug":"/grow-then-shrink-upgrade","permalink":"/rabbitmq-website/docs/grow-then-shrink-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/grow-then-shrink-upgrade.md","tags":[],"version":"4.1","frontMatter":{"title":"Grow-then-Shrink Upgrade"},"sidebar":"docsSidebar","previous":{"title":"Blue-Green Deployment","permalink":"/rabbitmq-website/docs/blue-green-upgrade"},"next":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/feature-flags/"}},{"id":"heartbeats","title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives","description":"<!--","source":"@site/versioned_docs/version-4.1/heartbeats.md","sourceDirName":".","slug":"/heartbeats","permalink":"/rabbitmq-website/docs/heartbeats","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/heartbeats.md","tags":[],"version":"4.1","frontMatter":{"title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives"},"sidebar":"docsSidebar","previous":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/conversions"},"next":{"title":"AMQP 0-9-1 Extensions","permalink":"/rabbitmq-website/docs/extensions"}},{"id":"http-api-reference","title":"HTTP API Reference","description":"<!--","source":"@site/versioned_docs/version-4.1/http-api-reference.md","sourceDirName":".","slug":"/http-api-reference","permalink":"/rabbitmq-website/docs/http-api-reference","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/http-api-reference.md","tags":[],"version":"4.1","frontMatter":{"title":"HTTP API Reference"}},{"id":"index","title":"RabbitMQ Documentation","description":"<!--","source":"@site/versioned_docs/version-4.1/index.md","sourceDirName":".","slug":"/","permalink":"/rabbitmq-website/docs/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/index.md","tags":[],"version":"4.1","frontMatter":{"title":"RabbitMQ Documentation"},"sidebar":"docsSidebar","next":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/download"}},{"id":"install-debian","title":"Installing on Debian and Ubuntu","description":"<!--","source":"@site/versioned_docs/version-4.1/install-debian.md","sourceDirName":".","slug":"/install-debian","permalink":"/rabbitmq-website/docs/install-debian","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-debian.md","tags":[],"version":"4.1","frontMatter":{"title":"Installing on Debian and Ubuntu","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/platforms"},"next":{"title":"RedHat","permalink":"/rabbitmq-website/docs/install-rpm"}},{"id":"install-generic-unix","title":"Generic Binary Build","description":"<!--","source":"@site/versioned_docs/version-4.1/install-generic-unix.md","sourceDirName":".","slug":"/install-generic-unix","permalink":"/rabbitmq-website/docs/install-generic-unix","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-generic-unix.md","tags":[],"version":"4.1","frontMatter":{"title":"Generic Binary Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"RedHat","permalink":"/rabbitmq-website/docs/install-rpm"},"next":{"title":"Windows","permalink":"/rabbitmq-website/docs/install-windows"}},{"id":"install-homebrew","title":"The Homebrew RabbitMQ Formula","description":"<!--","source":"@site/versioned_docs/version-4.1/install-homebrew.md","sourceDirName":".","slug":"/install-homebrew","permalink":"/rabbitmq-website/docs/install-homebrew","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-homebrew.md","tags":[],"version":"4.1","frontMatter":{"title":"The Homebrew RabbitMQ Formula","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/install-standalone-mac"},"next":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/upgrade"}},{"id":"install-rpm","title":"Installing on RPM-based Linux","description":"<!--","source":"@site/versioned_docs/version-4.1/install-rpm.md","sourceDirName":".","slug":"/install-rpm","permalink":"/rabbitmq-website/docs/install-rpm","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-rpm.md","tags":[],"version":"4.1","frontMatter":{"title":"Installing on RPM-based Linux","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/install-debian"},"next":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/install-generic-unix"}},{"id":"install-solaris","title":"Installing on Solaris","description":"<!--","source":"@site/versioned_docs/version-4.1/install-solaris.md","sourceDirName":".","slug":"/install-solaris","permalink":"/rabbitmq-website/docs/install-solaris","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-solaris.md","tags":[],"version":"4.1","frontMatter":{"title":"Installing on Solaris","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"install-standalone-mac","title":"Standalone MacOS Build","description":"<!--","source":"@site/versioned_docs/version-4.1/install-standalone-mac.md","sourceDirName":".","slug":"/install-standalone-mac","permalink":"/rabbitmq-website/docs/install-standalone-mac","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-standalone-mac.md","tags":[],"version":"4.1","frontMatter":{"title":"Standalone MacOS Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Windows","permalink":"/rabbitmq-website/docs/install-windows"},"next":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/install-homebrew"}},{"id":"install-windows","title":"Installing on Windows","description":"<!--","source":"@site/versioned_docs/version-4.1/install-windows.md","sourceDirName":".","slug":"/install-windows","permalink":"/rabbitmq-website/docs/install-windows","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-windows.md","tags":[],"version":"4.1","frontMatter":{"title":"Installing on Windows","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/install-generic-unix"},"next":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/install-standalone-mac"}},{"id":"install-windows-manual","title":"Installing on Windows manually","description":"<!--","source":"@site/versioned_docs/version-4.1/install-windows-manual.md","sourceDirName":".","slug":"/install-windows-manual","permalink":"/rabbitmq-website/docs/install-windows-manual","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/install-windows-manual.md","tags":[],"version":"4.1","frontMatter":{"title":"Installing on Windows manually","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"installing-plugins","title":"installing Additional Plugins","description":"<!--","source":"@site/versioned_docs/version-4.1/installing-plugins.md","sourceDirName":".","slug":"/installing-plugins","permalink":"/rabbitmq-website/docs/installing-plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/installing-plugins.md","tags":[],"version":"4.1","frontMatter":{"title":"installing Additional Plugins"},"sidebar":"docsSidebar","previous":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/stream"},"next":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/protocols"}},{"id":"lazy-queues","title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)","description":"<!--","source":"@site/versioned_docs/version-4.1/lazy-queues.md","sourceDirName":".","slug":"/lazy-queues","permalink":"/rabbitmq-website/docs/lazy-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/lazy-queues.md","tags":[],"version":"4.1","frontMatter":{"title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)"},"sidebar":"docsSidebar","previous":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/maxlength/"},"next":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/dlx"}},{"id":"ldap","title":"LDAP Support","description":"<!--","source":"@site/versioned_docs/version-4.1/ldap.md","sourceDirName":".","slug":"/ldap","permalink":"/rabbitmq-website/docs/ldap","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/ldap.md","tags":[],"version":"4.1","frontMatter":{"title":"LDAP Support"},"sidebar":"docsSidebar","previous":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/oauth2"},"next":{"title":"Cache","permalink":"/rabbitmq-website/docs/auth-cache-backend"}},{"id":"local-random-exchange","title":"Local Random Exchange","description":"<!--","source":"@site/versioned_docs/version-4.1/local-random-exchange.md","sourceDirName":".","slug":"/local-random-exchange","permalink":"/rabbitmq-website/docs/local-random-exchange","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/local-random-exchange.md","tags":[],"version":"4.1","frontMatter":{"title":"Local Random Exchange"},"sidebar":"docsSidebar","previous":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/direct-reply-to"},"next":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/connection-blocked"}},{"id":"logging","title":"Logging","description":"<!--","source":"@site/versioned_docs/version-4.1/logging.md","sourceDirName":".","slug":"/logging","permalink":"/rabbitmq-website/docs/logging","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/logging.md","tags":[],"version":"4.1","frontMatter":{"title":"Logging"},"sidebar":"docsSidebar","previous":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/relocate"},"next":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/vhosts"}},{"id":"man/rabbitmq-diagnostics.8","title":"rabbitmq-diagnostics.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-diagnostics.8.md","sourceDirName":"man","slug":"/man/rabbitmq-diagnostics.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-diagnostics.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-diagnostics.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-echopid.8","title":"rabbitmq-echopid.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-echopid.8.md","sourceDirName":"man","slug":"/man/rabbitmq-echopid.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-echopid.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-echopid.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-env.conf.5","title":"rabbitmq-env.conf.5","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-env.conf.5.md","sourceDirName":"man","slug":"/man/rabbitmq-env.conf.5","permalink":"/rabbitmq-website/docs/man/rabbitmq-env.conf.5","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-env.conf.5.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-plugins.8","title":"rabbitmq-plugins.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-plugins.8.md","sourceDirName":"man","slug":"/man/rabbitmq-plugins.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-plugins.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-plugins.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-queues.8","title":"rabbitmq-queues.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-queues.8.md","sourceDirName":"man","slug":"/man/rabbitmq-queues.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-queues.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-queues.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-server.8","title":"rabbitmq-server.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-server.8.md","sourceDirName":"man","slug":"/man/rabbitmq-server.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-server.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-server.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-service.8","title":"rabbitmq-service.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-service.8.md","sourceDirName":"man","slug":"/man/rabbitmq-service.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-service.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-service.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-streams.8","title":"rabbitmq-streams.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-streams.8.md","sourceDirName":"man","slug":"/man/rabbitmq-streams.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-streams.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-streams.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmq-upgrade.8","title":"rabbitmq-upgrade.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmq-upgrade.8.md","sourceDirName":"man","slug":"/man/rabbitmq-upgrade.8","permalink":"/rabbitmq-website/docs/man/rabbitmq-upgrade.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmq-upgrade.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/rabbitmqctl.8","title":"rabbitmqctl.8","description":"NAME","source":"@site/versioned_docs/version-4.1/man/rabbitmqctl.8.md","sourceDirName":"man","slug":"/man/rabbitmqctl.8","permalink":"/rabbitmq-website/docs/man/rabbitmqctl.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/rabbitmqctl.8.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"man/README","title":"RabbitMQ man Pages","description":"Source Files","source":"@site/versioned_docs/version-4.1/man/README.md","sourceDirName":"man","slug":"/man/","permalink":"/rabbitmq-website/docs/man/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/man/README.md","tags":[],"version":"4.1","frontMatter":{}},{"id":"manage-rabbitmq","title":"How to Manage RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.1/manage-rabbitmq.md","sourceDirName":".","slug":"/manage-rabbitmq","permalink":"/rabbitmq-website/docs/manage-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/manage-rabbitmq.md","tags":[],"version":"4.1","frontMatter":{"title":"How to Manage RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"AMQP 0-9-1 Extensions","permalink":"/rabbitmq-website/docs/extensions"},"next":{"title":"CLI","permalink":"/rabbitmq-website/docs/cli"}},{"id":"management-cli","title":"rabbitmqadmin v2, a Command Line Tool for the HTTP API","description":"<!--","source":"@site/versioned_docs/version-4.1/management-cli.md","sourceDirName":".","slug":"/management-cli","permalink":"/rabbitmq-website/docs/management-cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/management-cli.md","tags":[],"version":"4.1","frontMatter":{"title":"rabbitmqadmin v2, a Command Line Tool for the HTTP API","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"management/index","title":"Management Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/management/index.md","sourceDirName":"management","slug":"/management/","permalink":"/rabbitmq-website/docs/management/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/management/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Management Plugin"},"sidebar":"docsSidebar","previous":{"title":"Plugins","permalink":"/rabbitmq-website/docs/plugins"},"next":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/federation"}},{"id":"manpages","title":"Manual Pages","description":"<!--","source":"@site/versioned_docs/version-4.1/manpages.md","sourceDirName":".","slug":"/manpages","permalink":"/rabbitmq-website/docs/manpages","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/manpages.md","tags":[],"version":"4.1","frontMatter":{"title":"Manual Pages","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"maxlength/index","title":"Queue Length Limit","description":"<!--","source":"@site/versioned_docs/version-4.1/maxlength/index.md","sourceDirName":"maxlength","slug":"/maxlength/","permalink":"/rabbitmq-website/docs/maxlength/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/maxlength/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Queue Length Limit"},"sidebar":"docsSidebar","previous":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/ttl"},"next":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/lazy-queues"}},{"id":"memory","title":"Memory Threshold and Limit","description":"<!--","source":"@site/versioned_docs/version-4.1/memory.md","sourceDirName":".","slug":"/memory","permalink":"/rabbitmq-website/docs/memory","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/memory.md","tags":[],"version":"4.1","frontMatter":{"title":"Memory Threshold and Limit"},"sidebar":"docsSidebar","previous":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/alarms"},"next":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/disk-alarms"}},{"id":"memory-use/index","title":"Reasoning About Memory Use","description":"<!--","source":"@site/versioned_docs/version-4.1/memory-use/index.md","sourceDirName":"memory-use","slug":"/memory-use/","permalink":"/rabbitmq-website/docs/memory-use/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/memory-use/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Reasoning About Memory Use"},"sidebar":"docsSidebar","previous":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/ec2"},"next":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/alarms"}},{"id":"metadata-store/clustering","title":"Clustering and Khepri","description":"When RabbitMQ nodes are clustered, they call the metadata","source":"@site/versioned_docs/version-4.1/metadata-store/clustering.md","sourceDirName":"metadata-store","slug":"/metadata-store/clustering","permalink":"/rabbitmq-website/docs/metadata-store/clustering","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/metadata-store/clustering.md","tags":[],"version":"4.1","frontMatter":{"title":"Clustering and Khepri"},"sidebar":"docsSidebar","previous":{"title":"How to enable Khepri","permalink":"/rabbitmq-website/docs/metadata-store/how-to-enable-khepri"},"next":{"title":"Everyday Operations with Khepri","permalink":"/rabbitmq-website/docs/metadata-store/everyday-operations"}},{"id":"metadata-store/everyday-operations","title":"Everyday Operations with Khepri","description":"Even though the metadata store doesn’t store messages, its behavior will affect","source":"@site/versioned_docs/version-4.1/metadata-store/everyday-operations.md","sourceDirName":"metadata-store","slug":"/metadata-store/everyday-operations","permalink":"/rabbitmq-website/docs/metadata-store/everyday-operations","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/metadata-store/everyday-operations.md","tags":[],"version":"4.1","frontMatter":{"title":"Everyday Operations with Khepri"},"sidebar":"docsSidebar","previous":{"title":"Clustering and Khepri","permalink":"/rabbitmq-website/docs/metadata-store/clustering"},"next":{"title":"Failure recovery with Khepri","permalink":"/rabbitmq-website/docs/metadata-store/failure-recovery"}},{"id":"metadata-store/failure-recovery","title":"How Khepri Approaches Failure Recovery","description":"This section describes Khepri’s Raft-based approach to failure handling and","source":"@site/versioned_docs/version-4.1/metadata-store/failure-recovery.md","sourceDirName":"metadata-store","slug":"/metadata-store/failure-recovery","permalink":"/rabbitmq-website/docs/metadata-store/failure-recovery","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/metadata-store/failure-recovery.md","tags":[],"version":"4.1","frontMatter":{"title":"How Khepri Approaches Failure Recovery"},"sidebar":"docsSidebar","previous":{"title":"Everyday Operations with Khepri","permalink":"/rabbitmq-website/docs/metadata-store/everyday-operations"},"next":{"title":"Known issues with Khepri","permalink":"/rabbitmq-website/docs/metadata-store/known-issues"}},{"id":"metadata-store/how-to-enable-khepri","title":"How to Enable Khepri","description":"In RabbitMQ 4.1.x, Mnesia is still the default metadata store backend. Khepri","source":"@site/versioned_docs/version-4.1/metadata-store/how-to-enable-khepri.md","sourceDirName":"metadata-store","slug":"/metadata-store/how-to-enable-khepri","permalink":"/rabbitmq-website/docs/metadata-store/how-to-enable-khepri","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/metadata-store/how-to-enable-khepri.md","tags":[],"version":"4.1","frontMatter":{"title":"How to Enable Khepri"},"sidebar":"docsSidebar","previous":{"title":"Metadata store","permalink":"/rabbitmq-website/docs/metadata-store/"},"next":{"title":"Clustering and Khepri","permalink":"/rabbitmq-website/docs/metadata-store/clustering"}},{"id":"metadata-store/index","title":"Metadata store","description":"Role of the metadata store","source":"@site/versioned_docs/version-4.1/metadata-store/index.md","sourceDirName":"metadata-store","slug":"/metadata-store/","permalink":"/rabbitmq-website/docs/metadata-store/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/metadata-store/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Metadata store"},"sidebar":"docsSidebar","previous":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/parameters"},"next":{"title":"How to enable Khepri","permalink":"/rabbitmq-website/docs/metadata-store/how-to-enable-khepri"}},{"id":"metadata-store/khepri-faq","title":"Khepri FAQ","description":"I see the khepri_db feature flag is marked as experimental in the RabbitMQ code. Is it supported?","source":"@site/versioned_docs/version-4.1/metadata-store/khepri-faq.md","sourceDirName":"metadata-store","slug":"/metadata-store/khepri-faq","permalink":"/rabbitmq-website/docs/metadata-store/khepri-faq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/metadata-store/khepri-faq.md","tags":[],"version":"4.1","frontMatter":{"title":"Khepri FAQ"},"sidebar":"docsSidebar","previous":{"title":"Known issues with Khepri","permalink":"/rabbitmq-website/docs/metadata-store/known-issues"},"next":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/definitions"}},{"id":"metadata-store/known-issues","title":"Known issues with Khepri","description":"This document lists the most common known issues with Khepri that may affect","source":"@site/versioned_docs/version-4.1/metadata-store/known-issues.md","sourceDirName":"metadata-store","slug":"/metadata-store/known-issues","permalink":"/rabbitmq-website/docs/metadata-store/known-issues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/metadata-store/known-issues.md","tags":[],"version":"4.1","frontMatter":{"title":"Known issues with Khepri"},"sidebar":"docsSidebar","previous":{"title":"Failure recovery with Khepri","permalink":"/rabbitmq-website/docs/metadata-store/failure-recovery"},"next":{"title":"Khepri FAQ","permalink":"/rabbitmq-website/docs/metadata-store/khepri-faq"}},{"id":"monitoring/index","title":"Monitoring","description":"<!--","source":"@site/versioned_docs/version-4.1/monitoring/index.md","sourceDirName":"monitoring","slug":"/monitoring/","permalink":"/rabbitmq-website/docs/monitoring/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/monitoring/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Monitoring"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/troubleshooting/"},"next":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/prometheus/"}},{"id":"mqtt","title":"MQTT Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/mqtt.md","sourceDirName":".","slug":"/mqtt","permalink":"/rabbitmq-website/docs/mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/mqtt.md","tags":[],"version":"4.1","frontMatter":{"title":"MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/web-stomp"},"next":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/web-mqtt"}},{"id":"nack","title":"Negative Acknowledgements","description":"<!--","source":"@site/versioned_docs/version-4.1/nack.md","sourceDirName":".","slug":"/nack","permalink":"/rabbitmq-website/docs/nack","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/nack.md","tags":[],"version":"4.1","frontMatter":{"title":"Negative Acknowledgements"},"sidebar":"docsSidebar","previous":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/consumer-priority"},"next":{"title":"Queues","permalink":"/rabbitmq-website/docs/queues"}},{"id":"nettick","title":"Net Tick Time (Inter-node Communication Heartbeats)","description":"<!--","source":"@site/versioned_docs/version-4.1/nettick.md","sourceDirName":".","slug":"/nettick","permalink":"/rabbitmq-website/docs/nettick","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/nettick.md","tags":[],"version":"4.1","frontMatter":{"title":"Net Tick Time (Inter-node Communication Heartbeats)"},"sidebar":"docsSidebar","previous":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/networking"},"next":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/ssl/"}},{"id":"networking","title":"Networking and RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.1/networking.md","sourceDirName":".","slug":"/networking","permalink":"/rabbitmq-website/docs/networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/networking.md","tags":[],"version":"4.1","frontMatter":{"title":"Networking and RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/definitions"},"next":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/nettick"}},{"id":"oauth2","title":"OAuth 2.0 Authentication Backend","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2.md","sourceDirName":".","slug":"/oauth2","permalink":"/rabbitmq-website/docs/oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2.md","tags":[],"version":"4.1","frontMatter":{"title":"OAuth 2.0 Authentication Backend"},"sidebar":"docsSidebar","previous":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/passwords"},"next":{"title":"LDAP","permalink":"/rabbitmq-website/docs/ldap"}},{"id":"oauth2-examples-auth0","title":"Use auth0.com as OAuth 2.0 Server","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-auth0.md","sourceDirName":".","slug":"/oauth2-examples-auth0","permalink":"/rabbitmq-website/docs/oauth2-examples-auth0","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-auth0.md","tags":[],"version":"4.1","frontMatter":{"title":"Use auth0.com as OAuth 2.0 Server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-entra-id/index","title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-entra-id/index.md","sourceDirName":"oauth2-examples-entra-id","slug":"/oauth2-examples-entra-id/","permalink":"/rabbitmq-website/docs/oauth2-examples-entra-id/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-entra-id/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-forward-proxy","title":"Use an explicit forward proxy and Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-forward-proxy.md","sourceDirName":".","slug":"/oauth2-examples-forward-proxy","permalink":"/rabbitmq-website/docs/oauth2-examples-forward-proxy","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-forward-proxy.md","tags":[],"version":"4.1","frontMatter":{"title":"Use an explicit forward proxy and Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-google","title":"Use Google as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-google.md","sourceDirName":".","slug":"/oauth2-examples-google","permalink":"/rabbitmq-website/docs/oauth2-examples-google","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-google.md","tags":[],"version":"4.1","frontMatter":{"title":"Use Google as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-idp-initiated","title":"Use Identity Provider Initiated Logon","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-idp-initiated.md","sourceDirName":".","slug":"/oauth2-examples-idp-initiated","permalink":"/rabbitmq-website/docs/oauth2-examples-idp-initiated","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-idp-initiated.md","tags":[],"version":"4.1","frontMatter":{"title":"Use Identity Provider Initiated Logon","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-keycloak","title":"Use Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-keycloak.md","sourceDirName":".","slug":"/oauth2-examples-keycloak","permalink":"/rabbitmq-website/docs/oauth2-examples-keycloak","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-keycloak.md","tags":[],"version":"4.1","frontMatter":{"title":"Use Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-multiresource","title":"Using Multiple OAuth 2.0 Servers and/or Audiences","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-multiresource.md","sourceDirName":".","slug":"/oauth2-examples-multiresource","permalink":"/rabbitmq-website/docs/oauth2-examples-multiresource","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-multiresource.md","tags":[],"version":"4.1","frontMatter":{"title":"Using Multiple OAuth 2.0 Servers and/or Audiences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-okta","title":"Use Okta as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-okta.md","sourceDirName":".","slug":"/oauth2-examples-okta","permalink":"/rabbitmq-website/docs/oauth2-examples-okta","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-okta.md","tags":[],"version":"4.1","frontMatter":{"title":"Use Okta as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-proxy","title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples-proxy.md","sourceDirName":".","slug":"/oauth2-examples-proxy","permalink":"/rabbitmq-website/docs/oauth2-examples-proxy","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples-proxy.md","tags":[],"version":"4.1","frontMatter":{"title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples/index","title":"OAuth 2.0 Authentication Examples","description":"<!--","source":"@site/versioned_docs/version-4.1/oauth2-examples/index.md","sourceDirName":"oauth2-examples","slug":"/oauth2-examples/","permalink":"/rabbitmq-website/docs/oauth2-examples/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/oauth2-examples/index.md","tags":[],"version":"4.1","frontMatter":{"title":"OAuth 2.0 Authentication Examples","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"parameters","title":"Runtime Parameters","description":"<!--","source":"@site/versioned_docs/version-4.1/parameters.md","sourceDirName":".","slug":"/parameters","permalink":"/rabbitmq-website/docs/parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/parameters.md","tags":[],"version":"4.1","frontMatter":{"title":"Runtime Parameters"},"sidebar":"docsSidebar","previous":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/user-limits"},"next":{"title":"Metadata store","permalink":"/rabbitmq-website/docs/metadata-store/"}},{"id":"partitions","title":"Clustering and Network Partitions","description":"<!--","source":"@site/versioned_docs/version-4.1/partitions.md","sourceDirName":".","slug":"/partitions","permalink":"/rabbitmq-website/docs/partitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/partitions.md","tags":[],"version":"4.1","frontMatter":{"title":"Clustering and Network Partitions"},"sidebar":"docsSidebar","previous":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/cluster-formation"},"next":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/clustering-ssl"}},{"id":"passwords","title":"Credentials and Passwords","description":"<!--","source":"@site/versioned_docs/version-4.1/passwords.md","sourceDirName":".","slug":"/passwords","permalink":"/rabbitmq-website/docs/passwords","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/passwords.md","tags":[],"version":"4.1","frontMatter":{"title":"Credentials and Passwords","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/authentication"},"next":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/oauth2"}},{"id":"persistence-conf","title":"Persistence Configuration","description":"<!--","source":"@site/versioned_docs/version-4.1/persistence-conf.md","sourceDirName":".","slug":"/persistence-conf","permalink":"/rabbitmq-website/docs/persistence-conf","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/persistence-conf.md","tags":[],"version":"4.1","frontMatter":{"title":"Persistence Configuration"},"sidebar":"docsSidebar","previous":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/runtime"},"next":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/production-checklist"}},{"id":"platforms","title":"Supported Platforms","description":"<!--","source":"@site/versioned_docs/version-4.1/platforms.md","sourceDirName":".","slug":"/platforms","permalink":"/rabbitmq-website/docs/platforms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/platforms.md","tags":[],"version":"4.1","frontMatter":{"title":"Supported Platforms"},"sidebar":"docsSidebar","previous":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/signatures"},"next":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/install-debian"}},{"id":"plugins","title":"Plugins","description":"<!--","source":"@site/versioned_docs/version-4.1/plugins.md","sourceDirName":".","slug":"/plugins","permalink":"/rabbitmq-website/docs/plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/plugins.md","tags":[],"version":"4.1","frontMatter":{"title":"Plugins","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/distributed"},"next":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/management/"}},{"id":"policies","title":"Policies","description":"<!--","source":"@site/versioned_docs/version-4.1/policies.md","sourceDirName":".","slug":"/policies","permalink":"/rabbitmq-website/docs/policies","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/policies.md","tags":[],"version":"4.1","frontMatter":{"title":"Policies"}},{"id":"priority","title":"Classic Queues Support Priorities","description":"<!--","source":"@site/versioned_docs/version-4.1/priority.md","sourceDirName":".","slug":"/priority","permalink":"/rabbitmq-website/docs/priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/priority.md","tags":[],"version":"4.1","frontMatter":{"title":"Classic Queues Support Priorities"},"sidebar":"docsSidebar","previous":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/dlx"},"next":{"title":"Streams","permalink":"/rabbitmq-website/docs/streams"}},{"id":"production-checklist","title":"Production Deployment Guidelines","description":"<!--","source":"@site/versioned_docs/version-4.1/production-checklist.md","sourceDirName":".","slug":"/production-checklist","permalink":"/rabbitmq-website/docs/production-checklist","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/production-checklist.md","tags":[],"version":"4.1","frontMatter":{"title":"Production Deployment Guidelines"},"sidebar":"docsSidebar","previous":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/persistence-conf"},"next":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/troubleshooting/"}},{"id":"prometheus/index","title":"Monitoring with Prometheus and Grafana","description":"Overview","source":"@site/versioned_docs/version-4.1/prometheus/index.md","sourceDirName":"prometheus","slug":"/prometheus/","permalink":"/rabbitmq-website/docs/prometheus/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/prometheus/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Monitoring with Prometheus and Grafana","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/monitoring/"},"next":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/event-exchange"}},{"id":"protocols","title":"Which protocols does RabbitMQ support?","description":"<!--","source":"@site/versioned_docs/version-4.1/protocols.md","sourceDirName":".","slug":"/protocols","permalink":"/rabbitmq-website/docs/protocols","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/protocols.md","tags":[],"version":"4.1","frontMatter":{"title":"Which protocols does RabbitMQ support?","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/installing-plugins"},"next":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/docs/amqp"}},{"id":"publishers/index","title":"Publishers","description":"<!--","source":"@site/versioned_docs/version-4.1/publishers/index.md","sourceDirName":"publishers","slug":"/publishers/","permalink":"/rabbitmq-website/docs/publishers/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/publishers/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Publishers"},"sidebar":"docsSidebar","previous":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/use-rabbitmq"},"next":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/exchanges"}},{"id":"queues","title":"Queues","description":"<!--","source":"@site/versioned_docs/version-4.1/queues.md","sourceDirName":".","slug":"/queues","permalink":"/rabbitmq-website/docs/queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/queues.md","tags":[],"version":"4.1","frontMatter":{"title":"Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/nack"},"next":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/quorum-queues/"}},{"id":"quorum-queues/index","title":"Quorum Queues","description":"<!--","source":"@site/versioned_docs/version-4.1/quorum-queues/index.md","sourceDirName":"quorum-queues","slug":"/quorum-queues/","permalink":"/rabbitmq-website/docs/quorum-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/quorum-queues/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Quorum Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Queues","permalink":"/rabbitmq-website/docs/queues"},"next":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/classic-queues"}},{"id":"reliability","title":"Reliability Guide","description":"<!--","source":"@site/versioned_docs/version-4.1/reliability.md","sourceDirName":".","slug":"/reliability","permalink":"/rabbitmq-website/docs/reliability","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/reliability.md","tags":[],"version":"4.1","frontMatter":{"title":"Reliability Guide"},"sidebar":"docsSidebar","previous":{"title":"Channels","permalink":"/rabbitmq-website/docs/channels/"},"next":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/confirms"}},{"id":"relocate","title":"File and Directory Locations","description":"<!--","source":"@site/versioned_docs/version-4.1/relocate.md","sourceDirName":".","slug":"/relocate","permalink":"/rabbitmq-website/docs/relocate","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/relocate.md","tags":[],"version":"4.1","frontMatter":{"title":"File and Directory Locations"},"sidebar":"docsSidebar","previous":{"title":"Configuration","permalink":"/rabbitmq-website/docs/configure"},"next":{"title":"Logging","permalink":"/rabbitmq-website/docs/logging"}},{"id":"rolling-upgrade","title":"Rolling (in-place) Upgrade","description":"<!--","source":"@site/versioned_docs/version-4.1/rolling-upgrade.md","sourceDirName":".","slug":"/rolling-upgrade","permalink":"/rabbitmq-website/docs/rolling-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/rolling-upgrade.md","tags":[],"version":"4.1","frontMatter":{"title":"Rolling (in-place) Upgrade"},"sidebar":"docsSidebar","previous":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/upgrade"},"next":{"title":"Blue-Green Deployment","permalink":"/rabbitmq-website/docs/blue-green-upgrade"}},{"id":"runtime","title":"Runtime Tuning","description":"<!--","source":"@site/versioned_docs/version-4.1/runtime.md","sourceDirName":".","slug":"/runtime","permalink":"/rabbitmq-website/docs/runtime","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/runtime.md","tags":[],"version":"4.1","frontMatter":{"title":"Runtime Tuning","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/backup"},"next":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/persistence-conf"}},{"id":"semantics","title":"Broker Semantics","description":"Here we describe the broker semantics. This should be read together with the AMQP specification.","source":"@site/versioned_docs/version-4.1/semantics.md","sourceDirName":".","slug":"/semantics","permalink":"/rabbitmq-website/docs/semantics","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/semantics.md","tags":[],"version":"4.1","frontMatter":{"title":"Broker Semantics","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"sender-selected","title":"Sender-selected Distribution","description":"<!--","source":"@site/versioned_docs/version-4.1/sender-selected.md","sourceDirName":".","slug":"/sender-selected","permalink":"/rabbitmq-website/docs/sender-selected","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/sender-selected.md","tags":[],"version":"4.1","frontMatter":{"title":"Sender-selected Distribution"},"sidebar":"docsSidebar","previous":{"title":"Alternate Exchanges","permalink":"/rabbitmq-website/docs/ae"},"next":{"title":"Validated User ID","permalink":"/rabbitmq-website/docs/validated-user-id"}},{"id":"shovel","title":"Shovel Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/shovel.md","sourceDirName":".","slug":"/shovel","permalink":"/rabbitmq-website/docs/shovel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/shovel.md","tags":[],"version":"4.1","frontMatter":{"title":"Shovel Plugin"},"sidebar":"docsSidebar","previous":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/federation-reference"},"next":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/shovel-static"}},{"id":"shovel-dynamic","title":"Configuring Dynamic Shovels","description":"<!--","source":"@site/versioned_docs/version-4.1/shovel-dynamic.md","sourceDirName":".","slug":"/shovel-dynamic","permalink":"/rabbitmq-website/docs/shovel-dynamic","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/shovel-dynamic.md","tags":[],"version":"4.1","frontMatter":{"title":"Configuring Dynamic Shovels"},"sidebar":"docsSidebar","previous":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/shovel-static"},"next":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/stomp"}},{"id":"shovel-static","title":"Configuring Static Shovels","description":"<!--","source":"@site/versioned_docs/version-4.1/shovel-static.md","sourceDirName":".","slug":"/shovel-static","permalink":"/rabbitmq-website/docs/shovel-static","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/shovel-static.md","tags":[],"version":"4.1","frontMatter":{"title":"Configuring Static Shovels"},"sidebar":"docsSidebar","previous":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/shovel"},"next":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/shovel-dynamic"}},{"id":"signatures","title":"Package Signatures","description":"<!--","source":"@site/versioned_docs/version-4.1/signatures.md","sourceDirName":".","slug":"/signatures","permalink":"/rabbitmq-website/docs/signatures","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/signatures.md","tags":[],"version":"4.1","frontMatter":{"title":"Package Signatures","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/which-erlang"},"next":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/platforms"}},{"id":"snapshots","title":"Snapshots Releases","description":"<!--","source":"@site/versioned_docs/version-4.1/snapshots.md","sourceDirName":".","slug":"/snapshots","permalink":"/rabbitmq-website/docs/snapshots","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/snapshots.md","tags":[],"version":"4.1","frontMatter":{"title":"Snapshots Releases"},"sidebar":"docsSidebar","previous":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/deprecated-features/"},"next":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/use-rabbitmq"}},{"id":"spec-differences","title":"Spec Differences","description":"Undeprecated Features","source":"@site/versioned_docs/version-4.1/spec-differences.md","sourceDirName":".","slug":"/spec-differences","permalink":"/rabbitmq-website/docs/spec-differences","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/spec-differences.md","tags":[],"version":"4.1","frontMatter":{"title":"Spec Differences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"specification","title":"Compatibility and Conformance","description":"RabbitMQ core broker implements the AMQP 1.0 specification and AMQP 0-9-1 specification with a number of AMQP 0-9-1 extensions.","source":"@site/versioned_docs/version-4.1/specification.md","sourceDirName":".","slug":"/specification","permalink":"/rabbitmq-website/docs/specification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/specification.md","tags":[],"version":"4.1","frontMatter":{"title":"Compatibility and Conformance","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"ssl/index","title":"TLS Support","description":"<!--","source":"@site/versioned_docs/version-4.1/ssl/index.md","sourceDirName":"ssl","slug":"/ssl/","permalink":"/rabbitmq-website/docs/ssl/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/ssl/index.md","tags":[],"version":"4.1","frontMatter":{"title":"TLS Support"},"sidebar":"docsSidebar","previous":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/nettick"},"next":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/troubleshooting-networking"}},{"id":"stomp","title":"STOMP Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/stomp.md","sourceDirName":".","slug":"/stomp","permalink":"/rabbitmq-website/docs/stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/stomp.md","tags":[],"version":"4.1","frontMatter":{"title":"STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/shovel-dynamic"},"next":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/web-stomp"}},{"id":"stream","title":"Stream Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/stream.md","sourceDirName":".","slug":"/stream","permalink":"/rabbitmq-website/docs/stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/stream.md","tags":[],"version":"4.1","frontMatter":{"title":"Stream Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/web-mqtt"},"next":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/installing-plugins"}},{"id":"stream-core-plugin-comparison","title":"Stream Core vs Stream Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/stream-core-plugin-comparison.md","sourceDirName":".","slug":"/stream-core-plugin-comparison","permalink":"/rabbitmq-website/docs/stream-core-plugin-comparison","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/stream-core-plugin-comparison.md","tags":[],"version":"4.1","frontMatter":{"title":"Stream Core vs Stream Plugin","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"streams","title":"Streams and Superstreams (Partitioned Streams)","description":"<!--","source":"@site/versioned_docs/version-4.1/streams.md","sourceDirName":".","slug":"/streams","permalink":"/rabbitmq-website/docs/streams","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/streams.md","tags":[],"version":"4.1","frontMatter":{"title":"Streams and Superstreams (Partitioned Streams)"},"sidebar":"docsSidebar","previous":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/priority"},"next":{"title":"Channels","permalink":"/rabbitmq-website/docs/channels/"}},{"id":"troubleshooting-networking","title":"Troubleshooting Network Connectivity","description":"<!--","source":"@site/versioned_docs/version-4.1/troubleshooting-networking.md","sourceDirName":".","slug":"/troubleshooting-networking","permalink":"/rabbitmq-website/docs/troubleshooting-networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/troubleshooting-networking.md","tags":[],"version":"4.1","frontMatter":{"title":"Troubleshooting Network Connectivity"},"sidebar":"docsSidebar","previous":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/ssl/"},"next":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/troubleshooting-ssl"}},{"id":"troubleshooting-oauth2","title":"Troubleshooting OAuth 2","description":"<!--","source":"@site/versioned_docs/version-4.1/troubleshooting-oauth2.md","sourceDirName":".","slug":"/troubleshooting-oauth2","permalink":"/rabbitmq-website/docs/troubleshooting-oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/troubleshooting-oauth2.md","tags":[],"version":"4.1","frontMatter":{"title":"Troubleshooting OAuth 2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"troubleshooting-ssl","title":"Troubleshooting TLS-enabled Connections","description":"<!--","source":"@site/versioned_docs/version-4.1/troubleshooting-ssl.md","sourceDirName":".","slug":"/troubleshooting-ssl","permalink":"/rabbitmq-website/docs/troubleshooting-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/troubleshooting-ssl.md","tags":[],"version":"4.1","frontMatter":{"title":"Troubleshooting TLS-enabled Connections"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/troubleshooting-networking"},"next":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/clustering"}},{"id":"troubleshooting/index","title":"Troubleshooting Guidance","description":"<!--","source":"@site/versioned_docs/version-4.1/troubleshooting/index.md","sourceDirName":"troubleshooting","slug":"/troubleshooting/","permalink":"/rabbitmq-website/docs/troubleshooting/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/troubleshooting/index.md","tags":[],"version":"4.1","frontMatter":{"title":"Troubleshooting Guidance"},"sidebar":"docsSidebar","previous":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/production-checklist"},"next":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/monitoring/"}},{"id":"ttl","title":"Time-To-Live and Expiration","description":"<!--","source":"@site/versioned_docs/version-4.1/ttl.md","sourceDirName":".","slug":"/ttl","permalink":"/rabbitmq-website/docs/ttl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/ttl.md","tags":[],"version":"4.1","frontMatter":{"title":"Time-To-Live and Expiration"},"sidebar":"docsSidebar","previous":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/classic-queues"},"next":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/maxlength/"}},{"id":"upgrade","title":"Upgrading RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.1/upgrade.md","sourceDirName":".","slug":"/upgrade","permalink":"/rabbitmq-website/docs/upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/upgrade.md","tags":[],"version":"4.1","frontMatter":{"title":"Upgrading RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/install-homebrew"},"next":{"title":"Rolling Upgrade","permalink":"/rabbitmq-website/docs/rolling-upgrade"}},{"id":"uri-query-parameters","title":"URI Query Parameters","description":"<!--","source":"@site/versioned_docs/version-4.1/uri-query-parameters.md","sourceDirName":".","slug":"/uri-query-parameters","permalink":"/rabbitmq-website/docs/uri-query-parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/uri-query-parameters.md","tags":[],"version":"4.1","frontMatter":{"title":"URI Query Parameters","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"uri-spec","title":"RabbitMQ URI Specification","description":"<!--","source":"@site/versioned_docs/version-4.1/uri-spec.md","sourceDirName":".","slug":"/uri-spec","permalink":"/rabbitmq-website/docs/uri-spec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/uri-spec.md","tags":[],"version":"4.1","frontMatter":{"title":"RabbitMQ URI Specification","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"use-rabbitmq","title":"How to Use RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.1/use-rabbitmq.md","sourceDirName":".","slug":"/use-rabbitmq","permalink":"/rabbitmq-website/docs/use-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/use-rabbitmq.md","tags":[],"version":"4.1","frontMatter":{"title":"How to Use RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/snapshots"},"next":{"title":"Publishers","permalink":"/rabbitmq-website/docs/publishers/"}},{"id":"user-limits","title":"Per-user Resource Limits","description":"<!--","source":"@site/versioned_docs/version-4.1/user-limits.md","sourceDirName":".","slug":"/user-limits","permalink":"/rabbitmq-website/docs/user-limits","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/user-limits.md","tags":[],"version":"4.1","frontMatter":{"title":"Per-user Resource Limits","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/auth-notification"},"next":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/parameters"}},{"id":"validated-user-id","title":"Validated User-ID","description":"<!--","source":"@site/versioned_docs/version-4.1/validated-user-id.md","sourceDirName":".","slug":"/validated-user-id","permalink":"/rabbitmq-website/docs/validated-user-id","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/validated-user-id.md","tags":[],"version":"4.1","frontMatter":{"title":"Validated User-ID"},"sidebar":"docsSidebar","previous":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/sender-selected"},"next":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/exchanges"}},{"id":"vhosts","title":"Virtual Hosts","description":"<!--","source":"@site/versioned_docs/version-4.1/vhosts.md","sourceDirName":".","slug":"/vhosts","permalink":"/rabbitmq-website/docs/vhosts","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/vhosts.md","tags":[],"version":"4.1","frontMatter":{"title":"Virtual Hosts"},"sidebar":"docsSidebar","previous":{"title":"Logging","permalink":"/rabbitmq-website/docs/logging"},"next":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/access-control"}},{"id":"web-mqtt","title":"RabbitMQ Web MQTT Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/web-mqtt.md","sourceDirName":".","slug":"/web-mqtt","permalink":"/rabbitmq-website/docs/web-mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/web-mqtt.md","tags":[],"version":"4.1","frontMatter":{"title":"RabbitMQ Web MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/mqtt"},"next":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/stream"}},{"id":"web-stomp","title":"RabbitMQ Web STOMP Plugin","description":"<!--","source":"@site/versioned_docs/version-4.1/web-stomp.md","sourceDirName":".","slug":"/web-stomp","permalink":"/rabbitmq-website/docs/web-stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/web-stomp.md","tags":[],"version":"4.1","frontMatter":{"title":"RabbitMQ Web STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/stomp"},"next":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/mqtt"}},{"id":"which-erlang","title":"Erlang Version Requirements","description":"<!--","source":"@site/versioned_docs/version-4.1/which-erlang.md","sourceDirName":".","slug":"/which-erlang","permalink":"/rabbitmq-website/docs/which-erlang","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/which-erlang.md","tags":[],"version":"4.1","frontMatter":{"title":"Erlang Version Requirements","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/download"},"next":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/signatures"}},{"id":"windows-configuration","title":"Windows Configuration","description":"<!--","source":"@site/versioned_docs/version-4.1/windows-configuration.md","sourceDirName":".","slug":"/windows-configuration","permalink":"/rabbitmq-website/docs/windows-configuration","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.1/windows-configuration.md","tags":[],"version":"4.1","frontMatter":{"title":"Windows Configuration","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"}],"drafts":[],"sidebars":{"docsSidebar":[{"type":"doc","id":"index","label":"Introduction","translatable":true},{"type":"link","label":"Release Information","href":"/release-information"},{"type":"link","label":"Getting Started","href":"/tutorials"},{"type":"category","label":"Install and Upgrade","link":{"type":"doc","id":"download"},"items":[{"type":"doc","id":"which-erlang","label":"Erlang Version Requirements","translatable":true},{"type":"doc","id":"signatures","label":"Package Signatures","translatable":true},{"type":"category","label":"Supported Operating Systems","link":{"type":"doc","id":"platforms"},"items":[{"type":"category","label":"Linux/Unix","items":[{"type":"doc","id":"install-debian","label":"Debian and Ubuntu","translatable":true},{"type":"doc","id":"install-rpm","label":"RedHat","translatable":true},{"type":"doc","id":"install-generic-unix","label":"Generic Unix","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"install-windows","label":"Windows","translatable":true},{"type":"category","label":"MacOS","items":[{"type":"doc","id":"install-standalone-mac","label":"MacOS using Standalone Binary Build","translatable":true},{"type":"doc","id":"install-homebrew","label":"MacOs using Homebrew","translatable":true}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Kubernetes Operator","href":"/kubernetes/operator/install-operator"},{"type":"category","label":"Upgrade","link":{"type":"doc","id":"upgrade"},"items":[{"type":"doc","id":"rolling-upgrade","label":"Rolling Upgrade","translatable":true},{"type":"doc","id":"blue-green-upgrade","label":"Blue-Green Deployment","translatable":true},{"type":"doc","id":"grow-then-shrink-upgrade","label":"Grow-Then-Shrink Upgrade","translatable":true},{"type":"doc","id":"feature-flags/index","label":"Feature Flags","translatable":true},{"type":"doc","id":"deprecated-features/index","label":"Deprecated Features","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"snapshots","label":"Snapshots","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Use RabbitMQ","link":{"type":"doc","id":"use-rabbitmq"},"items":[{"type":"category","label":"Publishing Messages","link":{"type":"doc","id":"publishers/index"},"items":[{"type":"doc","id":"exchanges","label":"Exchanges","translatable":true},{"type":"doc","id":"direct-reply-to","label":"Direct reply-to","translatable":true},{"type":"doc","id":"local-random-exchange","label":"Local random exchange","translatable":true},{"type":"doc","id":"connection-blocked","label":"Blocked Connection Notifications","translatable":true},{"type":"doc","id":"e2e","label":"Exchange to Exchange Bindings","translatable":true},{"type":"doc","id":"ae","label":"Alternate Exchanges","translatable":true},{"type":"doc","id":"sender-selected","label":"Sender-selected Distribution","translatable":true},{"type":"doc","id":"validated-user-id","label":"Validated User ID","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"exchanges","label":"Exchanges","translatable":true},{"type":"category","label":"Consuming Messages","link":{"type":"doc","id":"consumers"},"items":[{"type":"doc","id":"consumer-cancel","label":"Consumer Cancellation Notifications","translatable":true},{"type":"doc","id":"consumer-prefetch","label":"Consumer Prefetch","translatable":true},{"type":"doc","id":"consumer-priority","label":"Consumer Priorites","translatable":true},{"type":"doc","id":"nack","label":"Negative Acknowledgements","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Queues","link":{"type":"doc","id":"queues"},"items":[{"type":"doc","id":"quorum-queues/index","label":"Quorum Queues","translatable":true},{"type":"doc","id":"classic-queues","label":"Classic Queues","translatable":true},{"type":"doc","id":"ttl","label":"Time-to-Live and Expiration","translatable":true},{"type":"doc","id":"maxlength/index","label":"Queue Length","translatable":true},{"type":"doc","id":"lazy-queues","label":"Lazy Queues","translatable":true},{"type":"doc","id":"dlx","label":"Dead Lettering","translatable":true},{"type":"doc","id":"priority","label":"Priority Queues","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"streams","label":"Streams","translatable":true},{"type":"doc","id":"channels/index","label":"Channels","translatable":true},{"type":"doc","id":"reliability","label":"Reliability and Data Safety","translatable":true},{"type":"doc","id":"confirms","label":"Consumer Acknowledgements and Publisher Confirms","translatable":true},{"type":"doc","id":"distributed","label":"Network Distribution","translatable":true},{"type":"category","label":"Plugins","link":{"type":"doc","id":"plugins"},"items":[{"type":"doc","id":"management/index","label":"Management Plugin","translatable":true},{"type":"category","label":"Federation Plugin","link":{"type":"doc","id":"federation"},"items":[{"type":"doc","id":"federated-exchanges/index","label":"Federated Exchanges","translatable":true},{"type":"doc","id":"federated-queues/index","label":"Federated Queues","translatable":true},{"type":"doc","id":"federation-reference","label":"Federation Reference","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Shovel Plugin","link":{"type":"doc","id":"shovel"},"items":[{"type":"doc","id":"shovel-static","label":"Static Shovels","translatable":true},{"type":"doc","id":"shovel-dynamic","label":"Dynamic Shovels","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"stomp","label":"STOMP Plugin","translatable":true},{"type":"doc","id":"web-stomp","label":"Web STOMP Plugin","translatable":true},{"type":"doc","id":"mqtt","label":"MQTT Plugin","translatable":true},{"type":"doc","id":"web-mqtt","label":"Web MQTT Plugin","translatable":true},{"type":"doc","id":"stream","label":"Stream Plugin","translatable":true},{"type":"doc","id":"installing-plugins","label":"Installing 3rd-party Plugins","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Protocols","link":{"type":"doc","id":"protocols"},"items":[{"type":"doc","id":"amqp","label":"AMQP 1.0","translatable":true},{"type":"doc","id":"connections/index","label":"Connections","translatable":true},{"type":"doc","id":"conversions","label":"Inter-Protocol Property Conversion","translatable":true},{"type":"doc","id":"heartbeats","label":"Heartbeats","translatable":true},{"type":"doc","id":"extensions","label":"AMQP 0-9-1 Extensions","translatable":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Client Libraries","href":"/client-libraries"}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Manage RabbitMQ","link":{"type":"doc","id":"manage-rabbitmq"},"items":[{"type":"doc","id":"cli","label":"CLI","translatable":true},{"type":"doc","id":"configure","label":"Configuration","translatable":true},{"type":"doc","id":"relocate","label":"File and Directory Locations","translatable":true},{"type":"doc","id":"logging","label":"Logging","translatable":true},{"type":"doc","id":"vhosts","label":"Virtual Hosts","translatable":true},{"type":"category","label":" Authentication and Authorization","link":{"type":"doc","id":"access-control"},"items":[{"type":"doc","id":"authentication","label":"AMQP 0-9-1 Authentication Mechanisms","translatable":true},{"type":"doc","id":"passwords","label":"Credentials and Passwords","translatable":true},{"type":"doc","id":"oauth2","label":"OAuth 2","translatable":true},{"type":"doc","id":"ldap","label":"LDAP","translatable":true},{"type":"doc","id":"auth-cache-backend","label":"Cache","translatable":true},{"type":"doc","id":"auth-notification","label":"Authentication Failure Notifications","translatable":true},{"type":"doc","id":"user-limits","label":"Per User Resource Limits","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"parameters","label":"Policies and Runtime Parameters","translatable":true},{"type":"category","label":"Metadata store","link":{"type":"doc","id":"metadata-store/index"},"items":[{"type":"doc","id":"metadata-store/how-to-enable-khepri","label":"How to enable Khepri","translatable":true},{"type":"doc","id":"metadata-store/clustering","label":"Clustering and Khepri","translatable":true},{"type":"doc","id":"metadata-store/everyday-operations","label":"Everyday Operations with Khepri","translatable":true},{"type":"doc","id":"metadata-store/failure-recovery","label":"Failure recovery with Khepri","translatable":true},{"type":"doc","id":"metadata-store/known-issues","label":"Known issues with Khepri","translatable":true},{"type":"doc","id":"metadata-store/khepri-faq","label":"Khepri FAQ","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"definitions","label":"Schema Definitions","translatable":true},{"type":"category","label":"Networking","link":{"type":"doc","id":"networking"},"items":[{"type":"doc","id":"nettick","label":"Net Tick Time","translatable":true},{"type":"doc","id":"ssl/index","label":"TLS Support","translatable":true},{"type":"doc","id":"troubleshooting-networking","label":"Troubleshooting Connectivity","translatable":true},{"type":"doc","id":"troubleshooting-ssl","label":"Troubleshooting TLS","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Clustering","link":{"type":"doc","id":"clustering"},"items":[{"type":"doc","id":"cluster-formation","label":"Cluster Formation","translatable":true},{"type":"doc","id":"partitions","label":"Network Partitions","translatable":true},{"type":"doc","id":"clustering-ssl","label":"Using TLS for Inter-node Traffic","translatable":true},{"type":"doc","id":"ec2","label":"RabbitMQ on Amazon EC2","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Resource Management","items":[{"type":"doc","id":"memory-use/index","label":"Analyzing how Memory is Used","translatable":true},{"type":"category","label":"Memory and Disk Alarms","link":{"type":"doc","id":"alarms"},"items":[{"type":"doc","id":"memory","label":"Memory Alarms","translatable":true},{"type":"doc","id":"disk-alarms","label":"Disk Alarms","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"flow-control","label":"Flow Control","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"backup","label":"Backup and Restore","translatable":true},{"type":"category","label":"Tuning","items":[{"type":"doc","id":"runtime","label":"Runtime Tuning","translatable":true},{"type":"doc","id":"persistence-conf","label":"Persistence Configuration","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"production-checklist","label":"Deployment Guidelines","translatable":true},{"type":"link","label":"RabbitMQ on Kubernetes","href":"/kubernetes/operator/operator-overview"},{"type":"doc","id":"troubleshooting/index","label":"Troubleshooting RabbitMQ","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Monitor RabbitMQ","link":{"type":"doc","id":"monitoring/index"},"items":[{"type":"doc","id":"prometheus/index","label":"Prometheus and Grafana","translatable":true},{"type":"doc","id":"event-exchange","label":"Event Exchange Plugin","translatable":true},{"type":"doc","id":"firehose","label":"Firehose Tracing","translatable":true}],"collapsed":true,"collapsible":true}]}},{"versionName":"4.0","label":"4.0","banner":"unmaintained","badge":true,"noIndex":false,"className":"docs-version-4.0","path":"/rabbitmq-website/docs/4.0","tagsPath":"/rabbitmq-website/docs/4.0/tags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0","editUrlLocalized":"https://github.com/rabbitmq/rabbitmq-website/tree/main/i18n/en/docusaurus-plugin-content-docs/version-4.0","isLast":false,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/versioned_sidebars/version-4.0-sidebars.json","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/versioned_docs/version-4.0","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs/version-4.0","docs":[{"id":"access-control","title":"Authentication, Authorisation, Access Control","description":"<!--","source":"@site/versioned_docs/version-4.0/access-control.md","sourceDirName":".","slug":"/access-control","permalink":"/rabbitmq-website/docs/4.0/access-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/access-control.md","tags":[],"version":"4.0","frontMatter":{"title":"Authentication, Authorisation, Access Control"},"sidebar":"docsSidebar","previous":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/4.0/vhosts"},"next":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/4.0/authentication"}},{"id":"ae","title":"Alternate Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.0/ae.md","sourceDirName":".","slug":"/ae","permalink":"/rabbitmq-website/docs/4.0/ae","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/ae.md","tags":[],"version":"4.0","frontMatter":{"title":"Alternate Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/4.0/e2e"},"next":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/4.0/sender-selected"}},{"id":"alarms","title":"Memory and Disk Alarms","description":"<!--","source":"@site/versioned_docs/version-4.0/alarms.md","sourceDirName":".","slug":"/alarms","permalink":"/rabbitmq-website/docs/4.0/alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/alarms.md","tags":[],"version":"4.0","frontMatter":{"title":"Memory and Disk Alarms"},"sidebar":"docsSidebar","previous":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/4.0/memory-use/"},"next":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/4.0/memory"}},{"id":"amqp","title":"AMQP 1.0","description":"<!--","source":"@site/versioned_docs/version-4.0/amqp.md","sourceDirName":".","slug":"/amqp","permalink":"/rabbitmq-website/docs/4.0/amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/amqp.md","tags":[],"version":"4.0","frontMatter":{"title":"AMQP 1.0"},"sidebar":"docsSidebar","previous":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/4.0/protocols"},"next":{"title":"Connections","permalink":"/rabbitmq-website/docs/4.0/connections/"}},{"id":"auth-cache-backend","title":"RabbitMQ Access Control Cache Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/auth-cache-backend.md","sourceDirName":".","slug":"/auth-cache-backend","permalink":"/rabbitmq-website/docs/4.0/auth-cache-backend","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/auth-cache-backend.md","tags":[],"version":"4.0","frontMatter":{"title":"RabbitMQ Access Control Cache Plugin"},"sidebar":"docsSidebar","previous":{"title":"LDAP","permalink":"/rabbitmq-website/docs/4.0/ldap"},"next":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/4.0/auth-notification"}},{"id":"auth-notification","title":"Authentication Failure Notifications","description":"<!--","source":"@site/versioned_docs/version-4.0/auth-notification.md","sourceDirName":".","slug":"/auth-notification","permalink":"/rabbitmq-website/docs/4.0/auth-notification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/auth-notification.md","tags":[],"version":"4.0","frontMatter":{"title":"Authentication Failure Notifications"},"sidebar":"docsSidebar","previous":{"title":"Cache","permalink":"/rabbitmq-website/docs/4.0/auth-cache-backend"},"next":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/4.0/user-limits"}},{"id":"authentication","title":"Authentication Mechanisms","description":"<!--","source":"@site/versioned_docs/version-4.0/authentication.md","sourceDirName":".","slug":"/authentication","permalink":"/rabbitmq-website/docs/4.0/authentication","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/authentication.md","tags":[],"version":"4.0","frontMatter":{"title":"Authentication Mechanisms"},"sidebar":"docsSidebar","previous":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/4.0/access-control"},"next":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/4.0/passwords"}},{"id":"backup","title":"Backup and Restore","description":"<!--","source":"@site/versioned_docs/version-4.0/backup.md","sourceDirName":".","slug":"/backup","permalink":"/rabbitmq-website/docs/4.0/backup","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/backup.md","tags":[],"version":"4.0","frontMatter":{"title":"Backup and Restore"},"sidebar":"docsSidebar","previous":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/4.0/flow-control"},"next":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/4.0/runtime"}},{"id":"blue-green-upgrade","title":"Blue-Green Deployment","description":"<!--","source":"@site/versioned_docs/version-4.0/blue-green-upgrade.md","sourceDirName":".","slug":"/blue-green-upgrade","permalink":"/rabbitmq-website/docs/4.0/blue-green-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/blue-green-upgrade.md","tags":[],"version":"4.0","frontMatter":{"title":"Blue-Green Deployment"},"sidebar":"docsSidebar","previous":{"title":"Rolling Upgrade","permalink":"/rabbitmq-website/docs/4.0/rolling-upgrade"},"next":{"title":"Grow-Then-Shrink Upgrade","permalink":"/rabbitmq-website/docs/4.0/grow-then-shrink-upgrade"}},{"id":"build-server","title":"Server Build Instructions","description":"<!--","source":"@site/versioned_docs/version-4.0/build-server.md","sourceDirName":".","slug":"/build-server","permalink":"/rabbitmq-website/docs/4.0/build-server","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/build-server.md","tags":[],"version":"4.0","frontMatter":{"title":"Server Build Instructions","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"channels/index","title":"Channels","description":"<!--","source":"@site/versioned_docs/version-4.0/channels/index.md","sourceDirName":"channels","slug":"/channels/","permalink":"/rabbitmq-website/docs/4.0/channels/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/channels/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Channels","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Streams","permalink":"/rabbitmq-website/docs/4.0/streams"},"next":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/4.0/reliability"}},{"id":"classic-queues","title":"Classic Queues","description":"<!--","source":"@site/versioned_docs/version-4.0/classic-queues.md","sourceDirName":".","slug":"/classic-queues","permalink":"/rabbitmq-website/docs/4.0/classic-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/classic-queues.md","tags":[],"version":"4.0","frontMatter":{"title":"Classic Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/4.0/quorum-queues/"},"next":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/4.0/ttl"}},{"id":"cli","title":"Command Line Tools","description":"<!--","source":"@site/versioned_docs/version-4.0/cli.md","sourceDirName":".","slug":"/cli","permalink":"/rabbitmq-website/docs/4.0/cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/cli.md","tags":[],"version":"4.0","frontMatter":{"title":"Command Line Tools"},"sidebar":"docsSidebar","previous":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/manage-rabbitmq"},"next":{"title":"Configuration","permalink":"/rabbitmq-website/docs/4.0/configure"}},{"id":"cluster-formation","title":"Cluster Formation and Peer Discovery","description":"<!--","source":"@site/versioned_docs/version-4.0/cluster-formation.md","sourceDirName":".","slug":"/cluster-formation","permalink":"/rabbitmq-website/docs/4.0/cluster-formation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/cluster-formation.md","tags":[],"version":"4.0","frontMatter":{"title":"Cluster Formation and Peer Discovery"},"sidebar":"docsSidebar","previous":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/4.0/clustering"},"next":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/4.0/partitions"}},{"id":"clustering","title":"Clustering Guide","description":"<!--","source":"@site/versioned_docs/version-4.0/clustering.md","sourceDirName":".","slug":"/clustering","permalink":"/rabbitmq-website/docs/4.0/clustering","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/clustering.md","tags":[],"version":"4.0","frontMatter":{"title":"Clustering Guide"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/4.0/troubleshooting-ssl"},"next":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/4.0/cluster-formation"}},{"id":"clustering-ssl","title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS","description":"<!--","source":"@site/versioned_docs/version-4.0/clustering-ssl.md","sourceDirName":".","slug":"/clustering-ssl","permalink":"/rabbitmq-website/docs/4.0/clustering-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/clustering-ssl.md","tags":[],"version":"4.0","frontMatter":{"title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS"},"sidebar":"docsSidebar","previous":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/4.0/partitions"},"next":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/4.0/ec2"}},{"id":"configure","title":"Configuration","description":"<!--","source":"@site/versioned_docs/version-4.0/configure.md","sourceDirName":".","slug":"/configure","permalink":"/rabbitmq-website/docs/4.0/configure","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/configure.md","tags":[],"version":"4.0","frontMatter":{"title":"Configuration"},"sidebar":"docsSidebar","previous":{"title":"CLI","permalink":"/rabbitmq-website/docs/4.0/cli"},"next":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/4.0/relocate"}},{"id":"confirms","title":"Consumer Acknowledgements and Publisher Confirms","description":"<!--","source":"@site/versioned_docs/version-4.0/confirms.md","sourceDirName":".","slug":"/confirms","permalink":"/rabbitmq-website/docs/4.0/confirms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/confirms.md","tags":[],"version":"4.0","frontMatter":{"title":"Consumer Acknowledgements and Publisher Confirms"},"sidebar":"docsSidebar","previous":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/4.0/reliability"},"next":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/4.0/distributed"}},{"id":"connection-blocked","title":"Blocked Connection Notifications","description":"<!--","source":"@site/versioned_docs/version-4.0/connection-blocked.md","sourceDirName":".","slug":"/connection-blocked","permalink":"/rabbitmq-website/docs/4.0/connection-blocked","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/connection-blocked.md","tags":[],"version":"4.0","frontMatter":{"title":"Blocked Connection Notifications"},"sidebar":"docsSidebar","previous":{"title":"Local random exchange","permalink":"/rabbitmq-website/docs/4.0/local-random-exchange"},"next":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/4.0/e2e"}},{"id":"connections/index","title":"Connections","description":"<!--","source":"@site/versioned_docs/version-4.0/connections/index.md","sourceDirName":"connections","slug":"/connections/","permalink":"/rabbitmq-website/docs/4.0/connections/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/connections/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Connections"},"sidebar":"docsSidebar","previous":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/docs/4.0/amqp"},"next":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/4.0/conversions"}},{"id":"consumer-cancel","title":"Consumer Cancel Notification","description":"<!--","source":"@site/versioned_docs/version-4.0/consumer-cancel.md","sourceDirName":".","slug":"/consumer-cancel","permalink":"/rabbitmq-website/docs/4.0/consumer-cancel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/consumer-cancel.md","tags":[],"version":"4.0","frontMatter":{"title":"Consumer Cancel Notification"},"sidebar":"docsSidebar","previous":{"title":"Consumers","permalink":"/rabbitmq-website/docs/4.0/consumers"},"next":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/4.0/consumer-prefetch"}},{"id":"consumer-prefetch","title":"Consumer Prefetch","description":"<!--","source":"@site/versioned_docs/version-4.0/consumer-prefetch.md","sourceDirName":".","slug":"/consumer-prefetch","permalink":"/rabbitmq-website/docs/4.0/consumer-prefetch","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/consumer-prefetch.md","tags":[],"version":"4.0","frontMatter":{"title":"Consumer Prefetch"},"sidebar":"docsSidebar","previous":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/4.0/consumer-cancel"},"next":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/4.0/consumer-priority"}},{"id":"consumer-priority","title":"Consumer Priorities","description":"<!--","source":"@site/versioned_docs/version-4.0/consumer-priority.md","sourceDirName":".","slug":"/consumer-priority","permalink":"/rabbitmq-website/docs/4.0/consumer-priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/consumer-priority.md","tags":[],"version":"4.0","frontMatter":{"title":"Consumer Priorities"},"sidebar":"docsSidebar","previous":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/4.0/consumer-prefetch"},"next":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/4.0/nack"}},{"id":"consumers","title":"Consumers","description":"<!--","source":"@site/versioned_docs/version-4.0/consumers.md","sourceDirName":".","slug":"/consumers","permalink":"/rabbitmq-website/docs/4.0/consumers","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/consumers.md","tags":[],"version":"4.0","frontMatter":{"title":"Consumers","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/4.0/exchanges"},"next":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/4.0/consumer-cancel"}},{"id":"conversions","title":"Inter-Protocol Property Conversions","description":"<!--","source":"@site/versioned_docs/version-4.0/conversions.md","sourceDirName":".","slug":"/conversions","permalink":"/rabbitmq-website/docs/4.0/conversions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/conversions.md","tags":[],"version":"4.0","frontMatter":{"title":"Inter-Protocol Property Conversions"},"sidebar":"docsSidebar","previous":{"title":"Connections","permalink":"/rabbitmq-website/docs/4.0/connections/"},"next":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/4.0/heartbeats"}},{"id":"definitions","title":"Schema Definition Export and Import","description":"<!--","source":"@site/versioned_docs/version-4.0/definitions.md","sourceDirName":".","slug":"/definitions","permalink":"/rabbitmq-website/docs/4.0/definitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/definitions.md","tags":[],"version":"4.0","frontMatter":{"title":"Schema Definition Export and Import"},"sidebar":"docsSidebar","previous":{"title":"Khepri FAQ","permalink":"/rabbitmq-website/docs/4.0/metadata-store/khepri-faq"},"next":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/networking"}},{"id":"deprecated-features/index","title":"Deprecated Features","description":"<!--","source":"@site/versioned_docs/version-4.0/deprecated-features/index.md","sourceDirName":"deprecated-features","slug":"/deprecated-features/","permalink":"/rabbitmq-website/docs/4.0/deprecated-features/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/deprecated-features/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Deprecated Features"},"sidebar":"docsSidebar","previous":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/4.0/feature-flags/"},"next":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/4.0/snapshots"}},{"id":"direct-reply-to","title":"Direct Reply-to","description":"<!--","source":"@site/versioned_docs/version-4.0/direct-reply-to.md","sourceDirName":".","slug":"/direct-reply-to","permalink":"/rabbitmq-website/docs/4.0/direct-reply-to","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/direct-reply-to.md","tags":[],"version":"4.0","frontMatter":{"title":"Direct Reply-to"},"sidebar":"docsSidebar","previous":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/4.0/exchanges"},"next":{"title":"Local random exchange","permalink":"/rabbitmq-website/docs/4.0/local-random-exchange"}},{"id":"disk-alarms","title":"Free Disk Space Alarms","description":"<!--","source":"@site/versioned_docs/version-4.0/disk-alarms.md","sourceDirName":".","slug":"/disk-alarms","permalink":"/rabbitmq-website/docs/4.0/disk-alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/disk-alarms.md","tags":[],"version":"4.0","frontMatter":{"title":"Free Disk Space Alarms"},"sidebar":"docsSidebar","previous":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/4.0/memory"},"next":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/4.0/flow-control"}},{"id":"distributed","title":"Distributed RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.0/distributed.md","sourceDirName":".","slug":"/distributed","permalink":"/rabbitmq-website/docs/4.0/distributed","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/distributed.md","tags":[],"version":"4.0","frontMatter":{"title":"Distributed RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/4.0/confirms"},"next":{"title":"Plugins","permalink":"/rabbitmq-website/docs/4.0/plugins"}},{"id":"dlx","title":"Dead Letter Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.0/dlx.md","sourceDirName":".","slug":"/dlx","permalink":"/rabbitmq-website/docs/4.0/dlx","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/dlx.md","tags":[],"version":"4.0","frontMatter":{"title":"Dead Letter Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/4.0/lazy-queues"},"next":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/4.0/priority"}},{"id":"download","title":"Installing RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.0/download.md","sourceDirName":".","slug":"/download","permalink":"/rabbitmq-website/docs/4.0/download","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/download.md","tags":[],"version":"4.0","frontMatter":{"title":"Installing RabbitMQ","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Introduction","permalink":"/rabbitmq-website/docs/4.0/"},"next":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/4.0/which-erlang"}},{"id":"e2e","title":"Exchange to Exchange Bindings","description":"<!--","source":"@site/versioned_docs/version-4.0/e2e.md","sourceDirName":".","slug":"/e2e","permalink":"/rabbitmq-website/docs/4.0/e2e","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/e2e.md","tags":[],"version":"4.0","frontMatter":{"title":"Exchange to Exchange Bindings"},"sidebar":"docsSidebar","previous":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/4.0/connection-blocked"},"next":{"title":"Alternate Exchanges","permalink":"/rabbitmq-website/docs/4.0/ae"}},{"id":"ec2","title":"Running RabbitMQ on Amazon EC2","description":"<!--","source":"@site/versioned_docs/version-4.0/ec2.md","sourceDirName":".","slug":"/ec2","permalink":"/rabbitmq-website/docs/4.0/ec2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/ec2.md","tags":[],"version":"4.0","frontMatter":{"title":"Running RabbitMQ on Amazon EC2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/4.0/clustering-ssl"},"next":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/4.0/memory-use/"}},{"id":"event-exchange","title":"Event Exchange Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/event-exchange.md","sourceDirName":".","slug":"/event-exchange","permalink":"/rabbitmq-website/docs/4.0/event-exchange","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/event-exchange.md","tags":[],"version":"4.0","frontMatter":{"title":"Event Exchange Plugin"},"sidebar":"docsSidebar","previous":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/4.0/prometheus/"},"next":{"title":"Firehose Tracing","permalink":"/rabbitmq-website/docs/4.0/firehose"}},{"id":"exchanges","title":"Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.0/exchanges.md","sourceDirName":".","slug":"/exchanges","permalink":"/rabbitmq-website/docs/4.0/exchanges","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/exchanges.md","tags":[],"version":"4.0","frontMatter":{"title":"Exchanges","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Publishers","permalink":"/rabbitmq-website/docs/4.0/publishers/"},"next":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/4.0/direct-reply-to"}},{"id":"extensions","title":"AMQP 0-9-1 Protocol Extensions","description":"<!--","source":"@site/versioned_docs/version-4.0/extensions.md","sourceDirName":".","slug":"/extensions","permalink":"/rabbitmq-website/docs/4.0/extensions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/extensions.md","tags":[],"version":"4.0","frontMatter":{"title":"AMQP 0-9-1 Protocol Extensions"},"sidebar":"docsSidebar","previous":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/4.0/heartbeats"},"next":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/manage-rabbitmq"}},{"id":"feature-flags/index","title":"Feature Flags","description":"<!--","source":"@site/versioned_docs/version-4.0/feature-flags/index.md","sourceDirName":"feature-flags","slug":"/feature-flags/","permalink":"/rabbitmq-website/docs/4.0/feature-flags/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/feature-flags/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Feature Flags"},"sidebar":"docsSidebar","previous":{"title":"Grow-Then-Shrink Upgrade","permalink":"/rabbitmq-website/docs/4.0/grow-then-shrink-upgrade"},"next":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/4.0/deprecated-features/"}},{"id":"federated-exchanges/index","title":"Federated Exchanges","description":"<!--","source":"@site/versioned_docs/version-4.0/federated-exchanges/index.md","sourceDirName":"federated-exchanges","slug":"/federated-exchanges/","permalink":"/rabbitmq-website/docs/4.0/federated-exchanges/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/federated-exchanges/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Federated Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/4.0/federation"},"next":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/4.0/federated-queues/"}},{"id":"federated-queues/index","title":"Federated Queues","description":"<!--","source":"@site/versioned_docs/version-4.0/federated-queues/index.md","sourceDirName":"federated-queues","slug":"/federated-queues/","permalink":"/rabbitmq-website/docs/4.0/federated-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/federated-queues/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Federated Queues"},"sidebar":"docsSidebar","previous":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/4.0/federated-exchanges/"},"next":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/4.0/federation-reference"}},{"id":"federation","title":"Federation Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/federation.md","sourceDirName":".","slug":"/federation","permalink":"/rabbitmq-website/docs/4.0/federation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/federation.md","tags":[],"version":"4.0","frontMatter":{"title":"Federation Plugin"},"sidebar":"docsSidebar","previous":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/4.0/management/"},"next":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/4.0/federated-exchanges/"}},{"id":"federation-reference","title":"Federation Reference","description":"<!--","source":"@site/versioned_docs/version-4.0/federation-reference.md","sourceDirName":".","slug":"/federation-reference","permalink":"/rabbitmq-website/docs/4.0/federation-reference","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/federation-reference.md","tags":[],"version":"4.0","frontMatter":{"title":"Federation Reference"},"sidebar":"docsSidebar","previous":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/4.0/federated-queues/"},"next":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/4.0/shovel"}},{"id":"firehose","title":"Firehose Tracer","description":"<!--","source":"@site/versioned_docs/version-4.0/firehose.md","sourceDirName":".","slug":"/firehose","permalink":"/rabbitmq-website/docs/4.0/firehose","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/firehose.md","tags":[],"version":"4.0","frontMatter":{"title":"Firehose Tracer"},"sidebar":"docsSidebar","previous":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/4.0/event-exchange"}},{"id":"flow-control","title":"Flow Control","description":"<!--","source":"@site/versioned_docs/version-4.0/flow-control.md","sourceDirName":".","slug":"/flow-control","permalink":"/rabbitmq-website/docs/4.0/flow-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/flow-control.md","tags":[],"version":"4.0","frontMatter":{"title":"Flow Control"},"sidebar":"docsSidebar","previous":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/4.0/disk-alarms"},"next":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/4.0/backup"}},{"id":"grow-then-shrink-upgrade","title":"Grow-then-Shrink Upgrade","description":"<!--","source":"@site/versioned_docs/version-4.0/grow-then-shrink-upgrade.md","sourceDirName":".","slug":"/grow-then-shrink-upgrade","permalink":"/rabbitmq-website/docs/4.0/grow-then-shrink-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/grow-then-shrink-upgrade.md","tags":[],"version":"4.0","frontMatter":{"title":"Grow-then-Shrink Upgrade"},"sidebar":"docsSidebar","previous":{"title":"Blue-Green Deployment","permalink":"/rabbitmq-website/docs/4.0/blue-green-upgrade"},"next":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/4.0/feature-flags/"}},{"id":"heartbeats","title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives","description":"<!--","source":"@site/versioned_docs/version-4.0/heartbeats.md","sourceDirName":".","slug":"/heartbeats","permalink":"/rabbitmq-website/docs/4.0/heartbeats","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/heartbeats.md","tags":[],"version":"4.0","frontMatter":{"title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives"},"sidebar":"docsSidebar","previous":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/4.0/conversions"},"next":{"title":"AMQP 0-9-1 Extensions","permalink":"/rabbitmq-website/docs/4.0/extensions"}},{"id":"http-api-reference","title":"HTTP API Reference","description":"<!--","source":"@site/versioned_docs/version-4.0/http-api-reference.md","sourceDirName":".","slug":"/http-api-reference","permalink":"/rabbitmq-website/docs/4.0/http-api-reference","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/http-api-reference.md","tags":[],"version":"4.0","frontMatter":{"title":"HTTP API Reference"}},{"id":"index","title":"RabbitMQ Documentation","description":"<!--","source":"@site/versioned_docs/version-4.0/index.md","sourceDirName":".","slug":"/","permalink":"/rabbitmq-website/docs/4.0/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/index.md","tags":[],"version":"4.0","frontMatter":{"title":"RabbitMQ Documentation"},"sidebar":"docsSidebar","next":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/download"}},{"id":"install-debian","title":"Installing on Debian and Ubuntu","description":"<!--","source":"@site/versioned_docs/version-4.0/install-debian.md","sourceDirName":".","slug":"/install-debian","permalink":"/rabbitmq-website/docs/4.0/install-debian","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-debian.md","tags":[],"version":"4.0","frontMatter":{"title":"Installing on Debian and Ubuntu","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/4.0/platforms"},"next":{"title":"RedHat","permalink":"/rabbitmq-website/docs/4.0/install-rpm"}},{"id":"install-generic-unix","title":"Generic Binary Build","description":"<!--","source":"@site/versioned_docs/version-4.0/install-generic-unix.md","sourceDirName":".","slug":"/install-generic-unix","permalink":"/rabbitmq-website/docs/4.0/install-generic-unix","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-generic-unix.md","tags":[],"version":"4.0","frontMatter":{"title":"Generic Binary Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"RedHat","permalink":"/rabbitmq-website/docs/4.0/install-rpm"},"next":{"title":"Windows","permalink":"/rabbitmq-website/docs/4.0/install-windows"}},{"id":"install-homebrew","title":"The Homebrew RabbitMQ Formula","description":"<!--","source":"@site/versioned_docs/version-4.0/install-homebrew.md","sourceDirName":".","slug":"/install-homebrew","permalink":"/rabbitmq-website/docs/4.0/install-homebrew","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-homebrew.md","tags":[],"version":"4.0","frontMatter":{"title":"The Homebrew RabbitMQ Formula","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/4.0/install-standalone-mac"},"next":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/upgrade"}},{"id":"install-rpm","title":"Installing on RPM-based Linux","description":"<!--","source":"@site/versioned_docs/version-4.0/install-rpm.md","sourceDirName":".","slug":"/install-rpm","permalink":"/rabbitmq-website/docs/4.0/install-rpm","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-rpm.md","tags":[],"version":"4.0","frontMatter":{"title":"Installing on RPM-based Linux","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/4.0/install-debian"},"next":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/4.0/install-generic-unix"}},{"id":"install-solaris","title":"Installing on Solaris","description":"<!--","source":"@site/versioned_docs/version-4.0/install-solaris.md","sourceDirName":".","slug":"/install-solaris","permalink":"/rabbitmq-website/docs/4.0/install-solaris","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-solaris.md","tags":[],"version":"4.0","frontMatter":{"title":"Installing on Solaris","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"install-standalone-mac","title":"Standalone MacOS Build","description":"<!--","source":"@site/versioned_docs/version-4.0/install-standalone-mac.md","sourceDirName":".","slug":"/install-standalone-mac","permalink":"/rabbitmq-website/docs/4.0/install-standalone-mac","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-standalone-mac.md","tags":[],"version":"4.0","frontMatter":{"title":"Standalone MacOS Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Windows","permalink":"/rabbitmq-website/docs/4.0/install-windows"},"next":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/4.0/install-homebrew"}},{"id":"install-windows","title":"Installing on Windows","description":"<!--","source":"@site/versioned_docs/version-4.0/install-windows.md","sourceDirName":".","slug":"/install-windows","permalink":"/rabbitmq-website/docs/4.0/install-windows","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-windows.md","tags":[],"version":"4.0","frontMatter":{"title":"Installing on Windows","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/4.0/install-generic-unix"},"next":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/4.0/install-standalone-mac"}},{"id":"install-windows-manual","title":"Installing on Windows manually","description":"<!--","source":"@site/versioned_docs/version-4.0/install-windows-manual.md","sourceDirName":".","slug":"/install-windows-manual","permalink":"/rabbitmq-website/docs/4.0/install-windows-manual","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/install-windows-manual.md","tags":[],"version":"4.0","frontMatter":{"title":"Installing on Windows manually","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"installing-plugins","title":"installing Additional Plugins","description":"<!--","source":"@site/versioned_docs/version-4.0/installing-plugins.md","sourceDirName":".","slug":"/installing-plugins","permalink":"/rabbitmq-website/docs/4.0/installing-plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/installing-plugins.md","tags":[],"version":"4.0","frontMatter":{"title":"installing Additional Plugins"},"sidebar":"docsSidebar","previous":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/4.0/stream"},"next":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/4.0/protocols"}},{"id":"lazy-queues","title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)","description":"<!--","source":"@site/versioned_docs/version-4.0/lazy-queues.md","sourceDirName":".","slug":"/lazy-queues","permalink":"/rabbitmq-website/docs/4.0/lazy-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/lazy-queues.md","tags":[],"version":"4.0","frontMatter":{"title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)"},"sidebar":"docsSidebar","previous":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/4.0/maxlength/"},"next":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/4.0/dlx"}},{"id":"ldap","title":"LDAP Support","description":"<!--","source":"@site/versioned_docs/version-4.0/ldap.md","sourceDirName":".","slug":"/ldap","permalink":"/rabbitmq-website/docs/4.0/ldap","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/ldap.md","tags":[],"version":"4.0","frontMatter":{"title":"LDAP Support"},"sidebar":"docsSidebar","previous":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/4.0/oauth2"},"next":{"title":"Cache","permalink":"/rabbitmq-website/docs/4.0/auth-cache-backend"}},{"id":"local-random-exchange","title":"Local Random Exchange","description":"<!--","source":"@site/versioned_docs/version-4.0/local-random-exchange.md","sourceDirName":".","slug":"/local-random-exchange","permalink":"/rabbitmq-website/docs/4.0/local-random-exchange","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/local-random-exchange.md","tags":[],"version":"4.0","frontMatter":{"title":"Local Random Exchange"},"sidebar":"docsSidebar","previous":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/4.0/direct-reply-to"},"next":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/4.0/connection-blocked"}},{"id":"logging","title":"Logging","description":"<!--","source":"@site/versioned_docs/version-4.0/logging.md","sourceDirName":".","slug":"/logging","permalink":"/rabbitmq-website/docs/4.0/logging","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/logging.md","tags":[],"version":"4.0","frontMatter":{"title":"Logging"},"sidebar":"docsSidebar","previous":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/4.0/relocate"},"next":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/4.0/vhosts"}},{"id":"man/rabbitmq-diagnostics.8","title":"rabbitmq-diagnostics.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-diagnostics.8.md","sourceDirName":"man","slug":"/man/rabbitmq-diagnostics.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-diagnostics.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-diagnostics.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-echopid.8","title":"rabbitmq-echopid.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-echopid.8.md","sourceDirName":"man","slug":"/man/rabbitmq-echopid.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-echopid.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-echopid.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-env.conf.5","title":"rabbitmq-env.conf.5","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-env.conf.5.md","sourceDirName":"man","slug":"/man/rabbitmq-env.conf.5","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-env.conf.5","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-env.conf.5.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-plugins.8","title":"rabbitmq-plugins.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-plugins.8.md","sourceDirName":"man","slug":"/man/rabbitmq-plugins.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-plugins.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-plugins.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-queues.8","title":"rabbitmq-queues.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-queues.8.md","sourceDirName":"man","slug":"/man/rabbitmq-queues.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-queues.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-queues.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-server.8","title":"rabbitmq-server.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-server.8.md","sourceDirName":"man","slug":"/man/rabbitmq-server.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-server.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-server.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-service.8","title":"rabbitmq-service.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-service.8.md","sourceDirName":"man","slug":"/man/rabbitmq-service.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-service.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-service.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-streams.8","title":"rabbitmq-streams.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-streams.8.md","sourceDirName":"man","slug":"/man/rabbitmq-streams.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-streams.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-streams.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmq-upgrade.8","title":"rabbitmq-upgrade.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmq-upgrade.8.md","sourceDirName":"man","slug":"/man/rabbitmq-upgrade.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmq-upgrade.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmq-upgrade.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/rabbitmqctl.8","title":"rabbitmqctl.8","description":"NAME","source":"@site/versioned_docs/version-4.0/man/rabbitmqctl.8.md","sourceDirName":"man","slug":"/man/rabbitmqctl.8","permalink":"/rabbitmq-website/docs/4.0/man/rabbitmqctl.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/rabbitmqctl.8.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"man/README","title":"RabbitMQ man Pages","description":"Source Files","source":"@site/versioned_docs/version-4.0/man/README.md","sourceDirName":"man","slug":"/man/","permalink":"/rabbitmq-website/docs/4.0/man/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/man/README.md","tags":[],"version":"4.0","frontMatter":{}},{"id":"manage-rabbitmq","title":"How to Manage RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.0/manage-rabbitmq.md","sourceDirName":".","slug":"/manage-rabbitmq","permalink":"/rabbitmq-website/docs/4.0/manage-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/manage-rabbitmq.md","tags":[],"version":"4.0","frontMatter":{"title":"How to Manage RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"AMQP 0-9-1 Extensions","permalink":"/rabbitmq-website/docs/4.0/extensions"},"next":{"title":"CLI","permalink":"/rabbitmq-website/docs/4.0/cli"}},{"id":"management-cli","title":"rabbitmqadmin v2, a Command Line Tool for the HTTP API","description":"<!--","source":"@site/versioned_docs/version-4.0/management-cli.md","sourceDirName":".","slug":"/management-cli","permalink":"/rabbitmq-website/docs/4.0/management-cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/management-cli.md","tags":[],"version":"4.0","frontMatter":{"title":"rabbitmqadmin v2, a Command Line Tool for the HTTP API","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"management/index","title":"Management Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/management/index.md","sourceDirName":"management","slug":"/management/","permalink":"/rabbitmq-website/docs/4.0/management/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/management/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Management Plugin"},"sidebar":"docsSidebar","previous":{"title":"Plugins","permalink":"/rabbitmq-website/docs/4.0/plugins"},"next":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/4.0/federation"}},{"id":"manpages","title":"Manual Pages","description":"<!--","source":"@site/versioned_docs/version-4.0/manpages.md","sourceDirName":".","slug":"/manpages","permalink":"/rabbitmq-website/docs/4.0/manpages","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/manpages.md","tags":[],"version":"4.0","frontMatter":{"title":"Manual Pages","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"maxlength/index","title":"Queue Length Limit","description":"<!--","source":"@site/versioned_docs/version-4.0/maxlength/index.md","sourceDirName":"maxlength","slug":"/maxlength/","permalink":"/rabbitmq-website/docs/4.0/maxlength/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/maxlength/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Queue Length Limit"},"sidebar":"docsSidebar","previous":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/4.0/ttl"},"next":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/4.0/lazy-queues"}},{"id":"memory","title":"Memory Threshold and Limit","description":"<!--","source":"@site/versioned_docs/version-4.0/memory.md","sourceDirName":".","slug":"/memory","permalink":"/rabbitmq-website/docs/4.0/memory","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/memory.md","tags":[],"version":"4.0","frontMatter":{"title":"Memory Threshold and Limit"},"sidebar":"docsSidebar","previous":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/4.0/alarms"},"next":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/4.0/disk-alarms"}},{"id":"memory-use/index","title":"Reasoning About Memory Use","description":"<!--","source":"@site/versioned_docs/version-4.0/memory-use/index.md","sourceDirName":"memory-use","slug":"/memory-use/","permalink":"/rabbitmq-website/docs/4.0/memory-use/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/memory-use/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Reasoning About Memory Use"},"sidebar":"docsSidebar","previous":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/4.0/ec2"},"next":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/4.0/alarms"}},{"id":"metadata-store/clustering","title":"Clustering and Khepri","description":"When RabbitMQ nodes are clustered, they call the metadata","source":"@site/versioned_docs/version-4.0/metadata-store/clustering.md","sourceDirName":"metadata-store","slug":"/metadata-store/clustering","permalink":"/rabbitmq-website/docs/4.0/metadata-store/clustering","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/metadata-store/clustering.md","tags":[],"version":"4.0","frontMatter":{"title":"Clustering and Khepri"},"sidebar":"docsSidebar","previous":{"title":"How to enable Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/how-to-enable-khepri"},"next":{"title":"Everyday Operations with Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/everyday-operations"}},{"id":"metadata-store/everyday-operations","title":"Everyday Operations with Khepri","description":"Even though the metadata store doesn’t store messages, its behavior will affect","source":"@site/versioned_docs/version-4.0/metadata-store/everyday-operations.md","sourceDirName":"metadata-store","slug":"/metadata-store/everyday-operations","permalink":"/rabbitmq-website/docs/4.0/metadata-store/everyday-operations","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/metadata-store/everyday-operations.md","tags":[],"version":"4.0","frontMatter":{"title":"Everyday Operations with Khepri"},"sidebar":"docsSidebar","previous":{"title":"Clustering and Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/clustering"},"next":{"title":"Failure recovery with Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/failure-recovery"}},{"id":"metadata-store/failure-recovery","title":"How Khepri Approaches Failure Recovery","description":"This section describes Khepri’s Raft-based approach to failure handling and","source":"@site/versioned_docs/version-4.0/metadata-store/failure-recovery.md","sourceDirName":"metadata-store","slug":"/metadata-store/failure-recovery","permalink":"/rabbitmq-website/docs/4.0/metadata-store/failure-recovery","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/metadata-store/failure-recovery.md","tags":[],"version":"4.0","frontMatter":{"title":"How Khepri Approaches Failure Recovery"},"sidebar":"docsSidebar","previous":{"title":"Everyday Operations with Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/everyday-operations"},"next":{"title":"Known issues with Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/known-issues"}},{"id":"metadata-store/how-to-enable-khepri","title":"How to Enable Khepri","description":"In RabbitMQ 4.0.x, Mnesia is still the default metadata store backend. Khepri","source":"@site/versioned_docs/version-4.0/metadata-store/how-to-enable-khepri.md","sourceDirName":"metadata-store","slug":"/metadata-store/how-to-enable-khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/how-to-enable-khepri","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/metadata-store/how-to-enable-khepri.md","tags":[],"version":"4.0","frontMatter":{"title":"How to Enable Khepri"},"sidebar":"docsSidebar","previous":{"title":"Metadata store","permalink":"/rabbitmq-website/docs/4.0/metadata-store/"},"next":{"title":"Clustering and Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/clustering"}},{"id":"metadata-store/index","title":"Metadata store","description":"Role of the metadata store","source":"@site/versioned_docs/version-4.0/metadata-store/index.md","sourceDirName":"metadata-store","slug":"/metadata-store/","permalink":"/rabbitmq-website/docs/4.0/metadata-store/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/metadata-store/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Metadata store"},"sidebar":"docsSidebar","previous":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/4.0/parameters"},"next":{"title":"How to enable Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/how-to-enable-khepri"}},{"id":"metadata-store/khepri-faq","title":"Khepri FAQ","description":"I see the khepri_db feature flag is marked as experimental in the RabbitMQ code. Is it supported?","source":"@site/versioned_docs/version-4.0/metadata-store/khepri-faq.md","sourceDirName":"metadata-store","slug":"/metadata-store/khepri-faq","permalink":"/rabbitmq-website/docs/4.0/metadata-store/khepri-faq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/metadata-store/khepri-faq.md","tags":[],"version":"4.0","frontMatter":{"title":"Khepri FAQ"},"sidebar":"docsSidebar","previous":{"title":"Known issues with Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/known-issues"},"next":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/4.0/definitions"}},{"id":"metadata-store/known-issues","title":"Known issues with Khepri","description":"This document lists the most common known issues with Khepri that may affect","source":"@site/versioned_docs/version-4.0/metadata-store/known-issues.md","sourceDirName":"metadata-store","slug":"/metadata-store/known-issues","permalink":"/rabbitmq-website/docs/4.0/metadata-store/known-issues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/metadata-store/known-issues.md","tags":[],"version":"4.0","frontMatter":{"title":"Known issues with Khepri"},"sidebar":"docsSidebar","previous":{"title":"Failure recovery with Khepri","permalink":"/rabbitmq-website/docs/4.0/metadata-store/failure-recovery"},"next":{"title":"Khepri FAQ","permalink":"/rabbitmq-website/docs/4.0/metadata-store/khepri-faq"}},{"id":"monitoring/index","title":"Monitoring","description":"<!--","source":"@site/versioned_docs/version-4.0/monitoring/index.md","sourceDirName":"monitoring","slug":"/monitoring/","permalink":"/rabbitmq-website/docs/4.0/monitoring/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/monitoring/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Monitoring"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/troubleshooting/"},"next":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/4.0/prometheus/"}},{"id":"mqtt","title":"MQTT Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/mqtt.md","sourceDirName":".","slug":"/mqtt","permalink":"/rabbitmq-website/docs/4.0/mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/mqtt.md","tags":[],"version":"4.0","frontMatter":{"title":"MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/4.0/web-stomp"},"next":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/4.0/web-mqtt"}},{"id":"nack","title":"Negative Acknowledgements","description":"<!--","source":"@site/versioned_docs/version-4.0/nack.md","sourceDirName":".","slug":"/nack","permalink":"/rabbitmq-website/docs/4.0/nack","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/nack.md","tags":[],"version":"4.0","frontMatter":{"title":"Negative Acknowledgements"},"sidebar":"docsSidebar","previous":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/4.0/consumer-priority"},"next":{"title":"Queues","permalink":"/rabbitmq-website/docs/4.0/queues"}},{"id":"nettick","title":"Net Tick Time (Inter-node Communication Heartbeats)","description":"<!--","source":"@site/versioned_docs/version-4.0/nettick.md","sourceDirName":".","slug":"/nettick","permalink":"/rabbitmq-website/docs/4.0/nettick","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/nettick.md","tags":[],"version":"4.0","frontMatter":{"title":"Net Tick Time (Inter-node Communication Heartbeats)"},"sidebar":"docsSidebar","previous":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/networking"},"next":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/4.0/ssl/"}},{"id":"networking","title":"Networking and RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.0/networking.md","sourceDirName":".","slug":"/networking","permalink":"/rabbitmq-website/docs/4.0/networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/networking.md","tags":[],"version":"4.0","frontMatter":{"title":"Networking and RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/4.0/definitions"},"next":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/4.0/nettick"}},{"id":"oauth2","title":"OAuth 2.0 Authentication Backend","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2.md","sourceDirName":".","slug":"/oauth2","permalink":"/rabbitmq-website/docs/4.0/oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2.md","tags":[],"version":"4.0","frontMatter":{"title":"OAuth 2.0 Authentication Backend"},"sidebar":"docsSidebar","previous":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/4.0/passwords"},"next":{"title":"LDAP","permalink":"/rabbitmq-website/docs/4.0/ldap"}},{"id":"oauth2-examples-auth0","title":"Use auth0.com as OAuth 2.0 Server","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-auth0.md","sourceDirName":".","slug":"/oauth2-examples-auth0","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-auth0","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-auth0.md","tags":[],"version":"4.0","frontMatter":{"title":"Use auth0.com as OAuth 2.0 Server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-entra-id/index","title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-entra-id/index.md","sourceDirName":"oauth2-examples-entra-id","slug":"/oauth2-examples-entra-id/","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-entra-id/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-entra-id/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-google","title":"Use Google as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-google.md","sourceDirName":".","slug":"/oauth2-examples-google","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-google","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-google.md","tags":[],"version":"4.0","frontMatter":{"title":"Use Google as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-idp-initiated","title":"Use Identity Provider Initiated Logon","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-idp-initiated.md","sourceDirName":".","slug":"/oauth2-examples-idp-initiated","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-idp-initiated","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-idp-initiated.md","tags":[],"version":"4.0","frontMatter":{"title":"Use Identity Provider Initiated Logon","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-keycloak","title":"Use Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-keycloak.md","sourceDirName":".","slug":"/oauth2-examples-keycloak","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-keycloak","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-keycloak.md","tags":[],"version":"4.0","frontMatter":{"title":"Use Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-multiresource","title":"Using Multiple OAuth 2.0 Servers and/or Audiences","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-multiresource.md","sourceDirName":".","slug":"/oauth2-examples-multiresource","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-multiresource","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-multiresource.md","tags":[],"version":"4.0","frontMatter":{"title":"Using Multiple OAuth 2.0 Servers and/or Audiences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-okta","title":"Use Okta as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-okta.md","sourceDirName":".","slug":"/oauth2-examples-okta","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-okta","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-okta.md","tags":[],"version":"4.0","frontMatter":{"title":"Use Okta as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-proxy","title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples-proxy.md","sourceDirName":".","slug":"/oauth2-examples-proxy","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples-proxy","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples-proxy.md","tags":[],"version":"4.0","frontMatter":{"title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples/index","title":"OAuth 2.0 Authentication Examples","description":"<!--","source":"@site/versioned_docs/version-4.0/oauth2-examples/index.md","sourceDirName":"oauth2-examples","slug":"/oauth2-examples/","permalink":"/rabbitmq-website/docs/4.0/oauth2-examples/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/oauth2-examples/index.md","tags":[],"version":"4.0","frontMatter":{"title":"OAuth 2.0 Authentication Examples","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"parameters","title":"Runtime Parameters","description":"<!--","source":"@site/versioned_docs/version-4.0/parameters.md","sourceDirName":".","slug":"/parameters","permalink":"/rabbitmq-website/docs/4.0/parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/parameters.md","tags":[],"version":"4.0","frontMatter":{"title":"Runtime Parameters"},"sidebar":"docsSidebar","previous":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/4.0/user-limits"},"next":{"title":"Metadata store","permalink":"/rabbitmq-website/docs/4.0/metadata-store/"}},{"id":"partitions","title":"Clustering and Network Partitions","description":"<!--","source":"@site/versioned_docs/version-4.0/partitions.md","sourceDirName":".","slug":"/partitions","permalink":"/rabbitmq-website/docs/4.0/partitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/partitions.md","tags":[],"version":"4.0","frontMatter":{"title":"Clustering and Network Partitions"},"sidebar":"docsSidebar","previous":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/4.0/cluster-formation"},"next":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/4.0/clustering-ssl"}},{"id":"passwords","title":"Credentials and Passwords","description":"<!--","source":"@site/versioned_docs/version-4.0/passwords.md","sourceDirName":".","slug":"/passwords","permalink":"/rabbitmq-website/docs/4.0/passwords","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/passwords.md","tags":[],"version":"4.0","frontMatter":{"title":"Credentials and Passwords","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/4.0/authentication"},"next":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/4.0/oauth2"}},{"id":"persistence-conf","title":"Persistence Configuration","description":"<!--","source":"@site/versioned_docs/version-4.0/persistence-conf.md","sourceDirName":".","slug":"/persistence-conf","permalink":"/rabbitmq-website/docs/4.0/persistence-conf","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/persistence-conf.md","tags":[],"version":"4.0","frontMatter":{"title":"Persistence Configuration"},"sidebar":"docsSidebar","previous":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/4.0/runtime"},"next":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/4.0/production-checklist"}},{"id":"platforms","title":"Supported Platforms","description":"<!--","source":"@site/versioned_docs/version-4.0/platforms.md","sourceDirName":".","slug":"/platforms","permalink":"/rabbitmq-website/docs/4.0/platforms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/platforms.md","tags":[],"version":"4.0","frontMatter":{"title":"Supported Platforms"},"sidebar":"docsSidebar","previous":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/4.0/signatures"},"next":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/4.0/install-debian"}},{"id":"plugins","title":"Plugins","description":"<!--","source":"@site/versioned_docs/version-4.0/plugins.md","sourceDirName":".","slug":"/plugins","permalink":"/rabbitmq-website/docs/4.0/plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/plugins.md","tags":[],"version":"4.0","frontMatter":{"title":"Plugins","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/4.0/distributed"},"next":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/4.0/management/"}},{"id":"policies","title":"Policies","description":"<!--","source":"@site/versioned_docs/version-4.0/policies.md","sourceDirName":".","slug":"/policies","permalink":"/rabbitmq-website/docs/4.0/policies","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/policies.md","tags":[],"version":"4.0","frontMatter":{"title":"Policies"}},{"id":"priority","title":"Classic Queues Support Priorities","description":"<!--","source":"@site/versioned_docs/version-4.0/priority.md","sourceDirName":".","slug":"/priority","permalink":"/rabbitmq-website/docs/4.0/priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/priority.md","tags":[],"version":"4.0","frontMatter":{"title":"Classic Queues Support Priorities"},"sidebar":"docsSidebar","previous":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/4.0/dlx"},"next":{"title":"Streams","permalink":"/rabbitmq-website/docs/4.0/streams"}},{"id":"production-checklist","title":"Production Deployment Guidelines","description":"<!--","source":"@site/versioned_docs/version-4.0/production-checklist.md","sourceDirName":".","slug":"/production-checklist","permalink":"/rabbitmq-website/docs/4.0/production-checklist","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/production-checklist.md","tags":[],"version":"4.0","frontMatter":{"title":"Production Deployment Guidelines"},"sidebar":"docsSidebar","previous":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/4.0/persistence-conf"},"next":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/troubleshooting/"}},{"id":"prometheus/index","title":"Monitoring with Prometheus and Grafana","description":"Overview","source":"@site/versioned_docs/version-4.0/prometheus/index.md","sourceDirName":"prometheus","slug":"/prometheus/","permalink":"/rabbitmq-website/docs/4.0/prometheus/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/prometheus/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Monitoring with Prometheus and Grafana","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/4.0/monitoring/"},"next":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/4.0/event-exchange"}},{"id":"protocols","title":"Which protocols does RabbitMQ support?","description":"<!--","source":"@site/versioned_docs/version-4.0/protocols.md","sourceDirName":".","slug":"/protocols","permalink":"/rabbitmq-website/docs/4.0/protocols","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/protocols.md","tags":[],"version":"4.0","frontMatter":{"title":"Which protocols does RabbitMQ support?","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/4.0/installing-plugins"},"next":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/docs/4.0/amqp"}},{"id":"publishers/index","title":"Publishers","description":"<!--","source":"@site/versioned_docs/version-4.0/publishers/index.md","sourceDirName":"publishers","slug":"/publishers/","permalink":"/rabbitmq-website/docs/4.0/publishers/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/publishers/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Publishers"},"sidebar":"docsSidebar","previous":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/use-rabbitmq"},"next":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/4.0/exchanges"}},{"id":"queues","title":"Queues","description":"<!--","source":"@site/versioned_docs/version-4.0/queues.md","sourceDirName":".","slug":"/queues","permalink":"/rabbitmq-website/docs/4.0/queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/queues.md","tags":[],"version":"4.0","frontMatter":{"title":"Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/4.0/nack"},"next":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/4.0/quorum-queues/"}},{"id":"quorum-queues/index","title":"Quorum Queues","description":"<!--","source":"@site/versioned_docs/version-4.0/quorum-queues/index.md","sourceDirName":"quorum-queues","slug":"/quorum-queues/","permalink":"/rabbitmq-website/docs/4.0/quorum-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/quorum-queues/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Quorum Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Queues","permalink":"/rabbitmq-website/docs/4.0/queues"},"next":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/4.0/classic-queues"}},{"id":"reliability","title":"Reliability Guide","description":"<!--","source":"@site/versioned_docs/version-4.0/reliability.md","sourceDirName":".","slug":"/reliability","permalink":"/rabbitmq-website/docs/4.0/reliability","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/reliability.md","tags":[],"version":"4.0","frontMatter":{"title":"Reliability Guide"},"sidebar":"docsSidebar","previous":{"title":"Channels","permalink":"/rabbitmq-website/docs/4.0/channels/"},"next":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/4.0/confirms"}},{"id":"relocate","title":"File and Directory Locations","description":"<!--","source":"@site/versioned_docs/version-4.0/relocate.md","sourceDirName":".","slug":"/relocate","permalink":"/rabbitmq-website/docs/4.0/relocate","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/relocate.md","tags":[],"version":"4.0","frontMatter":{"title":"File and Directory Locations"},"sidebar":"docsSidebar","previous":{"title":"Configuration","permalink":"/rabbitmq-website/docs/4.0/configure"},"next":{"title":"Logging","permalink":"/rabbitmq-website/docs/4.0/logging"}},{"id":"rolling-upgrade","title":"Rolling (in-place) Upgrade","description":"<!--","source":"@site/versioned_docs/version-4.0/rolling-upgrade.md","sourceDirName":".","slug":"/rolling-upgrade","permalink":"/rabbitmq-website/docs/4.0/rolling-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/rolling-upgrade.md","tags":[],"version":"4.0","frontMatter":{"title":"Rolling (in-place) Upgrade"},"sidebar":"docsSidebar","previous":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/upgrade"},"next":{"title":"Blue-Green Deployment","permalink":"/rabbitmq-website/docs/4.0/blue-green-upgrade"}},{"id":"runtime","title":"Runtime Tuning","description":"<!--","source":"@site/versioned_docs/version-4.0/runtime.md","sourceDirName":".","slug":"/runtime","permalink":"/rabbitmq-website/docs/4.0/runtime","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/runtime.md","tags":[],"version":"4.0","frontMatter":{"title":"Runtime Tuning","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/4.0/backup"},"next":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/4.0/persistence-conf"}},{"id":"semantics","title":"Broker Semantics","description":"Here we describe the broker semantics. This should be read together with the AMQP specification.","source":"@site/versioned_docs/version-4.0/semantics.md","sourceDirName":".","slug":"/semantics","permalink":"/rabbitmq-website/docs/4.0/semantics","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/semantics.md","tags":[],"version":"4.0","frontMatter":{"title":"Broker Semantics","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"sender-selected","title":"Sender-selected Distribution","description":"<!--","source":"@site/versioned_docs/version-4.0/sender-selected.md","sourceDirName":".","slug":"/sender-selected","permalink":"/rabbitmq-website/docs/4.0/sender-selected","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/sender-selected.md","tags":[],"version":"4.0","frontMatter":{"title":"Sender-selected Distribution"},"sidebar":"docsSidebar","previous":{"title":"Alternate Exchanges","permalink":"/rabbitmq-website/docs/4.0/ae"},"next":{"title":"Validated User ID","permalink":"/rabbitmq-website/docs/4.0/validated-user-id"}},{"id":"shovel","title":"Shovel Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/shovel.md","sourceDirName":".","slug":"/shovel","permalink":"/rabbitmq-website/docs/4.0/shovel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/shovel.md","tags":[],"version":"4.0","frontMatter":{"title":"Shovel Plugin"},"sidebar":"docsSidebar","previous":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/4.0/federation-reference"},"next":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/4.0/shovel-static"}},{"id":"shovel-dynamic","title":"Configuring Dynamic Shovels","description":"<!--","source":"@site/versioned_docs/version-4.0/shovel-dynamic.md","sourceDirName":".","slug":"/shovel-dynamic","permalink":"/rabbitmq-website/docs/4.0/shovel-dynamic","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/shovel-dynamic.md","tags":[],"version":"4.0","frontMatter":{"title":"Configuring Dynamic Shovels"},"sidebar":"docsSidebar","previous":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/4.0/shovel-static"},"next":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/4.0/stomp"}},{"id":"shovel-static","title":"Configuring Static Shovels","description":"<!--","source":"@site/versioned_docs/version-4.0/shovel-static.md","sourceDirName":".","slug":"/shovel-static","permalink":"/rabbitmq-website/docs/4.0/shovel-static","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/shovel-static.md","tags":[],"version":"4.0","frontMatter":{"title":"Configuring Static Shovels"},"sidebar":"docsSidebar","previous":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/4.0/shovel"},"next":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/4.0/shovel-dynamic"}},{"id":"signatures","title":"Package Signatures","description":"<!--","source":"@site/versioned_docs/version-4.0/signatures.md","sourceDirName":".","slug":"/signatures","permalink":"/rabbitmq-website/docs/4.0/signatures","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/signatures.md","tags":[],"version":"4.0","frontMatter":{"title":"Package Signatures","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/4.0/which-erlang"},"next":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/4.0/platforms"}},{"id":"snapshots","title":"Snapshots Releases","description":"<!--","source":"@site/versioned_docs/version-4.0/snapshots.md","sourceDirName":".","slug":"/snapshots","permalink":"/rabbitmq-website/docs/4.0/snapshots","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/snapshots.md","tags":[],"version":"4.0","frontMatter":{"title":"Snapshots Releases"},"sidebar":"docsSidebar","previous":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/4.0/deprecated-features/"},"next":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/use-rabbitmq"}},{"id":"spec-differences","title":"Spec Differences","description":"Undeprecated Features","source":"@site/versioned_docs/version-4.0/spec-differences.md","sourceDirName":".","slug":"/spec-differences","permalink":"/rabbitmq-website/docs/4.0/spec-differences","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/spec-differences.md","tags":[],"version":"4.0","frontMatter":{"title":"Spec Differences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"specification","title":"Compatibility and Conformance","description":"RabbitMQ core broker implements the AMQP 1.0 specification and AMQP 0-9-1 specification with a number of AMQP 0-9-1 extensions.","source":"@site/versioned_docs/version-4.0/specification.md","sourceDirName":".","slug":"/specification","permalink":"/rabbitmq-website/docs/4.0/specification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/specification.md","tags":[],"version":"4.0","frontMatter":{"title":"Compatibility and Conformance","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"ssl/index","title":"TLS Support","description":"<!--","source":"@site/versioned_docs/version-4.0/ssl/index.md","sourceDirName":"ssl","slug":"/ssl/","permalink":"/rabbitmq-website/docs/4.0/ssl/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/ssl/index.md","tags":[],"version":"4.0","frontMatter":{"title":"TLS Support"},"sidebar":"docsSidebar","previous":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/4.0/nettick"},"next":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/4.0/troubleshooting-networking"}},{"id":"stomp","title":"STOMP Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/stomp.md","sourceDirName":".","slug":"/stomp","permalink":"/rabbitmq-website/docs/4.0/stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/stomp.md","tags":[],"version":"4.0","frontMatter":{"title":"STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/4.0/shovel-dynamic"},"next":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/4.0/web-stomp"}},{"id":"stream","title":"Stream Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/stream.md","sourceDirName":".","slug":"/stream","permalink":"/rabbitmq-website/docs/4.0/stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/stream.md","tags":[],"version":"4.0","frontMatter":{"title":"Stream Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/4.0/web-mqtt"},"next":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/4.0/installing-plugins"}},{"id":"stream-core-plugin-comparison","title":"Stream Core vs Stream Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/stream-core-plugin-comparison.md","sourceDirName":".","slug":"/stream-core-plugin-comparison","permalink":"/rabbitmq-website/docs/4.0/stream-core-plugin-comparison","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/stream-core-plugin-comparison.md","tags":[],"version":"4.0","frontMatter":{"title":"Stream Core vs Stream Plugin","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"streams","title":"Streams and Super Streams (Partitioned Streams)","description":"<!--","source":"@site/versioned_docs/version-4.0/streams.md","sourceDirName":".","slug":"/streams","permalink":"/rabbitmq-website/docs/4.0/streams","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/streams.md","tags":[],"version":"4.0","frontMatter":{"title":"Streams and Super Streams (Partitioned Streams)"},"sidebar":"docsSidebar","previous":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/4.0/priority"},"next":{"title":"Channels","permalink":"/rabbitmq-website/docs/4.0/channels/"}},{"id":"troubleshooting-networking","title":"Troubleshooting Network Connectivity","description":"<!--","source":"@site/versioned_docs/version-4.0/troubleshooting-networking.md","sourceDirName":".","slug":"/troubleshooting-networking","permalink":"/rabbitmq-website/docs/4.0/troubleshooting-networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/troubleshooting-networking.md","tags":[],"version":"4.0","frontMatter":{"title":"Troubleshooting Network Connectivity"},"sidebar":"docsSidebar","previous":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/4.0/ssl/"},"next":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/4.0/troubleshooting-ssl"}},{"id":"troubleshooting-oauth2","title":"Troubleshooting OAuth 2","description":"<!--","source":"@site/versioned_docs/version-4.0/troubleshooting-oauth2.md","sourceDirName":".","slug":"/troubleshooting-oauth2","permalink":"/rabbitmq-website/docs/4.0/troubleshooting-oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/troubleshooting-oauth2.md","tags":[],"version":"4.0","frontMatter":{"title":"Troubleshooting OAuth 2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"troubleshooting-ssl","title":"Troubleshooting TLS-enabled Connections","description":"<!--","source":"@site/versioned_docs/version-4.0/troubleshooting-ssl.md","sourceDirName":".","slug":"/troubleshooting-ssl","permalink":"/rabbitmq-website/docs/4.0/troubleshooting-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/troubleshooting-ssl.md","tags":[],"version":"4.0","frontMatter":{"title":"Troubleshooting TLS-enabled Connections"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/4.0/troubleshooting-networking"},"next":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/4.0/clustering"}},{"id":"troubleshooting/index","title":"Troubleshooting Guidance","description":"<!--","source":"@site/versioned_docs/version-4.0/troubleshooting/index.md","sourceDirName":"troubleshooting","slug":"/troubleshooting/","permalink":"/rabbitmq-website/docs/4.0/troubleshooting/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/troubleshooting/index.md","tags":[],"version":"4.0","frontMatter":{"title":"Troubleshooting Guidance"},"sidebar":"docsSidebar","previous":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/4.0/production-checklist"},"next":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/4.0/monitoring/"}},{"id":"ttl","title":"Time-To-Live and Expiration","description":"<!--","source":"@site/versioned_docs/version-4.0/ttl.md","sourceDirName":".","slug":"/ttl","permalink":"/rabbitmq-website/docs/4.0/ttl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/ttl.md","tags":[],"version":"4.0","frontMatter":{"title":"Time-To-Live and Expiration"},"sidebar":"docsSidebar","previous":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/4.0/classic-queues"},"next":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/4.0/maxlength/"}},{"id":"upgrade","title":"Upgrading RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.0/upgrade.md","sourceDirName":".","slug":"/upgrade","permalink":"/rabbitmq-website/docs/4.0/upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/upgrade.md","tags":[],"version":"4.0","frontMatter":{"title":"Upgrading RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/4.0/install-homebrew"},"next":{"title":"Rolling Upgrade","permalink":"/rabbitmq-website/docs/4.0/rolling-upgrade"}},{"id":"uri-query-parameters","title":"URI Query Parameters","description":"<!--","source":"@site/versioned_docs/version-4.0/uri-query-parameters.md","sourceDirName":".","slug":"/uri-query-parameters","permalink":"/rabbitmq-website/docs/4.0/uri-query-parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/uri-query-parameters.md","tags":[],"version":"4.0","frontMatter":{"title":"URI Query Parameters","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"uri-spec","title":"RabbitMQ URI Specification","description":"<!--","source":"@site/versioned_docs/version-4.0/uri-spec.md","sourceDirName":".","slug":"/uri-spec","permalink":"/rabbitmq-website/docs/4.0/uri-spec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/uri-spec.md","tags":[],"version":"4.0","frontMatter":{"title":"RabbitMQ URI Specification","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"use-rabbitmq","title":"How to Use RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-4.0/use-rabbitmq.md","sourceDirName":".","slug":"/use-rabbitmq","permalink":"/rabbitmq-website/docs/4.0/use-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/use-rabbitmq.md","tags":[],"version":"4.0","frontMatter":{"title":"How to Use RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/4.0/snapshots"},"next":{"title":"Publishers","permalink":"/rabbitmq-website/docs/4.0/publishers/"}},{"id":"user-limits","title":"Per-user Resource Limits","description":"<!--","source":"@site/versioned_docs/version-4.0/user-limits.md","sourceDirName":".","slug":"/user-limits","permalink":"/rabbitmq-website/docs/4.0/user-limits","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/user-limits.md","tags":[],"version":"4.0","frontMatter":{"title":"Per-user Resource Limits","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/4.0/auth-notification"},"next":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/4.0/parameters"}},{"id":"validated-user-id","title":"Validated User-ID","description":"<!--","source":"@site/versioned_docs/version-4.0/validated-user-id.md","sourceDirName":".","slug":"/validated-user-id","permalink":"/rabbitmq-website/docs/4.0/validated-user-id","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/validated-user-id.md","tags":[],"version":"4.0","frontMatter":{"title":"Validated User-ID"},"sidebar":"docsSidebar","previous":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/4.0/sender-selected"},"next":{"title":"Exchanges","permalink":"/rabbitmq-website/docs/4.0/exchanges"}},{"id":"vhosts","title":"Virtual Hosts","description":"<!--","source":"@site/versioned_docs/version-4.0/vhosts.md","sourceDirName":".","slug":"/vhosts","permalink":"/rabbitmq-website/docs/4.0/vhosts","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/vhosts.md","tags":[],"version":"4.0","frontMatter":{"title":"Virtual Hosts"},"sidebar":"docsSidebar","previous":{"title":"Logging","permalink":"/rabbitmq-website/docs/4.0/logging"},"next":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/4.0/access-control"}},{"id":"web-mqtt","title":"RabbitMQ Web MQTT Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/web-mqtt.md","sourceDirName":".","slug":"/web-mqtt","permalink":"/rabbitmq-website/docs/4.0/web-mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/web-mqtt.md","tags":[],"version":"4.0","frontMatter":{"title":"RabbitMQ Web MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/4.0/mqtt"},"next":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/4.0/stream"}},{"id":"web-stomp","title":"RabbitMQ Web STOMP Plugin","description":"<!--","source":"@site/versioned_docs/version-4.0/web-stomp.md","sourceDirName":".","slug":"/web-stomp","permalink":"/rabbitmq-website/docs/4.0/web-stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/web-stomp.md","tags":[],"version":"4.0","frontMatter":{"title":"RabbitMQ Web STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/4.0/stomp"},"next":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/4.0/mqtt"}},{"id":"whats-new","title":"What\'s New in RabbitMQ 4.0","description":"<!--","source":"@site/versioned_docs/version-4.0/whats-new.md","sourceDirName":".","slug":"/whats-new","permalink":"/rabbitmq-website/docs/4.0/whats-new","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/whats-new.md","tags":[],"version":"4.0","frontMatter":{"title":"What\'s New in RabbitMQ 4.0"}},{"id":"which-erlang","title":"Erlang Version Requirements","description":"<!--","source":"@site/versioned_docs/version-4.0/which-erlang.md","sourceDirName":".","slug":"/which-erlang","permalink":"/rabbitmq-website/docs/4.0/which-erlang","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/which-erlang.md","tags":[],"version":"4.0","frontMatter":{"title":"Erlang Version Requirements","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/4.0/download"},"next":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/4.0/signatures"}},{"id":"windows-configuration","title":"Windows Configuration","description":"<!--","source":"@site/versioned_docs/version-4.0/windows-configuration.md","sourceDirName":".","slug":"/windows-configuration","permalink":"/rabbitmq-website/docs/4.0/windows-configuration","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-4.0/windows-configuration.md","tags":[],"version":"4.0","frontMatter":{"title":"Windows Configuration","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"}],"drafts":[],"sidebars":{"docsSidebar":[{"type":"doc","id":"index","label":"Introduction","translatable":true},{"type":"link","label":"Release Information","href":"/release-information"},{"type":"link","label":"Getting Started","href":"/tutorials"},{"type":"category","label":"Install and Upgrade","link":{"type":"doc","id":"download"},"items":[{"type":"doc","id":"which-erlang","label":"Erlang Version Requirements","translatable":true},{"type":"doc","id":"signatures","label":"Package Signatures","translatable":true},{"type":"category","label":"Supported Operating Systems","link":{"type":"doc","id":"platforms"},"items":[{"type":"category","label":"Linux/Unix","items":[{"type":"doc","id":"install-debian","label":"Debian and Ubuntu","translatable":true},{"type":"doc","id":"install-rpm","label":"RedHat","translatable":true},{"type":"doc","id":"install-generic-unix","label":"Generic Unix","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"install-windows","label":"Windows","translatable":true},{"type":"category","label":"MacOS","items":[{"type":"doc","id":"install-standalone-mac","label":"MacOS using Standalone Binary Build","translatable":true},{"type":"doc","id":"install-homebrew","label":"MacOs using Homebrew","translatable":true}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Kubernetes Operator","href":"/kubernetes/operator/install-operator"},{"type":"category","label":"Upgrade","link":{"type":"doc","id":"upgrade"},"items":[{"type":"doc","id":"rolling-upgrade","label":"Rolling Upgrade","translatable":true},{"type":"doc","id":"blue-green-upgrade","label":"Blue-Green Deployment","translatable":true},{"type":"doc","id":"grow-then-shrink-upgrade","label":"Grow-Then-Shrink Upgrade","translatable":true},{"type":"doc","id":"feature-flags/index","label":"Feature Flags","translatable":true},{"type":"doc","id":"deprecated-features/index","label":"Deprecated Features","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"snapshots","label":"Snapshots","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Use RabbitMQ","link":{"type":"doc","id":"use-rabbitmq"},"items":[{"type":"category","label":"Publishing Messages","link":{"type":"doc","id":"publishers/index"},"items":[{"type":"doc","id":"exchanges","label":"Exchanges","translatable":true},{"type":"doc","id":"direct-reply-to","label":"Direct reply-to","translatable":true},{"type":"doc","id":"local-random-exchange","label":"Local random exchange","translatable":true},{"type":"doc","id":"connection-blocked","label":"Blocked Connection Notifications","translatable":true},{"type":"doc","id":"e2e","label":"Exchange to Exchange Bindings","translatable":true},{"type":"doc","id":"ae","label":"Alternate Exchanges","translatable":true},{"type":"doc","id":"sender-selected","label":"Sender-selected Distribution","translatable":true},{"type":"doc","id":"validated-user-id","label":"Validated User ID","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"exchanges","label":"Exchanges","translatable":true},{"type":"category","label":"Consuming Messages","link":{"type":"doc","id":"consumers"},"items":[{"type":"doc","id":"consumer-cancel","label":"Consumer Cancellation Notifications","translatable":true},{"type":"doc","id":"consumer-prefetch","label":"Consumer Prefetch","translatable":true},{"type":"doc","id":"consumer-priority","label":"Consumer Priorites","translatable":true},{"type":"doc","id":"nack","label":"Negative Acknowledgements","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Queues","link":{"type":"doc","id":"queues"},"items":[{"type":"doc","id":"quorum-queues/index","label":"Quorum Queues","translatable":true},{"type":"doc","id":"classic-queues","label":"Classic Queues","translatable":true},{"type":"doc","id":"ttl","label":"Time-to-Live and Expiration","translatable":true},{"type":"doc","id":"maxlength/index","label":"Queue Length","translatable":true},{"type":"doc","id":"lazy-queues","label":"Lazy Queues","translatable":true},{"type":"doc","id":"dlx","label":"Dead Lettering","translatable":true},{"type":"doc","id":"priority","label":"Priority Queues","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"streams","label":"Streams","translatable":true},{"type":"doc","id":"channels/index","label":"Channels","translatable":true},{"type":"doc","id":"reliability","label":"Reliability and Data Safety","translatable":true},{"type":"doc","id":"confirms","label":"Consumer Acknowledgements and Publisher Confirms","translatable":true},{"type":"doc","id":"distributed","label":"Network Distribution","translatable":true},{"type":"category","label":"Plugins","link":{"type":"doc","id":"plugins"},"items":[{"type":"doc","id":"management/index","label":"Management Plugin","translatable":true},{"type":"category","label":"Federation Plugin","link":{"type":"doc","id":"federation"},"items":[{"type":"doc","id":"federated-exchanges/index","label":"Federated Exchanges","translatable":true},{"type":"doc","id":"federated-queues/index","label":"Federated Queues","translatable":true},{"type":"doc","id":"federation-reference","label":"Federation Reference","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Shovel Plugin","link":{"type":"doc","id":"shovel"},"items":[{"type":"doc","id":"shovel-static","label":"Static Shovels","translatable":true},{"type":"doc","id":"shovel-dynamic","label":"Dynamic Shovels","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"stomp","label":"STOMP Plugin","translatable":true},{"type":"doc","id":"web-stomp","label":"Web STOMP Plugin","translatable":true},{"type":"doc","id":"mqtt","label":"MQTT Plugin","translatable":true},{"type":"doc","id":"web-mqtt","label":"Web MQTT Plugin","translatable":true},{"type":"doc","id":"stream","label":"Stream Plugin","translatable":true},{"type":"doc","id":"installing-plugins","label":"Installing 3rd-party Plugins","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Protocols","link":{"type":"doc","id":"protocols"},"items":[{"type":"doc","id":"amqp","label":"AMQP 1.0","translatable":true},{"type":"doc","id":"connections/index","label":"Connections","translatable":true},{"type":"doc","id":"conversions","label":"Inter-Protocol Property Conversion","translatable":true},{"type":"doc","id":"heartbeats","label":"Heartbeats","translatable":true},{"type":"doc","id":"extensions","label":"AMQP 0-9-1 Extensions","translatable":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Client Libraries","href":"/client-libraries"}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Manage RabbitMQ","link":{"type":"doc","id":"manage-rabbitmq"},"items":[{"type":"doc","id":"cli","label":"CLI","translatable":true},{"type":"doc","id":"configure","label":"Configuration","translatable":true},{"type":"doc","id":"relocate","label":"File and Directory Locations","translatable":true},{"type":"doc","id":"logging","label":"Logging","translatable":true},{"type":"doc","id":"vhosts","label":"Virtual Hosts","translatable":true},{"type":"category","label":" Authentication and Authorization","link":{"type":"doc","id":"access-control"},"items":[{"type":"doc","id":"authentication","label":"AMQP 0-9-1 Authentication Mechanisms","translatable":true},{"type":"doc","id":"passwords","label":"Credentials and Passwords","translatable":true},{"type":"doc","id":"oauth2","label":"OAuth 2","translatable":true},{"type":"doc","id":"ldap","label":"LDAP","translatable":true},{"type":"doc","id":"auth-cache-backend","label":"Cache","translatable":true},{"type":"doc","id":"auth-notification","label":"Authentication Failure Notifications","translatable":true},{"type":"doc","id":"user-limits","label":"Per User Resource Limits","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"parameters","label":"Policies and Runtime Parameters","translatable":true},{"type":"category","label":"Metadata store","link":{"type":"doc","id":"metadata-store/index"},"items":[{"type":"doc","id":"metadata-store/how-to-enable-khepri","label":"How to enable Khepri","translatable":true},{"type":"doc","id":"metadata-store/clustering","label":"Clustering and Khepri","translatable":true},{"type":"doc","id":"metadata-store/everyday-operations","label":"Everyday Operations with Khepri","translatable":true},{"type":"doc","id":"metadata-store/failure-recovery","label":"Failure recovery with Khepri","translatable":true},{"type":"doc","id":"metadata-store/known-issues","label":"Known issues with Khepri","translatable":true},{"type":"doc","id":"metadata-store/khepri-faq","label":"Khepri FAQ","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"definitions","label":"Schema Definitions","translatable":true},{"type":"category","label":"Networking","link":{"type":"doc","id":"networking"},"items":[{"type":"doc","id":"nettick","label":"Net Tick Time","translatable":true},{"type":"doc","id":"ssl/index","label":"TLS Support","translatable":true},{"type":"doc","id":"troubleshooting-networking","label":"Troubleshooting Connectivity","translatable":true},{"type":"doc","id":"troubleshooting-ssl","label":"Troubleshooting TLS","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Clustering","link":{"type":"doc","id":"clustering"},"items":[{"type":"doc","id":"cluster-formation","label":"Cluster Formation","translatable":true},{"type":"doc","id":"partitions","label":"Network Partitions","translatable":true},{"type":"doc","id":"clustering-ssl","label":"Using TLS for Inter-node Traffic","translatable":true},{"type":"doc","id":"ec2","label":"RabbitMQ on Amazon EC2","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Resource Management","items":[{"type":"doc","id":"memory-use/index","label":"Analyzing how Memory is Used","translatable":true},{"type":"category","label":"Memory and Disk Alarms","link":{"type":"doc","id":"alarms"},"items":[{"type":"doc","id":"memory","label":"Memory Alarms","translatable":true},{"type":"doc","id":"disk-alarms","label":"Disk Alarms","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"flow-control","label":"Flow Control","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"backup","label":"Backup and Restore","translatable":true},{"type":"category","label":"Tuning","items":[{"type":"doc","id":"runtime","label":"Runtime Tuning","translatable":true},{"type":"doc","id":"persistence-conf","label":"Persistence Configuration","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"production-checklist","label":"Deployment Guidelines","translatable":true},{"type":"link","label":"RabbitMQ on Kubernetes","href":"/kubernetes/operator/operator-overview"},{"type":"doc","id":"troubleshooting/index","label":"Troubleshooting RabbitMQ","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Monitor RabbitMQ","link":{"type":"doc","id":"monitoring/index"},"items":[{"type":"doc","id":"prometheus/index","label":"Prometheus and Grafana","translatable":true},{"type":"doc","id":"event-exchange","label":"Event Exchange Plugin","translatable":true},{"type":"doc","id":"firehose","label":"Firehose Tracing","translatable":true}],"collapsed":true,"collapsible":true}]}},{"versionName":"3.13","label":"3.13","banner":"unmaintained","badge":true,"noIndex":false,"className":"docs-version-3.13","path":"/rabbitmq-website/docs/3.13","tagsPath":"/rabbitmq-website/docs/3.13/tags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13","editUrlLocalized":"https://github.com/rabbitmq/rabbitmq-website/tree/main/i18n/en/docusaurus-plugin-content-docs/version-3.13","isLast":false,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/versioned_sidebars/version-3.13-sidebars.json","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/versioned_docs/version-3.13","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs/version-3.13","docs":[{"id":"access-control","title":"Authentication, Authorisation, Access Control","description":"<!--","source":"@site/versioned_docs/version-3.13/access-control.md","sourceDirName":".","slug":"/access-control","permalink":"/rabbitmq-website/docs/3.13/access-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/access-control.md","tags":[],"version":"3.13","frontMatter":{"title":"Authentication, Authorisation, Access Control"},"sidebar":"docsSidebar","previous":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/3.13/vhosts"},"next":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/3.13/authentication"}},{"id":"ae","title":"Alternate Exchanges","description":"<!--","source":"@site/versioned_docs/version-3.13/ae.md","sourceDirName":".","slug":"/ae","permalink":"/rabbitmq-website/docs/3.13/ae","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/ae.md","tags":[],"version":"3.13","frontMatter":{"title":"Alternate Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/3.13/e2e"},"next":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/3.13/sender-selected"}},{"id":"alarms","title":"Memory and Disk Alarms","description":"<!--","source":"@site/versioned_docs/version-3.13/alarms.md","sourceDirName":".","slug":"/alarms","permalink":"/rabbitmq-website/docs/3.13/alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/alarms.md","tags":[],"version":"3.13","frontMatter":{"title":"Memory and Disk Alarms"},"sidebar":"docsSidebar","previous":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/3.13/memory-use/"},"next":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/3.13/memory"}},{"id":"auth-notification","title":"Authentication Failure Notifications","description":"<!--","source":"@site/versioned_docs/version-3.13/auth-notification.md","sourceDirName":".","slug":"/auth-notification","permalink":"/rabbitmq-website/docs/3.13/auth-notification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/auth-notification.md","tags":[],"version":"3.13","frontMatter":{"title":"Authentication Failure Notifications"},"sidebar":"docsSidebar","previous":{"title":"LDAP","permalink":"/rabbitmq-website/docs/3.13/ldap"},"next":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/3.13/user-limits"}},{"id":"authentication","title":"Authentication Mechanisms","description":"<!--","source":"@site/versioned_docs/version-3.13/authentication.md","sourceDirName":".","slug":"/authentication","permalink":"/rabbitmq-website/docs/3.13/authentication","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/authentication.md","tags":[],"version":"3.13","frontMatter":{"title":"Authentication Mechanisms"},"sidebar":"docsSidebar","previous":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/3.13/access-control"},"next":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/3.13/passwords"}},{"id":"backup","title":"Backup and Restore","description":"<!--","source":"@site/versioned_docs/version-3.13/backup.md","sourceDirName":".","slug":"/backup","permalink":"/rabbitmq-website/docs/3.13/backup","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/backup.md","tags":[],"version":"3.13","frontMatter":{"title":"Backup and Restore"},"sidebar":"docsSidebar","previous":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/3.13/flow-control"},"next":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/3.13/runtime"}},{"id":"blue-green-upgrade","title":"Upgrading RabbitMQ Using Blue-Green Deployment Strategy","description":"<!--","source":"@site/versioned_docs/version-3.13/blue-green-upgrade.md","sourceDirName":".","slug":"/blue-green-upgrade","permalink":"/rabbitmq-website/docs/3.13/blue-green-upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/blue-green-upgrade.md","tags":[],"version":"3.13","frontMatter":{"title":"Upgrading RabbitMQ Using Blue-Green Deployment Strategy","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/3.13/deprecated-features/"},"next":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/3.13/snapshots"}},{"id":"build-server","title":"Server Build Instructions","description":"<!--","source":"@site/versioned_docs/version-3.13/build-server.md","sourceDirName":".","slug":"/build-server","permalink":"/rabbitmq-website/docs/3.13/build-server","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/build-server.md","tags":[],"version":"3.13","frontMatter":{"title":"Server Build Instructions","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"channels/index","title":"Channels","description":"<!--","source":"@site/versioned_docs/version-3.13/channels/index.md","sourceDirName":"channels","slug":"/channels/","permalink":"/rabbitmq-website/docs/3.13/channels/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/channels/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Channels","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Streams","permalink":"/rabbitmq-website/docs/3.13/streams"},"next":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/3.13/reliability"}},{"id":"classic-queues","title":"Classic Queues","description":"<!--","source":"@site/versioned_docs/version-3.13/classic-queues.md","sourceDirName":".","slug":"/classic-queues","permalink":"/rabbitmq-website/docs/3.13/classic-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/classic-queues.md","tags":[],"version":"3.13","frontMatter":{"title":"Classic Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/3.13/quorum-queues/"},"next":{"title":"Mirrored Classic Queues","permalink":"/rabbitmq-website/docs/3.13/ha/"}},{"id":"cli","title":"Command Line Tools","description":"<!--","source":"@site/versioned_docs/version-3.13/cli.md","sourceDirName":".","slug":"/cli","permalink":"/rabbitmq-website/docs/3.13/cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/cli.md","tags":[],"version":"3.13","frontMatter":{"title":"Command Line Tools"},"sidebar":"docsSidebar","previous":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/manage-rabbitmq"},"next":{"title":"Configuration","permalink":"/rabbitmq-website/docs/3.13/configure"}},{"id":"cluster-formation","title":"Cluster Formation and Peer Discovery","description":"<!--","source":"@site/versioned_docs/version-3.13/cluster-formation.md","sourceDirName":".","slug":"/cluster-formation","permalink":"/rabbitmq-website/docs/3.13/cluster-formation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/cluster-formation.md","tags":[],"version":"3.13","frontMatter":{"title":"Cluster Formation and Peer Discovery"},"sidebar":"docsSidebar","previous":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/3.13/clustering"},"next":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/3.13/partitions"}},{"id":"clustering","title":"Clustering Guide","description":"<!--","source":"@site/versioned_docs/version-3.13/clustering.md","sourceDirName":".","slug":"/clustering","permalink":"/rabbitmq-website/docs/3.13/clustering","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/clustering.md","tags":[],"version":"3.13","frontMatter":{"title":"Clustering Guide"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/3.13/troubleshooting-ssl"},"next":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/3.13/cluster-formation"}},{"id":"clustering-ssl","title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS","description":"<!--","source":"@site/versioned_docs/version-3.13/clustering-ssl.md","sourceDirName":".","slug":"/clustering-ssl","permalink":"/rabbitmq-website/docs/3.13/clustering-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/clustering-ssl.md","tags":[],"version":"3.13","frontMatter":{"title":"Securing Cluster (Inter-node) and CLI Tool Communication with TLS"},"sidebar":"docsSidebar","previous":{"title":"Network Partitions","permalink":"/rabbitmq-website/docs/3.13/partitions"},"next":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/3.13/ec2"}},{"id":"configure","title":"Configuration","description":"<!--","source":"@site/versioned_docs/version-3.13/configure.md","sourceDirName":".","slug":"/configure","permalink":"/rabbitmq-website/docs/3.13/configure","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/configure.md","tags":[],"version":"3.13","frontMatter":{"title":"Configuration"},"sidebar":"docsSidebar","previous":{"title":"CLI","permalink":"/rabbitmq-website/docs/3.13/cli"},"next":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/3.13/relocate"}},{"id":"confirms","title":"Consumer Acknowledgements and Publisher Confirms","description":"<!--","source":"@site/versioned_docs/version-3.13/confirms.md","sourceDirName":".","slug":"/confirms","permalink":"/rabbitmq-website/docs/3.13/confirms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/confirms.md","tags":[],"version":"3.13","frontMatter":{"title":"Consumer Acknowledgements and Publisher Confirms"},"sidebar":"docsSidebar","previous":{"title":"Reliability and Data Safety","permalink":"/rabbitmq-website/docs/3.13/reliability"},"next":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/3.13/distributed"}},{"id":"connection-blocked","title":"Blocked Connection Notifications","description":"<!--","source":"@site/versioned_docs/version-3.13/connection-blocked.md","sourceDirName":".","slug":"/connection-blocked","permalink":"/rabbitmq-website/docs/3.13/connection-blocked","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/connection-blocked.md","tags":[],"version":"3.13","frontMatter":{"title":"Blocked Connection Notifications"},"sidebar":"docsSidebar","previous":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/3.13/direct-reply-to"},"next":{"title":"Exchange to Exchange Bindings","permalink":"/rabbitmq-website/docs/3.13/e2e"}},{"id":"connections/index","title":"Connections","description":"<!--","source":"@site/versioned_docs/version-3.13/connections/index.md","sourceDirName":"connections","slug":"/connections/","permalink":"/rabbitmq-website/docs/3.13/connections/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/connections/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Connections"},"sidebar":"docsSidebar","previous":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/3.13/protocols"},"next":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/3.13/conversions"}},{"id":"consumer-cancel","title":"Consumer Cancel Notification","description":"<!--","source":"@site/versioned_docs/version-3.13/consumer-cancel.md","sourceDirName":".","slug":"/consumer-cancel","permalink":"/rabbitmq-website/docs/3.13/consumer-cancel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/consumer-cancel.md","tags":[],"version":"3.13","frontMatter":{"title":"Consumer Cancel Notification"},"sidebar":"docsSidebar","previous":{"title":"Consumers","permalink":"/rabbitmq-website/docs/3.13/consumers"},"next":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/3.13/consumer-prefetch"}},{"id":"consumer-prefetch","title":"Consumer Prefetch","description":"<!--","source":"@site/versioned_docs/version-3.13/consumer-prefetch.md","sourceDirName":".","slug":"/consumer-prefetch","permalink":"/rabbitmq-website/docs/3.13/consumer-prefetch","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/consumer-prefetch.md","tags":[],"version":"3.13","frontMatter":{"title":"Consumer Prefetch"},"sidebar":"docsSidebar","previous":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/3.13/consumer-cancel"},"next":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/3.13/consumer-priority"}},{"id":"consumer-priority","title":"Consumer Priorities","description":"<!--","source":"@site/versioned_docs/version-3.13/consumer-priority.md","sourceDirName":".","slug":"/consumer-priority","permalink":"/rabbitmq-website/docs/3.13/consumer-priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/consumer-priority.md","tags":[],"version":"3.13","frontMatter":{"title":"Consumer Priorities"},"sidebar":"docsSidebar","previous":{"title":"Consumer Prefetch","permalink":"/rabbitmq-website/docs/3.13/consumer-prefetch"},"next":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/3.13/nack"}},{"id":"consumers","title":"Consumers","description":"<!--","source":"@site/versioned_docs/version-3.13/consumers.md","sourceDirName":".","slug":"/consumers","permalink":"/rabbitmq-website/docs/3.13/consumers","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/consumers.md","tags":[],"version":"3.13","frontMatter":{"title":"Consumers","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Validated User ID","permalink":"/rabbitmq-website/docs/3.13/validated-user-id"},"next":{"title":"Consumer Cancellation Notifications","permalink":"/rabbitmq-website/docs/3.13/consumer-cancel"}},{"id":"conversions","title":"Inter-Protocol Property Conversions","description":"<!--","source":"@site/versioned_docs/version-3.13/conversions.md","sourceDirName":".","slug":"/conversions","permalink":"/rabbitmq-website/docs/3.13/conversions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/conversions.md","tags":[],"version":"3.13","frontMatter":{"title":"Inter-Protocol Property Conversions"},"sidebar":"docsSidebar","previous":{"title":"Connections","permalink":"/rabbitmq-website/docs/3.13/connections/"},"next":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/3.13/heartbeats"}},{"id":"definitions","title":"Schema Definition Export and Import","description":"<!--","source":"@site/versioned_docs/version-3.13/definitions.md","sourceDirName":".","slug":"/definitions","permalink":"/rabbitmq-website/docs/3.13/definitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/definitions.md","tags":[],"version":"3.13","frontMatter":{"title":"Schema Definition Export and Import"},"sidebar":"docsSidebar","previous":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/3.13/parameters"},"next":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/networking"}},{"id":"deprecated-features/index","title":"Deprecated Features","description":"<!--","source":"@site/versioned_docs/version-3.13/deprecated-features/index.md","sourceDirName":"deprecated-features","slug":"/deprecated-features/","permalink":"/rabbitmq-website/docs/3.13/deprecated-features/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/deprecated-features/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Deprecated Features"},"sidebar":"docsSidebar","previous":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/3.13/feature-flags/"},"next":{"title":"Blue-Green Upgrade","permalink":"/rabbitmq-website/docs/3.13/blue-green-upgrade"}},{"id":"direct-reply-to","title":"Direct Reply-to","description":"<!--","source":"@site/versioned_docs/version-3.13/direct-reply-to.md","sourceDirName":".","slug":"/direct-reply-to","permalink":"/rabbitmq-website/docs/3.13/direct-reply-to","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/direct-reply-to.md","tags":[],"version":"3.13","frontMatter":{"title":"Direct Reply-to"},"sidebar":"docsSidebar","previous":{"title":"Publishers","permalink":"/rabbitmq-website/docs/3.13/publishers/"},"next":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/3.13/connection-blocked"}},{"id":"disk-alarms","title":"Free Disk Space Alarms","description":"<!--","source":"@site/versioned_docs/version-3.13/disk-alarms.md","sourceDirName":".","slug":"/disk-alarms","permalink":"/rabbitmq-website/docs/3.13/disk-alarms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/disk-alarms.md","tags":[],"version":"3.13","frontMatter":{"title":"Free Disk Space Alarms"},"sidebar":"docsSidebar","previous":{"title":"Memory Alarms","permalink":"/rabbitmq-website/docs/3.13/memory"},"next":{"title":"Flow Control","permalink":"/rabbitmq-website/docs/3.13/flow-control"}},{"id":"distributed","title":"Distributed RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-3.13/distributed.md","sourceDirName":".","slug":"/distributed","permalink":"/rabbitmq-website/docs/3.13/distributed","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/distributed.md","tags":[],"version":"3.13","frontMatter":{"title":"Distributed RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/3.13/confirms"},"next":{"title":"Plugins","permalink":"/rabbitmq-website/docs/3.13/plugins"}},{"id":"dlx","title":"Dead Letter Exchanges","description":"<!--","source":"@site/versioned_docs/version-3.13/dlx.md","sourceDirName":".","slug":"/dlx","permalink":"/rabbitmq-website/docs/3.13/dlx","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/dlx.md","tags":[],"version":"3.13","frontMatter":{"title":"Dead Letter Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/3.13/lazy-queues"},"next":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/3.13/priority"}},{"id":"download","title":"Installing RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-3.13/download.md","sourceDirName":".","slug":"/download","permalink":"/rabbitmq-website/docs/3.13/download","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/download.md","tags":[],"version":"3.13","frontMatter":{"title":"Installing RabbitMQ","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"What\'s New","permalink":"/rabbitmq-website/docs/3.13/whats-new"},"next":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/3.13/which-erlang"}},{"id":"e2e","title":"Exchange to Exchange Bindings","description":"<!--","source":"@site/versioned_docs/version-3.13/e2e.md","sourceDirName":".","slug":"/e2e","permalink":"/rabbitmq-website/docs/3.13/e2e","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/e2e.md","tags":[],"version":"3.13","frontMatter":{"title":"Exchange to Exchange Bindings"},"sidebar":"docsSidebar","previous":{"title":"Blocked Connection Notifications","permalink":"/rabbitmq-website/docs/3.13/connection-blocked"},"next":{"title":"Alternative Exchanges","permalink":"/rabbitmq-website/docs/3.13/ae"}},{"id":"ec2","title":"Running RabbitMQ on Amazon EC2","description":"<!--","source":"@site/versioned_docs/version-3.13/ec2.md","sourceDirName":".","slug":"/ec2","permalink":"/rabbitmq-website/docs/3.13/ec2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/ec2.md","tags":[],"version":"3.13","frontMatter":{"title":"Running RabbitMQ on Amazon EC2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/3.13/clustering-ssl"},"next":{"title":"Analyzing how Memory is Used","permalink":"/rabbitmq-website/docs/3.13/memory-use/"}},{"id":"event-exchange","title":"Event Exchange Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/event-exchange.md","sourceDirName":".","slug":"/event-exchange","permalink":"/rabbitmq-website/docs/3.13/event-exchange","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/event-exchange.md","tags":[],"version":"3.13","frontMatter":{"title":"Event Exchange Plugin"},"sidebar":"docsSidebar","previous":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/3.13/prometheus/"},"next":{"title":"Firehose Tracing","permalink":"/rabbitmq-website/docs/3.13/firehose"}},{"id":"extensions","title":"Protocol Extensions","description":"<!--","source":"@site/versioned_docs/version-3.13/extensions.md","sourceDirName":".","slug":"/extensions","permalink":"/rabbitmq-website/docs/3.13/extensions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/extensions.md","tags":[],"version":"3.13","frontMatter":{"title":"Protocol Extensions"},"sidebar":"docsSidebar","previous":{"title":"Heartbeats","permalink":"/rabbitmq-website/docs/3.13/heartbeats"},"next":{"title":"How to Manage RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/manage-rabbitmq"}},{"id":"feature-flags/index","title":"Feature Flags","description":"<!--","source":"@site/versioned_docs/version-3.13/feature-flags/index.md","sourceDirName":"feature-flags","slug":"/feature-flags/","permalink":"/rabbitmq-website/docs/3.13/feature-flags/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/feature-flags/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Feature Flags"},"sidebar":"docsSidebar","previous":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/upgrade"},"next":{"title":"Deprecated Features","permalink":"/rabbitmq-website/docs/3.13/deprecated-features/"}},{"id":"federated-exchanges/index","title":"Federated Exchanges","description":"<!--","source":"@site/versioned_docs/version-3.13/federated-exchanges/index.md","sourceDirName":"federated-exchanges","slug":"/federated-exchanges/","permalink":"/rabbitmq-website/docs/3.13/federated-exchanges/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/federated-exchanges/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Federated Exchanges"},"sidebar":"docsSidebar","previous":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/3.13/federation"},"next":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/3.13/federated-queues/"}},{"id":"federated-queues/index","title":"Federated Queues","description":"<!--","source":"@site/versioned_docs/version-3.13/federated-queues/index.md","sourceDirName":"federated-queues","slug":"/federated-queues/","permalink":"/rabbitmq-website/docs/3.13/federated-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/federated-queues/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Federated Queues"},"sidebar":"docsSidebar","previous":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/3.13/federated-exchanges/"},"next":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/3.13/federation-reference"}},{"id":"federation","title":"Federation Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/federation.md","sourceDirName":".","slug":"/federation","permalink":"/rabbitmq-website/docs/3.13/federation","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/federation.md","tags":[],"version":"3.13","frontMatter":{"title":"Federation Plugin"},"sidebar":"docsSidebar","previous":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/3.13/management/"},"next":{"title":"Federated Exchanges","permalink":"/rabbitmq-website/docs/3.13/federated-exchanges/"}},{"id":"federation-reference","title":"Federation Reference","description":"<!--","source":"@site/versioned_docs/version-3.13/federation-reference.md","sourceDirName":".","slug":"/federation-reference","permalink":"/rabbitmq-website/docs/3.13/federation-reference","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/federation-reference.md","tags":[],"version":"3.13","frontMatter":{"title":"Federation Reference"},"sidebar":"docsSidebar","previous":{"title":"Federated Queues","permalink":"/rabbitmq-website/docs/3.13/federated-queues/"},"next":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/3.13/shovel"}},{"id":"firehose","title":"Firehose Tracer","description":"<!--","source":"@site/versioned_docs/version-3.13/firehose.md","sourceDirName":".","slug":"/firehose","permalink":"/rabbitmq-website/docs/3.13/firehose","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/firehose.md","tags":[],"version":"3.13","frontMatter":{"title":"Firehose Tracer"},"sidebar":"docsSidebar","previous":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/3.13/event-exchange"}},{"id":"flow-control","title":"Flow Control","description":"<!--","source":"@site/versioned_docs/version-3.13/flow-control.md","sourceDirName":".","slug":"/flow-control","permalink":"/rabbitmq-website/docs/3.13/flow-control","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/flow-control.md","tags":[],"version":"3.13","frontMatter":{"title":"Flow Control"},"sidebar":"docsSidebar","previous":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/3.13/disk-alarms"},"next":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/3.13/backup"}},{"id":"ha/index","title":"Classic Queue Mirroring","description":"<!--","source":"@site/versioned_docs/version-3.13/ha/index.md","sourceDirName":"ha","slug":"/ha/","permalink":"/rabbitmq-website/docs/3.13/ha/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/ha/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Classic Queue Mirroring"},"sidebar":"docsSidebar","previous":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/3.13/classic-queues"},"next":{"title":"Migrate Mirrored Classic Queues to Quorum Queues","permalink":"/rabbitmq-website/docs/3.13/migrate-mcq-to-qq"}},{"id":"heartbeats","title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives","description":"<!--","source":"@site/versioned_docs/version-3.13/heartbeats.md","sourceDirName":".","slug":"/heartbeats","permalink":"/rabbitmq-website/docs/3.13/heartbeats","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/heartbeats.md","tags":[],"version":"3.13","frontMatter":{"title":"Detecting Dead TCP Connections with Heartbeats and TCP Keepalives"},"sidebar":"docsSidebar","previous":{"title":"Inter-Protocol Property Conversion","permalink":"/rabbitmq-website/docs/3.13/conversions"},"next":{"title":"Protocol Extensions","permalink":"/rabbitmq-website/docs/3.13/extensions"}},{"id":"index","title":"RabbitMQ Documentation","description":"<!--","source":"@site/versioned_docs/version-3.13/index.md","sourceDirName":".","slug":"/","permalink":"/rabbitmq-website/docs/3.13/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/index.md","tags":[],"version":"3.13","frontMatter":{"title":"RabbitMQ Documentation"},"sidebar":"docsSidebar","next":{"title":"What\'s New","permalink":"/rabbitmq-website/docs/3.13/whats-new"}},{"id":"install-debian","title":"Installing on Debian and Ubuntu","description":"<!--","source":"@site/versioned_docs/version-3.13/install-debian.md","sourceDirName":".","slug":"/install-debian","permalink":"/rabbitmq-website/docs/3.13/install-debian","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-debian.md","tags":[],"version":"3.13","frontMatter":{"title":"Installing on Debian and Ubuntu","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/3.13/platforms"},"next":{"title":"RedHat","permalink":"/rabbitmq-website/docs/3.13/install-rpm"}},{"id":"install-generic-unix","title":"Generic Binary Build","description":"<!--","source":"@site/versioned_docs/version-3.13/install-generic-unix.md","sourceDirName":".","slug":"/install-generic-unix","permalink":"/rabbitmq-website/docs/3.13/install-generic-unix","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-generic-unix.md","tags":[],"version":"3.13","frontMatter":{"title":"Generic Binary Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"RedHat","permalink":"/rabbitmq-website/docs/3.13/install-rpm"},"next":{"title":"Windows","permalink":"/rabbitmq-website/docs/3.13/install-windows"}},{"id":"install-homebrew","title":"The Homebrew RabbitMQ Formula","description":"<!--","source":"@site/versioned_docs/version-3.13/install-homebrew.md","sourceDirName":".","slug":"/install-homebrew","permalink":"/rabbitmq-website/docs/3.13/install-homebrew","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-homebrew.md","tags":[],"version":"3.13","frontMatter":{"title":"The Homebrew RabbitMQ Formula","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/3.13/install-standalone-mac"},"next":{"title":"Upgrading RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/upgrade"}},{"id":"install-rpm","title":"Installing on RPM-based Linux","description":"<!--","source":"@site/versioned_docs/version-3.13/install-rpm.md","sourceDirName":".","slug":"/install-rpm","permalink":"/rabbitmq-website/docs/3.13/install-rpm","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-rpm.md","tags":[],"version":"3.13","frontMatter":{"title":"Installing on RPM-based Linux","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/3.13/install-debian"},"next":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/3.13/install-generic-unix"}},{"id":"install-solaris","title":"Installing on Solaris","description":"<!--","source":"@site/versioned_docs/version-3.13/install-solaris.md","sourceDirName":".","slug":"/install-solaris","permalink":"/rabbitmq-website/docs/3.13/install-solaris","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-solaris.md","tags":[],"version":"3.13","frontMatter":{"title":"Installing on Solaris","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"install-standalone-mac","title":"Standalone MacOS Build","description":"<!--","source":"@site/versioned_docs/version-3.13/install-standalone-mac.md","sourceDirName":".","slug":"/install-standalone-mac","permalink":"/rabbitmq-website/docs/3.13/install-standalone-mac","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-standalone-mac.md","tags":[],"version":"3.13","frontMatter":{"title":"Standalone MacOS Build","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Windows","permalink":"/rabbitmq-website/docs/3.13/install-windows"},"next":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/3.13/install-homebrew"}},{"id":"install-windows","title":"Installing on Windows","description":"<!--","source":"@site/versioned_docs/version-3.13/install-windows.md","sourceDirName":".","slug":"/install-windows","permalink":"/rabbitmq-website/docs/3.13/install-windows","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-windows.md","tags":[],"version":"3.13","frontMatter":{"title":"Installing on Windows","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Generic Unix","permalink":"/rabbitmq-website/docs/3.13/install-generic-unix"},"next":{"title":"MacOS using Standalone Binary Build","permalink":"/rabbitmq-website/docs/3.13/install-standalone-mac"}},{"id":"install-windows-manual","title":"Installing on Windows manually","description":"<!--","source":"@site/versioned_docs/version-3.13/install-windows-manual.md","sourceDirName":".","slug":"/install-windows-manual","permalink":"/rabbitmq-website/docs/3.13/install-windows-manual","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/install-windows-manual.md","tags":[],"version":"3.13","frontMatter":{"title":"Installing on Windows manually","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"installing-plugins","title":"installing Additional Plugins","description":"<!--","source":"@site/versioned_docs/version-3.13/installing-plugins.md","sourceDirName":".","slug":"/installing-plugins","permalink":"/rabbitmq-website/docs/3.13/installing-plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/installing-plugins.md","tags":[],"version":"3.13","frontMatter":{"title":"installing Additional Plugins"},"sidebar":"docsSidebar","previous":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/3.13/stream"},"next":{"title":"Which protocols does RabbitMQ support?","permalink":"/rabbitmq-website/docs/3.13/protocols"}},{"id":"lazy-queues","title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)","description":"<!--","source":"@site/versioned_docs/version-3.13/lazy-queues.md","sourceDirName":".","slug":"/lazy-queues","permalink":"/rabbitmq-website/docs/3.13/lazy-queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/lazy-queues.md","tags":[],"version":"3.13","frontMatter":{"title":"Classic Queues Operating in \\"Lazy\\" Queue Mode (A Lazy Queue)"},"sidebar":"docsSidebar","previous":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/3.13/maxlength/"},"next":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/3.13/dlx"}},{"id":"ldap","title":"LDAP Support","description":"<!--","source":"@site/versioned_docs/version-3.13/ldap.md","sourceDirName":".","slug":"/ldap","permalink":"/rabbitmq-website/docs/3.13/ldap","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/ldap.md","tags":[],"version":"3.13","frontMatter":{"title":"LDAP Support"},"sidebar":"docsSidebar","previous":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/3.13/oauth2"},"next":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/3.13/auth-notification"}},{"id":"logging","title":"Logging","description":"<!--","source":"@site/versioned_docs/version-3.13/logging.md","sourceDirName":".","slug":"/logging","permalink":"/rabbitmq-website/docs/3.13/logging","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/logging.md","tags":[],"version":"3.13","frontMatter":{"title":"Logging"},"sidebar":"docsSidebar","previous":{"title":"File and Directory Locations","permalink":"/rabbitmq-website/docs/3.13/relocate"},"next":{"title":"Virtual Hosts","permalink":"/rabbitmq-website/docs/3.13/vhosts"}},{"id":"man/rabbitmq-diagnostics.8","title":"rabbitmq-diagnostics.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-diagnostics.8.md","sourceDirName":"man","slug":"/man/rabbitmq-diagnostics.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-diagnostics.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-diagnostics.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-echopid.8","title":"rabbitmq-echopid.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-echopid.8.md","sourceDirName":"man","slug":"/man/rabbitmq-echopid.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-echopid.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-echopid.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-env.conf.5","title":"rabbitmq-env.conf.5","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-env.conf.5.md","sourceDirName":"man","slug":"/man/rabbitmq-env.conf.5","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-env.conf.5","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-env.conf.5.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-plugins.8","title":"rabbitmq-plugins.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-plugins.8.md","sourceDirName":"man","slug":"/man/rabbitmq-plugins.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-plugins.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-plugins.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-queues.8","title":"rabbitmq-queues.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-queues.8.md","sourceDirName":"man","slug":"/man/rabbitmq-queues.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-queues.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-queues.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-server.8","title":"rabbitmq-server.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-server.8.md","sourceDirName":"man","slug":"/man/rabbitmq-server.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-server.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-server.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-service.8","title":"rabbitmq-service.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-service.8.md","sourceDirName":"man","slug":"/man/rabbitmq-service.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-service.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-service.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-streams.8","title":"rabbitmq-streams.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-streams.8.md","sourceDirName":"man","slug":"/man/rabbitmq-streams.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-streams.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-streams.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmq-upgrade.8","title":"rabbitmq-upgrade.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmq-upgrade.8.md","sourceDirName":"man","slug":"/man/rabbitmq-upgrade.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmq-upgrade.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmq-upgrade.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/rabbitmqctl.8","title":"rabbitmqctl.8","description":"NAME","source":"@site/versioned_docs/version-3.13/man/rabbitmqctl.8.md","sourceDirName":"man","slug":"/man/rabbitmqctl.8","permalink":"/rabbitmq-website/docs/3.13/man/rabbitmqctl.8","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/rabbitmqctl.8.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"man/README","title":"RabbitMQ man Pages","description":"Source Files","source":"@site/versioned_docs/version-3.13/man/README.md","sourceDirName":"man","slug":"/man/","permalink":"/rabbitmq-website/docs/3.13/man/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/man/README.md","tags":[],"version":"3.13","frontMatter":{}},{"id":"manage-rabbitmq","title":"How to Manage RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-3.13/manage-rabbitmq.md","sourceDirName":".","slug":"/manage-rabbitmq","permalink":"/rabbitmq-website/docs/3.13/manage-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/manage-rabbitmq.md","tags":[],"version":"3.13","frontMatter":{"title":"How to Manage RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Protocol Extensions","permalink":"/rabbitmq-website/docs/3.13/extensions"},"next":{"title":"CLI","permalink":"/rabbitmq-website/docs/3.13/cli"}},{"id":"management-cli","title":"Management Command Line Tool","description":"<!--","source":"@site/versioned_docs/version-3.13/management-cli.md","sourceDirName":".","slug":"/management-cli","permalink":"/rabbitmq-website/docs/3.13/management-cli","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/management-cli.md","tags":[],"version":"3.13","frontMatter":{"title":"Management Command Line Tool","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"management/index","title":"Management Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/management/index.md","sourceDirName":"management","slug":"/management/","permalink":"/rabbitmq-website/docs/3.13/management/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/management/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Management Plugin"},"sidebar":"docsSidebar","previous":{"title":"Plugins","permalink":"/rabbitmq-website/docs/3.13/plugins"},"next":{"title":"Federation Plugin","permalink":"/rabbitmq-website/docs/3.13/federation"}},{"id":"manpages","title":"Manual Pages","description":"<!--","source":"@site/versioned_docs/version-3.13/manpages.md","sourceDirName":".","slug":"/manpages","permalink":"/rabbitmq-website/docs/3.13/manpages","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/manpages.md","tags":[],"version":"3.13","frontMatter":{"title":"Manual Pages","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"maxlength/index","title":"Queue Length Limit","description":"<!--","source":"@site/versioned_docs/version-3.13/maxlength/index.md","sourceDirName":"maxlength","slug":"/maxlength/","permalink":"/rabbitmq-website/docs/3.13/maxlength/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/maxlength/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Queue Length Limit"},"sidebar":"docsSidebar","previous":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/3.13/ttl"},"next":{"title":"Lazy Queues","permalink":"/rabbitmq-website/docs/3.13/lazy-queues"}},{"id":"memory","title":"Memory Threshold and Limit","description":"<!--","source":"@site/versioned_docs/version-3.13/memory.md","sourceDirName":".","slug":"/memory","permalink":"/rabbitmq-website/docs/3.13/memory","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/memory.md","tags":[],"version":"3.13","frontMatter":{"title":"Memory Threshold and Limit"},"sidebar":"docsSidebar","previous":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/3.13/alarms"},"next":{"title":"Disk Alarms","permalink":"/rabbitmq-website/docs/3.13/disk-alarms"}},{"id":"memory-use/index","title":"Reasoning About Memory Use","description":"<!--","source":"@site/versioned_docs/version-3.13/memory-use/index.md","sourceDirName":"memory-use","slug":"/memory-use/","permalink":"/rabbitmq-website/docs/3.13/memory-use/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/memory-use/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Reasoning About Memory Use"},"sidebar":"docsSidebar","previous":{"title":"RabbitMQ on Amazon EC2","permalink":"/rabbitmq-website/docs/3.13/ec2"},"next":{"title":"Memory and Disk Alarms","permalink":"/rabbitmq-website/docs/3.13/alarms"}},{"id":"migrate-mcq-to-qq","title":"Migrate your RabbitMQ Mirrored Classic Queues to Quorum Queues","description":"<!--","source":"@site/versioned_docs/version-3.13/migrate-mcq-to-qq.md","sourceDirName":".","slug":"/migrate-mcq-to-qq","permalink":"/rabbitmq-website/docs/3.13/migrate-mcq-to-qq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/migrate-mcq-to-qq.md","tags":[],"version":"3.13","frontMatter":{"title":"Migrate your RabbitMQ Mirrored Classic Queues to Quorum Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Mirrored Classic Queues","permalink":"/rabbitmq-website/docs/3.13/ha/"},"next":{"title":"Time-to-Live and Expiration","permalink":"/rabbitmq-website/docs/3.13/ttl"}},{"id":"monitoring/index","title":"Monitoring","description":"<!--","source":"@site/versioned_docs/version-3.13/monitoring/index.md","sourceDirName":"monitoring","slug":"/monitoring/","permalink":"/rabbitmq-website/docs/3.13/monitoring/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/monitoring/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Monitoring"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/troubleshooting/"},"next":{"title":"Prometheus and Grafana","permalink":"/rabbitmq-website/docs/3.13/prometheus/"}},{"id":"mqtt","title":"MQTT Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/mqtt.md","sourceDirName":".","slug":"/mqtt","permalink":"/rabbitmq-website/docs/3.13/mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/mqtt.md","tags":[],"version":"3.13","frontMatter":{"title":"MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/3.13/web-stomp"},"next":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/3.13/web-mqtt"}},{"id":"nack","title":"Negative Acknowledgements","description":"<!--","source":"@site/versioned_docs/version-3.13/nack.md","sourceDirName":".","slug":"/nack","permalink":"/rabbitmq-website/docs/3.13/nack","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/nack.md","tags":[],"version":"3.13","frontMatter":{"title":"Negative Acknowledgements"},"sidebar":"docsSidebar","previous":{"title":"Consumer Priorites","permalink":"/rabbitmq-website/docs/3.13/consumer-priority"},"next":{"title":"Queues","permalink":"/rabbitmq-website/docs/3.13/queues"}},{"id":"nettick","title":"Net Tick Time (Inter-node Communication Heartbeats)","description":"<!--","source":"@site/versioned_docs/version-3.13/nettick.md","sourceDirName":".","slug":"/nettick","permalink":"/rabbitmq-website/docs/3.13/nettick","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/nettick.md","tags":[],"version":"3.13","frontMatter":{"title":"Net Tick Time (Inter-node Communication Heartbeats)"},"sidebar":"docsSidebar","previous":{"title":"Networking and RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/networking"},"next":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/3.13/ssl/"}},{"id":"networking","title":"Networking and RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-3.13/networking.md","sourceDirName":".","slug":"/networking","permalink":"/rabbitmq-website/docs/3.13/networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/networking.md","tags":[],"version":"3.13","frontMatter":{"title":"Networking and RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/3.13/definitions"},"next":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/3.13/nettick"}},{"id":"oauth2","title":"OAuth 2.0 Authentication Backend","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2.md","sourceDirName":".","slug":"/oauth2","permalink":"/rabbitmq-website/docs/3.13/oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2.md","tags":[],"version":"3.13","frontMatter":{"title":"OAuth 2.0 Authentication Backend"},"sidebar":"docsSidebar","previous":{"title":"Credentials and Passwords","permalink":"/rabbitmq-website/docs/3.13/passwords"},"next":{"title":"LDAP","permalink":"/rabbitmq-website/docs/3.13/ldap"}},{"id":"oauth2-examples-auth0","title":"Use auth0.com as OAuth 2.0 Server","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-auth0.md","sourceDirName":".","slug":"/oauth2-examples-auth0","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-auth0","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-auth0.md","tags":[],"version":"3.13","frontMatter":{"title":"Use auth0.com as OAuth 2.0 Server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-entra-id/index","title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-entra-id/index.md","sourceDirName":"oauth2-examples-entra-id","slug":"/oauth2-examples-entra-id/","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-entra-id/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-entra-id/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Use Microsoft Entra ID (previously known as Azure AD) as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-google","title":"Use Google as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-google.md","sourceDirName":".","slug":"/oauth2-examples-google","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-google","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-google.md","tags":[],"version":"3.13","frontMatter":{"title":"Use Google as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-idp-initiated","title":"Use Identity Provider Initiated Logon","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-idp-initiated.md","sourceDirName":".","slug":"/oauth2-examples-idp-initiated","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-idp-initiated","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-idp-initiated.md","tags":[],"version":"3.13","frontMatter":{"title":"Use Identity Provider Initiated Logon","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-keycloak","title":"Use Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-keycloak.md","sourceDirName":".","slug":"/oauth2-examples-keycloak","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-keycloak","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-keycloak.md","tags":[],"version":"3.13","frontMatter":{"title":"Use Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-multiresource","title":"Using Multiple OAuth 2.0 Servers and/or Audiences","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-multiresource.md","sourceDirName":".","slug":"/oauth2-examples-multiresource","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-multiresource","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-multiresource.md","tags":[],"version":"3.13","frontMatter":{"title":"Using Multiple OAuth 2.0 Servers and/or Audiences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-okta","title":"Use Okta as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-okta.md","sourceDirName":".","slug":"/oauth2-examples-okta","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-okta","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-okta.md","tags":[],"version":"3.13","frontMatter":{"title":"Use Okta as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples-proxy","title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples-proxy.md","sourceDirName":".","slug":"/oauth2-examples-proxy","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples-proxy","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples-proxy.md","tags":[],"version":"3.13","frontMatter":{"title":"Use OAuth2 Proxy and Keycloak as OAuth 2.0 server","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"oauth2-examples/index","title":"OAuth 2.0 Authentication Examples","description":"<!--","source":"@site/versioned_docs/version-3.13/oauth2-examples/index.md","sourceDirName":"oauth2-examples","slug":"/oauth2-examples/","permalink":"/rabbitmq-website/docs/3.13/oauth2-examples/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/oauth2-examples/index.md","tags":[],"version":"3.13","frontMatter":{"title":"OAuth 2.0 Authentication Examples","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"parameters","title":"Runtime Parameters","description":"<!--","source":"@site/versioned_docs/version-3.13/parameters.md","sourceDirName":".","slug":"/parameters","permalink":"/rabbitmq-website/docs/3.13/parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/parameters.md","tags":[],"version":"3.13","frontMatter":{"title":"Runtime Parameters"},"sidebar":"docsSidebar","previous":{"title":"Per User Resource Limits","permalink":"/rabbitmq-website/docs/3.13/user-limits"},"next":{"title":"Schema Definitions","permalink":"/rabbitmq-website/docs/3.13/definitions"}},{"id":"partitions","title":"Clustering and Network Partitions","description":"<!--","source":"@site/versioned_docs/version-3.13/partitions.md","sourceDirName":".","slug":"/partitions","permalink":"/rabbitmq-website/docs/3.13/partitions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/partitions.md","tags":[],"version":"3.13","frontMatter":{"title":"Clustering and Network Partitions"},"sidebar":"docsSidebar","previous":{"title":"Cluster Formation","permalink":"/rabbitmq-website/docs/3.13/cluster-formation"},"next":{"title":"Using TLS for Inter-node Traffic","permalink":"/rabbitmq-website/docs/3.13/clustering-ssl"}},{"id":"passwords","title":"Credentials and Passwords","description":"<!--","source":"@site/versioned_docs/version-3.13/passwords.md","sourceDirName":".","slug":"/passwords","permalink":"/rabbitmq-website/docs/3.13/passwords","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/passwords.md","tags":[],"version":"3.13","frontMatter":{"title":"Credentials and Passwords","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"AMQP 0-9-1 Authentication Mechanisms","permalink":"/rabbitmq-website/docs/3.13/authentication"},"next":{"title":"OAuth 2","permalink":"/rabbitmq-website/docs/3.13/oauth2"}},{"id":"persistence-conf","title":"Persistence Configuration","description":"<!--","source":"@site/versioned_docs/version-3.13/persistence-conf.md","sourceDirName":".","slug":"/persistence-conf","permalink":"/rabbitmq-website/docs/3.13/persistence-conf","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/persistence-conf.md","tags":[],"version":"3.13","frontMatter":{"title":"Persistence Configuration"},"sidebar":"docsSidebar","previous":{"title":"Runtime Tuning","permalink":"/rabbitmq-website/docs/3.13/runtime"},"next":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/3.13/production-checklist"}},{"id":"platforms","title":"Supported Platforms","description":"<!--","source":"@site/versioned_docs/version-3.13/platforms.md","sourceDirName":".","slug":"/platforms","permalink":"/rabbitmq-website/docs/3.13/platforms","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/platforms.md","tags":[],"version":"3.13","frontMatter":{"title":"Supported Platforms"},"sidebar":"docsSidebar","previous":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/3.13/signatures"},"next":{"title":"Debian and Ubuntu","permalink":"/rabbitmq-website/docs/3.13/install-debian"}},{"id":"plugins","title":"Plugins","description":"<!--","source":"@site/versioned_docs/version-3.13/plugins.md","sourceDirName":".","slug":"/plugins","permalink":"/rabbitmq-website/docs/3.13/plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/plugins.md","tags":[],"version":"3.13","frontMatter":{"title":"Plugins","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Network Distribution","permalink":"/rabbitmq-website/docs/3.13/distributed"},"next":{"title":"Management Plugin","permalink":"/rabbitmq-website/docs/3.13/management/"}},{"id":"policies","title":"Policies","description":"<!--","source":"@site/versioned_docs/version-3.13/policies.md","sourceDirName":".","slug":"/policies","permalink":"/rabbitmq-website/docs/3.13/policies","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/policies.md","tags":[],"version":"3.13","frontMatter":{"title":"Policies"}},{"id":"priority","title":"Classic Queues Support Priorities","description":"<!--","source":"@site/versioned_docs/version-3.13/priority.md","sourceDirName":".","slug":"/priority","permalink":"/rabbitmq-website/docs/3.13/priority","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/priority.md","tags":[],"version":"3.13","frontMatter":{"title":"Classic Queues Support Priorities"},"sidebar":"docsSidebar","previous":{"title":"Dead Lettering","permalink":"/rabbitmq-website/docs/3.13/dlx"},"next":{"title":"Streams","permalink":"/rabbitmq-website/docs/3.13/streams"}},{"id":"production-checklist","title":"Production Deployment Guidelines","description":"<!--","source":"@site/versioned_docs/version-3.13/production-checklist.md","sourceDirName":".","slug":"/production-checklist","permalink":"/rabbitmq-website/docs/3.13/production-checklist","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/production-checklist.md","tags":[],"version":"3.13","frontMatter":{"title":"Production Deployment Guidelines"},"sidebar":"docsSidebar","previous":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/3.13/persistence-conf"},"next":{"title":"Troubleshooting RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/troubleshooting/"}},{"id":"prometheus/index","title":"Monitoring with Prometheus and Grafana","description":"Overview","source":"@site/versioned_docs/version-3.13/prometheus/index.md","sourceDirName":"prometheus","slug":"/prometheus/","permalink":"/rabbitmq-website/docs/3.13/prometheus/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/prometheus/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Monitoring with Prometheus and Grafana","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/3.13/monitoring/"},"next":{"title":"Event Exchange Plugin","permalink":"/rabbitmq-website/docs/3.13/event-exchange"}},{"id":"protocols","title":"Which protocols does RabbitMQ support?","description":"<!--","source":"@site/versioned_docs/version-3.13/protocols.md","sourceDirName":".","slug":"/protocols","permalink":"/rabbitmq-website/docs/3.13/protocols","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/protocols.md","tags":[],"version":"3.13","frontMatter":{"title":"Which protocols does RabbitMQ support?","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/3.13/installing-plugins"},"next":{"title":"Connections","permalink":"/rabbitmq-website/docs/3.13/connections/"}},{"id":"publishers/index","title":"Publishers","description":"<!--","source":"@site/versioned_docs/version-3.13/publishers/index.md","sourceDirName":"publishers","slug":"/publishers/","permalink":"/rabbitmq-website/docs/3.13/publishers/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/publishers/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Publishers"},"sidebar":"docsSidebar","previous":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/use-rabbitmq"},"next":{"title":"Direct reply-to","permalink":"/rabbitmq-website/docs/3.13/direct-reply-to"}},{"id":"queues","title":"Queues","description":"<!--","source":"@site/versioned_docs/version-3.13/queues.md","sourceDirName":".","slug":"/queues","permalink":"/rabbitmq-website/docs/3.13/queues","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/queues.md","tags":[],"version":"3.13","frontMatter":{"title":"Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Negative Acknowledgements","permalink":"/rabbitmq-website/docs/3.13/nack"},"next":{"title":"Quorum Queues","permalink":"/rabbitmq-website/docs/3.13/quorum-queues/"}},{"id":"quorum-queues/index","title":"Quorum Queues","description":"<!--","source":"@site/versioned_docs/version-3.13/quorum-queues/index.md","sourceDirName":"quorum-queues","slug":"/quorum-queues/","permalink":"/rabbitmq-website/docs/3.13/quorum-queues/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/quorum-queues/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Quorum Queues","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Queues","permalink":"/rabbitmq-website/docs/3.13/queues"},"next":{"title":"Classic Queues","permalink":"/rabbitmq-website/docs/3.13/classic-queues"}},{"id":"reliability","title":"Reliability Guide","description":"<!--","source":"@site/versioned_docs/version-3.13/reliability.md","sourceDirName":".","slug":"/reliability","permalink":"/rabbitmq-website/docs/3.13/reliability","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/reliability.md","tags":[],"version":"3.13","frontMatter":{"title":"Reliability Guide"},"sidebar":"docsSidebar","previous":{"title":"Channels","permalink":"/rabbitmq-website/docs/3.13/channels/"},"next":{"title":"Consumer Acknowledgements and Publisher Confirms","permalink":"/rabbitmq-website/docs/3.13/confirms"}},{"id":"relocate","title":"File and Directory Locations","description":"<!--","source":"@site/versioned_docs/version-3.13/relocate.md","sourceDirName":".","slug":"/relocate","permalink":"/rabbitmq-website/docs/3.13/relocate","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/relocate.md","tags":[],"version":"3.13","frontMatter":{"title":"File and Directory Locations"},"sidebar":"docsSidebar","previous":{"title":"Configuration","permalink":"/rabbitmq-website/docs/3.13/configure"},"next":{"title":"Logging","permalink":"/rabbitmq-website/docs/3.13/logging"}},{"id":"runtime","title":"Runtime Tuning","description":"<!--","source":"@site/versioned_docs/version-3.13/runtime.md","sourceDirName":".","slug":"/runtime","permalink":"/rabbitmq-website/docs/3.13/runtime","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/runtime.md","tags":[],"version":"3.13","frontMatter":{"title":"Runtime Tuning","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Backup and Restore","permalink":"/rabbitmq-website/docs/3.13/backup"},"next":{"title":"Persistence Configuration","permalink":"/rabbitmq-website/docs/3.13/persistence-conf"}},{"id":"semantics","title":"Broker Semantics","description":"Here we describe the broker semantics. This should be read together with the AMQP specification.","source":"@site/versioned_docs/version-3.13/semantics.md","sourceDirName":".","slug":"/semantics","permalink":"/rabbitmq-website/docs/3.13/semantics","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/semantics.md","tags":[],"version":"3.13","frontMatter":{"title":"Broker Semantics","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"sender-selected","title":"Sender-selected Distribution","description":"<!--","source":"@site/versioned_docs/version-3.13/sender-selected.md","sourceDirName":".","slug":"/sender-selected","permalink":"/rabbitmq-website/docs/3.13/sender-selected","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/sender-selected.md","tags":[],"version":"3.13","frontMatter":{"title":"Sender-selected Distribution"},"sidebar":"docsSidebar","previous":{"title":"Alternative Exchanges","permalink":"/rabbitmq-website/docs/3.13/ae"},"next":{"title":"Validated User ID","permalink":"/rabbitmq-website/docs/3.13/validated-user-id"}},{"id":"shovel","title":"Shovel Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/shovel.md","sourceDirName":".","slug":"/shovel","permalink":"/rabbitmq-website/docs/3.13/shovel","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/shovel.md","tags":[],"version":"3.13","frontMatter":{"title":"Shovel Plugin"},"sidebar":"docsSidebar","previous":{"title":"Federation Reference","permalink":"/rabbitmq-website/docs/3.13/federation-reference"},"next":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/3.13/shovel-static"}},{"id":"shovel-dynamic","title":"Configuring Dynamic Shovels","description":"<!--","source":"@site/versioned_docs/version-3.13/shovel-dynamic.md","sourceDirName":".","slug":"/shovel-dynamic","permalink":"/rabbitmq-website/docs/3.13/shovel-dynamic","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/shovel-dynamic.md","tags":[],"version":"3.13","frontMatter":{"title":"Configuring Dynamic Shovels"},"sidebar":"docsSidebar","previous":{"title":"Static Shovels","permalink":"/rabbitmq-website/docs/3.13/shovel-static"},"next":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/3.13/stomp"}},{"id":"shovel-static","title":"Configuring Static Shovels","description":"<!--","source":"@site/versioned_docs/version-3.13/shovel-static.md","sourceDirName":".","slug":"/shovel-static","permalink":"/rabbitmq-website/docs/3.13/shovel-static","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/shovel-static.md","tags":[],"version":"3.13","frontMatter":{"title":"Configuring Static Shovels"},"sidebar":"docsSidebar","previous":{"title":"Shovel Plugin","permalink":"/rabbitmq-website/docs/3.13/shovel"},"next":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/3.13/shovel-dynamic"}},{"id":"signatures","title":"Package Signatures","description":"<!--","source":"@site/versioned_docs/version-3.13/signatures.md","sourceDirName":".","slug":"/signatures","permalink":"/rabbitmq-website/docs/3.13/signatures","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/signatures.md","tags":[],"version":"3.13","frontMatter":{"title":"Package Signatures","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Erlang Version Requirements","permalink":"/rabbitmq-website/docs/3.13/which-erlang"},"next":{"title":"Supported Platforms","permalink":"/rabbitmq-website/docs/3.13/platforms"}},{"id":"snapshots","title":"Snapshots Releases","description":"<!--","source":"@site/versioned_docs/version-3.13/snapshots.md","sourceDirName":".","slug":"/snapshots","permalink":"/rabbitmq-website/docs/3.13/snapshots","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/snapshots.md","tags":[],"version":"3.13","frontMatter":{"title":"Snapshots Releases"},"sidebar":"docsSidebar","previous":{"title":"Blue-Green Upgrade","permalink":"/rabbitmq-website/docs/3.13/blue-green-upgrade"},"next":{"title":"How to Use RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/use-rabbitmq"}},{"id":"spec-differences","title":"Spec Differences","description":"Undeprecated Features","source":"@site/versioned_docs/version-3.13/spec-differences.md","sourceDirName":".","slug":"/spec-differences","permalink":"/rabbitmq-website/docs/3.13/spec-differences","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/spec-differences.md","tags":[],"version":"3.13","frontMatter":{"title":"Spec Differences","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"specification","title":"Compatibility and Conformance","description":"RabbitMQ core broker implements the AMQP 1.0 specification and AMQP 0-9-1 specification with a number of AMQP 0-9-1 extensions.","source":"@site/versioned_docs/version-3.13/specification.md","sourceDirName":".","slug":"/specification","permalink":"/rabbitmq-website/docs/3.13/specification","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/specification.md","tags":[],"version":"3.13","frontMatter":{"title":"Compatibility and Conformance","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"ssl/index","title":"TLS Support","description":"<!--","source":"@site/versioned_docs/version-3.13/ssl/index.md","sourceDirName":"ssl","slug":"/ssl/","permalink":"/rabbitmq-website/docs/3.13/ssl/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/ssl/index.md","tags":[],"version":"3.13","frontMatter":{"title":"TLS Support"},"sidebar":"docsSidebar","previous":{"title":"Net Tick Time","permalink":"/rabbitmq-website/docs/3.13/nettick"},"next":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/3.13/troubleshooting-networking"}},{"id":"stomp","title":"STOMP Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/stomp.md","sourceDirName":".","slug":"/stomp","permalink":"/rabbitmq-website/docs/3.13/stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/stomp.md","tags":[],"version":"3.13","frontMatter":{"title":"STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"Dynamic Shovels","permalink":"/rabbitmq-website/docs/3.13/shovel-dynamic"},"next":{"title":"Web STOMP Plugin","permalink":"/rabbitmq-website/docs/3.13/web-stomp"}},{"id":"stream","title":"Stream Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/stream.md","sourceDirName":".","slug":"/stream","permalink":"/rabbitmq-website/docs/3.13/stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/stream.md","tags":[],"version":"3.13","frontMatter":{"title":"Stream Plugin"},"sidebar":"docsSidebar","previous":{"title":"Web MQTT Plugin","permalink":"/rabbitmq-website/docs/3.13/web-mqtt"},"next":{"title":"Installing 3rd-party Plugins","permalink":"/rabbitmq-website/docs/3.13/installing-plugins"}},{"id":"stream-core-plugin-comparison","title":"Stream Core vs Stream Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/stream-core-plugin-comparison.md","sourceDirName":".","slug":"/stream-core-plugin-comparison","permalink":"/rabbitmq-website/docs/3.13/stream-core-plugin-comparison","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/stream-core-plugin-comparison.md","tags":[],"version":"3.13","frontMatter":{"title":"Stream Core vs Stream Plugin","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"streams","title":"Streams and Superstreams (Partitioned Streams)","description":"<!--","source":"@site/versioned_docs/version-3.13/streams.md","sourceDirName":".","slug":"/streams","permalink":"/rabbitmq-website/docs/3.13/streams","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/streams.md","tags":[],"version":"3.13","frontMatter":{"title":"Streams and Superstreams (Partitioned Streams)"},"sidebar":"docsSidebar","previous":{"title":"Priority Queues","permalink":"/rabbitmq-website/docs/3.13/priority"},"next":{"title":"Channels","permalink":"/rabbitmq-website/docs/3.13/channels/"}},{"id":"troubleshooting-networking","title":"Troubleshooting Network Connectivity","description":"<!--","source":"@site/versioned_docs/version-3.13/troubleshooting-networking.md","sourceDirName":".","slug":"/troubleshooting-networking","permalink":"/rabbitmq-website/docs/3.13/troubleshooting-networking","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/troubleshooting-networking.md","tags":[],"version":"3.13","frontMatter":{"title":"Troubleshooting Network Connectivity"},"sidebar":"docsSidebar","previous":{"title":"TLS Support","permalink":"/rabbitmq-website/docs/3.13/ssl/"},"next":{"title":"Troubleshooting TLS","permalink":"/rabbitmq-website/docs/3.13/troubleshooting-ssl"}},{"id":"troubleshooting-oauth2","title":"Troubleshooting OAuth 2","description":"<!--","source":"@site/versioned_docs/version-3.13/troubleshooting-oauth2.md","sourceDirName":".","slug":"/troubleshooting-oauth2","permalink":"/rabbitmq-website/docs/3.13/troubleshooting-oauth2","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/troubleshooting-oauth2.md","tags":[],"version":"3.13","frontMatter":{"title":"Troubleshooting OAuth 2","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"troubleshooting-ssl","title":"Troubleshooting TLS-enabled Connections","description":"<!--","source":"@site/versioned_docs/version-3.13/troubleshooting-ssl.md","sourceDirName":".","slug":"/troubleshooting-ssl","permalink":"/rabbitmq-website/docs/3.13/troubleshooting-ssl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/troubleshooting-ssl.md","tags":[],"version":"3.13","frontMatter":{"title":"Troubleshooting TLS-enabled Connections"},"sidebar":"docsSidebar","previous":{"title":"Troubleshooting Connectivity","permalink":"/rabbitmq-website/docs/3.13/troubleshooting-networking"},"next":{"title":"Clustering Guide","permalink":"/rabbitmq-website/docs/3.13/clustering"}},{"id":"troubleshooting/index","title":"Troubleshooting Guidance","description":"<!--","source":"@site/versioned_docs/version-3.13/troubleshooting/index.md","sourceDirName":"troubleshooting","slug":"/troubleshooting/","permalink":"/rabbitmq-website/docs/3.13/troubleshooting/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/troubleshooting/index.md","tags":[],"version":"3.13","frontMatter":{"title":"Troubleshooting Guidance"},"sidebar":"docsSidebar","previous":{"title":"Deployment Guidelines","permalink":"/rabbitmq-website/docs/3.13/production-checklist"},"next":{"title":"Monitoring","permalink":"/rabbitmq-website/docs/3.13/monitoring/"}},{"id":"ttl","title":"Time-To-Live and Expiration","description":"<!--","source":"@site/versioned_docs/version-3.13/ttl.md","sourceDirName":".","slug":"/ttl","permalink":"/rabbitmq-website/docs/3.13/ttl","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/ttl.md","tags":[],"version":"3.13","frontMatter":{"title":"Time-To-Live and Expiration"},"sidebar":"docsSidebar","previous":{"title":"Migrate Mirrored Classic Queues to Quorum Queues","permalink":"/rabbitmq-website/docs/3.13/migrate-mcq-to-qq"},"next":{"title":"Queue Length","permalink":"/rabbitmq-website/docs/3.13/maxlength/"}},{"id":"upgrade","title":"Upgrading RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-3.13/upgrade.md","sourceDirName":".","slug":"/upgrade","permalink":"/rabbitmq-website/docs/3.13/upgrade","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/upgrade.md","tags":[],"version":"3.13","frontMatter":{"title":"Upgrading RabbitMQ","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"MacOs using Homebrew","permalink":"/rabbitmq-website/docs/3.13/install-homebrew"},"next":{"title":"Feature Flags","permalink":"/rabbitmq-website/docs/3.13/feature-flags/"}},{"id":"uri-query-parameters","title":"URI Query Parameters","description":"<!--","source":"@site/versioned_docs/version-3.13/uri-query-parameters.md","sourceDirName":".","slug":"/uri-query-parameters","permalink":"/rabbitmq-website/docs/3.13/uri-query-parameters","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/uri-query-parameters.md","tags":[],"version":"3.13","frontMatter":{"title":"URI Query Parameters","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"uri-spec","title":"RabbitMQ URI Specification","description":"<!--","source":"@site/versioned_docs/version-3.13/uri-spec.md","sourceDirName":".","slug":"/uri-spec","permalink":"/rabbitmq-website/docs/3.13/uri-spec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/uri-spec.md","tags":[],"version":"3.13","frontMatter":{"title":"RabbitMQ URI Specification","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"},{"id":"use-rabbitmq","title":"How to Use RabbitMQ","description":"<!--","source":"@site/versioned_docs/version-3.13/use-rabbitmq.md","sourceDirName":".","slug":"/use-rabbitmq","permalink":"/rabbitmq-website/docs/3.13/use-rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/use-rabbitmq.md","tags":[],"version":"3.13","frontMatter":{"title":"How to Use RabbitMQ"},"sidebar":"docsSidebar","previous":{"title":"Snapshots","permalink":"/rabbitmq-website/docs/3.13/snapshots"},"next":{"title":"Publishers","permalink":"/rabbitmq-website/docs/3.13/publishers/"}},{"id":"user-limits","title":"Per-user Resource Limits","description":"<!--","source":"@site/versioned_docs/version-3.13/user-limits.md","sourceDirName":".","slug":"/user-limits","permalink":"/rabbitmq-website/docs/3.13/user-limits","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/user-limits.md","tags":[],"version":"3.13","frontMatter":{"title":"Per-user Resource Limits","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Authentication Failure Notifications","permalink":"/rabbitmq-website/docs/3.13/auth-notification"},"next":{"title":"Policies and Runtime Parameters","permalink":"/rabbitmq-website/docs/3.13/parameters"}},{"id":"validated-user-id","title":"Validated User-ID","description":"<!--","source":"@site/versioned_docs/version-3.13/validated-user-id.md","sourceDirName":".","slug":"/validated-user-id","permalink":"/rabbitmq-website/docs/3.13/validated-user-id","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/validated-user-id.md","tags":[],"version":"3.13","frontMatter":{"title":"Validated User-ID"},"sidebar":"docsSidebar","previous":{"title":"Sender-selected Distribution","permalink":"/rabbitmq-website/docs/3.13/sender-selected"},"next":{"title":"Consumers","permalink":"/rabbitmq-website/docs/3.13/consumers"}},{"id":"vhosts","title":"Virtual Hosts","description":"<!--","source":"@site/versioned_docs/version-3.13/vhosts.md","sourceDirName":".","slug":"/vhosts","permalink":"/rabbitmq-website/docs/3.13/vhosts","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/vhosts.md","tags":[],"version":"3.13","frontMatter":{"title":"Virtual Hosts"},"sidebar":"docsSidebar","previous":{"title":"Logging","permalink":"/rabbitmq-website/docs/3.13/logging"},"next":{"title":"Authentication, Authorisation, Access Control","permalink":"/rabbitmq-website/docs/3.13/access-control"}},{"id":"web-mqtt","title":"RabbitMQ Web MQTT Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/web-mqtt.md","sourceDirName":".","slug":"/web-mqtt","permalink":"/rabbitmq-website/docs/3.13/web-mqtt","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/web-mqtt.md","tags":[],"version":"3.13","frontMatter":{"title":"RabbitMQ Web MQTT Plugin"},"sidebar":"docsSidebar","previous":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/3.13/mqtt"},"next":{"title":"Stream Plugin","permalink":"/rabbitmq-website/docs/3.13/stream"}},{"id":"web-stomp","title":"RabbitMQ Web STOMP Plugin","description":"<!--","source":"@site/versioned_docs/version-3.13/web-stomp.md","sourceDirName":".","slug":"/web-stomp","permalink":"/rabbitmq-website/docs/3.13/web-stomp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/web-stomp.md","tags":[],"version":"3.13","frontMatter":{"title":"RabbitMQ Web STOMP Plugin"},"sidebar":"docsSidebar","previous":{"title":"STOMP Plugin","permalink":"/rabbitmq-website/docs/3.13/stomp"},"next":{"title":"MQTT Plugin","permalink":"/rabbitmq-website/docs/3.13/mqtt"}},{"id":"whats-new","title":"What\'s New in RabbitMQ 3.13","description":"<!--","source":"@site/versioned_docs/version-3.13/whats-new.md","sourceDirName":".","slug":"/whats-new","permalink":"/rabbitmq-website/docs/3.13/whats-new","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/whats-new.md","tags":[],"version":"3.13","frontMatter":{"title":"What\'s New in RabbitMQ 3.13"},"sidebar":"docsSidebar","previous":{"title":"Introduction","permalink":"/rabbitmq-website/docs/3.13/"},"next":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/download"}},{"id":"which-erlang","title":"Erlang Version Requirements","description":"<!--","source":"@site/versioned_docs/version-3.13/which-erlang.md","sourceDirName":".","slug":"/which-erlang","permalink":"/rabbitmq-website/docs/3.13/which-erlang","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/which-erlang.md","tags":[],"version":"3.13","frontMatter":{"title":"Erlang Version Requirements","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar","previous":{"title":"Installing RabbitMQ","permalink":"/rabbitmq-website/docs/3.13/download"},"next":{"title":"Package Signatures","permalink":"/rabbitmq-website/docs/3.13/signatures"}},{"id":"windows-configuration","title":"Windows Configuration","description":"<!--","source":"@site/versioned_docs/version-3.13/windows-configuration.md","sourceDirName":".","slug":"/windows-configuration","permalink":"/rabbitmq-website/docs/3.13/windows-configuration","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/versioned_docs/version-3.13/windows-configuration.md","tags":[],"version":"3.13","frontMatter":{"title":"Windows Configuration","displayed_sidebar":"docsSidebar"},"sidebar":"docsSidebar"}],"drafts":[],"sidebars":{"docsSidebar":[{"type":"doc","id":"index","label":"Introduction","translatable":true},{"type":"doc","id":"whats-new","label":"What\'s New","translatable":true},{"type":"link","label":"Getting Started","href":"/tutorials"},{"type":"category","label":"Install and Upgrade","link":{"type":"doc","id":"download"},"items":[{"type":"doc","id":"which-erlang","label":"Erlang Version Requirements","translatable":true},{"type":"doc","id":"signatures","label":"Package Signatures","translatable":true},{"type":"category","label":"Supported Operating Systems","link":{"type":"doc","id":"platforms"},"items":[{"type":"category","label":"Linux/Unix","items":[{"type":"doc","id":"install-debian","label":"Debian and Ubuntu","translatable":true},{"type":"doc","id":"install-rpm","label":"RedHat","translatable":true},{"type":"doc","id":"install-generic-unix","label":"Generic Unix","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"install-windows","label":"Windows","translatable":true},{"type":"category","label":"MacOS","items":[{"type":"doc","id":"install-standalone-mac","label":"MacOS using Standalone Binary Build","translatable":true},{"type":"doc","id":"install-homebrew","label":"MacOs using Homebrew","translatable":true}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Kubernetes Operator","href":"/kubernetes/operator/install-operator"},{"type":"category","label":"Upgrade","link":{"type":"doc","id":"upgrade"},"items":[{"type":"doc","id":"feature-flags/index","label":"Feature Flags","translatable":true},{"type":"doc","id":"deprecated-features/index","label":"Deprecated Features","translatable":true},{"type":"doc","id":"blue-green-upgrade","label":"Blue-Green Upgrade","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"snapshots","label":"Snapshots","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Use RabbitMQ","link":{"type":"doc","id":"use-rabbitmq"},"items":[{"type":"category","label":"Publishing Messages","link":{"type":"doc","id":"publishers/index"},"items":[{"type":"doc","id":"direct-reply-to","label":"Direct reply-to","translatable":true},{"type":"doc","id":"connection-blocked","label":"Blocked Connection Notifications","translatable":true},{"type":"doc","id":"e2e","label":"Exchange to Exchange Bindings","translatable":true},{"type":"doc","id":"ae","label":"Alternative Exchanges","translatable":true},{"type":"doc","id":"sender-selected","label":"Sender-selected Distribution","translatable":true},{"type":"doc","id":"validated-user-id","label":"Validated User ID","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Consuming Messages","link":{"type":"doc","id":"consumers"},"items":[{"type":"doc","id":"consumer-cancel","label":"Consumer Cancellation Notifications","translatable":true},{"type":"doc","id":"consumer-prefetch","label":"Consumer Prefetch","translatable":true},{"type":"doc","id":"consumer-priority","label":"Consumer Priorites","translatable":true},{"type":"doc","id":"nack","label":"Negative Acknowledgements","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Queues","link":{"type":"doc","id":"queues"},"items":[{"type":"doc","id":"quorum-queues/index","label":"Quorum Queues","translatable":true},{"type":"doc","id":"classic-queues","label":"Classic Queues","translatable":true},{"type":"doc","id":"ha/index","label":"Mirrored Classic Queues","translatable":true},{"type":"doc","id":"migrate-mcq-to-qq","label":"Migrate Mirrored Classic Queues to Quorum Queues","translatable":true},{"type":"doc","id":"ttl","label":"Time-to-Live and Expiration","translatable":true},{"type":"doc","id":"maxlength/index","label":"Queue Length","translatable":true},{"type":"doc","id":"lazy-queues","label":"Lazy Queues","translatable":true},{"type":"doc","id":"dlx","label":"Dead Lettering","translatable":true},{"type":"doc","id":"priority","label":"Priority Queues","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"streams","label":"Streams","translatable":true},{"type":"doc","id":"channels/index","label":"Channels","translatable":true},{"type":"doc","id":"reliability","label":"Reliability and Data Safety","translatable":true},{"type":"doc","id":"confirms","label":"Consumer Acknowledgements and Publisher Confirms","translatable":true},{"type":"doc","id":"distributed","label":"Network Distribution","translatable":true},{"type":"category","label":"Plugins","link":{"type":"doc","id":"plugins"},"items":[{"type":"doc","id":"management/index","label":"Management Plugin","translatable":true},{"type":"category","label":"Federation Plugin","link":{"type":"doc","id":"federation"},"items":[{"type":"doc","id":"federated-exchanges/index","label":"Federated Exchanges","translatable":true},{"type":"doc","id":"federated-queues/index","label":"Federated Queues","translatable":true},{"type":"doc","id":"federation-reference","label":"Federation Reference","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Shovel Plugin","link":{"type":"doc","id":"shovel"},"items":[{"type":"doc","id":"shovel-static","label":"Static Shovels","translatable":true},{"type":"doc","id":"shovel-dynamic","label":"Dynamic Shovels","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"stomp","label":"STOMP Plugin","translatable":true},{"type":"doc","id":"web-stomp","label":"Web STOMP Plugin","translatable":true},{"type":"doc","id":"mqtt","label":"MQTT Plugin","translatable":true},{"type":"doc","id":"web-mqtt","label":"Web MQTT Plugin","translatable":true},{"type":"doc","id":"stream","label":"Stream Plugin","translatable":true},{"type":"doc","id":"installing-plugins","label":"Installing 3rd-party Plugins","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Protocols","link":{"type":"doc","id":"protocols"},"items":[{"type":"doc","id":"connections/index","label":"Connections","translatable":true},{"type":"doc","id":"conversions","label":"Inter-Protocol Property Conversion","translatable":true},{"type":"doc","id":"heartbeats","label":"Heartbeats","translatable":true},{"type":"doc","id":"extensions","label":"Protocol Extensions","translatable":true}],"collapsed":true,"collapsible":true},{"type":"link","label":"Client Libraries","href":"/client-libraries"}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Manage RabbitMQ","link":{"type":"doc","id":"manage-rabbitmq"},"items":[{"type":"doc","id":"cli","label":"CLI","translatable":true},{"type":"doc","id":"configure","label":"Configuration","translatable":true},{"type":"doc","id":"relocate","label":"File and Directory Locations","translatable":true},{"type":"doc","id":"logging","label":"Logging","translatable":true},{"type":"doc","id":"vhosts","label":"Virtual Hosts","translatable":true},{"type":"category","label":" Authentication and Authorization","link":{"type":"doc","id":"access-control"},"items":[{"type":"doc","id":"authentication","label":"AMQP 0-9-1 Authentication Mechanisms","translatable":true},{"type":"doc","id":"passwords","label":"Credentials and Passwords","translatable":true},{"type":"doc","id":"oauth2","label":"OAuth 2","translatable":true},{"type":"doc","id":"ldap","label":"LDAP","translatable":true},{"type":"doc","id":"auth-notification","label":"Authentication Failure Notifications","translatable":true},{"type":"doc","id":"user-limits","label":"Per User Resource Limits","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"parameters","label":"Policies and Runtime Parameters","translatable":true},{"type":"doc","id":"definitions","label":"Schema Definitions","translatable":true},{"type":"category","label":"Networking","link":{"type":"doc","id":"networking"},"items":[{"type":"doc","id":"nettick","label":"Net Tick Time","translatable":true},{"type":"doc","id":"ssl/index","label":"TLS Support","translatable":true},{"type":"doc","id":"troubleshooting-networking","label":"Troubleshooting Connectivity","translatable":true},{"type":"doc","id":"troubleshooting-ssl","label":"Troubleshooting TLS","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Clustering","link":{"type":"doc","id":"clustering"},"items":[{"type":"doc","id":"cluster-formation","label":"Cluster Formation","translatable":true},{"type":"doc","id":"partitions","label":"Network Partitions","translatable":true},{"type":"doc","id":"clustering-ssl","label":"Using TLS for Inter-node Traffic","translatable":true},{"type":"doc","id":"ec2","label":"RabbitMQ on Amazon EC2","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Resource Management","items":[{"type":"doc","id":"memory-use/index","label":"Analyzing how Memory is Used","translatable":true},{"type":"category","label":"Memory and Disk Alarms","link":{"type":"doc","id":"alarms"},"items":[{"type":"doc","id":"memory","label":"Memory Alarms","translatable":true},{"type":"doc","id":"disk-alarms","label":"Disk Alarms","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"flow-control","label":"Flow Control","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"backup","label":"Backup and Restore","translatable":true},{"type":"category","label":"Tuning","items":[{"type":"doc","id":"runtime","label":"Runtime Tuning","translatable":true},{"type":"doc","id":"persistence-conf","label":"Persistence Configuration","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"production-checklist","label":"Deployment Guidelines","translatable":true},{"type":"link","label":"RabbitMQ on Kubernetes","href":"/kubernetes/operator/operator-overview"},{"type":"doc","id":"troubleshooting/index","label":"Troubleshooting RabbitMQ","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"How to Monitor RabbitMQ","link":{"type":"doc","id":"monitoring/index"},"items":[{"type":"doc","id":"prometheus/index","label":"Prometheus and Grafana","translatable":true},{"type":"doc","id":"event-exchange","label":"Event Exchange Plugin","translatable":true},{"type":"doc","id":"firehose","label":"Firehose Tracing","translatable":true}],"collapsed":true,"collapsible":true}]}}]},"tutorials":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/rabbitmq-website/tutorials","tagsPath":"/rabbitmq-website/tutorials/tags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials","editUrlLocalized":"https://github.com/rabbitmq/rabbitmq-website/tree/main/i18n/en/docusaurus-plugin-content-docs-tutorials/current","isLast":true,"routePriority":-1,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/sidebarsTutorials.js","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/tutorials","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs-tutorials/current","docs":[{"id":"amqp-concepts/index","title":"AMQP 0-9-1 Model Explained","description":"<!--","source":"@site/tutorials/amqp-concepts/index.md","sourceDirName":"amqp-concepts","slug":"/amqp-concepts/","permalink":"/rabbitmq-website/tutorials/amqp-concepts/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/amqp-concepts/index.md","tags":[],"version":"current","frontMatter":{"title":"AMQP 0-9-1 Model Explained","displayed_sidebar":"tutorialsSidebar"},"sidebar":"tutorialsSidebar"},{"id":"index","title":"RabbitMQ Tutorials","description":"<!--","source":"@site/tutorials/index.md","sourceDirName":".","slug":"/","permalink":"/rabbitmq-website/tutorials/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/index.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Tutorials"},"sidebar":"tutorialsSidebar","next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-python"}},{"id":"tutorial-five-dotnet","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-dotnet.md","sourceDirName":".","slug":"/tutorial-five-dotnet","permalink":"/rabbitmq-website/tutorials/tutorial-five-dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-dotnet.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-dotnet"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-dotnet"}},{"id":"tutorial-five-elixir","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-elixir.md","sourceDirName":".","slug":"/tutorial-five-elixir","permalink":"/rabbitmq-website/tutorials/tutorial-five-elixir","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-elixir.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-elixir"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-elixir"}},{"id":"tutorial-five-go","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-go.md","sourceDirName":".","slug":"/tutorial-five-go","permalink":"/rabbitmq-website/tutorials/tutorial-five-go","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-go.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-go"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-go"}},{"id":"tutorial-five-java","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-java.md","sourceDirName":".","slug":"/tutorial-five-java","permalink":"/rabbitmq-website/tutorials/tutorial-five-java","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-java.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-java"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-java"}},{"id":"tutorial-five-javascript","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-javascript.md","sourceDirName":".","slug":"/tutorial-five-javascript","permalink":"/rabbitmq-website/tutorials/tutorial-five-javascript","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-javascript.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-javascript"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-javascript"}},{"id":"tutorial-five-objectivec","title":"RabbitMQ tutorial - Topics","description":"Topics","source":"@site/tutorials/tutorial-five-objectivec.md","sourceDirName":".","slug":"/tutorial-five-objectivec","permalink":"/rabbitmq-website/tutorials/tutorial-five-objectivec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-objectivec.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-objectivec"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-swift"}},{"id":"tutorial-five-php","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-php.md","sourceDirName":".","slug":"/tutorial-five-php","permalink":"/rabbitmq-website/tutorials/tutorial-five-php","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-php.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-php"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-php"}},{"id":"tutorial-five-python","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-python.md","sourceDirName":".","slug":"/tutorial-five-python","permalink":"/rabbitmq-website/tutorials/tutorial-five-python","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-python.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-python"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-python"}},{"id":"tutorial-five-ruby","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-ruby.md","sourceDirName":".","slug":"/tutorial-five-ruby","permalink":"/rabbitmq-website/tutorials/tutorial-five-ruby","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-ruby.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-ruby"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-ruby"}},{"id":"tutorial-five-spring-amqp","title":"RabbitMQ tutorial - Topics","description":"<!--","source":"@site/tutorials/tutorial-five-spring-amqp.md","sourceDirName":".","slug":"/tutorial-five-spring-amqp","permalink":"/rabbitmq-website/tutorials/tutorial-five-spring-amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-spring-amqp.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-spring-amqp"},"next":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-spring-amqp"}},{"id":"tutorial-five-swift","title":"RabbitMQ tutorial - Topics","description":"Topics","source":"@site/tutorials/tutorial-five-swift.md","sourceDirName":".","slug":"/tutorial-five-swift","permalink":"/rabbitmq-website/tutorials/tutorial-five-swift","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-five-swift.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Topics"},"sidebar":"tutorialsSidebar","previous":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-swift"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-spring-amqp"}},{"id":"tutorial-four-dotnet","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-dotnet.md","sourceDirName":".","slug":"/tutorial-four-dotnet","permalink":"/rabbitmq-website/tutorials/tutorial-four-dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-dotnet.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-dotnet"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-dotnet"}},{"id":"tutorial-four-elixir","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-elixir.md","sourceDirName":".","slug":"/tutorial-four-elixir","permalink":"/rabbitmq-website/tutorials/tutorial-four-elixir","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-elixir.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-elixir"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-elixir"}},{"id":"tutorial-four-go","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-go.md","sourceDirName":".","slug":"/tutorial-four-go","permalink":"/rabbitmq-website/tutorials/tutorial-four-go","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-go.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-go"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-go"}},{"id":"tutorial-four-java","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-java.md","sourceDirName":".","slug":"/tutorial-four-java","permalink":"/rabbitmq-website/tutorials/tutorial-four-java","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-java.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-java"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-java"}},{"id":"tutorial-four-javascript","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-javascript.md","sourceDirName":".","slug":"/tutorial-four-javascript","permalink":"/rabbitmq-website/tutorials/tutorial-four-javascript","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-javascript.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-javascript"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-javascript"}},{"id":"tutorial-four-objectivec","title":"RabbitMQ tutorial - Routing","description":"Routing","source":"@site/tutorials/tutorial-four-objectivec.md","sourceDirName":".","slug":"/tutorial-four-objectivec","permalink":"/rabbitmq-website/tutorials/tutorial-four-objectivec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-objectivec.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-objectivec"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-objectivec"}},{"id":"tutorial-four-php","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-php.md","sourceDirName":".","slug":"/tutorial-four-php","permalink":"/rabbitmq-website/tutorials/tutorial-four-php","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-php.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-php"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-php"}},{"id":"tutorial-four-python","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-python.md","sourceDirName":".","slug":"/tutorial-four-python","permalink":"/rabbitmq-website/tutorials/tutorial-four-python","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-python.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-python"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-python"}},{"id":"tutorial-four-ruby","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-ruby.md","sourceDirName":".","slug":"/tutorial-four-ruby","permalink":"/rabbitmq-website/tutorials/tutorial-four-ruby","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-ruby.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-ruby"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-ruby"}},{"id":"tutorial-four-spring-amqp","title":"RabbitMQ tutorial - Routing","description":"<!--","source":"@site/tutorials/tutorial-four-spring-amqp.md","sourceDirName":".","slug":"/tutorial-four-spring-amqp","permalink":"/rabbitmq-website/tutorials/tutorial-four-spring-amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-spring-amqp.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-spring-amqp"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-spring-amqp"}},{"id":"tutorial-four-swift","title":"RabbitMQ tutorial - Routing","description":"Routing","source":"@site/tutorials/tutorial-four-swift.md","sourceDirName":".","slug":"/tutorial-four-swift","permalink":"/rabbitmq-website/tutorials/tutorial-four-swift","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-four-swift.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Routing"},"sidebar":"tutorialsSidebar","previous":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-swift"},"next":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-swift"}},{"id":"tutorial-one-dotnet","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-dotnet.md","sourceDirName":".","slug":"/tutorial-one-dotnet","permalink":"/rabbitmq-website/tutorials/tutorial-one-dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-dotnet.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Publisher Confirms","permalink":"/rabbitmq-website/tutorials/tutorial-seven-php"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-dotnet"}},{"id":"tutorial-one-dotnet-stream","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-dotnet-stream.md","sourceDirName":".","slug":"/tutorial-one-dotnet-stream","permalink":"/rabbitmq-website/tutorials/tutorial-one-dotnet-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-dotnet-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-java-stream"},"next":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-dotnet-stream"}},{"id":"tutorial-one-elixir","title":"RabbitMQ tutorial - \\"Hello world!\\"","description":"Introduction","source":"@site/tutorials/tutorial-one-elixir.md","sourceDirName":".","slug":"/tutorial-one-elixir","permalink":"/rabbitmq-website/tutorials/tutorial-one-elixir","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-elixir.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello world!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-go"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-elixir"}},{"id":"tutorial-one-go","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-go.md","sourceDirName":".","slug":"/tutorial-one-go","permalink":"/rabbitmq-website/tutorials/tutorial-one-go","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-go.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-javascript"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-go"}},{"id":"tutorial-one-go-stream","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-go-stream.md","sourceDirName":".","slug":"/tutorial-one-go-stream","permalink":"/rabbitmq-website/tutorials/tutorial-one-go-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-go-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-dotnet-stream"},"next":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-go-stream"}},{"id":"tutorial-one-java","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-java.md","sourceDirName":".","slug":"/tutorial-one-java","permalink":"/rabbitmq-website/tutorials/tutorial-one-java","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-java.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-python"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-java"}},{"id":"tutorial-one-java-stream","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-java-stream.md","sourceDirName":".","slug":"/tutorial-one-java-stream","permalink":"/rabbitmq-website/tutorials/tutorial-one-java-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-java-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-spring-amqp"},"next":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-java-stream"}},{"id":"tutorial-one-javascript","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-javascript.md","sourceDirName":".","slug":"/tutorial-one-javascript","permalink":"/rabbitmq-website/tutorials/tutorial-one-javascript","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-javascript.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Publisher Confirms","permalink":"/rabbitmq-website/tutorials/tutorial-seven-dotnet"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-javascript"}},{"id":"tutorial-one-javascript-stream","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-javascript-stream.md","sourceDirName":".","slug":"/tutorial-one-javascript-stream","permalink":"/rabbitmq-website/tutorials/tutorial-one-javascript-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-javascript-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-python-stream"},"next":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-javascript-stream"}},{"id":"tutorial-one-objectivec","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"\\"Hello World\\"","source":"@site/tutorials/tutorial-one-objectivec.md","sourceDirName":".","slug":"/tutorial-one-objectivec","permalink":"/rabbitmq-website/tutorials/tutorial-one-objectivec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-objectivec.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-elixir"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-objectivec"}},{"id":"tutorial-one-php","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-php.md","sourceDirName":".","slug":"/tutorial-one-php","permalink":"/rabbitmq-website/tutorials/tutorial-one-php","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-php.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-ruby"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-php"}},{"id":"tutorial-one-python","title":"RabbitMQ tutorial - \\"Hello world!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-python.md","sourceDirName":".","slug":"/tutorial-one-python","permalink":"/rabbitmq-website/tutorials/tutorial-one-python","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-python.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello world!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Get Started","permalink":"/rabbitmq-website/tutorials/"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-python"}},{"id":"tutorial-one-python-stream","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-python-stream.md","sourceDirName":".","slug":"/tutorial-one-python-stream","permalink":"/rabbitmq-website/tutorials/tutorial-one-python-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-python-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-rust-stream"},"next":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-python-stream"}},{"id":"tutorial-one-ruby","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-ruby.md","sourceDirName":".","slug":"/tutorial-one-ruby","permalink":"/rabbitmq-website/tutorials/tutorial-one-ruby","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-ruby.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Publisher Confirms","permalink":"/rabbitmq-website/tutorials/tutorial-seven-java"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-ruby"}},{"id":"tutorial-one-rust-stream","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-rust-stream.md","sourceDirName":".","slug":"/tutorial-one-rust-stream","permalink":"/rabbitmq-website/tutorials/tutorial-one-rust-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-rust-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-go-stream"},"next":{"title":"Offset Tracking","permalink":"/rabbitmq-website/tutorials/tutorial-two-rust-stream"}},{"id":"tutorial-one-spring-amqp","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"<!--","source":"@site/tutorials/tutorial-one-spring-amqp.md","sourceDirName":".","slug":"/tutorial-one-spring-amqp","permalink":"/rabbitmq-website/tutorials/tutorial-one-spring-amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-spring-amqp.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-swift"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-spring-amqp"}},{"id":"tutorial-one-swift","title":"RabbitMQ tutorial - \\"Hello World!\\"","description":"\\"Hello World\\"","source":"@site/tutorials/tutorial-one-swift.md","sourceDirName":".","slug":"/tutorial-one-swift","permalink":"/rabbitmq-website/tutorials/tutorial-one-swift","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-one-swift.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - \\"Hello World!\\""},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-objectivec"},"next":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-swift"}},{"id":"tutorial-seven-dotnet","title":"RabbitMQ tutorial - Reliable Publishing with Publisher Confirms","description":"<!--","source":"@site/tutorials/tutorial-seven-dotnet.md","sourceDirName":".","slug":"/tutorial-seven-dotnet","permalink":"/rabbitmq-website/tutorials/tutorial-seven-dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-seven-dotnet.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Reliable Publishing with Publisher Confirms"},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-dotnet"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-javascript"}},{"id":"tutorial-seven-java","title":"RabbitMQ tutorial - Reliable Publishing with Publisher Confirms","description":"<!--","source":"@site/tutorials/tutorial-seven-java.md","sourceDirName":".","slug":"/tutorial-seven-java","permalink":"/rabbitmq-website/tutorials/tutorial-seven-java","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-seven-java.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Reliable Publishing with Publisher Confirms"},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-java"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-ruby"}},{"id":"tutorial-seven-php","title":"RabbitMQ tutorial - Reliable Publishing with Publisher Confirms","description":"<!--","source":"@site/tutorials/tutorial-seven-php.md","sourceDirName":".","slug":"/tutorial-seven-php","permalink":"/rabbitmq-website/tutorials/tutorial-seven-php","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-seven-php.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Reliable Publishing with Publisher Confirms"},"sidebar":"tutorialsSidebar","previous":{"title":"RPC","permalink":"/rabbitmq-website/tutorials/tutorial-six-php"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-dotnet"}},{"id":"tutorial-six-dotnet","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-dotnet.md","sourceDirName":".","slug":"/tutorial-six-dotnet","permalink":"/rabbitmq-website/tutorials/tutorial-six-dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-dotnet.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-dotnet"},"next":{"title":"Publisher Confirms","permalink":"/rabbitmq-website/tutorials/tutorial-seven-dotnet"}},{"id":"tutorial-six-elixir","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-elixir.md","sourceDirName":".","slug":"/tutorial-six-elixir","permalink":"/rabbitmq-website/tutorials/tutorial-six-elixir","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-elixir.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-elixir"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-objectivec"}},{"id":"tutorial-six-go","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-go.md","sourceDirName":".","slug":"/tutorial-six-go","permalink":"/rabbitmq-website/tutorials/tutorial-six-go","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-go.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-go"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-elixir"}},{"id":"tutorial-six-java","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-java.md","sourceDirName":".","slug":"/tutorial-six-java","permalink":"/rabbitmq-website/tutorials/tutorial-six-java","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-java.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-java"},"next":{"title":"Publisher Confirms","permalink":"/rabbitmq-website/tutorials/tutorial-seven-java"}},{"id":"tutorial-six-javascript","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-javascript.md","sourceDirName":".","slug":"/tutorial-six-javascript","permalink":"/rabbitmq-website/tutorials/tutorial-six-javascript","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-javascript.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-javascript"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-go"}},{"id":"tutorial-six-php","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-php.md","sourceDirName":".","slug":"/tutorial-six-php","permalink":"/rabbitmq-website/tutorials/tutorial-six-php","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-php.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-php"},"next":{"title":"Publisher Confirms","permalink":"/rabbitmq-website/tutorials/tutorial-seven-php"}},{"id":"tutorial-six-python","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-python.md","sourceDirName":".","slug":"/tutorial-six-python","permalink":"/rabbitmq-website/tutorials/tutorial-six-python","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-python.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-python"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-java"}},{"id":"tutorial-six-ruby","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-ruby.md","sourceDirName":".","slug":"/tutorial-six-ruby","permalink":"/rabbitmq-website/tutorials/tutorial-six-ruby","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-ruby.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-ruby"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-php"}},{"id":"tutorial-six-spring-amqp","title":"RabbitMQ tutorial - Remote procedure call (RPC)","description":"<!--","source":"@site/tutorials/tutorial-six-spring-amqp.md","sourceDirName":".","slug":"/tutorial-six-spring-amqp","permalink":"/rabbitmq-website/tutorials/tutorial-six-spring-amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-six-spring-amqp.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Remote procedure call (RPC)"},"sidebar":"tutorialsSidebar","previous":{"title":"Topics","permalink":"/rabbitmq-website/tutorials/tutorial-five-spring-amqp"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-java-stream"}},{"id":"tutorial-three-dotnet","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-dotnet.md","sourceDirName":".","slug":"/tutorial-three-dotnet","permalink":"/rabbitmq-website/tutorials/tutorial-three-dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-dotnet.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-dotnet"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-dotnet"}},{"id":"tutorial-three-elixir","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-elixir.md","sourceDirName":".","slug":"/tutorial-three-elixir","permalink":"/rabbitmq-website/tutorials/tutorial-three-elixir","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-elixir.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-elixir"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-elixir"}},{"id":"tutorial-three-go","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-go.md","sourceDirName":".","slug":"/tutorial-three-go","permalink":"/rabbitmq-website/tutorials/tutorial-three-go","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-go.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-go"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-go"}},{"id":"tutorial-three-java","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-java.md","sourceDirName":".","slug":"/tutorial-three-java","permalink":"/rabbitmq-website/tutorials/tutorial-three-java","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-java.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-java"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-java"}},{"id":"tutorial-three-javascript","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-javascript.md","sourceDirName":".","slug":"/tutorial-three-javascript","permalink":"/rabbitmq-website/tutorials/tutorial-three-javascript","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-javascript.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-javascript"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-javascript"}},{"id":"tutorial-three-objectivec","title":"RabbitMQ tutorial - Publish/Subscribe","description":"Publish/Subscribe","source":"@site/tutorials/tutorial-three-objectivec.md","sourceDirName":".","slug":"/tutorial-three-objectivec","permalink":"/rabbitmq-website/tutorials/tutorial-three-objectivec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-objectivec.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-objectivec"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-objectivec"}},{"id":"tutorial-three-php","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-php.md","sourceDirName":".","slug":"/tutorial-three-php","permalink":"/rabbitmq-website/tutorials/tutorial-three-php","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-php.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-php"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-php"}},{"id":"tutorial-three-python","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-python.md","sourceDirName":".","slug":"/tutorial-three-python","permalink":"/rabbitmq-website/tutorials/tutorial-three-python","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-python.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-python"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-python"}},{"id":"tutorial-three-ruby","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-ruby.md","sourceDirName":".","slug":"/tutorial-three-ruby","permalink":"/rabbitmq-website/tutorials/tutorial-three-ruby","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-ruby.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-ruby"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-ruby"}},{"id":"tutorial-three-spring-amqp","title":"RabbitMQ tutorial - Publish/Subscribe","description":"<!--","source":"@site/tutorials/tutorial-three-spring-amqp.md","sourceDirName":".","slug":"/tutorial-three-spring-amqp","permalink":"/rabbitmq-website/tutorials/tutorial-three-spring-amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-spring-amqp.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-spring-amqp"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-spring-amqp"}},{"id":"tutorial-three-swift","title":"RabbitMQ tutorial - Publish/Subscribe","description":"Publish/Subscribe","source":"@site/tutorials/tutorial-three-swift.md","sourceDirName":".","slug":"/tutorial-three-swift","permalink":"/rabbitmq-website/tutorials/tutorial-three-swift","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-three-swift.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Publish/Subscribe"},"sidebar":"tutorialsSidebar","previous":{"title":"Work Queues","permalink":"/rabbitmq-website/tutorials/tutorial-two-swift"},"next":{"title":"Routing","permalink":"/rabbitmq-website/tutorials/tutorial-four-swift"}},{"id":"tutorial-two-dotnet","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-dotnet.md","sourceDirName":".","slug":"/tutorial-two-dotnet","permalink":"/rabbitmq-website/tutorials/tutorial-two-dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-dotnet.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-dotnet"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-dotnet"}},{"id":"tutorial-two-dotnet-stream","title":"RabbitMQ tutorial - Offset Tracking","description":"<!--","source":"@site/tutorials/tutorial-two-dotnet-stream.md","sourceDirName":".","slug":"/tutorial-two-dotnet-stream","permalink":"/rabbitmq-website/tutorials/tutorial-two-dotnet-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-dotnet-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Offset Tracking"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-dotnet-stream"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-go-stream"}},{"id":"tutorial-two-elixir","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-elixir.md","sourceDirName":".","slug":"/tutorial-two-elixir","permalink":"/rabbitmq-website/tutorials/tutorial-two-elixir","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-elixir.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-elixir"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-elixir"}},{"id":"tutorial-two-go","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-go.md","sourceDirName":".","slug":"/tutorial-two-go","permalink":"/rabbitmq-website/tutorials/tutorial-two-go","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-go.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-go"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-go"}},{"id":"tutorial-two-go-stream","title":"RabbitMQ tutorial - Offset Tracking","description":"<!--","source":"@site/tutorials/tutorial-two-go-stream.md","sourceDirName":".","slug":"/tutorial-two-go-stream","permalink":"/rabbitmq-website/tutorials/tutorial-two-go-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-go-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Offset Tracking"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-go-stream"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-rust-stream"}},{"id":"tutorial-two-java","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-java.md","sourceDirName":".","slug":"/tutorial-two-java","permalink":"/rabbitmq-website/tutorials/tutorial-two-java","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-java.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-java"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-java"}},{"id":"tutorial-two-java-stream","title":"RabbitMQ tutorial - Offset Tracking","description":"<!--","source":"@site/tutorials/tutorial-two-java-stream.md","sourceDirName":".","slug":"/tutorial-two-java-stream","permalink":"/rabbitmq-website/tutorials/tutorial-two-java-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-java-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Offset Tracking"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-java-stream"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-dotnet-stream"}},{"id":"tutorial-two-javascript","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-javascript.md","sourceDirName":".","slug":"/tutorial-two-javascript","permalink":"/rabbitmq-website/tutorials/tutorial-two-javascript","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-javascript.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-javascript"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-javascript"}},{"id":"tutorial-two-javascript-stream","title":"RabbitMQ tutorial - Offset Tracking","description":"<!--","source":"@site/tutorials/tutorial-two-javascript-stream.md","sourceDirName":".","slug":"/tutorial-two-javascript-stream","permalink":"/rabbitmq-website/tutorials/tutorial-two-javascript-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-javascript-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Offset Tracking"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-javascript-stream"}},{"id":"tutorial-two-objectivec","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-objectivec.md","sourceDirName":".","slug":"/tutorial-two-objectivec","permalink":"/rabbitmq-website/tutorials/tutorial-two-objectivec","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-objectivec.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-objectivec"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-objectivec"}},{"id":"tutorial-two-php","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-php.md","sourceDirName":".","slug":"/tutorial-two-php","permalink":"/rabbitmq-website/tutorials/tutorial-two-php","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-php.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-php"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-php"}},{"id":"tutorial-two-python","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-python.md","sourceDirName":".","slug":"/tutorial-two-python","permalink":"/rabbitmq-website/tutorials/tutorial-two-python","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-python.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-python"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-python"}},{"id":"tutorial-two-python-stream","title":"RabbitMQ tutorial - Offset Tracking","description":"<!--","source":"@site/tutorials/tutorial-two-python-stream.md","sourceDirName":".","slug":"/tutorial-two-python-stream","permalink":"/rabbitmq-website/tutorials/tutorial-two-python-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-python-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Offset Tracking"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-python-stream"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-javascript-stream"}},{"id":"tutorial-two-ruby","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-ruby.md","sourceDirName":".","slug":"/tutorial-two-ruby","permalink":"/rabbitmq-website/tutorials/tutorial-two-ruby","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-ruby.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-ruby"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-ruby"}},{"id":"tutorial-two-rust-stream","title":"RabbitMQ tutorial - Offset Tracking","description":"<!--","source":"@site/tutorials/tutorial-two-rust-stream.md","sourceDirName":".","slug":"/tutorial-two-rust-stream","permalink":"/rabbitmq-website/tutorials/tutorial-two-rust-stream","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-rust-stream.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Offset Tracking"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-rust-stream"},"next":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-python-stream"}},{"id":"tutorial-two-spring-amqp","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-spring-amqp.md","sourceDirName":".","slug":"/tutorial-two-spring-amqp","permalink":"/rabbitmq-website/tutorials/tutorial-two-spring-amqp","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-spring-amqp.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-spring-amqp"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-spring-amqp"}},{"id":"tutorial-two-swift","title":"RabbitMQ tutorial - Work Queues","description":"<!--","source":"@site/tutorials/tutorial-two-swift.md","sourceDirName":".","slug":"/tutorial-two-swift","permalink":"/rabbitmq-website/tutorials/tutorial-two-swift","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/tutorials/tutorial-two-swift.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ tutorial - Work Queues"},"sidebar":"tutorialsSidebar","previous":{"title":"Hello World","permalink":"/rabbitmq-website/tutorials/tutorial-one-swift"},"next":{"title":"Publish/Subscribe","permalink":"/rabbitmq-website/tutorials/tutorial-three-swift"}}],"drafts":[],"sidebars":{"tutorialsSidebar":[{"type":"doc","id":"index","label":"Get Started","translatable":true},{"type":"category","label":"Python","items":[{"type":"doc","id":"tutorial-one-python","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-python","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-python","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-python","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-python","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-python","label":"RPC","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Java","items":[{"type":"doc","id":"tutorial-one-java","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-java","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-java","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-java","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-java","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-java","label":"RPC","translatable":true},{"type":"doc","id":"tutorial-seven-java","label":"Publisher Confirms","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Ruby","items":[{"type":"doc","id":"tutorial-one-ruby","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-ruby","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-ruby","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-ruby","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-ruby","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-ruby","label":"RPC","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"PHP","items":[{"type":"doc","id":"tutorial-one-php","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-php","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-php","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-php","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-php","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-php","label":"RPC","translatable":true},{"type":"doc","id":"tutorial-seven-php","label":"Publisher Confirms","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":".NET","items":[{"type":"doc","id":"tutorial-one-dotnet","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-dotnet","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-dotnet","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-dotnet","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-dotnet","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-dotnet","label":"RPC","translatable":true},{"type":"doc","id":"tutorial-seven-dotnet","label":"Publisher Confirms","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"JavaScript","items":[{"type":"doc","id":"tutorial-one-javascript","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-javascript","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-javascript","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-javascript","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-javascript","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-javascript","label":"RPC","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Go","items":[{"type":"doc","id":"tutorial-one-go","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-go","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-go","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-go","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-go","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-go","label":"RPC","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Elixir","items":[{"type":"doc","id":"tutorial-one-elixir","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-elixir","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-elixir","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-elixir","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-elixir","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-elixir","label":"RPC","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Objective-C","items":[{"type":"doc","id":"tutorial-one-objectivec","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-objectivec","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-objectivec","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-objectivec","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-objectivec","label":"Topics","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Swift","items":[{"type":"doc","id":"tutorial-one-swift","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-swift","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-swift","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-swift","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-swift","label":"Topics","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Spring AMQP","items":[{"type":"doc","id":"tutorial-one-spring-amqp","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-spring-amqp","label":"Work Queues","translatable":true},{"type":"doc","id":"tutorial-three-spring-amqp","label":"Publish/Subscribe","translatable":true},{"type":"doc","id":"tutorial-four-spring-amqp","label":"Routing","translatable":true},{"type":"doc","id":"tutorial-five-spring-amqp","label":"Topics","translatable":true},{"type":"doc","id":"tutorial-six-spring-amqp","label":"RPC","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Java Stream","items":[{"type":"doc","id":"tutorial-one-java-stream","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-java-stream","label":"Offset Tracking","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":".NET Stream","items":[{"type":"doc","id":"tutorial-one-dotnet-stream","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-dotnet-stream","label":"Offset Tracking","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Go Stream","items":[{"type":"doc","id":"tutorial-one-go-stream","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-go-stream","label":"Offset Tracking","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Rust Stream","items":[{"type":"doc","id":"tutorial-one-rust-stream","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-rust-stream","label":"Offset Tracking","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Python Stream","items":[{"type":"doc","id":"tutorial-one-python-stream","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-python-stream","label":"Offset Tracking","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Node.js Stream","items":[{"type":"doc","id":"tutorial-one-javascript-stream","label":"Hello World","translatable":true},{"type":"doc","id":"tutorial-two-javascript-stream","label":"Offset Tracking","translatable":true}],"collapsed":true,"collapsible":true}]}}]},"release-information":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/rabbitmq-website/release-information","tagsPath":"/rabbitmq-website/release-information/tags","isLast":true,"routePriority":-1,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/sidebarsReleaseInfo.js","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/release-information","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs-release-information/current","docs":[{"id":"deprecated-features-list","title":"List of Deprecated Features","description":"<!--","source":"@site/release-information/deprecated-features-list.md","sourceDirName":".","slug":"/deprecated-features-list","permalink":"/rabbitmq-website/release-information/deprecated-features-list","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"List of Deprecated Features"},"sidebar":"releaseInfoSidebar","previous":{"title":"Release Information","permalink":"/rabbitmq-website/release-information/"}},{"id":"index","title":"Release Information","description":"<!--","source":"@site/release-information/index.md","sourceDirName":".","slug":"/","permalink":"/rabbitmq-website/release-information/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Release Information"},"sidebar":"releaseInfoSidebar","next":{"title":"Deprecated Features","permalink":"/rabbitmq-website/release-information/deprecated-features-list"}}],"drafts":[],"sidebars":{"releaseInfoSidebar":[{"type":"doc","id":"index","label":"Release Information","translatable":true},{"type":"doc","id":"deprecated-features-list","label":"Deprecated Features","translatable":true}]}}]},"kubernetes":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/rabbitmq-website/kubernetes","tagsPath":"/rabbitmq-website/kubernetes/tags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes","editUrlLocalized":"https://github.com/rabbitmq/rabbitmq-website/tree/main/i18n/en/docusaurus-plugin-content-docs-kubernetes/current","isLast":true,"routePriority":-1,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/sidebarsKubernetes.js","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/kubernetes","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs-kubernetes/current","docs":[{"id":"operator/configure-operator-defaults","title":"Modifying the RabbitMQ Cluster Operator Default Configuration","description":"<!--","source":"@site/kubernetes/operator/configure-operator-defaults.md","sourceDirName":"operator","slug":"/operator/configure-operator-defaults","permalink":"/rabbitmq-website/kubernetes/operator/configure-operator-defaults","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/configure-operator-defaults.md","tags":[],"version":"current","frontMatter":{"title":"Modifying the RabbitMQ Cluster Operator Default Configuration"},"sidebar":"kubernetesSidebar","previous":{"title":"Install Operator","permalink":"/rabbitmq-website/kubernetes/operator/install-operator"},"next":{"title":"kubectl Plugin","permalink":"/rabbitmq-website/kubernetes/operator/kubectl-plugin"}},{"id":"operator/debug-operator","title":"Debugging the RabbitMQ Kubernetes Operators","description":"<!--","source":"@site/kubernetes/operator/debug-operator.md","sourceDirName":"operator","slug":"/operator/debug-operator","permalink":"/rabbitmq-website/kubernetes/operator/debug-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/debug-operator.md","tags":[],"version":"current","frontMatter":{"title":"Debugging the RabbitMQ Kubernetes Operators","displayed_sidebar":"kubernetesSidebar"},"sidebar":"kubernetesSidebar"},{"id":"operator/install-operator","title":"Installing RabbitMQ Cluster Operator in a Kubernetes Cluster","description":"<!--","source":"@site/kubernetes/operator/install-operator.md","sourceDirName":"operator","slug":"/operator/install-operator","permalink":"/rabbitmq-website/kubernetes/operator/install-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/install-operator.md","tags":[],"version":"current","frontMatter":{"title":"Installing RabbitMQ Cluster Operator in a Kubernetes Cluster"},"sidebar":"kubernetesSidebar","previous":{"title":"Quickstart","permalink":"/rabbitmq-website/kubernetes/operator/quickstart-operator"},"next":{"title":"Configure defaults","permalink":"/rabbitmq-website/kubernetes/operator/configure-operator-defaults"}},{"id":"operator/install-topology-operator","title":"Installing RabbitMQ Messaging Topology Operator","description":"Overview","source":"@site/kubernetes/operator/install-topology-operator.md","sourceDirName":"operator","slug":"/operator/install-topology-operator","permalink":"/rabbitmq-website/kubernetes/operator/install-topology-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/install-topology-operator.md","tags":[],"version":"current","frontMatter":{"title":"Installing RabbitMQ Messaging Topology Operator"},"sidebar":"kubernetesSidebar","previous":{"title":"Upgrade Operator","permalink":"/rabbitmq-website/kubernetes/operator/upgrade-operator"},"next":{"title":"Using Topology Operator","permalink":"/rabbitmq-website/kubernetes/operator/using-topology-operator"}},{"id":"operator/kubectl-plugin","title":"RabbitMQ Cluster Operator Plugin for kubectl","description":"Installing the RabbitMQ Cluster Operator plugin for kubectl makes installing the RabbitMQ Cluster Kubernetes Operator into any Kubernetes instance easier because each plugin command automates many interactions with the kubernetes API and the RabbitMQ Cluster Operator. The plugin also includes several commands for common workflows with RabbitMQ clusters.","source":"@site/kubernetes/operator/kubectl-plugin.md","sourceDirName":"operator","slug":"/operator/kubectl-plugin","permalink":"/rabbitmq-website/kubernetes/operator/kubectl-plugin","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/kubectl-plugin.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Cluster Operator Plugin for kubectl"},"sidebar":"kubernetesSidebar","previous":{"title":"Configure defaults","permalink":"/rabbitmq-website/kubernetes/operator/configure-operator-defaults"},"next":{"title":"Using Operator","permalink":"/rabbitmq-website/kubernetes/operator/using-operator/"}},{"id":"operator/operator-monitoring","title":"Monitoring RabbitMQ Instances Deployed by the Kubernetes Cluster Operator","description":"Use this information to learn how to monitor RabbitMQ instances deployed by the Kubernetes Cluster Operator.","source":"@site/kubernetes/operator/operator-monitoring.md","sourceDirName":"operator","slug":"/operator/operator-monitoring","permalink":"/rabbitmq-website/kubernetes/operator/operator-monitoring","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/operator-monitoring.md","tags":[],"version":"current","frontMatter":{"title":"Monitoring RabbitMQ Instances Deployed by the Kubernetes Cluster Operator"},"sidebar":"kubernetesSidebar","previous":{"title":"Using Operator","permalink":"/rabbitmq-website/kubernetes/operator/using-operator/"},"next":{"title":"Troubleshooting","permalink":"/rabbitmq-website/kubernetes/operator/troubleshooting-operator"}},{"id":"operator/operator-overview","title":"RabbitMQ Kubernetes Operators: Cluster Operator and Messaging Topology Operator","description":"The RabbitMQ team develop and maintain two Kubernetes operators: the RabbitMQ Cluster Kubernetes Operator and the RabbitMQ Messaging Topology Operator.","source":"@site/kubernetes/operator/operator-overview.md","sourceDirName":"operator","slug":"/operator/operator-overview","permalink":"/rabbitmq-website/kubernetes/operator/operator-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/operator-overview.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Kubernetes Operators: Cluster Operator and Messaging Topology Operator"},"sidebar":"kubernetesSidebar","next":{"title":"Quickstart","permalink":"/rabbitmq-website/kubernetes/operator/quickstart-operator"}},{"id":"operator/quickstart-operator","title":"RabbitMQ Cluster Kubernetes Operator Quickstart","description":"This is the fastest way to get up and running with a RabbitMQ cluster deployed by the Cluster Operator.","source":"@site/kubernetes/operator/quickstart-operator.md","sourceDirName":"operator","slug":"/operator/quickstart-operator","permalink":"/rabbitmq-website/kubernetes/operator/quickstart-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/quickstart-operator.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Cluster Kubernetes Operator Quickstart"},"sidebar":"kubernetesSidebar","previous":{"title":"RabbitMQ Kubernetes Operators: Cluster Operator and Messaging Topology Operator","permalink":"/rabbitmq-website/kubernetes/operator/operator-overview"},"next":{"title":"Install Operator","permalink":"/rabbitmq-website/kubernetes/operator/install-operator"}},{"id":"operator/tls-topology-operator","title":"Using TLS with the Messaging Topology Kubernetes Operator","description":"If the RabbitmqClusters managed by the Messaging Topology Operator are configured to serve the HTTP API","source":"@site/kubernetes/operator/tls-topology-operator.md","sourceDirName":"operator","slug":"/operator/tls-topology-operator","permalink":"/rabbitmq-website/kubernetes/operator/tls-topology-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/tls-topology-operator.md","tags":[],"version":"current","frontMatter":{"title":"Using TLS with the Messaging Topology Kubernetes Operator"},"sidebar":"kubernetesSidebar","previous":{"title":"Using Topology Operator","permalink":"/rabbitmq-website/kubernetes/operator/using-topology-operator"},"next":{"title":"Troubleshooting","permalink":"/rabbitmq-website/kubernetes/operator/troubleshooting-topology-operator"}},{"id":"operator/troubleshooting-operator","title":"Troubleshooting the Cluster Operator","description":"Use this information to troubleshoot common problems with the RabbitMQ Cluster Kubernetes Operator.","source":"@site/kubernetes/operator/troubleshooting-operator.md","sourceDirName":"operator","slug":"/operator/troubleshooting-operator","permalink":"/rabbitmq-website/kubernetes/operator/troubleshooting-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/troubleshooting-operator.md","tags":[],"version":"current","frontMatter":{"title":"Troubleshooting the Cluster Operator"},"sidebar":"kubernetesSidebar","previous":{"title":"Monitoring","permalink":"/rabbitmq-website/kubernetes/operator/operator-monitoring"},"next":{"title":"Upgrade Operator","permalink":"/rabbitmq-website/kubernetes/operator/upgrade-operator"}},{"id":"operator/troubleshooting-topology-operator","title":"Troubleshooting Messaging Topology Kubernetes Operator","description":"This guide covers the basics of troubleshooting of RabbitMQ Messaging Topology Operator.","source":"@site/kubernetes/operator/troubleshooting-topology-operator.md","sourceDirName":"operator","slug":"/operator/troubleshooting-topology-operator","permalink":"/rabbitmq-website/kubernetes/operator/troubleshooting-topology-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/troubleshooting-topology-operator.md","tags":[],"version":"current","frontMatter":{"title":"Troubleshooting Messaging Topology Kubernetes Operator"},"sidebar":"kubernetesSidebar","previous":{"title":"TLS Support","permalink":"/rabbitmq-website/kubernetes/operator/tls-topology-operator"}},{"id":"operator/upgrade-operator","title":"Upgrading the RabbitMQ Kubernetes Operators","description":"This topic describes how to upgrade the RabbitMQ Kubernetes Operators, and their components.","source":"@site/kubernetes/operator/upgrade-operator.md","sourceDirName":"operator","slug":"/operator/upgrade-operator","permalink":"/rabbitmq-website/kubernetes/operator/upgrade-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/upgrade-operator.md","tags":[],"version":"current","frontMatter":{"title":"Upgrading the RabbitMQ Kubernetes Operators"},"sidebar":"kubernetesSidebar","previous":{"title":"Troubleshooting","permalink":"/rabbitmq-website/kubernetes/operator/troubleshooting-operator"},"next":{"title":"Install Topology Operator","permalink":"/rabbitmq-website/kubernetes/operator/install-topology-operator"}},{"id":"operator/using-on-openshift","title":"Using the RabbitMQ Kubernetes Operators on Openshift","description":"Overview","source":"@site/kubernetes/operator/using-on-openshift.md","sourceDirName":"operator","slug":"/operator/using-on-openshift","permalink":"/rabbitmq-website/kubernetes/operator/using-on-openshift","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/using-on-openshift.md","tags":[],"version":"current","frontMatter":{"title":"Using the RabbitMQ Kubernetes Operators on Openshift","displayed_sidebar":"kubernetesSidebar"},"sidebar":"kubernetesSidebar"},{"id":"operator/using-operator/index","title":"Using the RabbitMQ Cluster Kubernetes Operator","description":"How to use the RabbitMQ Cluster Kubernetes Operator","source":"@site/kubernetes/operator/using-operator/index.md","sourceDirName":"operator/using-operator","slug":"/operator/using-operator/","permalink":"/rabbitmq-website/kubernetes/operator/using-operator/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/using-operator/index.md","tags":[],"version":"current","frontMatter":{"title":"Using the RabbitMQ Cluster Kubernetes Operator"},"sidebar":"kubernetesSidebar","previous":{"title":"kubectl Plugin","permalink":"/rabbitmq-website/kubernetes/operator/kubectl-plugin"},"next":{"title":"Monitoring","permalink":"/rabbitmq-website/kubernetes/operator/operator-monitoring"}},{"id":"operator/using-topology-operator","title":"Using the RabbitMQ Messaging Topology Kubernetes Operator","description":"Use this information to learn how to deploy Custom Resource objects that will be managed by the Messaging Topology Operator.","source":"@site/kubernetes/operator/using-topology-operator.md","sourceDirName":"operator","slug":"/operator/using-topology-operator","permalink":"/rabbitmq-website/kubernetes/operator/using-topology-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/using-topology-operator.md","tags":[],"version":"current","frontMatter":{"title":"Using the RabbitMQ Messaging Topology Kubernetes Operator"},"sidebar":"kubernetesSidebar","previous":{"title":"Install Topology Operator","permalink":"/rabbitmq-website/kubernetes/operator/install-topology-operator"},"next":{"title":"TLS Support","permalink":"/rabbitmq-website/kubernetes/operator/tls-topology-operator"}},{"id":"operator/vault-topology-operator","title":"Using Vault with Messaging Topology Kubernetes Operator","description":"If the RabbitmqClusters managed by the Messaging Topology Operator are configured to have their default user credentials","source":"@site/kubernetes/operator/vault-topology-operator.md","sourceDirName":"operator","slug":"/operator/vault-topology-operator","permalink":"/rabbitmq-website/kubernetes/operator/vault-topology-operator","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/kubernetes/operator/vault-topology-operator.md","tags":[],"version":"current","frontMatter":{"title":"Using Vault with Messaging Topology Kubernetes Operator","displayed_sidebar":"kubernetesSidebar"},"sidebar":"kubernetesSidebar"}],"drafts":[],"sidebars":{"kubernetesSidebar":[{"type":"category","label":"Kubernetes Operator","link":{"type":"doc","id":"operator/operator-overview"},"items":[{"type":"doc","id":"operator/quickstart-operator","label":"Quickstart","translatable":true},{"type":"doc","id":"operator/install-operator","label":"Install Operator","translatable":true},{"type":"doc","id":"operator/configure-operator-defaults","label":"Configure defaults","translatable":true},{"type":"doc","id":"operator/kubectl-plugin","label":"kubectl Plugin","translatable":true},{"type":"doc","id":"operator/using-operator/index","label":"Using Operator","translatable":true},{"type":"doc","id":"operator/operator-monitoring","label":"Monitoring","translatable":true},{"type":"doc","id":"operator/troubleshooting-operator","label":"Troubleshooting","translatable":true},{"type":"doc","id":"operator/upgrade-operator","label":"Upgrade Operator","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Kubernetes Topology Operator","items":[{"type":"doc","id":"operator/install-topology-operator","label":"Install Topology Operator","translatable":true},{"type":"doc","id":"operator/using-topology-operator","label":"Using Topology Operator","translatable":true},{"type":"doc","id":"operator/tls-topology-operator","label":"TLS Support","translatable":true},{"type":"doc","id":"operator/troubleshooting-topology-operator","label":"Troubleshooting","translatable":true}],"collapsed":true,"collapsible":true}]}}]},"client-libraries":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/rabbitmq-website/client-libraries","tagsPath":"/rabbitmq-website/client-libraries/tags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries","editUrlLocalized":"https://github.com/rabbitmq/rabbitmq-website/tree/main/i18n/en/docusaurus-plugin-content-docs-client-libraries/current","isLast":true,"routePriority":-1,"sidebarFilePath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/sidebarsClientLibs.js","contentPath":"/mnt/d/xy2401/codeDoc/rabbitmq-website/client-libraries","contentPathLocalized":"/mnt/d/xy2401/codeDoc/rabbitmq-website/i18n/en/docusaurus-plugin-content-docs-client-libraries/current","docs":[{"id":"amqp-client-libraries","title":"AMQP 1.0 Client Libraries","description":"<!--","source":"@site/client-libraries/amqp-client-libraries.md","sourceDirName":".","slug":"/amqp-client-libraries","permalink":"/rabbitmq-website/client-libraries/amqp-client-libraries","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/amqp-client-libraries.md","tags":[],"version":"current","frontMatter":{"title":"AMQP 1.0 Client Libraries"},"sidebar":"clientLibsSidebar","previous":{"title":"Client Libraries","permalink":"/rabbitmq-website/client-libraries/"},"next":{"title":"RabbitMQ Java Client Library","permalink":"/rabbitmq-website/client-libraries/java-client"}},{"id":"build-dotnet-client","title":"Build RabbitMQ .NET Client from Source","description":"<!--","source":"@site/client-libraries/build-dotnet-client.md","sourceDirName":".","slug":"/build-dotnet-client","permalink":"/rabbitmq-website/client-libraries/build-dotnet-client","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/build-dotnet-client.md","tags":[],"version":"current","frontMatter":{"title":"Build RabbitMQ .NET Client from Source"}},{"id":"build-erlang-client","title":"RabbitMQ Erlang Client Library Build Instructions","description":"<!--","source":"@site/client-libraries/build-erlang-client.md","sourceDirName":".","slug":"/build-erlang-client","permalink":"/rabbitmq-website/client-libraries/build-erlang-client","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/build-erlang-client.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Erlang Client Library Build Instructions"}},{"id":"build-java-client","title":"Build RabbitMQ Java Client from Source","description":"<!--","source":"@site/client-libraries/build-java-client.md","sourceDirName":".","slug":"/build-java-client","permalink":"/rabbitmq-website/client-libraries/build-java-client","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/build-java-client.md","tags":[],"version":"current","frontMatter":{"title":"Build RabbitMQ Java Client from Source"}},{"id":"devtools","title":"Clients Libraries and Developer Tools","description":"<!--","source":"@site/client-libraries/devtools.md","sourceDirName":".","slug":"/devtools","permalink":"/rabbitmq-website/client-libraries/devtools","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/devtools.md","tags":[],"version":"current","frontMatter":{"title":"Clients Libraries and Developer Tools"},"sidebar":"clientLibsSidebar","previous":{"title":"API guide","permalink":"/rabbitmq-website/client-libraries/erlang-client-user-guide"}},{"id":"dotnet","title":".NET/C# RabbitMQ Client Library","description":"<!--","source":"@site/client-libraries/dotnet.md","sourceDirName":".","slug":"/dotnet","permalink":"/rabbitmq-website/client-libraries/dotnet","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/dotnet.md","tags":[],"version":"current","frontMatter":{"title":".NET/C# RabbitMQ Client Library"},"sidebar":"clientLibsSidebar","previous":{"title":"Support information","permalink":"/rabbitmq-website/client-libraries/java-versions"},"next":{"title":"API guide","permalink":"/rabbitmq-website/client-libraries/dotnet-api-guide"}},{"id":"dotnet-api-guide","title":".NET/C# Client API Guide","description":"<!--","source":"@site/client-libraries/dotnet-api-guide.md","sourceDirName":".","slug":"/dotnet-api-guide","permalink":"/rabbitmq-website/client-libraries/dotnet-api-guide","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/dotnet-api-guide.md","tags":[],"version":"current","frontMatter":{"title":".NET/C# Client API Guide"},"sidebar":"clientLibsSidebar","previous":{"title":".NET/C# RabbitMQ Client Library","permalink":"/rabbitmq-website/client-libraries/dotnet"},"next":{"title":"Erlang RabbitMQ client Library","permalink":"/rabbitmq-website/client-libraries/erlang-client"}},{"id":"erlang-client","title":"Erlang RabbitMQ client Library","description":"<!--","source":"@site/client-libraries/erlang-client.md","sourceDirName":".","slug":"/erlang-client","permalink":"/rabbitmq-website/client-libraries/erlang-client","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/erlang-client.md","tags":[],"version":"current","frontMatter":{"title":"Erlang RabbitMQ client Library"},"sidebar":"clientLibsSidebar","previous":{"title":"API guide","permalink":"/rabbitmq-website/client-libraries/dotnet-api-guide"},"next":{"title":"API guide","permalink":"/rabbitmq-website/client-libraries/erlang-client-user-guide"}},{"id":"erlang-client-user-guide","title":"Erlang RabbitMQ Client library","description":"<!--","source":"@site/client-libraries/erlang-client-user-guide.md","sourceDirName":".","slug":"/erlang-client-user-guide","permalink":"/rabbitmq-website/client-libraries/erlang-client-user-guide","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/erlang-client-user-guide.md","tags":[],"version":"current","frontMatter":{"title":"Erlang RabbitMQ Client library"},"sidebar":"clientLibsSidebar","previous":{"title":"Erlang RabbitMQ client Library","permalink":"/rabbitmq-website/client-libraries/erlang-client"},"next":{"title":"Developer tools","permalink":"/rabbitmq-website/client-libraries/devtools"}},{"id":"index","title":"Client Documentation","description":"<!--","source":"@site/client-libraries/index.md","sourceDirName":".","slug":"/","permalink":"/rabbitmq-website/client-libraries/","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/index.md","tags":[],"version":"current","frontMatter":{"title":"Client Documentation"},"sidebar":"clientLibsSidebar","next":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/client-libraries/amqp-client-libraries"}},{"id":"interoperability","title":"Interoperability","description":"Interoperation with Qpid","source":"@site/client-libraries/interoperability.md","sourceDirName":".","slug":"/interoperability","permalink":"/rabbitmq-website/client-libraries/interoperability","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/interoperability.md","tags":[],"version":"current","frontMatter":{"title":"Interoperability","displayed_sidebar":"clientLibsSidebar"},"sidebar":"clientLibsSidebar"},{"id":"java-api-guide","title":"Java Client API Guide","description":"<!--","source":"@site/client-libraries/java-api-guide.md","sourceDirName":".","slug":"/java-api-guide","permalink":"/rabbitmq-website/client-libraries/java-api-guide","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/java-api-guide.md","tags":[],"version":"current","frontMatter":{"title":"Java Client API Guide"},"sidebar":"clientLibsSidebar","previous":{"title":"RabbitMQ Java Client Library","permalink":"/rabbitmq-website/client-libraries/java-client"},"next":{"title":"JMS client","permalink":"/rabbitmq-website/client-libraries/jms-client"}},{"id":"java-client","title":"RabbitMQ Java Client Library","description":"<!--","source":"@site/client-libraries/java-client.md","sourceDirName":".","slug":"/java-client","permalink":"/rabbitmq-website/client-libraries/java-client","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/java-client.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ Java Client Library"},"sidebar":"clientLibsSidebar","previous":{"title":"AMQP 1.0","permalink":"/rabbitmq-website/client-libraries/amqp-client-libraries"},"next":{"title":"API guide","permalink":"/rabbitmq-website/client-libraries/java-api-guide"}},{"id":"java-tools","title":"Java Tools","description":"<!--","source":"@site/client-libraries/java-tools.md","sourceDirName":".","slug":"/java-tools","permalink":"/rabbitmq-website/client-libraries/java-tools","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/java-tools.md","tags":[],"version":"current","frontMatter":{"title":"Java Tools"},"sidebar":"clientLibsSidebar","previous":{"title":"JMS client","permalink":"/rabbitmq-website/client-libraries/jms-client"},"next":{"title":"Support information","permalink":"/rabbitmq-website/client-libraries/java-versions"}},{"id":"java-versions","title":"Java Libraries","description":"<!--","source":"@site/client-libraries/java-versions.md","sourceDirName":".","slug":"/java-versions","permalink":"/rabbitmq-website/client-libraries/java-versions","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/java-versions.md","tags":[],"version":"current","frontMatter":{"title":"Java Libraries"},"sidebar":"clientLibsSidebar","previous":{"title":"Tools","permalink":"/rabbitmq-website/client-libraries/java-tools"},"next":{"title":".NET/C# RabbitMQ Client Library","permalink":"/rabbitmq-website/client-libraries/dotnet"}},{"id":"jms-client","title":"RabbitMQ JMS Client","description":"<!--","source":"@site/client-libraries/jms-client.md","sourceDirName":".","slug":"/jms-client","permalink":"/rabbitmq-website/client-libraries/jms-client","draft":false,"unlisted":false,"editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/client-libraries/jms-client.md","tags":[],"version":"current","frontMatter":{"title":"RabbitMQ JMS Client"},"sidebar":"clientLibsSidebar","previous":{"title":"API guide","permalink":"/rabbitmq-website/client-libraries/java-api-guide"},"next":{"title":"Tools","permalink":"/rabbitmq-website/client-libraries/java-tools"}}],"drafts":[],"sidebars":{"clientLibsSidebar":[{"type":"doc","id":"index","label":"Client Libraries","translatable":true},{"type":"doc","id":"amqp-client-libraries","label":"AMQP 1.0","translatable":true},{"type":"category","label":"Java","link":{"type":"doc","id":"java-client"},"items":[{"type":"doc","id":"java-api-guide","label":"API guide","translatable":true},{"type":"doc","id":"jms-client","label":"JMS client","translatable":true},{"type":"doc","id":"java-tools","label":"Tools","translatable":true},{"type":"doc","id":"java-versions","label":"Support information","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":".NET/C#","link":{"type":"doc","id":"dotnet"},"items":[{"type":"doc","id":"dotnet-api-guide","label":"API guide","translatable":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Erlang","link":{"type":"doc","id":"erlang-client"},"items":[{"type":"doc","id":"erlang-client-user-guide","label":"API guide","translatable":true}],"collapsed":true,"collapsible":true},{"type":"doc","id":"devtools","label":"Developer tools","translatable":true}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[{"id":"/2025/04/24/rabbitmq-is-not-affected-by-cve-2025-32433","metadata":{"permalink":"/rabbitmq-website/blog/2025/04/24/rabbitmq-is-not-affected-by-cve-2025-32433","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-04-24-rabbitmq-is-not-affected-by-cve-2025-32433/index.md","source":"@site/blog/2025-04-24-rabbitmq-is-not-affected-by-cve-2025-32433/index.md","title":"RabbitMQ is not affected by CVE-2025-32433 (an Erlang/OTP CVE)","description":"RabbitMQ is Not Affected by CVE-2025-32433","date":"2025-04-24T00:00:00.000Z","tags":[{"inline":true,"label":"security","permalink":"/rabbitmq-website/blog/tags/security"}],"readingTime":0.68,"hasTruncateMarker":false,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"RabbitMQ is not affected by CVE-2025-32433 (an Erlang/OTP CVE)","tags":["security"],"authors":["mklishin"]},"unlisted":false,"nextItem":{"title":"AMQP 1.0 over WebSocket","permalink":"/rabbitmq-website/blog/2025/04/16/amqp-websocket"}},"content":"## RabbitMQ is Not Affected by CVE-2025-32433\\r\\n\\r\\nRabbitMQ is not affected by [CVE-2025-32433](https://github.com/erlang/otp/security/advisories/GHSA-37cp-fgq5-7wc2),\\r\\na vulnerability in the Erlang\'s SSH library. RabbitMQ does not use SSH, neither the server nor the client parts.\\r\\n\\r\\n## Team RabbitMQ\'s Erlang Packages Do Not Include SSH\\r\\n\\r\\nTeam RabbitMQ produces [a zero dependency Erlang RPM](https://github.com/rabbitmq/erlang-rpm/releases)\\r\\nthat does not include the SSH library since it is not used. Our [Debian packages](https://github.com/rabbitmq/erlang-debian-package) are split into multiple fine-grained components,\\r\\nand the RabbitMQ installation guide [skips SSH library installation](https://www.rabbitmq.com/docs/install-debian).\\r\\n\\r\\n## Patched Versions Are Available\\r\\n\\r\\nTeam RabbitMQ\'s [RPM repositories](https://rabbitmq.com/docs/install-rpm) and [Debian repositories](https://www.rabbitmq.com/docs/install-debian) were updated to include Erlang `27.3.3`, `26.2.5.11` and `25.3.2.20`.\\r\\n\\r\\nFor aarch64 (64-bit ARM) RPM packages, see [`rabbitmq/erlang-rpm` releases](https://github.com/rabbitmq/erlang-rpm/releases).\\r\\n\\r\\nFor aarch64 (64-bit ARM) Debian packages of Erlang `26.2.5.11`, see [this Launchpad repository](https://launchpad.net/~rabbitmq/+archive/ubuntu/rabbitmq-erlang).\\r\\n\\r\\nRabbitMQ [community Docker image](https://github.com/docker-library/rabbitmq) was also upgraded to Erlang `27.3.3` and `26.2.5.11` last week."},{"id":"/2025/04/16/amqp-websocket","metadata":{"permalink":"/rabbitmq-website/blog/2025/04/16/amqp-websocket","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-04-16-amqp-websocket/index.md","source":"@site/blog/2025-04-16-amqp-websocket/index.md","title":"AMQP 1.0 over WebSocket","description":"We are delighted to announce support for AMQP 1.0 over WebSocket in VMware Tanzu RabbitMQ 4.1.","date":"2025-04-16T00:00:00.000Z","tags":[{"inline":true,"label":"AMQP 1.0","permalink":"/rabbitmq-website/blog/tags/amqp-1-0"},{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"},{"inline":true,"label":"RabbitMQ 4.1","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-1"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":5.68,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"AMQP 1.0 over WebSocket","tags":["AMQP 1.0","Web Messaging","RabbitMQ 4.1","New Features"],"authors":["dansari"],"image":"./amqp-bunnies.png"},"unlisted":false,"prevItem":{"title":"RabbitMQ is not affected by CVE-2025-32433 (an Erlang/OTP CVE)","permalink":"/rabbitmq-website/blog/2025/04/24/rabbitmq-is-not-affected-by-cve-2025-32433"},"nextItem":{"title":"RabbitMQ 4.1.0 is released","permalink":"/rabbitmq-website/blog/2025/04/15/rabbitmq-4.1.0-is-released"}},"content":"We are delighted to announce support for AMQP 1.0 over WebSocket in [VMware Tanzu RabbitMQ](https://www.vmware.com/products/app-platform/tanzu-rabbitmq) 4.1.\\r\\n\\r\\nThis feature enables any browser-based application to communicate with RabbitMQ using AMQP 1.0, paving the way for a wide range of efficient browser-based business messaging scenarios.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## What is WebSocket?\\r\\n\\r\\nWebSocket, defined in [RFC 6455](https://datatracker.ietf.org/doc/html/rfc6455), is a simple protocol consisting of two parts:\\r\\n```\\r\\nClient                                   Server\\r\\n  |                                         |\\r\\n  |================ Part I =================|\\r\\n  |---- WebSocket Handshake Request ------->|\\r\\n  |       GET /some/path HTTP/1.1           |\\r\\n  |       Upgrade: websocket                |\\r\\n  |       Connection: Upgrade               |\\r\\n  |       Sec-WebSocket-Protocol: amqp      |\\r\\n  |                                         |\\r\\n  |<-- WebSocket Handshake Response --------|\\r\\n  |       HTTP/1.1 101 Switching Protocols  |\\r\\n  |       Upgrade: websocket                |\\r\\n  |       Connection: Upgrade               |\\r\\n  |       Sec-WebSocket-Protocol: amqp      |\\r\\n  |                                         |\\r\\n  |================ Part II ================|\\r\\n  |<========= WebSocket Connection ========>|\\r\\n  |        Full-duplex communication        |\\r\\n  |                                         |\\r\\n  |<---------- Binary Data [AMQP] --------->|\\r\\n  |<---------- Binary Data [AMQP] --------->|\\r\\n  |<---------- Binary Data [AMQP] --------->|\\r\\n  |                 ...                     |\\r\\n  |                                         |\\r\\n  |----------- Close Frame ---------------->|\\r\\n  |<---------- Close Frame -----------------|\\r\\n```\\r\\n\\r\\nThe first part is the handshake, consisting of an HTTP request and response.\\r\\nThe second part is the data transfer:\\r\\na single TCP connection remains open between client and server, allowing either side to push binary data to the other at any time.\\r\\n\\r\\nIn this example, the binary data consists of [AMQP frames](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp31280) because the client proposed `Sec-WebSocket-Protocol: amqp` to the server, and the server accepted it.\\r\\nThe `Sec-WebSocket-Protocol` header specifies the application-level protocol layered over WebSocket.\\r\\n\\r\\nThe protocol stack for this communication looks like this:\\r\\n```\\r\\n+-------------------+\\r\\n|      AMQP         |  Application Layer\\r\\n+-------------------+\\r\\n|    WebSocket      |\\r\\n+-------------------+\\r\\n|       TCP         |  Transport Layer\\r\\n+-------------------+\\r\\n|       IP          |  Network Layer\\r\\n+-------------------+\\r\\n|     Ethernet      |  Link Layer\\r\\n+-------------------+\\r\\n```\\r\\n\\r\\nThe WebSocket protocol itself does not dictate the application-layer protocol, allowing for flexibility.\\r\\nIt could support any protocol, including STOMP and MQTT.\\r\\n\\r\\n## Why WebSocket?\\r\\n\\r\\nWebSocket provides the following advantages:\\r\\n1. **Browser Compatibility:**\\r\\nIt allows browser-based applications to use application-layer protocols other than HTTP.\\r\\nFor security reasons, browsers restrict JavaScript from opening raw TCP connections to communicate using protocols like AMQP or MQTT.\\r\\nWebSocket protects against malicious JavaScript running in a browser, therefore enabling secure application-layer communication over the WebSocket layer.\\r\\n2. **Firewall traversal:**\\r\\nWebSocket facilitates communication in environments with restrictive firewall rules.\\r\\nFor example, while port 443 (`https`) may be allowed, port [5671](/docs/networking#ports) for `amqps` might be blocked.\\r\\nIn such cases, a secure WebSocket (`wss`) connection on port 443 can be used to communicate over AMQP.\\r\\n\\r\\nModern browsers universally support WebSocket, making it a practical choice for web-based applications.\\r\\n\\r\\n## WebSocket in RabbitMQ\\r\\n\\r\\nRabbitMQ has long supported [STOMP over WebSocket](/docs/web-stomp) and [MQTT over WebSocket](/docs/web-mqtt) through the `rabbitmq_web_stomp` and `rabbitmq_web_mqtt` plugins, respectively.\\r\\n\\r\\nVMware Tanzu RabbitMQ 4.1 introduces the new `rabbitmq_web_amqp` plugin, compliant with the [AMQP WebSocket Binding Committee Specification 01](https://docs.oasis-open.org/amqp-bindmap/amqp-wsb/v1.0/cs01/amqp-wsb-v1.0-cs01.html).\\r\\nThis plugin operates similarly to the existing WebSocket plugins, starting a listener to manage WebSocket protocol aspects.\\r\\n\\r\\nPreviously, browser-based applications connected to RabbitMQ using MQTT or STOMP over WebSocket, often due to the lack of AMQP support.\\r\\nAMQP over WebSocket brings the following benefits:\\r\\n* **Feature Richness:**\\r\\nUnlike MQTT and STOMP which are designed for simplicity, AMQP is a protocol designed for business messaging supporting more advanced features.\\r\\n* **Efficiency**:\\r\\nAMQP is binary and efficient, whereas STOMP is text-oriented.\\r\\n\\r\\nThis makes AMQP over WebSocket an excellent choice for efficient, feature-rich browser-based business messaging.\\r\\n\\r\\n## WebSocket Relay\\r\\n\\r\\nBefore this plugin, a workaround involved using a WebSocket relay.\\r\\nA relay would accept WebSocket connections from clients and open separate TCP connections to RabbitMQ.\\r\\nWhile functional, this approach introduced downsides such as:\\r\\n1. Additional latency from the extra network hop.\\r\\n2. Increased resource usage to maintain two TCP connections per client.\\r\\n3. Operational overhead for deploying and monitoring the relay.\\r\\n4. An additional potential point of failure.\\r\\n\\r\\nThe new plugin eliminates these issues by providing direct AMQP over WebSocket support.\\r\\n\\r\\n## Example\\r\\n\\r\\nRabbitMQ includes plugins `rabbitmq_web_stomp_examples` and `rabbitmq_web_mqtt_examples` with basic examples called [\\"echo\\" and \\"bunny\\"](/blog/2012/05/14/introducing-rabbitmq-web-stomp#the-usage).\\r\\nSimilarly, VMware Tanzu RabbitMQ 4.1 introduces `rabbitmq_web_amqp_examples`.\\r\\n\\r\\nThe AMQP over WebSocket \\"bunny\\" example works as follows:\\r\\n1. The `rabbitmq_web_amqp_examples` plugin creates a [stream](/docs/streams) named `amq.web_amqp_examples.bunny`.\\r\\n2. When visiting `http://localhost:15670/web-amqp-examples/bunny.html`, the plugin serves files `bunny.html`, `bunny.png`, and `rhea.js`.\\r\\nThe `bunny.html` file displays the `bunny.png`.\\r\\nAdditionally, the `bunny.html` file contains JavaScript code which creates an AMQP over WebSocket connection from the browser to RabbitMQ:\\r\\n```js\\r\\n// default AMQP over WebSocket port and path in RabbitMQ\\r\\nvar url = \\"ws://\\" + location.hostname + \\":15678/ws\\"\\r\\nvar ws = client.websocket_connect(WebSocket);\\r\\nvar connection = client.connect({\\r\\n    \\"connection_details\\":ws(url, [\\"amqp\\"]),\\r\\n    // Setting username without password causes rhea to use SASL mechanism ANONYMOUS.\\r\\n    \\"username\\": \\"ignored\\",\\r\\n});\\r\\n```\\r\\n\\r\\nThis code snippet uses the `rhea.js` file.\\r\\n[rhea](https://github.com/amqp/rhea) is an open source AMQP 1.0 TypeScript/JavaScript library.\\r\\nThis single file can be created by running the following commands in the root directory of the `rhea` repository:\\r\\n```bash\\r\\nnpm install\\r\\nmake browserify\\r\\n```\\r\\n\\r\\nNot only did the browser open an AMQP over WebSocket connection, but it also created a [session](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#section-sessions) and [links](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#section-links) to/from the pre-declared stream:\\r\\n```js\\r\\nvar address = \\"/queues/\\" + stream\\r\\nclient.on(\\"connection_open\\", function (context) {\\r\\n    sender = context.connection.open_sender(address);\\r\\n    // If we open a new brower tab, we want to see the existing drawing.\\r\\n    const filter = {\'my-filter\': amqp_types.wrap_described(\\"first\\", \\"rabbitmq:stream-offset-spec\\")};\\r\\n    context.connection.open_receiver({source:{address: address, filter: filter}});\\r\\n});\\r\\n```\\r\\n\\r\\n![AMQP over WebSocket connection](web-amqp-connection.png)\\r\\n\\r\\n3. If you open a second browser tab at the same URL, it also creates an AMQP over WebSocket connection publishing to and consuming from the same stream.\\r\\n4. When you draw on either of the two browser tabs, the other tab sees the live drawing because both tabs consume from the same stream:\\r\\n\\r\\n![Bunny Example](amqp-bunnies.png)\\r\\n\\r\\n## Clients\\r\\n\\r\\nAs of RabbitMQ 4.1, the following [RabbitMQ AMQP 1.0 client libraries](/client-libraries/amqp-client-libraries) are available:\\r\\n1. [RabbitMQ AMQP 1.0 **Java** client](https://github.com/rabbitmq/rabbitmq-amqp-java-client)\\r\\n2. [RabbitMQ AMQP 1.0 **.NET** client](https://github.com/rabbitmq/rabbitmq-amqp-dotnet-client)\\r\\n3. [RabbitMQ AMQP 1.0 **Go** client](https://github.com/rabbitmq/rabbitmq-amqp-go-client)\\r\\n4. [RabbitMQ AMQP 1.0 **Python** client](https://github.com/rabbitmq/rabbitmq-amqp-python-client)\\r\\n\\r\\nSome of these libraries are in the early stages of development.\\r\\n\\r\\nThe full benefit of the new AMQP over WebSocket plugin will be realised with a RabbitMQ AMQP 1.0 **JavaScript** library because as explained in the [Native AMQP 1.0](/blog/2024/08/05/native-amqp#rabbitmq-amqp-10-clients) blog post, these RabbitMQ specific wrappers allow to declare [exchanges](/tutorials/amqp-concepts#exchanges), [queues](/tutorials/amqp-concepts#queues), and [bindings](/tutorials/amqp-concepts#bindings).\\r\\n\\r\\nSince as of RabbitMQ 4.1 no such RabbitMQ specific JavaScript library is available yet, for the time being, existing JavaScript AMQP 1.0 clients such as [rhea](https://github.com/amqp/rhea) can be used instead.\\r\\n\\r\\n## Wrapping up\\r\\n\\r\\nVMware Tanzu RabbitMQ 4.1 enables browsers to communicate with RabbitMQ using AMQP 1.0.\\r\\n\\r\\nPlease note: the new AMQP over WebSocket plugin is a closed-source feature available exclusively in the commercial [VMware Tanzu RabbitMQ](https://www.vmware.com/products/app-platform/tanzu-rabbitmq) offering.\\r\\nIt is not part of the open source RabbitMQ distribution.\\r\\n\\r\\nWhile this blog post illustrated the feature with a playful example involving a bunny, AMQP 1.0 is an efficient protocol built for business messaging.\\r\\nThink of enterprise tools like Salesforce, Workday, or Jira - all running in the browser and benefiting from real-time messaging."},{"id":"/2025/04/15/rabbitmq-4.1.0-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2025/04/15/rabbitmq-4.1.0-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-04-15-rabbitmq-4.1.0-is-released/index.md","source":"@site/blog/2025-04-15-rabbitmq-4.1.0-is-released/index.md","title":"RabbitMQ 4.1.0 is released","description":"RabbitMQ 4.1.0 is","date":"2025-04-15T00:00:00.000Z","tags":[{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases"},{"inline":true,"label":"RabbitMQ 4.1","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-1"}],"readingTime":4.02,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"RabbitMQ 4.1.0 is released","tags":["Releases","RabbitMQ 4.1"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"AMQP 1.0 over WebSocket","permalink":"/rabbitmq-website/blog/2025/04/16/amqp-websocket"},"nextItem":{"title":"RabbitMQ 4.0.9 is released","permalink":"/rabbitmq-website/blog/2025/04/14/rabbitmq-4.0.9-is-released"}},"content":"[RabbitMQ `4.1.0`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0) is\\r\\na new minor release that includes [multiple performance improvements](/blog/2025/04/08/4.1-performance-improvements),\\r\\nand a number of features such as thew [new peer discovery mechanism for Kubernetes](/blog/2025/04/04/new-k8s-peer-discovery).\\r\\n\\r\\nSee Compatibility Notes below to learn about **breaking or potentially breaking changes** in this release.\\r\\n\\r\\n\\r\\n## Highlights\\r\\n\\r\\nSome key improvements in this release are listed below.\\r\\n\\r\\n### Quorum Queue Throughput and Parallelism Improvements\\r\\n\\r\\nQuorum queue log reads are now offloaded to channels (sessions, connections).\\r\\n\\r\\nIn practical terms this means improved consumer throughput, lower interference of publishers\\r\\non queue delivery rate to consumers, and improved CPU core utilization by each quorum queue\\r\\n(assuming there are enough cores available to the node).\\r\\n\\r\\n### Initial Support for AMQP 1.0 Filter Expressions\\r\\n\\r\\nSupport for the `properties` and `application-properties` filters of [AMQP Filter Expressions Version 1.0 Working Draft 09](https://groups.oasis-open.org/higherlogic/ws/public/document?document_id=66227).\\r\\n\\r\\nAs described in the [AMQP 1.0 Filter Expressions](https://www.rabbitmq.com/blog/2024/12/13/amqp-filter-expressions) blog post,\\r\\nthis feature enables multiple concurrent clients each consuming only a subset of messages from a stream while maintaining message order.\\r\\n\\r\\n### Feature Flags Quality of Life Improvements\\r\\n\\r\\nGraduated (mandatory) [feature flags](https://www.rabbitmq.com/docs/feature-flags) several minors ago has proven that they could use some user experience improvements.\\r\\nFor example, certain required feature flags will now be enabled on node boot when all nodes in the cluster support them.\\r\\n\\r\\nSee core server changes below as well as the [GitHub project dedicated to feature flags improvements](https://github.com/orgs/rabbitmq/projects/4/views/1)\\r\\nfor the complete list of related changes.\\r\\n\\r\\n### rabbitmqadmin v2\\r\\n\\r\\n[`rabbitmqadmin` v2](/docs/management-cli) is a major revision of the\\r\\noriginal CLI client for the RabbitMQ HTTP API.\\r\\n\\r\\nIt supports a much broader set of operations, including health checks, operations\\r\\non federation upstreams, shovels, transformations of exported definitions,\\r\\n(some) Tanzu RabbitMQ HTTP API endpoints, `--long-option` and subcommand inference in interactive mode,\\r\\nand more.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Breaking Changes and Compatibility Notes\\r\\n\\r\\n### Initial AMQP 0-9-1 Maximum Frame Size\\r\\n\\r\\nBefore a client connection can negotiate a maximum frame size (`frame_max`), it must authenticate\\r\\nsuccessfully. Before the authenticated phase, a special lower `frame_max` value\\r\\nis used.\\r\\n\\r\\nWith this release, the value was increased from the original 4096 bytes to 8192\\r\\nto accommodate larger [JWT tokens](https://www.rabbitmq.com/docs/oauth2).\\r\\n\\r\\nClients that do override `frame_max` now must use values of 8192 bytes or greater.\\r\\nWe recommend using the default server value of `131072`: do not override the `frame_max`\\r\\nkey in `rabbitmq.conf` and do not set it in the application code.\\r\\n\\r\\n[`amqplib`](https://github.com/amqp-node/amqplib/) is a popular client library that has been using\\r\\na low `frame_max` default of `4096`. Its users must [upgrade to a compatible version](https://github.com/amqp-node/amqplib/blob/main/CHANGELOG.md#v0107)\\r\\n(starting with `0.10.7`) or explicitly use a higher `frame_max`.\\r\\n\\r\\n\\r\\n### MQTT\\r\\n\\r\\n * The default MQTT [Maximum Packet Size](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901086) changed from 256 MiB to 16 MiB.\\r\\n\\r\\n   This default can be overridden by [configuring](https://www.rabbitmq.com/docs/configure#config-file) `mqtt.max_packet_size_authenticated`.\\r\\n   Note that this value must not be greater than `max_message_size` (which also defaults to 16 MiB).\\r\\n\\r\\n### etcd Peer Discovery\\r\\n\\r\\nThe following `rabbitmq.conf` settings are unsupported:\\r\\n* `cluster_formation.etcd.ssl_options.fail_if_no_peer_cert`\\r\\n* `cluster_formation.etcd.ssl_options.dh`\\r\\n* `cluster_formation.etcd.ssl_options.dhfile`\\r\\n\\r\\n## Erlang/OTP Compatibility Notes\\r\\n\\r\\nThis release [requires Erlang 26.2](/docs/which-erlang) and supports Erlang 27.x.\\r\\n\\r\\n[Provisioning Latest Erlang Releases](/docs/which-erlang#erlang-repositories) explains\\r\\nwhat package repositories and tools can be used to provision latest patch versions of Erlang 26.x and 27.x.\\r\\n\\r\\n\\r\\n## Release Artifacts\\r\\n\\r\\nArtifacts for preview releases are distributed via GitHub releases:\\r\\n\\r\\n * In main repository, [`rabbitmq/rabbitmq-server`](https://github.com/rabbitmq/rabbitmq-server/releases)\\r\\n * In the development builds repository, [`rabbitmq/server-packages`](https://github.com/rabbitmq/server-packages/releases)\\r\\n\\r\\nThere is a `4.1.0` preview version of the [community RabbitMQ image](https://github.com/docker-library/rabbitmq).\\r\\n\\r\\n\\r\\n## Upgrading to 4.1.0\\r\\n\\r\\n### Documentation guides on upgrades\\r\\n\\r\\nSee the [Upgrading guide](https://www.rabbitmq.com/docs/upgrade) for documentation on upgrades and [GitHub releases](https://github.com/rabbitmq/rabbitmq-server/releases)\\r\\nfor release notes of individual releases.\\r\\n\\r\\nThis release series supports upgrades from `4.0.x` and `3.13.x`.\\r\\n\\r\\n[Blue/Green Deployment](https://www.rabbitmq.com/docs/blue-green-upgrade)-style upgrades are avaialble for migrations\\r\\nfrom RabbitMQ `3.12.x` series.\\r\\n\\r\\n### New Required Feature Flags\\r\\n\\r\\nNone. The required feature flag set is the same as in `4.0.x`.\\r\\n\\r\\n### Mixed version cluster compatibility\\r\\n\\r\\nRabbitMQ 4.1.0 nodes can run alongside `4.0.x` nodes. `4.1.x`-specific features can only be made available when all nodes in the cluster\\r\\nupgrade to 4.1.0 or a later patch release in the new series.\\r\\n\\r\\nWhile operating in mixed version mode, some aspects of the system may not behave as expected. The list of known behavior changes will be covered in future updates.\\r\\nOnce all nodes are upgraded to 4.1.0, these irregularities will go away.\\r\\n\\r\\nMixed version clusters are a mechanism that allows rolling upgrade and are not meant to be run for extended\\r\\nperiods of time (no more than a few hours).\\r\\n\\r\\n### Recommended Post-upgrade Procedures\\r\\n\\r\\nThis version does not require any additional post-upgrade procedures\\r\\ncompared to other versions.\\r\\n\\r\\n\\r\\n## Release Artifacts\\r\\n\\r\\nRelease artifacts can be obtained on [GitHub](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.9)\\r\\nas well as [RPM](https://www.rabbitmq.com/docs/install-rpm), [Debian](https://www.rabbitmq.com/docs/install-debian) package repositories.\\r\\n\\r\\n\\r\\n## Community Support Now Only Covers the 4.1.x Series\\r\\n\\r\\nWith the release of [RabbitMQ `4.1.0`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0), this series is\\r\\nno longer covered by [community support](/release-information).\\r\\n\\r\\nFuture `4.0.x` releases will only be available to [paying customers](/contact)\\r\\nvia the Broadcom customer portal.\\r\\n\\r\\nAll non-paying users must [upgrade to `4.1.0`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0)\\r\\nin order to be covered by community support from the core team."},{"id":"/2025/04/14/rabbitmq-4.0.9-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2025/04/14/rabbitmq-4.0.9-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-04-14-rabbitmq-4.0.9-is-released/index.md","source":"@site/blog/2025-04-14-rabbitmq-4.0.9-is-released/index.md","title":"RabbitMQ 4.0.9 is released","description":"RabbitMQ 4.0.9 is","date":"2025-04-14T00:00:00.000Z","tags":[{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"}],"readingTime":0.515,"hasTruncateMarker":false,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"RabbitMQ 4.0.9 is released","tags":["Releases","RabbitMQ 4.0"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.1.0 is released","permalink":"/rabbitmq-website/blog/2025/04/15/rabbitmq-4.1.0-is-released"},"nextItem":{"title":"RabbitMQ 4.1 Performance Improvements","permalink":"/rabbitmq-website/blog/2025/04/08/4.1-performance-improvements"}},"content":"[RabbitMQ `4.0.9`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.9) is\\r\\na new patch release in the `4.0.x` series.\\r\\n\\r\\n\\r\\n## Release Artifacts\\r\\n\\r\\nRelease artifacts can be obtained on [GitHub](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.9)\\r\\nas well as [RPM](/docs/install-rpm), [Debian](/docs/install-debian) package repositories.\\r\\n\\r\\n\\r\\n## Community Support Now Only Covers the 4.1.x Series\\r\\n\\r\\nWith the release of [RabbitMQ `4.1.0`](/blog/2025/04/15/rabbitmq-4.1.0-is-released), this series is\\r\\nno longer covered by [community support](https://www.rabbitmq.com/release-information).\\r\\n\\r\\nFuture `4.0.x` releases will only be available to [paying customers](/contact)\\r\\nvia the Broadcom customer portal.\\r\\n\\r\\nAll non-paying users must [upgrade to `4.1.0`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.1.0)\\r\\nin order to be covered by community support from the core team.\\r\\n\\r\\n\\r\\n## Upgrade Guidance\\r\\n\\r\\nIf [upgrading](https://www.rabbitmq.com/docs/upgrade) from a version prior to 4.0, please consult\\r\\nthe [`4.0` release notes](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.1)."},{"id":"/2025/04/08/4.1-performance-improvements","metadata":{"permalink":"/rabbitmq-website/blog/2025/04/08/4.1-performance-improvements","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-04-08-4.1-performance-improvements/index.md","source":"@site/blog/2025-04-08-4.1-performance-improvements/index.md","title":"RabbitMQ 4.1 Performance Improvements","description":"RabbitMQ 4.1 is around the corner (update: has been released)","date":"2025-04-08T00:00:00.000Z","tags":[{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"},{"inline":true,"label":"performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"RabbitMQ 4.1","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-1"}],"readingTime":4.655,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"RabbitMQ 4.1 Performance Improvements","tags":["Announcements","performance","RabbitMQ 4.1"],"authors":["kura"],"image":"./qq-memory-usage.png"},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.0.9 is released","permalink":"/rabbitmq-website/blog/2025/04/14/rabbitmq-4.0.9-is-released"},"nextItem":{"title":"RabbitMQ 4.1: New Kubernetes Peer Discovery Mechanism","permalink":"/rabbitmq-website/blog/2025/04/04/new-k8s-peer-discovery"}},"content":"RabbitMQ 4.1 [is around the corner](/blog/2025/04/15/rabbitmq-4.1.0-is-released) (update: has been released)\\r\\nand, as usual, apart from new features, we have made some internal changes that should provide better performance.\\r\\n\\r\\nThere are at least 4 notable changes:\\r\\n\\r\\n1. Lower and more stable memory usage for quorum queues\\r\\n1. Much better performance when consuming a long quorum queue\\r\\n1. Better performance for Websocket connections\\r\\n1. Lower memory usage and/or higher throughput for TCP connections\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Quorum Queues: Lower Memory Usage\\r\\n\\r\\nQuorum queues in RabbitMQ 4.1 should use less memory in many situations. As you may be aware,\\r\\n[in the past quorum queues had a sawtooth-like memory usage pattern](/docs/4.0/quorum-queues#how-memory-wal-and-segments-files-interact).\\r\\nThey would fill up an in-memory buffer (cache) for recent [Raft](https://raft.github.io/) operations and once full,\\r\\nthe buffer was emptied and then filled up again.\\r\\n\\r\\nIn RabbitMQ 4.1, these entries are deleted much more frequently, leading to a more stable memory usage\\r\\nunder many conditions. Here\'s the memory usage of a cluster initially running 4.0 and then upgraded\\r\\nto 4.1:\\r\\n\\r\\n![Memory usage of a cluster before/after upgrading from 4.0 to 4.1](qq-memory-usage.png)\\r\\n\\r\\nThe exact details of the workload are not super important, since this difference should be visible\\r\\nfor many different workloads, but for completeness, here they are:\\r\\n\\r\\n- there were 10 quorum queues\\r\\n- all messages were 1kb in size\\r\\n- each queue received 500 messages per second from a single publisher (so 5000 messages per second total for all queues)\\r\\n- each queue had a single consumer (a vast majority of messages was consumed within 10 milliseconds since being published)\\r\\n- the queues were effectively empty, since all messages were promptly consumed\\r\\n\\r\\nIt\'s worth remembering that such a low and stable memory usage cannot be expected\\r\\nin all conditions. For example, [quorum queues keep metadata about messages in the queue in memory](https://www.rabbitmq.com/blog/2025/01/17/how-are-the-messages-stored#message-metadata)\\r\\nand therefore, if you have\\r\\nmany messages in the queues (messages are not immediately consumed), this metadata will\\r\\nconsume memory. There are also other factors and in-memory structures that will grow based on the workload.\\r\\nNevertheless, memory usage should be lower and less spiky in many common situations.\\r\\n\\r\\n## Quorum Queues: Offloading Disk Reads\\r\\n\\r\\nLet\'s consider a completely different workload - one where messages accumulate in the queues\\r\\nand then consumers need to catch up to empty the queues. Historically, quorum queues could get overwhelmed\\r\\nby an influx of consumers, especially if the messages were large and consumers requested a lot of them\\r\\n(either they had a large prefetch buffer or there were a lot of consumers, or both).\\r\\nIn this scenario, the queue could get so busy reading the older messages from disk (to dispatch them to the consumers)\\r\\nthat publishers had to wait quite a bit to have their messages accepted by the queue.\\r\\n\\r\\nIn RabbitMQ 4.1, such disk reads are offloaded to the AMQP 0.9.1 channel or AMQP 1.0 session processes\\r\\n(based on the protocol used). The queue has much less work to do and can keep serving\\r\\nthe publishers.\\r\\n\\r\\nLet\'s take a look at the differences in publishing and consumption rates between 4.0 and 4.1:\\r\\n\\r\\n![Influx of consumers, 4.0 to 4.1](qq-disk-read-offload.png)\\r\\n\\r\\nHere\'s what\'s going on in this graph:\\r\\n\\r\\n1. We have two clusters running, 4.0 (green lines) and 4.1 (yellow)\\r\\n2. Both clusters receive ~6000 messages per second, each message is 20kb\\r\\n3. Initially, there are no consumers; hence, the consumption rate is zero\\r\\n4. After some time, consumers start and try to consume messages\\r\\n5. In each environment, there are are now 10 consumers, each with a 300 message prefetch buffer\\r\\n6. 4.0 environment is overwhelmed - the publishing rate drops to just ~100 messages per second\\r\\n7. Meanwhile, 4.1 environment continues serving the publishers with no noticeable impact\\r\\n8. Additionally, the consumption rate is almost double in the 4.1 environment\\r\\n9. Once the backlog of messages is consumed, both environments can handle ~7000 messages per second in and out\\r\\n\\r\\nNot only are the publishers not throttled, but the consumers are also able to consume the messages much faster!\\r\\n\\r\\n## Better Performance of WebSocket Connections\\r\\n\\r\\nTo serve HTTP connections, RabbitMQ uses a popular Erlang HTTP server called [Cowboy](https://github.com/ninenines/cowboy)\\r\\n(developed by [Loïc Hoguin](https://github.com/essen) long before he joined the RabbitMQ team).\\r\\nRabbitMQ 4.1 upgrades Cowboy to version 2.13.0, which [significantly improves WebSocket\\r\\nperformance](https://ninenines.eu/articles/cowboy-2.13.0-performance/) for all systems that rely on Cowboy,\\r\\nincluding RabbitMQ. Upgrading to RabbitMQ 4.1 should therefore be particularly beneficial to anyone using\\r\\n[AMQP](/blog/2025/04/16/amqp-websocket), [MQTT](https://www.rabbitmq.com/docs/web-mqtt) or [STOMP](https://www.rabbitmq.com/docs/web-stomp) over WebSocket.\\r\\n\\r\\n## TCP Buffer Auto-Tuning\\r\\n\\r\\nA key improvement described in\\r\\n[Cowboy 2.13.0 release blog post](https://ninenines.eu/articles/cowboy-2.13.0-performance/) \\r\\nis the dynamic TCP buffer auto-tuning. For WebSocket connections, these improvements\\r\\nin Cowboy automatically benefit RabbitMQ users, since Cowboy handles HTTP connections to RabbitMQ.\\r\\n\\r\\nIn RabbitMQ 4.1, we incorporated the same TCP buffer auto-tuning mechanism into the AMQP listener,\\r\\nwhich is a completely separate code path and does not\\r\\nuse Cowboy (since Cowboy is an HTTP server). Thanks to this work, RabbitMQ should use less memory for AMQP\\r\\n0.9.1 and 1.0 connections, without a noticeable performance penalty. The amount of memory saved depends on\\r\\nyour current buffer size and the number of connections, but in our tests it saved a few hundred megabytes\\r\\nof memory in a system with a few thousand connections.\\r\\n\\r\\nIt\'s worth pointing out that the buffer discussed in this paragraph is a user-space buffer and should\\r\\nnot be confused with `recbuf` / `sndbuf` buffers which are kernel buffers. These can be\\r\\n[statically configured](https://www.rabbitmq.com/docs/networking#tuning-for-throughput-tcp-buffers)\\r\\nand if they are not, they are auto-tuned by the Linux kernel (the behaviour on other operating systems\\r\\nmay differ).\\r\\n\\r\\nThe value of `tcp_listen_options.buffer`, which used to control the size of the now auto-tuned buffer,\\r\\nis ignored."},{"id":"/2025/04/04/new-k8s-peer-discovery","metadata":{"permalink":"/rabbitmq-website/blog/2025/04/04/new-k8s-peer-discovery","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-04-04-new-k8s-peer-discovery/index.md","source":"@site/blog/2025-04-04-new-k8s-peer-discovery/index.md","title":"RabbitMQ 4.1: New Kubernetes Peer Discovery Mechanism","description":"RabbitMQ 4.1 includes a completely redesigned peer discovery plugin for Kubernetes.","date":"2025-04-04T00:00:00.000Z","tags":[{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"},{"inline":true,"label":"kubernetes","permalink":"/rabbitmq-website/blog/tags/kubernetes"},{"inline":true,"label":"RabbitMQ 4.1","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-1"}],"readingTime":4.605,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"RabbitMQ 4.1: New Kubernetes Peer Discovery Mechanism","tags":["Announcements","kubernetes","RabbitMQ 4.1"],"authors":["kura"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.1 Performance Improvements","permalink":"/rabbitmq-website/blog/2025/04/08/4.1-performance-improvements"},"nextItem":{"title":"RabbitMQ 4.0.7 is released","permalink":"/rabbitmq-website/blog/2025/02/26/rabbitmq-4.0.7-is-released"}},"content":"RabbitMQ 4.1 includes a completely redesigned peer discovery plugin for Kubernetes.\\r\\nNo configuration changes should be needed when upgrading to 4.1, so if you want,\\r\\nyou can just stop reading here. If you are interested in the details, read on.\\r\\nThis blog post explains the peer discovery subsystem in general\\r\\nand the changes to `rabbitmq_peer_discovery_k8s` in particular.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## What Is Peer Discovery?\\r\\n\\r\\nSay you want to have a 3-node RabbitMQ cluster - you start 3 instances of RabbitMQ but then\\r\\nwhat? You can manually tell two of them to join the third one using\\r\\n`rabbitmqctl join_cluster` command and voilà, you have a 3-node cluster.\\r\\n\\r\\nMost users would prefer this process to be automated however. That\'s where\\r\\npeer discovery comes in. There is a handful of peer discovery plugins available in RabbitMQ\\r\\nfor different situations. The simplest one is called\\r\\n[classic peer discovery](https://www.rabbitmq.com/docs/cluster-formation#peer-discovery-classic-config)\\r\\nand allows you to just put the hostnames of the nodes in the configuration file,\\r\\nso that RabbitMQ automatically initiates the cluster formation with them upon startup.\\r\\n\\r\\n:::note\\r\\nIt is a common misconception that the peer discovery is performed every time a node starts.\\r\\nThis is not the case, it is only performed when a node starts for the first time\\r\\n(when it has an empty data folder).\\r\\n:::\\r\\n\\r\\nHowever, based on how you deploy RabbitMQ, the hostnames may not be known upfront.\\r\\nEven if they are, you need a different configuration file for each cluster, which\\r\\nmay be inconvenient if you want a quick way to spin up new clusters for testing\\r\\nenvironments for example.\\r\\n\\r\\nIn such cases, you can use other peer discovery plugins, which allow nodes to register\\r\\nwith some external systems such as Consul or etcd and query these systems for a list\\r\\nof registered nodes. This way you don\'t need to know the hostnames upfront - the nodes\\r\\ndiscover each other automatically.\\r\\n\\r\\n## Kubernetes Peer Discovery before RabbitMQ 4.1\\r\\n\\r\\nBefore RabbitMQ 4.1, `rabbitmq_peer_discovery_k8s` performed the peer discovery by querying\\r\\nthe Kubernetes API server for a list of endpoints behind a service (Kubernetes automatically\\r\\nregisters pods of a given StatefulSet as endpoints). However, there were a few issues with\\r\\nthis approach:\\r\\n1. some users reported that occasionally, cluster formation would fail and the pods\\r\\nwould form multiple separate clusters; we never received enough data to diagnose this issue\\r\\nand it never occurred in our testing (we tried thousands of times...)\\r\\n2. it required permissions to query the Kubernetes API; not a big deal, but it was unnecessary\\r\\nand some security-conscious users were asking why we needed this\\r\\n3. it was a convoluted way of asking a question, we already know the answer to...\\r\\n\\r\\n## Kubernetes Peer Discovery in RabbitMQ 4.1\\r\\n\\r\\nWhen deploying RabbitMQ to Kubernetes, you should always use a StatefulSet.\\r\\nAll pods that belong to a StatefulSet are named consistently with the name of the StatefulSet,\\r\\nfollowed by a hyphen and an\\r\\n[ordinal index](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#ordinal-index).\\r\\nThe ordinal index start is configurable, but is almost always `0`, so let\'s just assume it is `0`.\\r\\nGiven that, a 3-node cluster deployed to Kubernetes will always have nodes with suffixes `-0`, `-1` and `-2`.\\r\\nThere\'s no need to query the Kubernetes API to know this!\\r\\n\\r\\nThe new plugin doesn\'t perform any Kubernetes API queries. It just assumes that a pod with `-0` suffix\\r\\nwill exist and treats it as the \\"seed\\" node. All other nodes will join the cluster by joining\\r\\nthe `-0` node. If the `-0` node is not up, other nodes will wait forever for it to come up\\r\\n(they will never form a cluster without the `-0` node). Remember that peer discovery only\\r\\nhappens when a node starts for the first time, so \\"waiting forever for node `-0`\\" only\\r\\napplies to the first time you deploy a given cluster.\\r\\n\\r\\n### Advanced Configuration\\r\\n\\r\\nFor the vast majority of users, this upgrade should be completely transparent. First of all,\\r\\nsince peer discovery is only performed when a node starts for the first time,\\r\\nif you upgrade an existing cluster, peer discovery changes won\'t affect you.\\r\\n\\r\\nSecond, the new plugin accepts, but ignores, all configuration options of the old plugin. You will\\r\\nsee some warnings in the logs about deprecated options being used, but you can safely ignore them.\\r\\n\\r\\nIf the default configuration doesn\'t work for you, there are two settings you can use:\\r\\n\\r\\n1. If you are using an ordinal start other than `0` (and seriously, why would you?!), you should\\r\\nconfigure the plugin by setting `cluster_formation.k8s.ordinal_start = N` where `N` is the ordinal start.\\r\\nWhen set, all nodes will try to join the `-N` node, rather than the `-0` node.\\r\\n\\r\\n2. Additionally, you can set `cluster_formation.k8s.seed_node = rabbit@seed-node-hostname` to\\r\\njust say what the seed node is. We don\'t expect this setting to ever be needed, but it\'s there\\r\\nif you really need it.\\r\\n\\r\\n### What If I\'m Using The Cluster Operator?\\r\\n\\r\\n[Cluster Operator](https://www.rabbitmq.com/kubernetes/operator/operator-overview#cluster-operator)\\r\\nis the recommended way of deploying RabbitMQ to Kubernetes, so if you are using it - great.\\r\\nYou should be able to continue using it with no changes. You will see the aforementioned warnings in the logs,\\r\\nbecause the Cluster Operator allows deploying different RabbitMQ versions, not just 4.1.\\r\\nTherefore, for the time being, it will continue setting values required by the old version of\\r\\n`rabbitmq_peer_discovery_k8s` in the configuration file. Such a configuration works for both 4.1 and older\\r\\nversions. At some point in the future, Cluster Operator will drop support for RabbitMQ versions older\\r\\nthan 4.1 and we\'ll remove these settings from the ConfigMap declared by the Cluster Operator."},{"id":"/2025/02/26/rabbitmq-4.0.7-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2025/02/26/rabbitmq-4.0.7-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-02-26-rabbitmq-4.0.7-is-released/index.md","source":"@site/blog/2025-02-26-rabbitmq-4.0.7-is-released/index.md","title":"RabbitMQ 4.0.7 is released","description":"RabbitMQ 4.0.7","date":"2025-02-26T00:00:00.000Z","tags":[{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"}],"readingTime":0.28,"hasTruncateMarker":false,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"RabbitMQ 4.0.7 is released","tags":["Releases","RabbitMQ 4.0"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.1: New Kubernetes Peer Discovery Mechanism","permalink":"/rabbitmq-website/blog/2025/04/04/new-k8s-peer-discovery"},"nextItem":{"title":"RabbitMQ 4.0.6 is released","permalink":"/rabbitmq-website/blog/2025/02/11/rabbitmq-4.0.6-is-released"}},"content":"## RabbitMQ 4.0.7\\r\\n\\r\\n[RabbitMQ `4.0.7`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.7) is\\r\\na new patch release in the `4.0.x` series.\\r\\n\\r\\nThis series is currently covered by [community support](https://www.rabbitmq.com/release-information).\\r\\n\\r\\n## Release Artifacts\\r\\n\\r\\nRelease artifacts can be obtained on [GitHub](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.7)\\r\\nas well as [RPM](https://www.rabbitmq.com/docs/install-rpm), [Debian](https://www.rabbitmq.com/docs/install-debian) package repositories.\\r\\n\\r\\n## Upgrade Guidance\\r\\n\\r\\nIf [upgrading](https://www.rabbitmq.com/docs/upgrade) from a version prior to 4.0, please consult\\r\\nthe [`4.0` release notes](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.1)."},{"id":"/2025/02/11/rabbitmq-4.0.6-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2025/02/11/rabbitmq-4.0.6-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-02-11-rabbitmq-4.0.6-is-released/index.md","source":"@site/blog/2025-02-11-rabbitmq-4.0.6-is-released/index.md","title":"RabbitMQ 4.0.6 is released","description":"RabbitMQ 4.0.6","date":"2025-02-11T00:00:00.000Z","tags":[{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"}],"readingTime":0.28,"hasTruncateMarker":false,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"RabbitMQ 4.0.6 is released","tags":["Releases","RabbitMQ 4.0"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.0.7 is released","permalink":"/rabbitmq-website/blog/2025/02/26/rabbitmq-4.0.7-is-released"},"nextItem":{"title":"Tanzu RabbitMQ 3.13.8 is released","permalink":"/rabbitmq-website/blog/2025/02/07/tanzu-rabbitmq-3.13.8-is-released"}},"content":"## RabbitMQ 4.0.6\\r\\n\\r\\n[RabbitMQ `4.0.6`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.6) is\\r\\na new patch release in the `4.0.x` series.\\r\\n\\r\\nThis series is currently covered by [community support](https://www.rabbitmq.com/release-information).\\r\\n\\r\\n## Release Artifacts\\r\\n\\r\\nRelease artifacts can be obtained on [GitHub](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.6)\\r\\nas well as [RPM](https://www.rabbitmq.com/docs/install-rpm), [Debian](https://www.rabbitmq.com/docs/install-debian) package repositories.\\r\\n\\r\\n## Upgrade Guidance\\r\\n\\r\\nIf [upgrading](https://www.rabbitmq.com/docs/upgrade) from a version prior to 4.0, please consult\\r\\nthe [`4.0` release notes](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.1)."},{"id":"/2025/02/07/tanzu-rabbitmq-3.13.8-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2025/02/07/tanzu-rabbitmq-3.13.8-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-02-07-tanzu-rabbitmq-3.13.8-is-released/index.md","source":"@site/blog/2025-02-07-tanzu-rabbitmq-3.13.8-is-released/index.md","title":"Tanzu RabbitMQ 3.13.8 is released","description":"Tanzu RabbitMQ 3.13.8 is a new patch release in the 3.13.x series of","date":"2025-02-07T00:00:00.000Z","tags":[{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases"},{"inline":true,"label":"Tanzu RabbitMQ","permalink":"/rabbitmq-website/blog/tags/tanzu-rabbit-mq"},{"inline":true,"label":"RabbitMQ 3.13","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13"}],"readingTime":0.555,"hasTruncateMarker":false,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Tanzu RabbitMQ 3.13.8 is released","tags":["Releases","Tanzu RabbitMQ","RabbitMQ 3.13"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.0.6 is released","permalink":"/rabbitmq-website/blog/2025/02/11/rabbitmq-4.0.6-is-released"},"nextItem":{"title":"RabbitMQ 3.13.8 is released","permalink":"/rabbitmq-website/blog/2025/02/07/rabbitmq-3.13.8-is-released"}},"content":"[Tanzu RabbitMQ `3.13.8`](https://support.broadcom.com/group/ecx/productfiles?subFamily=VMware%20Tanzu%20RabbitMQ&displayGroup=VMware%20Tanzu%20RabbitMQ&release=3.13.8&os=&servicePk=527640&language=EN) is a new patch release in the `3.13.x` series of\\r\\nthe [commercial edition of RabbitMQ](https://www.vmware.com/products/app-platform/tanzu-rabbitmq).\\r\\n\\r\\nThis edition includes additional feature such as Warm Standby Replication, intra-cluster traffic\\r\\ncompression and a FIPS-enabled Erlang runtime.\\r\\n\\r\\nTanzu RabbitMQ is available [on Kubernetes](https://techdocs.broadcom.com/us/en/vmware-tanzu/data-solutions/tanzu-rabbitmq-on-kubernetes/3-13/tanzu-rabbitmq-kubernetes/overview.html), as an [OCI image](https://techdocs.broadcom.com/us/en/vmware-tanzu/data-solutions/tanzu-rabbitmq-oci/3-13/tanzu-rabbitmq-oci-image/overview.html),\\r\\nand an [OVA image](https://techdocs.broadcom.com/us/en/vmware-tanzu/data-solutions/tanzu-rabbitmq-ova/3-13/tanzu-rabbitmq-ova-virtual-machine/overview.html).\\r\\n\\r\\nThis release is based on open source RabbitMQ `3.13.x` and includes all the latest backports\\r\\nin [open source RabbitMQ `3.13.8`](https://www.rabbitmq.com/blog/2025/02/07/rabbitmq-3.13.8-is-released).\\r\\n\\r\\n# Release Artifacts\\r\\n\\r\\nRelease artifacts for the `3.13.x` series can be obtained via the [Broadcom customer portal](https://support.broadcom.com/):\\r\\n\\r\\n * [Artifacts](https://support.broadcom.com/group/ecx/productfiles?subFamily=VMware%20Tanzu%20RabbitMQ&displayGroup=VMware%20Tanzu%20RabbitMQ&release=3.13.8&os=&servicePk=527640&language=EN)\\r\\n * Tanzu RabbitMQ [on Kubernetes](https://support.broadcom.com/group/ecx/productfiles?subFamily=VMware%20Tanzu%20RabbitMQ%20on%20Kubernetes&displayGroup=VMware%20Tanzu%20RabbitMQ%20on%20Kubernetes&release=3.13.8&os=&servicePk=527733&language=EN)\\r\\n\\r\\n\\r\\n# Upgrade Guidance\\r\\n\\r\\nIf [upgrading](https://www.rabbitmq.com/docs/upgrade) from a version prior to 3.13.9, please first consult the [open source RabbitMQ 3.13.0 release notes](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.13.0)."},{"id":"/2025/02/07/rabbitmq-3.13.8-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2025/02/07/rabbitmq-3.13.8-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-02-07-rabbitmq-3.13.8-is-released/index.md","source":"@site/blog/2025-02-07-rabbitmq-3.13.8-is-released/index.md","title":"RabbitMQ 3.13.8 is released","description":"RabbitMQ 3.13.8 is a new patch release in the 3.13.x series.","date":"2025-02-07T00:00:00.000Z","tags":[{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases"},{"inline":true,"label":"RabbitMQ 3.13","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13"}],"readingTime":0.3,"hasTruncateMarker":false,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"RabbitMQ 3.13.8 is released","tags":["Releases","RabbitMQ 3.13"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Tanzu RabbitMQ 3.13.8 is released","permalink":"/rabbitmq-website/blog/2025/02/07/tanzu-rabbitmq-3.13.8-is-released"},"nextItem":{"title":"How Are The Messages Stored? Not in Memory!","permalink":"/rabbitmq-website/blog/2025/01/17/how-are-the-messages-stored"}},"content":"RabbitMQ `3.13.8` is a new patch release in the `3.13.x` series.\\r\\nThis series is currently covered by [commercial support](https://www.rabbitmq.com/release-information) only.\\r\\n\\r\\nFor publicly available open source releases, see the [`4.0.x` series](https://www.rabbitmq.com/blog/tags/rabbit-mq-4-0).\\r\\n\\r\\n# Release Artifacts\\r\\n\\r\\nRelease artifacts for the `3.13.x` series can be obtained via the [Broadcom customer portal](https://techdocs.broadcom.com/us/en/vmware-tanzu/data-solutions/open-source-rabbitmq/3-13/opn-src-rabbitmq/site-install.html).\\r\\n\\r\\n# Upgrade Guidance\\r\\n\\r\\nIf [upgrading](https://www.rabbitmq.com/docs/upgrade) from a version prior to 3.13.9, please consult the [3.13.0 release notes](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.13.0)."},{"id":"/2025/01/17/how-are-the-messages-stored","metadata":{"permalink":"/rabbitmq-website/blog/2025/01/17/how-are-the-messages-stored","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2025-01-17-how-are-the-messages-stored/index.md","source":"@site/blog/2025-01-17-how-are-the-messages-stored/index.md","title":"How Are The Messages Stored? Not in Memory!","description":"It\'s time to retire the myth that RabbitMQ stores messages in memory. While it was true in the early days of RabbitMQ,","date":"2025-01-17T00:00:00.000Z","tags":[{"inline":true,"label":"Classic Queues","permalink":"/rabbitmq-website/blog/tags/classic-queues"},{"inline":true,"label":"Quorum Queues","permalink":"/rabbitmq-website/blog/tags/quorum-queues"},{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"}],"readingTime":13.415,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"How Are The Messages Stored? Not in Memory!","tags":["Classic Queues","Quorum Queues","Streams"],"authors":["kura"],"image":"./classic-queues.png"},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.13.8 is released","permalink":"/rabbitmq-website/blog/2025/02/07/rabbitmq-3.13.8-is-released"},"nextItem":{"title":"Security Best Practices: epmd","permalink":"/rabbitmq-website/blog/2024/12/18/epmd-public-exposure"}},"content":"It\'s time to retire the myth that RabbitMQ stores messages in memory. While it was true in the early days of RabbitMQ,\\r\\nand an option for the last 10 years, modern RabbitMQ versions almost always write messages\\r\\nto disk right away. In this blog post we review how different queue types store messages but the short answer is: not in memory!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nLet\'s start by clarifying what we mean by storing messages in memory, since it is not a precise statement.\\r\\nIf interpreted as \\"RabbitMQ uses memory to process messages\\", this phrase is certainly true.\\r\\nWhen client applications send data to RabbitMQ, that data appears in memory buffers first (that\'s true for all\\r\\nnetwork-based software). It is also true, that RabbitMQ might cache some messages in memory,\\r\\nfor example to improve performance (again, true for virtually all software that needs to serve data).\\r\\n\\r\\nHowever, I keep hearing this phrase used to express concerns about message durability - if you power off the server,\\r\\nyour messages will be lost! In this context, modern RabbitMQ versions almost never store messages in memory.\\r\\n\\r\\n:::important\\r\\nThere is no configuration in which publishing 1GB of messages to RabbitMQ with no connected consumers,\\r\\nwould lead to 1GB of memory being used to store these messages. Some subset of messages can be cached in memory,\\r\\nbut messages are stored on disk.\\r\\n:::\\r\\n\\r\\nWe\'ll go through different queue types and discuss how the messages are processed, stored and when they are confirmed\\r\\nto the publishers. Publisher confirmations are critical here - RabbitMQ doesn\'t offer guarantees for messages that\\r\\nwere not confirmed. If you haven\'t received the confirmation, you can\'t even know whether the message reached\\r\\nRabbitMQ (the network connection could have failed for example). With that in mind, let\'s go through the different queue types.\\r\\n\\r\\n## Classic Queues\\r\\n\\r\\n[Classic queues](https://www.rabbitmq.com/docs/classic-queues) is the oldest kind of queues in RabbitMQ and the main source of \\"RabbitMQ stores messages in memory\\" misconception.\\r\\nRabbitMQ was first released in 2007. Disks were significantly slower back then and therefore classic queues were designed\\r\\nto try to avoid writing messages to disk. There was a whole bunch of settings to configure when RabbitMQ should\\r\\nwrite messages to disk (a process called \\"paging\\") so it would not keep messages in memory indefinitely but indeed,\\r\\nyou could say RabbitMQ stored messages in memory back then. However, that was a long time ago.\\r\\n\\r\\nIn RabbitMQ 3.6, released in 2015, the \\"lazy mode\\" was introduced. A queue configured to be lazy, always\\r\\nstored messages on disk and didn\'t keep them in memory at all. This means that \\"RabbitMQ stores messages in memory\\"\\r\\nwas not true 10 years ago. It\'d still do this by default, but it was completely optional.\\r\\n\\r\\nLazy mode was removed in RabbitMQ in 3.12, released in 2023, but the default (and the only available) behaviour\\r\\nchanged and is similar to the lazy mode, although not exactly the same. Therefore, for over a year now, classic queues don\'t store\\r\\nmessages in memory and can\'t even be configured to do so. The myth is almost entirely false at this point.\\r\\n\\r\\nAlmost entirely? So here\'s how classic queues work right now: they accumulate incoming messages in a small in-memory buffer\\r\\nand write them to disk as a batch, as soon as the in-memory buffer is full. Since we don\'t know if more messages will come,\\r\\nthere are additional triggers that flush that buffer, including a flush after a certain number of batched messages\\r\\n(even if they are too small to use the whole buffer) and after\\r\\na certain number of operations on that batch is performed. Additionally, the queue monitors how quickly messages are consumed\\r\\nand makes decisions based on that (if there are fast consumers, more messages will be cached in memory). Finally, there\'s the\\r\\nlast-resort trigger which will flush the buffer every 200ms. So the absolute maximum of how long a message can be stored in\\r\\nmemory is 200ms but in practice, I\'ve never seen this happen. Publishers usually receive confirms within a few milliseconds\\r\\nand they are sent only after the message was written to disk.\\r\\n\\r\\n### But I See No Disk Activity When I Use a Classic Queue!\\r\\n\\r\\nIndeed, it\'s entirely possible to publish messages to classic queues and see virtually no disk writes nor disk reads.\\r\\nHow is that possible? It\'s an optimisation for a very specific, but relatively common case. As explained above, messages\\r\\ncan be briefly kept in memory but if there are active consumers that are waiting for messages (their prefetch buffer is not full),\\r\\nmessages that reach the queue are dispatched to the consumers immediately, without waiting for their batch to be written to disk.\\r\\nA message that gets acknowledged by the consumer before this message\'s batch is written to disk, will not be written to disk at all,\\r\\nbecause it simply doesn\'t need to be. Queues don\'t store acknowledged messages, so if the message is acknowledged before it is written,\\r\\nit doesn\'t get written. If it\'s acknowledged after it was written, it\'s deleted from the queue (the actual removal from disk\\r\\nwill happen later, asynchronously, but it is considered deleted immediately).\\r\\n\\r\\nIt\'s worth mentioning that classic queues have [two separate storage mechanisms](https://www.rabbitmq.com/blog/2024/01/11/3.13-release#classic-queues-storage-primer).\\r\\nMessages below 4kb (configurable through `queue_index_embed_msgs_below`) are stored in a per-queue message store and messages above that threshold\\r\\nare stored in a per-vhost message store. The optimisation mentioned above only works for messages that would be stored in the per-queue message store.\\r\\n\\r\\nSo here it is, in modern RabbitMQ versions, classic queues store messages in memory for a very short period of time (milliseconds)\\r\\nand no more than 200ms for sure. They may not write messages to disk at all, if the messages are small,\\r\\nand consumed quickly enough, but this is just a performance optimisation. I\'ll leave it up to you to decide if that\\r\\nqualifies as \\"RabbitMQ stores messages in memory\\", but I think a more accurate statement would be \\"when a message is delivered to\\r\\na classic queue, RabbitMQ writes messages to disk with a short delay\\". But yes, that means that for a brief moment, they are only in memory.\\r\\n\\r\\n### Surely, Transient Messages Are Stored in Memory?\\r\\n\\r\\nNo. Again, things were different in the past but as of RabbitMQ 4.0, the only difference between persistent and transient messages\\r\\nis when RabbitMQ sends back the publisher confirm. The messages are stored the same way as described above.\\r\\n\\r\\nFor persistent messages, the confirm is sent when either of these two events takes place:\\r\\n1. The message is written to disk\\r\\n1. The message is delivered and acknowledged by a consumer (if that happens before it\'s written to disk)\\r\\n\\r\\nFor transient messages, the confirm is sent as soon as the message reaches the queue and enters the in-memory buffer.\\r\\nSince the message is transient, the guarantees are lax: the queue received the message, the publisher can move on.\\r\\n\\r\\n### What About fsync?\\r\\n\\r\\n`fsync` is a low-level file system operation that should ensure that messages are really written to disk.\\r\\nThere are multiple layers of I/O buffers between a user-space process such as RabbitMQ and actual hardware, including operating\\r\\nsystem buffers and internal disk buffers. Performing a write without performing `fsync` doesn\'t guarantee that the data\\r\\nwill survive a sudden power loss. Unfortunately, `fsync` is a relatively slow operation, so any I/O intensive software has to\\r\\ndecide if, and when, to call it. While classic queues call `fsync` in some cases (for example, when RabbitMQ stops gracefully),\\r\\nfsync is not performed before publisher confirms are sent. Therefore, even durable messages that a publisher received a confirmation for,\\r\\ncan technically be lost if the server crashes. If you need stronger guarantees, you can use [quorum queues](/docs/quorum-queues).\\r\\n\\r\\n## Quorum Queues\\r\\n\\r\\nFrom the initial release in RabbitMQ 3.8 (released in 2019), [quorum queues](https://www.rabbitmq.com/docs/quorum-queues) always stored\\r\\nmessages on disk. While the initial versions had an additional in-memory **cache** for messages, it was removed in RabbitMQ 3.10.\\r\\n\\r\\nThe situation is therefore simple: if the publisher received a confirmation, this means the message had already been\\r\\nwritten to disk and `fsync`-ed on the quorum of nodes (in the most common scenario of a 3-node cluster, that means\\r\\nit was written and `fsync`-ed on at least 2 nodes).\\r\\n\\r\\nSince RabbitMQ doesn\'t offer any guarantees for messages that have not been confirmed to publishers, we could pretty much stop here.\\r\\nHowever, for the sake of completeness, I\'ll mention that some messages are technically in memory:\\r\\n1. The queue process has a mailbox (an Erlang/OTP concept) where requests to the queue process (such as enqueue/dequeue operations)\\r\\narrive for processing. The quorum queue process receives messages from the mailbox and processes them as a batch. When there\'s\\r\\na lot of requests, these operations may accumulate in the mailbox and therefore, assuming there are enqueue operations there, at this\\r\\npoint, some messages are only in-memory. However, this generally means RabbitMQ is at least briefly overloaded and\\r\\neither way, these operations are usually processed within a few milliseconds. Plus, these messages are not confirmed yet.\\r\\n2. Quorum queues rely on the [Raft protocol](https://raft.github.io/) and our [Raft implementations](https://github.com/rabbitmq/ra/)\\r\\nstores the most recent Raft operations in memory. For enqueue operations this means that the message is in memory as well. However,\\r\\nat this point the message is already written to disk and `fsync`-ed or it hasn\'t been confirmed yet.\\r\\n\\r\\n## Streams\\r\\n\\r\\nWith [Streams](https://www.rabbitmq.com/docs/streams), the situation is even simpler than with quorum queues: Streams never supported keeping messages in memory, period.\\r\\nThe main difference between queues and stream in general, is that streams can be read multiple times and therefore consuming\\r\\na message doesn\'t remove that message from a stream. There\'s no point in storing messages only in memory, if we need to be able\\r\\nto deliver them to consumers multiple times, potentially long after they were published.\\r\\n\\r\\nStreams do not perform `fsync`, since they were optimised for high message throughput.\\r\\n\\r\\nFor completeness, just like quorum queues (and any other Erlang process), the stream process has a mailbox where requests to the stream\\r\\nprocess arrive. There\'s therefore a moment where the messages are stored in memory for a short time. Once again though,\\r\\nthese are messages that have not been confirmed yet and they rarely stay in memory for more than a few milliseconds.\\r\\n\\r\\n## MQTT QoS 0 Queues\\r\\n\\r\\nRabbitMQ 3.12 introduced [Native MQTT support](/blog/2023/03/21/native-mqtt), and as part of that work, a new queue type was introduced,\\r\\nspecifically for MQTT QoS 0 consumers (you can\'t explicitly declare a queue of this type, you have to create an MQTT QoS 0 subscription).\\r\\nSince QoS 0 basically means best-effort but no guarantees, QoS 0 messages are not written to disk at all and are delivered directly to the\\r\\nconsumers that are present. Effectively, there\'s no queue at all (beyond the Erlang mailbox). Messages received from the publisher are\\r\\nimmediately delivered to the consumers and removed from memory.\\r\\n\\r\\nDoes this qualify as storing messages in memory? I\'d say it doesn\'t - the messages are in memory initially, simply because\\r\\nthat\'s how computers work, and are removed from memory as soon as they are delivered to the consumers. We don\'t really store\\r\\nthem in memory - we just process them and never write them to disk in this case. You can disagree and say that this is exactly\\r\\nwhat \\"storing messages in memory means\\" but even then - this only applies to MQTT QoS 0 usage and the messages will generally stay\\r\\nin memory for no more than a fraction of second.\\r\\n\\r\\n## Message Metadata\\r\\n\\r\\nSo far I focused on message bodies, since that\'s what people usually mean when talking about storing messages in memory. However,\\r\\nRabbitMQ also needs to keep track of the messages that are currently present in the queues. For example, when a queues has a defined\\r\\n[`x-max-length` limit](https://www.rabbitmq.com/docs/maxlength), RabbitMQ needs to keep track of the total size of all the messages in the queue,\\r\\nso when it delivers a message, it keeps the message size (but not the message body itself) in memory, to just subtract it quickly\\r\\nfrom the total size of the queue, once the consumer acknowledges the messages.\\r\\n\\r\\nThis kind of metadata is stored differently by different queue type, but even when stored in memory, it will consume\\r\\nsignificantly less memory than the message bodies would and doesn\'t change any guarantees about the message durability.\\r\\n\\r\\nHere\'s how we store the metadata for different queue types:\\r\\n* Classic queues\\r\\n  - for messages stored in the per-queue message store, no data is stored in memory\\r\\n  - for messages stored in the per-vhost message store, there\'s some metadata in memory\\r\\n* Quorum queues\\r\\n  - metadata is stored in memory (at least 32 bytes per message, sometimes a bit more, for example when [message TTL](https://www.rabbitmq.com/docs/ttl) is used)\\r\\n* Streams\\r\\n  - no message metadata is stored in memory\\r\\n\\r\\nThis basically means that for messages under 4KB stored in classic queues, as well as for streams, regardless of how many messages\\r\\nthere are in the queue/stream, the memory usage is constant. You will run out disk before you run out of memory (you should\\r\\nconfigure [retention](https://www.rabbitmq.com/docs/streams#retention)/[length](https://www.rabbitmq.com/docs/maxlength) limits\\r\\nto avoid running out disk, but that\'s a different story).\\r\\n\\r\\nHere\'s an illustration highlighting the difference between the two classic queue storage mechanisms. In this test,\\r\\nI first published 1 million messages of 4000 bytes each, then deleted the queue and published 1 million messages of 4100 bytes\\r\\neach. As you can see, the memory usage was stable in the first phase (small fluctuations notwithstanding), but when publishing\\r\\nlarger messages, we can see the memory usage grows as well. This is because 4100 bytes is above the threshold, so these\\r\\nmessages are stored in the per-vhost message store and the per-vhost message store keeps some metadata in memory. A million 4KB\\r\\nmessages would have taken up 4GB of memory to store, while the actual usage is still below 400MB.\\r\\n\\r\\n![Classic Queues: memory usage when publishing small and large messages](classic-queues.png)\\r\\n\\r\\n## Summary\\r\\n\\r\\nHere\'s the summary of the key points.\\r\\n\\r\\n| Type    | When are the messages written to disk?                                                       | fsync? | When is the publisher confirm sent?                                                                                                             |\\r\\n|---------|----------------------------------------------------------------------------------------------|--------|-------------------------------------------------------------------------------------------------------------------------------------------------|\\r\\n| Classic | After a few milliseconds or as soon as the in-memory buffer is full (whichever happens first)| No     | **Durable messages**: when the message is written to disk or consumed & acknowledged <br/> **Transient messages**: as soon as batched in memory |\\r\\n| Quorum  | Immediately (except for unconfirmed messages waiting in the mailbox, see above for details)  | Yes    | When written to disk and fsynced by the quorum of nodes (most commonly 2 out of 3 nodes)                                                        |\\r\\n| Streams | Immediately (except for unconfirmed messages waiting in the mailbox, see above for details)  | No     | When written to disk by the quorum of nodes (most commonly 2 out of 3 nodes)                                                                    |\\r\\n\\r\\nThe flexibility provided by RabbitMQ, with support for multiple protocols, queue types and other configurations (eg. single node,\\r\\nvs a cluster with queue replication), combined with 18 years of history and evolution, means that almost any \\"RabbitMQ does/doesn\'t do X\\"\\r\\nstatement is incorrect or at least imprecise. They should almost always be quantified with a specific version and configuration.\\r\\n\\r\\nGoing back to the title of this post, I think it\'s fair to say that \\"RabbitMQ doesn\'t store messages in memory\\" is much\\r\\ncloser to the truth, than the opposite claim, which still circulates in discussions involving RabbitMQ. Regardless of the queue type,\\r\\nthere is no configuration in which publishing, say, 1GB of messages to RabbitMQ with no connected consumers, would lead to 1GB of memory being\\r\\nused to store these messages. Most importantly, if you want high data safety guarantees, quorum queues are available and store data safely\\r\\nby default. If you publish a message to a quorum queue and receive the confirmation, it\'d take a disastrous event for RabbitMQ to lose it\\r\\n(and if you want to protect messages from disastrous events, you might be interested in the commercial\\r\\n[Warm Standby Replication plugin](https://techdocs.broadcom.com/us/en/vmware-tanzu/data-solutions/tanzu-rabbitmq-on-kubernetes/4-0/tanzu-rabbitmq-kubernetes/standby-replication.html)).\\r\\n\\r\\nIf you don\'t need such data safety guarantees, you don\'t have to pay the intrinsic overhead of data safety. Just use the right tool for the job."},{"id":"/2024/12/18/epmd-public-exposure","metadata":{"permalink":"/rabbitmq-website/blog/2024/12/18/epmd-public-exposure","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-12-18-epmd-public-exposure/index.md","source":"@site/blog/2024-12-18-epmd-public-exposure/index.md","title":"Security Best Practices: epmd","description":"Security Best Practices: epmd","date":"2024-12-18T00:00:00.000Z","tags":[{"inline":true,"label":"security","permalink":"/rabbitmq-website/blog/tags/security"}],"readingTime":0.85,"hasTruncateMarker":false,"authors":[{"name":"Erlang Ecosystem Foundation","url":"https://github.com/erlef","socials":{"github":"https://github.com/erlef"},"imageURL":"https://github.com/erlef.png","key":"eef","page":null}],"frontMatter":{"title":"Security Best Practices: epmd","tags":["security"],"authors":["eef"]},"unlisted":false,"prevItem":{"title":"How Are The Messages Stored? Not in Memory!","permalink":"/rabbitmq-website/blog/2025/01/17/how-are-the-messages-stored"},"nextItem":{"title":"RabbitMQ 4.0.5 is released","permalink":"/rabbitmq-website/blog/2024/12/16/rabbitmq-4.0.5-is-released"}},"content":"## Security Best Practices: epmd\\r\\n\\r\\nThe Erlang Port Mapper Daemon (`epmd`) is a built-in component that helps Erlang-based applications (including RabbitMQ) discover each other’s distribution ports.\\r\\nTogether with DNS for hostname resolution, `epmd` is a piece of infrastructure RabbitMQ nodes rely on for clustering, inter-node communication\\r\\nand CLI tools connectivity.\\r\\n\\r\\nWhile `epm` is very limited in scope, its exposure to the public Internet often means that Erlang distribution ports are also exposed.\\r\\nThis creates a potential security risk: if attackers find these distribution ports, they\'d be one secret value away from being able to run\\r\\nCLI commands against the node (or cluster).\\r\\n\\r\\nRecent scans have revealed over 85,000 instances of publicly accessible `epmd`, with roughly half associated with RabbitMQ servers.\\r\\n\\r\\nFortunately, all it usually takes to mitigate this risk is limiting network access to a range of ports. `epmd` and inter-node communication\\r\\ncan also be limited to local network interfaces, in particular for single node clusters used for running tests.\\r\\n\\r\\nRead the full article on the [Erlang Ecosystem Foundation blog](https://erlef.org/blog/eef/epmd-public-exposure)."},{"id":"/2024/12/16/rabbitmq-4.0.5-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2024/12/16/rabbitmq-4.0.5-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-12-16-rabbitmq-4.0.5-is-released/index.md","source":"@site/blog/2024-12-16-rabbitmq-4.0.5-is-released/index.md","title":"RabbitMQ 4.0.5 is released","description":"RabbitMQ 4.0.5","date":"2024-12-16T00:00:00.000Z","tags":[{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"}],"readingTime":0.28,"hasTruncateMarker":false,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"RabbitMQ 4.0.5 is released","tags":["Releases","RabbitMQ 4.0"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Security Best Practices: epmd","permalink":"/rabbitmq-website/blog/2024/12/18/epmd-public-exposure"},"nextItem":{"title":"AMQP 1.0 Filter Expressions","permalink":"/rabbitmq-website/blog/2024/12/13/amqp-filter-expressions"}},"content":"## RabbitMQ 4.0.5\\r\\n\\r\\n[RabbitMQ `4.0.5`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.5) is\\r\\na new patch release in the `4.0.x` series.\\r\\n\\r\\nThis series is currently covered by [community support](https://www.rabbitmq.com/release-information).\\r\\n\\r\\n## Release Artifacts\\r\\n\\r\\nRelease artifacts can be obtained on [GitHub](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.5) as well as [RPM](https://www.rabbitmq.com/docs/install-rpm), [Debian](https://www.rabbitmq.com/docs/install-debian) package repositories.\\r\\n\\r\\n## Upgrade Guidance\\r\\n\\r\\nIf [upgrading](https://www.rabbitmq.com/docs/upgrade) from a version prior to 4.0, please consult\\r\\nthe [`4.0` release notes](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.1)."},{"id":"/2024/12/13/amqp-filter-expressions","metadata":{"permalink":"/rabbitmq-website/blog/2024/12/13/amqp-filter-expressions","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-12-13-amqp-filter-expressions/index.md","source":"@site/blog/2024-12-13-amqp-filter-expressions/index.md","title":"AMQP 1.0 Filter Expressions","description":"RabbitMQ 4.1 introduces an exciting new feature: AMQP filter expressions for streams.","date":"2024-12-13T00:00:00.000Z","tags":[{"inline":true,"label":"AMQP 1.0","permalink":"/rabbitmq-website/blog/tags/amqp-1-0"},{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"RabbitMQ 4.1","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-1"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.92,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"AMQP 1.0 Filter Expressions","tags":["AMQP 1.0","Streams","RabbitMQ 4.1","New Features"],"authors":["dansari"],"image":"./stream-filtering-consumers.png"},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.0.5 is released","permalink":"/rabbitmq-website/blog/2024/12/16/rabbitmq-4.0.5-is-released"},"nextItem":{"title":"AMQP 1.0 Modified Outcome","permalink":"/rabbitmq-website/blog/2024/10/11/modified-outcome"}},"content":"RabbitMQ 4.1 [introduces](https://github.com/rabbitmq/rabbitmq-server/pull/12415) an exciting new feature: AMQP filter expressions for [streams](/docs/streams).\\r\\n\\r\\nThis feature enables RabbitMQ to support multiple concurrent clients, each consuming only a specific subset of messages while preserving message order.\\r\\nAdditionally, it minimizes network traffic between RabbitMQ and its clients by dispatching only the messages that match the clients\' interests.\\r\\n\\r\\nIn this blog post, we’ll explore what AMQP filter expressions are and walk through a simple Java example of how to use them.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Specification\\r\\n\\r\\nAs outlined in the [Native AMQP 1.0](/blog/2024/08/05/native-amqp) blog post, one of AMQP 1.0\'s strengths is its extensibility, supported by numerous extension specifications.\\r\\nRabbitMQ 4.1 takes advantage of the extension specification [AMQP Filter Expressions Version 1.0 Working Draft 09](https://groups.oasis-open.org/higherlogic/ws/public/document?document_id=66227).\\r\\n\\r\\nThis specification defines AMQP type definitions for message filter expressions.\\r\\nFilter expressions are predicates evaluated against a message, returning either `true` or `false`.\\r\\nIf a predicate evaluates to `true`, the broker dispatches the message to the consumer.\\r\\n\\r\\nRabbitMQ 4.1 implements a subset of this specification, including:\\r\\n* **§ 4.2.4 properties filter**: Applies to the immutable [properties](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-properties) section of the message.\\r\\n* **§ 4.2.5 application-properties filter**: Applies to the immutable [application-properties](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-application-properties) section of the message.\\r\\n\\r\\n## Example\\r\\n\\r\\nImagine each message carries metadata specifying a particular color.\\r\\nDifferent consumers can subscribe to the same stream, filtering messages to receive only those matching the color they are interested in.\\r\\n\\r\\n![Consumers filtering messages from a stream](./stream-filtering-consumers.svg)\\r\\n\\r\\nThe first consumer receives all green messages.\\r\\nThe second consumer receives all purple messages.\\r\\nThe third consumer receives all blue messages.\\r\\n\\r\\n<details>\\r\\n<summary>Try this example.</summary>\\r\\n\\r\\nYou can try this example using the [amqp-filter-expressions](https://github.com/ansd/amqp-filter-expressions/tree/v0.1.0) sample app along with the [RabbitMQ AMQP 1.0 Java Client](https://github.com/rabbitmq/rabbitmq-amqp-java-client) by following these steps:\\r\\n1. Start the RabbitMQ server with the following command:\\r\\n```bash\\r\\ndocker run -it --rm --name rabbitmq \\\\\\r\\n    -p 5672:5672 -p 15672:15672 \\\\\\r\\n    rabbitmq:4.1-rc-management\\r\\n```\\r\\n2. Navigate to the root directory of the sample app and start the client:\\r\\n```bash\\r\\nmvn clean compile exec:java\\r\\n```\\r\\n\\r\\nUpon running the sample app, you should see the following output on the console:\\r\\n```\\r\\npublisher sent message 0 with color green\\r\\npublisher sent message 1 with color blue\\r\\npublisher sent message 2 with color purple\\r\\npublisher sent message 3 with color purple\\r\\npublisher sent message 4 with color green\\r\\npublisher sent message 5 with color green\\r\\nconsumer (filter green) received message 0\\r\\nconsumer (filter green) received message 4\\r\\nconsumer (filter green) received message 5\\r\\nconsumer (filter purple) received message 2\\r\\nconsumer (filter purple) received message 3\\r\\nconsumer (filter blue) received message 1\\r\\nconsumer (filter &s:e) received message 1\\r\\nconsumer (filter &s:e) received message 2\\r\\nconsumer (filter &s:e) received message 3\\r\\n```\\r\\n\\r\\nIn this example, the publisher sends six messages, assigning each a specific color in the application-properties section.\\r\\n\\r\\n* The first consumer applies an application-properties filter for `color: green`, receiving all green messages in the order they were published to the stream.\\r\\n* Similarly, the second consumer filters for `color: purple`, receiving all purple messages, and the third consumer filters for `color: blue`, receiving all blue messages.\\r\\n\\r\\nAdditionally, this sample app contains a fourth consumer (not shown in the picture above) with a filter that matches messages whose color ends with the letter `e`.\\r\\n(As per the specification, the filter expression `&s:suffix` matches values ending with the specified suffix.)\\r\\nThis fourth consumer therefore receives messages with colors blue and purple.\\r\\n\\r\\n</details>\\r\\n\\r\\nAMQP filter expressions enable multiple clients to concurrently consume specific subsets of messages from the same stream while preserving message order.\\r\\nThis feature also minimizes network traffic between RabbitMQ and its clients by dispatching only the messages that match each client’s interests.\\r\\n\\r\\n## Stream Filtering Comparison\\r\\n\\r\\nThe **AMQP filter expressions** feature described in this blog post should not be confused with the [**Bloom filter-based stream filtering**](/blog/2023/10/16/stream-filtering) introduced in RabbitMQ 3.13.\\r\\n\\r\\nBoth features serve the same purpose: filtering messages from a stream.\\r\\nHowever, their implementations differ, resulting in distinct characteristics:\\r\\n\\r\\n| Feature | AMQP Filter Expressions | Bloom Filter Based-Stream Filtering |\\r\\n| --- | --- | --- |\\r\\n| Supported Protocols | AMQP 1.0 | Primarily for the [RabbitMQ Streams protocol](https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbitmq_stream/docs/PROTOCOL.adoc), but also supports AMQP 1.0, AMQP 0.9.1, and STOMP. |\\r\\n| False Positives | None | Possible: Requires additional per-message filtering on the client side. |\\r\\n| Support for Multiple Values to Filter on (Publisher) | Yes: Publishers can define multiple values in the properties or application-properties sections. | No: Publishers can assign only one filter value per message. |\\r\\n| Support for Multiple Filter Expressions (Consumer) | Yes: Consumers can provide multiple filter expressions, and a message is delivered if *all* filters match. | Yes: Consumers can specify multiple filter values, and a message is delivered if *any* filter matches. |\\r\\n| Prefix and Suffix Matching | Yes: For string values, consumers can define expressions like: \\"Filter messages whose [subject](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-properties) starts with `emea.`\\" or \\"Filter messages whose [application-properties](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-application-properties) section has a key `color` and the value ends with `e`. | No |\\r\\n| Broker Overhead | Implemented using efficient Erlang pattern matching or term equality operations. However, every message is read into memory for each consumer (unless combined with Bloom filter-based filtering). | Minimal: Bloom filter membership checks use constant time.  With the RabbitMQ Streams protocol, the [`sendfile` system call](https://man7.org/linux/man-pages/man2/sendfile.2.html) optimizes chunk delivery without messages entering user space. |\\r\\n| Network Overhead | Lower: Only messages matching the consumer\'s filters are transferred. | Higher: Entire [chunks](/blog/2023/10/24/stream-filtering-internals#structure-of-a-stream) are transferred even if only one message matches. |\\r\\n\\r\\nBoth features can be used together when consuming via AMQP 1.0.\\r\\n\\r\\n## Summary\\r\\n\\r\\nRabbitMQ 4.1 addresses the [challenge](https://github.com/rabbitmq/rabbitmq-server/issues/262) of enabling multiple consumers on a single queue/stream while ensuring certain messages (e.g., those with the same subject or ID) are always processed by the same consumer, preserving in-order processing.\\r\\n\\r\\nAlthough this feature is not available for [classic queues](/docs/classic-queues) or [quorum queues](/docs/quorum-queues), AMQP filter expressions allow consumers to filter messages when consuming from a stream.\\r\\nSince streams are immutable logs, total message order is maintained."},{"id":"/2024/10/11/modified-outcome","metadata":{"permalink":"/rabbitmq-website/blog/2024/10/11/modified-outcome","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-10-11-modified-outcome/index.md","source":"@site/blog/2024-10-11-modified-outcome/index.md","title":"AMQP 1.0 Modified Outcome","description":"This blog post explores use cases of the AMQP 1.0 modified outcome.","date":"2024-10-11T00:00:00.000Z","tags":[{"inline":true,"label":"AMQP 1.0","permalink":"/rabbitmq-website/blog/tags/amqp-1-0"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.635,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null},{"name":"Karl Nilsson","url":"https://github.com/kjnilsson","socials":{"github":"https://github.com/kjnilsson","linkedin":"https://www.linkedin.com/in/kjnils/","bluesky":"https://bsky.app/profile/kjnilsson.bsky.social"},"imageURL":"https://github.com/kjnilsson.png","key":"nkarl","page":null},{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"AMQP 1.0 Modified Outcome","tags":["AMQP 1.0","RabbitMQ 4.0","New Features"],"authors":["dansari","nkarl","acogoluegnes"],"image":"./modified-outcome.png"},"unlisted":false,"prevItem":{"title":"AMQP 1.0 Filter Expressions","permalink":"/rabbitmq-website/blog/2024/12/13/amqp-filter-expressions"},"nextItem":{"title":"Ten Benefits of AMQP 1.0 Flow Control","permalink":"/rabbitmq-website/blog/2024/09/02/amqp-flow-control"}},"content":"This blog post explores use cases of the AMQP 1.0 [modified outcome](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-modified).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThe modified outcome is a [feature](/docs/amqp#outcomes) exclusive to AMQP 1.0 and not available in AMQP 0.9.1\\r\\nIt is supported in [quorum queues](/docs/quorum-queues), but not in [classic queues](/docs/classic-queues).\\r\\n\\r\\nThis feature enables consumers to add or update [message annotations](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-message-annotations) before requeueing or [dead lettering](/docs/dlx) a message.\\r\\n\\r\\n## Requeue\\r\\n\\r\\nIncluding additional metadata when requeuing a message can be valuable for improving traceability and debugging during message processing.\\r\\n\\r\\nFor example, an application using the [RabbitMQ AMQP 1.0 Java Client](https://github.com/rabbitmq/rabbitmq-amqp-java-client) can set specific message annotations before requeuing the message at the head of a quorum queue, as shown below:\\r\\n```java\\r\\nConsumer consumer = connection.consumerBuilder()\\r\\n    .queue(ordersQueue)\\r\\n    .messageHandler((context, message) -> {\\r\\n        Map<String, Object> annotations = new HashMap<>();\\r\\n        annotations.put(\\"x-opt-requeue-reason\\", \\"external_service_unavailable\\");\\r\\n        annotations.put(\\"x-opt-requeue-time\\", System.currentTimeMillis());\\r\\n        annotations.put(\\"x-opt-requeued-by\\", \\"consumer_1\\");\\r\\n        context.requeue(annotations);\\r\\n    }).build();\\r\\n```\\r\\n\\r\\nThese annotations could use different types including [map](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html#type-map), [list](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html#type-list), or [array](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html#type-array).\\r\\nThis flexibility allows not only setting details like the last requeue reason, time, and consumer, but also tracking a history of requeue events.\\r\\nMaintaining such a history can reveal patterns, such as identifying consumers that requeue messages more frequently or discovering common requeue reasons across the system.\\r\\nHowever, keep in mind that quorum queues retain modified message annotations in memory, which increases the memory overhead per requeued message.\\r\\n\\r\\nSetting custom headers before requeueing a message at the head of the queue is not supported in AMQP 0.9.1.\\r\\n\\r\\nWhether requeuing a message to a quorum queue via AMQP 1.0 or AMQP 0.9.1, the [x-delivery-count](https://www.rabbitmq.com/docs/quorum-queues#poison-message-handling) annotation will always be incremented.\\r\\n\\r\\n## Dead Letter\\r\\n\\r\\nWhen dead lettering a message, the consumer can include a custom reason for the dead lettering in the message annotations:\\r\\n```java\\r\\nConsumer consumer = connection.consumerBuilder()\\r\\n    .queue(ordersQueue)\\r\\n    .messageHandler((context, message) -> {\\r\\n        Map<String, Object> annotations = new HashMap<>();\\r\\n        annotations.put(\\"x-opt-dead-letter-reason\\", \\"Incompatible Message Format\\");\\r\\n        context.discard(annotations);\\r\\n    }).build();\\r\\n```\\r\\n\\r\\nWhen dead lettering to a [headers exchange](/tutorials/amqp-concepts#exchange-headers), the consumer can even decide which target queue the message will be routed to:\\r\\n\\r\\n![An AMQP 1.0 consumer can use the modified outcome to decide which dead letter queue a message is routed to.](modified-outcome.svg)\\r\\n\\r\\nIn this example, two dead letter quorum queues are bound to the dead letter headers exchange:\\r\\n1. `transient-failures-dlq`\\r\\n2. `business-logic-failures-dlq`\\r\\n\\r\\nDifferent dead letter queues can be processed by different apps or teams, with varying actions taken depending on the nature of the failure.\\r\\nFor instance, all messages in the `transient-failures-dlq` could be re-published to the original `orders` queue, while messages in the `business-logic-failures-dlq` might require human intervention.\\r\\n\\r\\nMore dead letter queues could be added, such as:\\r\\n* `data-integrity-dlq` for messages with unknown schema\\r\\n* `resource-limit-dlq` for cases where rate limits were exceeded\\r\\n* `critical-errors-dlq` for situations that require administrator attention.\\r\\n\\r\\nIt’s crucial that all messages dead lettered from the `orders` queue are routable.\\r\\nThe [alternate exchange](/docs/ae) in the above diagram provides \\"or else\\" routing semantics, ensuring messages end up in the `uncategorised-dlq` if no `x-opt-dead-letter-category` annotation is set.\\r\\nThis might occur, for example, if the publisher sets a `ttl` [header](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-header) but no consumer grants [link credit](/blog/2024/09/02/amqp-flow-control#link-credit), causing the message to expire and be dead lettered.\\r\\n\\r\\nThe scenario depicted above is demonstrated in the [modified-outcome sample application](https://github.com/ansd/modified-outcome/blob/v0.1.0/src/main/java/com/github/ansd/App.java).\\r\\n\\r\\n<details>\\r\\n<summary>modified-outcome sample application</summary>\\r\\n\\r\\nThe sample app uses the [RabbitMQ AMQP 1.0 Java Client](https://github.com/rabbitmq/rabbitmq-amqp-java-client).\\r\\n\\r\\nYou can run this sample application as follows:\\r\\n1. Start RabbitMQ server via `docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:4.0-management`\\r\\n2. In the root directory of [the sample app](https://github.com/ansd/modified-outcome/tree/v0.1.0), start the client via `mvn clean compile exec:java`.\\r\\n\\r\\nAfter publishing a message to the `orders` queue, the client app consumes the message and outputs the following on the console:\\r\\n```\\r\\npublisher: received ACCEPTED outcome\\r\\nconsumer: setting annotations {x-opt-dead-letter-reason=Customer Not Eligible for Discount, x-opt-dead-letter-category=business-logic} and dead lettering...\\r\\n```\\r\\nThe message will be dead lettered to the `business-logic-failures-dlq`.\\r\\n\\r\\nTo prevent message loss during dead lettering, the sample app uses [at-least-once dead lettering](/blog/2022/03/29/at-least-once-dead-lettering).\\r\\n\\r\\n</details>\\r\\n\\r\\n## Dead Letter vs. Re-publish\\r\\n\\r\\nAn AMQP 0.9.1 consumer cannot set custom headers before dead lettering a message.\\r\\nHowever, instead of using `basic.nack` or `basic.reject` with `requeue=false` to dead letter a message, an AMQP 0.9.1 client could follow this approach:\\r\\n1. Re-publish the message directly to a specific \\"dead letter\\" queue with new custom headers.\\r\\n2. Wait for RabbitMQ to confirm the re-published message.\\r\\n3. Acknowledge the original message via `basic.ack`.\\r\\n\\r\\nAn AMQP 1.0 client can choose between dead lettering with custom message annotations or re-publishing the message.\\r\\nBoth approaches have their advantages and trade-offs:\\r\\n\\r\\n| Criteria | Dead Letter with Custom Reason | Re-publish with Custom Reason |\\r\\n| --- | --- | --- |\\r\\n| Simplicity | Easier for consumers. | More complex, as the consumer must handle the republishing process. |\\r\\n| Overhead | Low overhead. | Higher overhead for the client: the message payload must be re-published from the client to RabbitMQ, with additional latency due to the extra publish and confirm steps. |\\r\\n| Network Failure between client and RabbitMQ before settling the consumed message. | Message gets requeued. | The message might have been both re-published and requeued, resulting in one copy ending up in the \\"dead letter\\" queue and another in the original queue. |\\r\\n| Flexibility |\\tCan modify only message annotations and route based on dead letter headers exchange. | Allows modification of any part of the message and re-publishing to any exchange. |\\r\\n\\r\\n## Wrapping Up\\r\\nAMQP 1.0\'s modified outcome feature allows consumers to modify message annotations before requeueing or dead lettering.\\r\\n\\r\\nRather than relying solely on RabbitMQ\'s built-in dead lettering tracking via [x-opt-deaths](/docs/dlx#effects), consumers can customise dead lettering event tracking and even choose which dead letter queue a message is sent to."},{"id":"/2024/09/02/amqp-flow-control","metadata":{"permalink":"/rabbitmq-website/blog/2024/09/02/amqp-flow-control","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-09-02-amqp-flow-control/index.md","source":"@site/blog/2024-09-02-amqp-flow-control/index.md","title":"Ten Benefits of AMQP 1.0 Flow Control","description":"This blog post outlines ten advantages of AMQP 1.0 flow control over AMQP 0.9.1, supported by two benchmarks demonstrating significant performance gains.","date":"2024-09-02T00:00:00.000Z","tags":[{"inline":true,"label":"AMQP 1.0","permalink":"/rabbitmq-website/blog/tags/amqp-1-0"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"},{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Technical Deep Dive","permalink":"/rabbitmq-website/blog/tags/technical-deep-dive"}],"readingTime":31.715,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"Ten Benefits of AMQP 1.0 Flow Control","tags":["AMQP 1.0","RabbitMQ 4.0","Performance","Technical Deep Dive"],"authors":["dansari"],"image":"./figure-2-45.png"},"unlisted":false,"prevItem":{"title":"AMQP 1.0 Modified Outcome","permalink":"/rabbitmq-website/blog/2024/10/11/modified-outcome"},"nextItem":{"title":"RabbitMQ 4.0: New Quorum Queue Features","permalink":"/rabbitmq-website/blog/2024/08/28/quorum-queues-in-4.0"}},"content":"This blog post outlines ten advantages of AMQP 1.0 flow control over AMQP 0.9.1, supported by two benchmarks demonstrating significant performance gains.\\r\\nAdditionally, we delve into the powerful AMQP 1.0 flow control primitives and how they are used in RabbitMQ.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n> [Flow control](https://en.wikipedia.org/wiki/Flow_control_(data)) is the process of managing the rate of data transmission between two nodes to prevent a fast sender from overwhelming a slow receiver.\\r\\n\\r\\nThe AMQP 1.0 protocol defines flow control at two different levels:\\r\\n1. [Link Flow Control](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-flow-control)\\r\\n2. [Session Flow Control](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-session-flow-control)\\r\\n\\r\\n## Link Flow Control\\r\\n\\r\\nIn AMQP 1.0, messages are sent over a [link](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#section-links).\\r\\nA link connects either a sending client application to an [exchange](/tutorials/amqp-concepts#exchanges) in RabbitMQ or a [queue](/tutorials/amqp-concepts#queues) in RabbitMQ to a consuming client application.\\r\\n\\r\\n:::info\\r\\n\\r\\nWhile the AMQP 1.0 specification uses the terms \\"senders\\" and \\"receivers\\", the RabbitMQ documentation refers to [\\"publishers\\"](/docs/publishers) (or \\"producers\\") and [\\"consumers\\"](/docs/consumers).\\r\\nWhen discussing client applications, these terms can be used interchangeably. Therefore, a client application instance that:\\r\\n* Sends messages to RabbitMQ is a **sender** / **publisher** / **producer** (with RabbitMQ acting as the **receiver**).\\r\\n* Receives messages from RabbitMQ is a **receiver** / **consumer** (with RabbitMQ acting as the **sender**).\\r\\n\\r\\n:::\\r\\n\\r\\n### Link-Credit\\r\\n\\r\\nThe central idea behind AMQP 1.0 link flow control is simple:\\r\\n**To receive messages, a consumer must grant credits to the sending queue.**\\r\\n\\r\\nOne credit corresponds to one message.\\r\\nFor example, when the consumer grants 10 credits, RabbitMQ is allowed to send 10 messages.\\r\\nThis straightforward principle, where the receiver provides **feedback** to the sender, ensures that the sender never overwhelms the receiver.\\r\\n\\r\\nBoth the receiver and sender maintain their own \\"link state\\".\\r\\nPart of this state is the current link credit.\\r\\nLink credit decreases by 1 each time a message is transferred.\\r\\nSpecifically, the sender reduces link credit by 1 when it sends a message, and the receiver reduces link credit by 1 when it receives a message.\\r\\nWhen the sender\'s link credit reaches 0, it must stop sending messages.\\r\\n\\r\\nMessages are sent in [transfer](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-transfer) frames.\\r\\n\\r\\nCredits are granted in [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frames:\\r\\n```xml\\r\\n<field name=\\"link-credit\\" type=\\"uint\\"/>\\r\\n```\\r\\nAs you might have guessed, they are called \\"flow\\" frames because these frames carry flow control information.\\r\\nThe type [uint](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html#type-uint) stands for unsigned integer, a value between 0 and a large number (2^32 - 1).\\r\\n\\r\\nEven after the link is successfully set up (\\"[attached](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp315568)\\" in AMQP 1.0 terms), RabbitMQ is not allowed to start sending messages to the consumer until the consumer sends its first `flow` frame, granting link credit to the sending queue.\\r\\n\\r\\nIn its simplest form, when a client (receiver) grants a single credit to the queue (sender), the queue will send a single message, as illustrated in [Figure 2.43: Synchronous Get](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp416352) of the AMQP 1.0 specification:\\r\\n\\r\\n```\\r\\nReceiver                                      Sender\\r\\n=================================================================\\r\\n                                      ...\\r\\nflow(link-credit=1)               ---------->\\r\\n                                        +---- transfer(...)\\r\\n*block until transfer arrives*         /\\r\\n                                  <---+\\r\\n                                      ...\\r\\n-----------------------------------------------------------------\\r\\n```\\r\\n\\r\\nSynchronously getting a single message at a time will result in low throughput. Therefore, a client typically grants multiple credits to a queue, as shown in [Figure 2.45: Asynchronous Notification](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp424576) of the AMQP 1.0 specification:\\r\\n\\r\\n```\\r\\nReceiver                                          Sender\\r\\n=====================================================================\\r\\n                                      ...\\r\\n                                  <----------     transfer(...)\\r\\n                                  <----------     transfer(...)\\r\\nflow(link-credit=delta)           ---+   +---     transfer(...)\\r\\n                                      \\\\ /\\r\\n                                       x\\r\\n                                      / \\\\\\r\\n                                  <--+   +-->\\r\\n                                  <----------     transfer(...)\\r\\n                                  <----------     transfer(...)\\r\\nflow(link-credit=delta)           ---+   +---     transfer(...)\\r\\n                                      \\\\ /\\r\\n                                       x\\r\\n                                      / \\\\\\r\\n                                  <--+   +-->\\r\\n                                      ...\\r\\n---------------------------------------------------------------------\\r\\n```\\r\\n\\r\\nIf the receiver grants N credits and waits for **all** N messages to arrive before granting the next N credits, throughput will be higher compared to figure 2.43 where `N=1`.\\r\\nHowever, if you look closely at figure 2.45, you will observe that the receiver grants more credits before receiving all previous messages.\\r\\nThis approach results in the highest throughput.\\r\\nFor example, in figure 2.45, the receiver might have granted 6 credits initially, and then sends another `flow` frame with `link-credit = 6` to RabbitMQ whenever it has received 3 messages.\\r\\n\\r\\n:::note\\r\\n\\r\\nGranting link credit is not cumulative.\\r\\n\\r\\nWhen the receiver sends a `flow` frame with `link-credit = N`, the receiver **sets** the current credit to N instead of adding N more credits.\\r\\nFor example, if a receiver sends two `flow` frames with `link-credit = 50` without any messages being transferred in between, the receiver will have 50 credits, not 100.\\r\\n\\r\\n:::\\r\\n\\r\\nThe receiver knows its current processing capacity and therefore it is always the receiver (and never the sender) that determines the current link credit.\\r\\nThe sender only \\"consumes\\" link credit granted by the receiver by sending more messages.\\r\\n\\r\\nThe receiver is allowed to dynamically increase or decrease the amount of link credit depending on its current processing capacity.\\r\\n\\r\\n:::tip[Benefit #1]\\r\\n\\r\\n**A consuming client application can dynamically adjust how many messages it wants to receive from a specific queue.**\\r\\n\\r\\nThis is a great advantage of link flow control in AMQP 1.0 over [consumer prefetch](/docs/consumer-prefetch) in AMQP 0.9.1.\\r\\nIn AMQP 0.9.1, the [basic.qos](https://github.com/rabbitmq/amqp-0.9.1-spec/blob/main/pdf/amqp-xml-doc0-9-1.pdf) method applies to **all** consumers on the given [AMQP 0.9.1 channel](/docs/channels).\\r\\nFurthermore, dynamically updating the consumer prefetch is not possible or convenient, as discussed in [#10174](https://github.com/rabbitmq/rabbitmq-server/discussions/10174) and [#11955](https://github.com/rabbitmq/rabbitmq-server/discussions/11955).\\r\\n\\r\\n:::\\r\\n\\r\\n:::tip[Benefit #2]\\r\\n\\r\\n**A consuming client application can dynamically prioritize which queue(s), out of multiple queues on the same session, it wants to receive messages from.**\\r\\n\\r\\nThis is another advantage of link flow control in AMQP 1.0 over [consumer prefetch](/docs/consumer-prefetch) in AMQP 0.9.1.\\r\\nOnce an AMQP 0.9.1 client calls `basic.consume` on multiple queues, it will continuously receive messages from all these queues until it calls `basic.cancel`.\\r\\n\\r\\n:::\\r\\n\\r\\nYou might wonder: What are good values for link-credit and how often should the client top up link credit?\\r\\nAs is often the case, the answer is that you will need to benchmark your specific workload with different values to find out.\\r\\n\\r\\nInstead of implementing fancy algorithms, I would recommend starting simple:\\r\\nfor example, the client could initially grant 200 link credits and send a flow with `link-credit = 200` whenever the remaining link credit falls below 100.\\r\\n\\r\\nIn fact, this is what RabbitMQ does the other way around:\\r\\nThe RabbitMQ AMQP 1.0 [session process](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.x/deps/rabbit/src/rabbit_amqp_session.erl) grants initially [170 link credits](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.x/deps/rabbit/src/rabbit_amqp_session.erl#L52) to the publisher, and grants again 170 link credits when the remaining link credit falls below half (i.e. 85) **and** the number of unconfirmed messages is less than 170.\\r\\n(Internally on the broker, publisher confirms are always enabled between AMQP 1.0 session process and target queues, even when no confirms are sent to the publishing client.\\r\\nThis means that if the target queue does not confirm fast enough, RabbitMQ stops granting link credit to the sending application.)\\r\\nPlease note that these RabbitMQ implementation details can change at any time.\\r\\n\\r\\nThe value of `170` is configurable via [advanced.config](/docs/configure#advanced-config-file) setting `rabbit.max_link_credit`.\\r\\n\\r\\n\\r\\n:::tip[Benefit #3]\\r\\n\\r\\n**When one target queue is overloaded, the publisher can continue publishing at high speed to all other target queues.**\\r\\n\\r\\nApplications can send to multiple queues on the same AMQP 1.0 connection or session (by attaching multiple links).\\r\\nLet\'s assume a simple scenario where a client opens two links:\\r\\n* Link 1 sends to a classic queue.\\r\\n* Link 2 sends to a 5-replica quorum queue.\\r\\n\\r\\nBefore confirming a message, the quorum queue must have replicated the message to a majority of replicas, with each replica [fsync](https://man7.org/linux/man-pages/man2/fsync.2.html)ing the message to its local disk.\\r\\n\\r\\nIn contrast, classic queues do not replicate messages.\\r\\nFurthermore, when a message is consumed and acknowledged quickly enough, classic queues can (thereafter) confirm the message back to the publisher without ever writing it to disk.\\r\\nHence, in this scenario, throughput for the classic queue will be far higher than for the quorum queue.\\r\\n\\r\\nThe beauty of AMQP 1.0 link flow control is that RabbitMQ can slow down granting credits on Link 2 while continuing to grant credits on Link 1 at a high frequency.\\r\\nTherefore, even when the 5-replica quorum queue does not process messages as quickly as the (single replica) classic queue, the client can continue to send at full speed to the classic queue.\\r\\n\\r\\nThe following picture is copied from a [previous](/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts#quorum-queues) AMQP 0.9.1 blog post:\\r\\n\\r\\n![Flow control in AMQP 0.9.1](credit-flow-quorum-queue.png)\\r\\n\\r\\nThe word \\"credit\\" in this picture refers to RabbitMQ\'s internal flow control for AMQP 0.9.1 connections and is unrelated to link credit in AMQP 1.0.\\r\\n\\r\\nThe `reader` in the above picture is the Erlang process that reads AMQP 0.9.1 frames from the socket.\\r\\nThe picture shows that for AMQP 0.9.1 connections, RabbitMQ will block the `reader`, causing TCP backpressure to be applied to the client.\\r\\nTherefore, when a single target queue becomes overloaded, RabbitMQ throttles the AMQP 0.9.1 connection, affecting the publishing to all other target queues.\\r\\n\\r\\nThe following benchmark shows how AMQP 1.0 can provide multiple times higher throughput compared to AMQP 0.9.1 when a connection sends to more than one target queue.\\r\\n\\r\\n<details>\\r\\n<summary>Benchmark: Two senders</summary>\\r\\n\\r\\nTo put the theory we just discussed into practice, the [two_senders](https://github.com/ansd/rabbitmq-amqp/blob/v0.1.0/two_senders/main.go) program simulates a similar scenario.\\r\\n\\r\\nThis program opens a single AMQP 0.9.1 connection and channel, as well as a single AMQP 1.0 connection and session.\\r\\n\\r\\nOn both the AMQP 0.9.1 channel and the AMQP 1.0 session, there are two goroutines that publish as quickly as possible into a classic queue and a quorum queue.\\r\\nThis results in four target queues in total:\\r\\n\\r\\n```\\r\\n    main.go                                                      RabbitMQ\\r\\n+-------------+                                     +----------------------------------+\\r\\n|             |        AMQP 0.9.1 connection        |                                  |\\r\\n|             |#####################################|                                  |\\r\\n|    +---+    |-------------------------------------|    +------------------------+    |\\r\\n|    | P |                                               | classic-queue-amqp-091 |    |\\r\\n|    +---+                                               +------------------------+    |\\r\\n|                        AMQP 0.9.1 channel                                            |\\r\\n|    +---+                                               +------------------------+    |\\r\\n|    | P |                                               | quorum-queue-amqp-091  |    |\\r\\n|    +---+    |-------------------------------------|    +------------------------+    |\\r\\n|             |#####################################|                                  |\\r\\n|             |                                     |                                  |\\r\\n|             |                                     |                                  |\\r\\n|             |                                     |                                  |\\r\\n|             |#####################################|                                  |\\r\\n|    +---+    |-------------------------------------|    +-----------------------+     |\\r\\n|    | P |O============================================>O| classic-queue-amqp-10 |     |\\r\\n|    +---+                                               +-----------------------+     |\\r\\n|                        AMQP 1.0 session                                              |\\r\\n|    +---+                                               +-----------------------+     |\\r\\n|    | P |O======================================+=====>O| quorum-queue-amqp-10  |     |\\r\\n|    +-+-+    |----------------------------------|--|    +-----------------------+     |\\r\\n|      |      |##################################|##|                                  |\\r\\n|      |      |        AMQP 1.0 connection       |  |                                  |\\r\\n+------|------+                                  |  +----------------------------------+\\r\\n       |                                         |\\r\\n       |                                         |\\r\\n   Publisher                               AMQP 1.0 link\\r\\n   goroutine\\r\\n```\\r\\n\\r\\nRun the benchmark as follows:\\r\\n1. Start RabbitMQ server [v4.0.0-beta.6](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0-beta.6) using `make run-broker` on an Ubuntu box. (On macOS, `fsync` does not write physically to the platters).\\r\\n2. Execute the Go program with `go run two_senders/main.go`. After 10 seconds, the Go program will complete.\\r\\n3. List the number of messages in each queue:\\r\\n```\\r\\n./sbin/rabbitmqctl --silent list_queues name type messages --formatter=pretty_table\\r\\n┌────────────────────────┬─────────┬──────────┐\\r\\n│ name                   │ type    │ messages │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ classic-queue-amqp-091 │ classic │ 159077   │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ quorum-queue-amqp-091  │ quorum  │ 155782   │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ classic-queue-amqp-10  │ classic │ 1089075  │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ quorum-queue-amqp-10   │ quorum  │ 148580   │\\r\\n└────────────────────────┴─────────┴──────────┘\\r\\n```\\r\\n\\r\\nAs explained in the [AMQP 1.0 Benchmarks](/blog/2024/08/21/amqp-benchmarks#quorum-queues) blog post, quorum queues [fsync](https://man7.org/linux/man-pages/man2/fsync.2.html) (`fdatasync` to be precise), whereas classic queues do not.\\r\\nTherefore, even without replication, a quorum queue is significantly slower than a classic queue because I use a consumer-grade disk where each `fsync` takes at least 5 milliseconds.\\r\\nFor production clusters, it is recommended to use high-end, enterprise-grade disks that `fsync` faster.\\r\\n\\r\\nThe results show that the single AMQP 0.9.1 connection sends roughly the same number of messages to both the target classic queue and the target quorum queue.\\r\\nThis is because `quorum-queue-amqp-091` causes the entire AMQP 0.9.1 connection to be blocked (and unblocked) around 80 times per second in my benchmark.\\r\\nAs a result, the publishing rate to multiple target queues (`classic-queue-amqp-091` and `quorum-queue-amqp-091`) on a single AMQP 0.9.1 connection is constrained by the slowest target queue (`quorum-queue-amqp-091`).\\r\\nIn total, the AMQP 0.9.1 connection sends `159,077 + 155,782 = 314,859` messages.\\r\\n\\r\\nIn contrast, thanks to link flow control, RabbitMQ throttles only the link to the `quorum-queue-amqp-10` [target](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-target), allowing the AMQP 1.0 client to continue publishing at full speed to the `classic-queue-amqp-10` target.\\r\\nIn total, the AMQP 1.0 connection sends `1,089,075 + 148,580 = 1,237,655` messages.\\r\\n\\r\\nTherefore, in our simple benchmark, the total send throughput of AMQP 1.0 is four times (!) higher than that of AMQP 0.9.1.\\r\\n\\r\\n</details>\\r\\n\\r\\n:::\\r\\n\\r\\n:::tip[Benefit #4]\\r\\n\\r\\n**When one target queue is overloaded, the client can continue consuming at high speed from all source queues.\\r\\nTherefore, AMQP 1.0 clients can use a single connection for both publishing and consuming at high throughput.**\\r\\n\\r\\nBenefit #3 described how a single overloaded target queue causes RabbitMQ to block the reader process from reading any AMQP 0.9.1 frames.\\r\\nThis means that not only can the client no longer publish messages, but it also **cannot consume** messages.\\r\\nThis is because the client\'s message [acknowledgements](/docs/confirms#acknowledgement-modes) are no longer processed by RabbitMQ, preventing the delivery of new messages to the consumer once its [prefetch](/docs/confirms#channel-qos-prefetch) limit is reached.\\r\\n\\r\\nAlthough this throttling in consumption is temporary (with the AMQP 0.9.1 `reader` process being blocked and unblocked many times per second), it can significantly reduce the consumption rate.\\r\\n\\r\\nThe RabbitMQ AMQP 0.9.1 [documentation](/docs/connections#flow-control) advises:\\r\\n> It is therefore recommended that, when possible, publishers and consumers use separate connections so that consumers are isolated from potential flow control that may be applied to publishing connections, affecting manual consumer acknowledgements.\\r\\n\\r\\nThis has led to an entire ecosystem of AMQP 0.9.1 client libraries adopting this \\"best practice\\" of using separate connections for publishing and consuming.\\r\\nFor example the RabbitMQ AMQP 0.9.1 C++ library [states](https://github.com/bloomberg/rmqcpp/blob/1.0.0/README.md#features):\\r\\n> Publishing and Consuming happens on different connections:\\r\\n>\\r\\n> A common application pitfall is to consume & produce on the same connection.\\r\\n> This can cause slow-downs in consumption rate, as RabbitMQ applies backpressure to fast publishers - depending on the exact queues being consumed/published from this can cause a vicious cycle.\\r\\n\\r\\nIn contrast, AMQP 1.0 link flow control allows to slow down only the link sender in the client application.\\r\\nAll other links (whether sending or consuming) can continue to operate at full speed.\\r\\n\\r\\nTherefore, in AMQP 1.0, clients can use a single connection for both publishing and consuming.\\r\\n\\r\\n<details>\\r\\n<summary>Benchmark: One sender, one receiver</summary>\\r\\n\\r\\nProgram [one_sender_one_receiver](https://github.com/ansd/rabbitmq-amqp/blob/v0.1.0/one_sender_one_receiver/main.go) simulates a scenario where a client opens two links:\\r\\n* Link 1 receives from a classic queue.\\r\\n* Link 2 sends to a quorum queue.\\r\\n\\r\\nThis program opens a single AMQP 0.9.1 connection and channel, as well as a single AMQP 1.0 connection and session.\\r\\n\\r\\nTo prepare for the benchmark, the program writes one million messages into each classic queue.\\r\\n\\r\\nOn both the AMQP 0.9.1 channel and the AMQP 1.0 session, there are two goroutines:\\r\\n* One goroutine (Link 1) that receives messages with a prefetch of 200 from the classic queue and acknowledges each one.\\r\\n* One goroutine (Link 2) that publishes in batches of 10,000 messages to the quorum queue.\\r\\n(After all 10,000 confirmations are received, the next batch is published.)\\r\\n\\r\\n```\\r\\n    main.go                                                      RabbitMQ\\r\\n+-------------+                                     +----------------------------------+\\r\\n|             |        AMQP 0.9.1 connection        |                                  |\\r\\n|             |#####################################|                                  |\\r\\n|    +---+    |-------------------------------------|    +------------------------+    |\\r\\n|    | C |                                               | classic-queue-amqp-091 |    |\\r\\n|    +---+                                               +------------------------+    |\\r\\n|                        AMQP 0.9.1 channel                                            |\\r\\n|    +---+                                               +------------------------+    |\\r\\n|    | P |                                               | quorum-queue-amqp-091  |    |\\r\\n|    +---+    |-------------------------------------|    +------------------------+    |\\r\\n|             |#####################################|                                  |\\r\\n|             |                                     |                                  |\\r\\n|             |                                     |                                  |\\r\\n|             |                                     |                                  |\\r\\n|             |#####################################|                                  |\\r\\n|    +---+    |-------------------------------------|    +-----------------------+     |\\r\\n|    | C |O<============================================O| classic-queue-amqp-10 |     |\\r\\n|    +---+                                               +-----------------------+     |\\r\\n|                        AMQP 1.0 session                                              |\\r\\n|    +---+                                               +-----------------------+     |\\r\\n|    | P |O======================================+=====>O| quorum-queue-amqp-10  |     |\\r\\n|    +-+-+    |----------------------------------|--|    +-----------------------+     |\\r\\n|      |      |##################################|##|                                  |\\r\\n|      |      |        AMQP 1.0 connection       |  |                                  |\\r\\n+------|------+                                  |  +----------------------------------+\\r\\n       |                                         |\\r\\n       |                                         |\\r\\nPublisher or Consumer                      AMQP 1.0 link\\r\\n   goroutine\\r\\n```\\r\\n\\r\\nRun the benchmark as follows:\\r\\n1. Start RabbitMQ server [v4.0.0-beta.6](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0-beta.6) using `make run-broker` on an Ubuntu box.\\r\\n2. Execute the Go program with `go run one_sender_one_receiver/main.go`\\r\\n3. Once the program completes, list the number of messages in each queue:\\r\\n```\\r\\n./sbin/rabbitmqctl --silent list_queues name type messages --formatter=pretty_table\\r\\n┌────────────────────────┬─────────┬──────────┐\\r\\n│ name                   │ type    │ messages │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ classic-queue-amqp-091 │ classic │ 990932   │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ quorum-queue-amqp-091  │ quorum  │ 172800   │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ classic-queue-amqp-10  │ classic │ 336229   │\\r\\n├────────────────────────┼─────────┼──────────┤\\r\\n│ quorum-queue-amqp-10   │ quorum  │ 130000   │\\r\\n└────────────────────────┴─────────┴──────────┘\\r\\n```\\r\\n\\r\\nWhile the AMQP 0.9.1 client consumes only `1,000,000 - 990,932 = 9,068` messages, the AMQP 1.0 client consumes `1,000,000 - 336,229 = 663,771` messages.\\r\\n\\r\\nTherefore, in this benchmark, the AMQP 1.0 client receives 73 times (!) more messages than the AMQP 0.9.1 client.\\r\\n\\r\\n</details>\\r\\n\\r\\n:::\\r\\n\\r\\n:::note\\r\\n\\r\\nIn AMQP 0.9.1, [consumer prefetch](/docs/consumer-prefetch) limits the number of unacknowledged messages.\\r\\nWhen a consumer acknowledges messages by sending `basic.ack` frames, RabbitMQ delivers additional messages.\\r\\n\\r\\nIn AMQP 1.0, message acknowledgment is independent of link flow control.\\r\\nA consumer acknowledging messages by sending [disposition](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-disposition) frames will not prompt RabbitMQ to deliver more messages.\\r\\nInstead, the client must replenish link credit by sending `flow` frames for RabbitMQ to continue sending messages.\\r\\nFor convenience, some AMQP 1.0 client libraries automatically send both `disposition` and `flow` frames when your application acknowledges messages.\\r\\n\\r\\n:::\\r\\n\\r\\n### Delivery-Count\\r\\n\\r\\nSo far, we understand only one field of the [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frame: `link-credit`.\\r\\n\\r\\nWhat happens in the following scenario?\\r\\n```\\r\\nReceiver                                  Sender\\r\\n=======================================================================\\r\\n                              ...\\r\\nlink state:                               link state:\\r\\n link-credit = 3                           link-credit = 3\\r\\n\\r\\nflow(link-credit = 6)     ---+   +---     transfer(...)\\r\\n                              \\\\ /\\r\\n                               x\\r\\n                              / \\\\\\r\\n                          <--+   +-->\\r\\n\\r\\nlink state:                               link state:\\r\\n link-credit = 5                           link-credit = 6\\r\\n```\\r\\nInitially, `link-credit` is 3.\\r\\nThe receiver decides to send a `flow` frame, setting the new `link-credit` to 6.\\r\\nIn parallel, the sender sends a `transfer` frame.\\r\\n\\r\\nSince the receiver received the `transfer` frame after it sent the `flow` frame, it will compute its new link-credit as `6 - 1 = 5`.\\r\\nHowever, because the sender received the `flow` frame after it sent the `transfer` frame, it will set the credit to 6.\\r\\nAs a result, the state - and therefore the view of how many credits the link has left - becomes misaligned.\\r\\nThis is problematic because the sender could potentially overflow the receiver.\\r\\n\\r\\nTo prevent such misalignments, a second field is needed in both the link state and the `flow` frame:\\r\\n```xml\\r\\n<field name=\\"delivery-count\\" type=\\"sequence-no\\"/>\\r\\n```\\r\\n\\r\\nThe delivery-count is increased by 1 each time a message is transferred.\\r\\nSpecifically, the sender increments the delivery-count whenever it sends a message, and the receiver increments the delivery-count whenever it receives a message.\\r\\n\\r\\nWhen the sender receives a `flow` frame (which contains both link-credit and delivery-count), the sender sets its link-credit according to this [formula](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-flow-control):\\r\\n```\\r\\nlink-credit(snd) := delivery-count(rcv) + link-credit(rcv) - delivery-count(snd).\\r\\n```\\r\\n`(snd)` refers to the link state at the sender, while the link state at the receiver `(rcv)` is sent within the `flow` frame to the sender.\\r\\n\\r\\nAt the sender, this formula means:\\r\\n\\"Set the new link-credit to the link-credit I just received in the flow frame minus any in-flight deliveries.\\"\\r\\n\\r\\nThe purpose of the delivery-count is to establish an order in the sequence of events, which are:\\r\\n* Sender sends message\\r\\n* Receiver receives message\\r\\n* Receivers grants link-credit\\r\\n* Sender computes receiver\'s link-credit\\r\\n\\r\\nUsing the delivery-count resolves the misalignment issue we discussed earlier.\\r\\n\\r\\nLet’s assume the delivery-count is initially set to 20:\\r\\n```\\r\\nReceiver                                      Sender\\r\\n========================================================================================\\r\\n                                  ...\\r\\nlink state:                                   link state:\\r\\n delivery-count = 20                           delivery-count = 20\\r\\n link-credit = 3                               link-credit = 3\\r\\n\\r\\nflow(delivery-count = 20,\\r\\n     link-credit = 6)         ---+   +---     transfer(...)\\r\\n                                  \\\\ /\\r\\n                                   x\\r\\n                                  / \\\\\\r\\n                              <--+   +-->\\r\\n\\r\\nlink state:                                   link state:\\r\\n delivery-count = 21                           delivery-count = 21\\r\\n link-credit = 5                               link-credit = 20+6-21 = 5 (above formula)\\r\\n```\\r\\n\\r\\n:::note\\r\\n\\r\\nSome AMQP 1.0 fields, including the delivery-count are of type [sequence-no](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-sequence-no).\\r\\nThese are 32-bit [RFC-1982](https://www.ietf.org/rfc/rfc1982.txt) serial numbers that range from `[0 .. 4,294,967,295]` and wrap around: Adding 1 to 4,294,967,295 results in 0.\\r\\n\\r\\n:::\\r\\n\\r\\n:::note\\r\\n\\r\\nThe delivery-count is initialized by the sender, which sends its chosen value in the `initial-delivery-count` field of the [attach](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-attach) frame.\\r\\n\\r\\nThe sender can initialize the delivery-count to any value it chooses, such as 0, 10, or 4,294,967,295.\\r\\nThis value has no intrinsic meaning beyond the purpose we discussed earlier: comparing the delivery-count of the receiver with that of the sender to determine how many messages are in-flight.\\r\\n\\r\\n:::\\r\\n\\r\\n:::info\\r\\n\\r\\nFrom what I can tell, the AMQP 1.0 link flow control seems to be based on the paper [Credit-Based Flow Control for ATM Networks](https://www.eecs.harvard.edu/~htk/publication/1995-ieee-network-kung-morris.pdf) from 1995.\\r\\n\\r\\nThe formula\\r\\n```\\r\\nlink-credit(snd) := delivery-count(rcv) + link-credit(rcv) - delivery-count(snd).\\r\\n```\\r\\nfrom the AMQP 1.0 specification in section [2.6.7](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-flow-control) matches the formula\\r\\n```\\r\\nCrd_Bal = Buf_Alloc - (Tx_Cnt - Fwd_Cnt)(1)\\r\\n```\\r\\nin the paper.\\r\\n\\r\\nThe AMQP 1.0 specification even adopts similar terminology from the paper, such as \\"link\\" and \\"node.\\"\\r\\nFurthermore, the specification likely refers to \\"delivery-count\\" because it is called \\"count\\" in the paper as well (even though the specification clarifies that in AMQP it\'s not actually a count, but rather a sequence number).\\r\\n\\r\\nFigure 2 in the paper illustrates the concept nicely:\\r\\n\\r\\n![Credit-Based Flow Control for ATM Networks, Figure 2: Credit Update Protocol](figure-2-credit-update-protocol.png)\\r\\n\\r\\nIn this figure:\\r\\n* `Tx_Cnt` corresponds to `delivery-count(snd)`\\r\\n* `Fwd_Cnt` corresponds to `delivery-count(rcv)`\\r\\n* `Crd_Bal` corresponds to `link-credit(snd)`\\r\\n* `Buf_Alloc` corresponds to `link-credit(rcv)`\\r\\n\\r\\nThe paper explains in detail how frequently and by how much a receiver should top up link credit.\\r\\nIf you want to become an expert in AMQP 1.0 flow control, I recommend reading both the AMQP 1.0 specification and the paper.\\r\\n\\r\\n:::\\r\\n\\r\\n### Drain\\r\\n\\r\\nHaving understood the two most important link control fields of the [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frame (`link-credit` and `delivery-count`), let\'s move on to the `drain` field:\\r\\n\\r\\n```xml\\r\\n<field name=\\"drain\\" type=\\"boolean\\" default=\\"false\\"/>\\r\\n```\\r\\n\\r\\nBy default, the `drain` field is set to `false`.\\r\\nThe receiver decides whether drain mode is enabled, and the sender sets `drain` to the last known value from the receiver.\\r\\n\\r\\nDraining means that the sender should use all link credit from the receiver by sending available messages.\\r\\nIf there are not enough messages to send, the sender must still exhaust all link credit as follows:\\r\\n1. Advance the delivery-count by the remaining link-credit.\\r\\n2. Set link-credit to 0.\\r\\n3. Send a `flow` frame to the receiver.\\r\\n\\r\\nBy setting the `drain` field to `true`, the consumer requests RabbitMQ to \\"Either send a [transfer](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-transfer) or a [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frame.\\"\\r\\nIf the source queue is empty, RabbitMQ will promptly reply with only a `flow` frame.\\r\\n\\r\\nTherefore, the `drain` field allows a consumer to set a timeout when synchronously getting messages, as shown in [Figure 2.44: Synchronous Get with a Timeout](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp416352) of the AMQP 1.0 specification:\\r\\n\\r\\n```\\r\\n    Receiver                                      Sender\\r\\n    =================================================================\\r\\n                                          ...\\r\\n    flow(link-credit=1)               ---------->\\r\\n  *wait for link-credit <= 0*\\r\\n    flow(drain=True)                  ---+   +--- transfer(...)\\r\\n                                          \\\\ /\\r\\n                                           x\\r\\n                                          / \\\\\\r\\n(1)                                   <--+   +-->\\r\\n(2)                                   <---------- flow(...)\\r\\n                                          ...\\r\\n    -----------------------------------------------------------------\\r\\n      (1) If a message is available within the timeout, it will\\r\\n          arrive at this point.\\r\\n      (2) If a message is not available within the timeout, the\\r\\n          drain flag will ensure that the sender promptly advances the\\r\\n          delivery-count until link-credit is consumed.\\r\\n```\\r\\n\\r\\nBecause the link-credit is consumed quickly, the consumer can unambiguously determine whether a message was received or if the operation timed out.\\r\\n\\r\\n### Echo\\r\\n\\r\\nSimilar to the `drain` field, the `echo` field is:\\r\\n* set to `false` by default\\r\\n* determined by the consumer, as RabbitMQ does not set this field in its current implementation\\r\\n\\r\\n```xml\\r\\n<field name=\\"echo\\" type=\\"boolean\\" default=\\"false\\"/>\\r\\n```\\r\\n\\r\\nThe consumer can set the `echo` field to request RabbitMQ to reply with a `flow` frame.\\r\\nOne use case is depicted in [Figure 2.46: Stopping Incoming Messages](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp429232) of the AMQP 1.0 specification:\\r\\n\\r\\n```\\r\\n    Receiver                                       Sender\\r\\n    ================================================================\\r\\n                                           ...\\r\\n                                       <---------- transfer(...)\\r\\n    flow(...,                          ---+   +--- transfer(...)\\r\\n         link-credit=0,                    \\\\ /\\r\\n         echo=True)                         x\\r\\n                                           / \\\\\\r\\n(1)                                    <--+   +-->\\r\\n(2)                                    <---------- flow(...)\\r\\n                                           ...\\r\\n    ----------------------------------------------------------------\\r\\n      (1) In-flight transfers can still arrive until the flow state\\r\\n          is updated at the sender.\\r\\n      (2) At this point no further transfers will arrive.\\r\\n```\\r\\n\\r\\n:::tip[Benefit #5]\\r\\n\\r\\n**In AMQP 1.0, a consumer can be stopped/paused and later resumed.**\\r\\n\\r\\nIn AMQP 0.9.1, a consumer cannot be paused and resumed. Instead, the consumer must be cancelled using the `basic.cancel` method before registering a new consumer with `basic.consume`.\\r\\n\\r\\n:::\\r\\n\\r\\n:::tip[Benefit #6]\\r\\n\\r\\n**AMQP 1.0 allows a graceful handoff from one [single active consumer](/docs/consumers#single-active-consumer) to the next, while maintaining message order.**\\r\\n\\r\\nIn AMQP 1.0, the consumer can either stop the link first and acknowledge messages before [detach](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-detach)ing the link (preferred), or detach the link directly.\\r\\nDetaching the link directly will requeue any unacknowledged messages.\\r\\nEither way, detaching the link causes the next consumer to be activated and to receive the messages in the original order.\\r\\n\\r\\nIn contrast, a single active consumer in AMQP 0.9.1 cannot gracefully and safely hand over to the next one.\\r\\nWhen an AMQP 0.9.1 consumer cancels consumption via `basic.cancel` but still has unacknowledged messages, the queue will activate the next consumer.\\r\\nIf the AMQP 0.9.1 client crashes shortly after, messages checked out to the old consumer will be requeued, potentially violating message order.\\r\\nTo maintain message order, an AMQP 0.9.1 client must close the entire channel (without calling `basic.cancel` first) so that messages are requeued before the next consumer is activated.\\r\\n\\r\\n:::\\r\\n\\r\\n### Available\\r\\n\\r\\nRabbitMQ sets the `available` field in the [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frame to inform the consumer how many messages are available:\\r\\n```xml\\r\\n<field name=\\"available\\" type=\\"uint\\"/>\\r\\n```\\r\\n\\r\\nThe `available` value is only an approximation because, from the time the queue emits this information until the `flow` frame arrives at the consumer, this information can already be outdated, for instance when other clients publish messages to or consume messages from this queue.\\r\\n\\r\\nFor [classic queues](/docs/classic-queues) and [quorum queues](/docs/quorum-queues), `available` indicates the number of messages ready for delivery (i.e. the queue length excluding messages that are checked out to consumers).\\r\\n\\r\\nFor [streams](/docs/streams), `available` represents the difference between the committed offset and the last consumed [offset](/docs/streams#consuming).\\r\\nRoughly, the committed offset is what the different stream [replicas](/docs/streams#replication-factor) in the RabbitMQ cluster agree is the end of the stream.\\r\\nThe last consumed offset might be the same as the committed offset or lag behind it.\\r\\nThe `available` value is merely an estimate because [a stream offset does not necessarily represent a message](/docs/streams#limitations-ui-metrics).\\r\\n\\r\\nIf the [Single Active Consumer](/docs/consumers#single-active-consumer) feature is enabled, quorum queues will return `available = 0` for all inactive (waiting) consumers.\\r\\nThis makes sense since no messages are available for inactive consumers, regardless of how much credit they have topped up.\\r\\n\\r\\nIn the [previous](#echo) section, we learned that one use case for the consumer setting the `echo` field is to stop a link.\\r\\nAnother use case is when a consumer wants to learn about the number of messages available in the queue it consumes from.\\r\\n\\r\\n:::tip[Benefit #7]\\r\\n\\r\\n**AMQP 1.0 informs the consumer about the number of messages available in the queue.**\\r\\n\\r\\nIncluding this information in every `flow` frame sent from RabbitMQ to the consumer is an advantage over AMQP 0.9.1.\\r\\nIn AMQP 0.9.1, methods to query available messages are more cumbersome and less efficient:\\r\\n* `queue.declare` with `passive=true`: The `queue.declare_ok` reply will contain a `message_count` field.\\r\\n* `basic.get`: The `basic.get_ok` reply will contain a `message_count` field.\\r\\n\\r\\n:::\\r\\n\\r\\nThe `available` field could also be set by a publisher to tell RabbitMQ how many messages the publisher has available to send.\\r\\nCurrently, RabbitMQ ignores this information.\\r\\n\\r\\n### Properties\\r\\n\\r\\nThe `properties` field of the [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frame can carry application specific link state properties:\\r\\n\\r\\n```xml\\r\\n<field name=\\"properties\\" type=\\"fields\\"/>\\r\\n```\\r\\n\\r\\nCurrently, RabbitMQ does not make use of this field.\\r\\n\\r\\n:::tip[Benefit #8]\\r\\n\\r\\n**AMQP 1.0 link flow control is extensible.**\\r\\n\\r\\nImagine that RabbitMQ wants to enable publishers to send messages directly to the quorum queue leader.\\r\\nSince all [Ra](https://github.com/rabbitmq/ra) commands, including enqueuing a message, must go through the leader first, it would make sense for the client to connect directly to the RabbitMQ node that hosts the quorum queue leader.\\r\\nThis \\"queue locality\\" would reduce RabbitMQ intra-cluster traffic, thereby improving latency and throughput.\\r\\nWhen the leader changes, instead of causing RabbitMQ to [detach](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-detach) the link - which could be disruptive to the publishing application - RabbitMQ could push a leader change notification, including the new RabbitMQ node hosting the quorum queue leader, to the publisher via the `properties` field.\\r\\nThe application could then decide when it is convenient to detach the link and attach a new link on a different connection to continue publishing \\"locally\\".\\r\\n\\r\\nAlternatively, RabbitMQ could send a boolean value for a key `local` in every `flow` frame\'s `properties` field to indicate whether the link is currently publishing or consuming locally.\\r\\nIf the `local` field flips from `true` to `false`, the client could query the new queue topology and leader via [HTTP over AMQP 1.0](https://github.com/oasis-tcs/amqp-specs/blob/master/http-over-amqp-v1.0-wd06a.docx).\\r\\n\\r\\nThese are just hypothetical examples showing how RabbitMQ could make use of link flow control extensibility in the future, which is an advantage over AMQP 0.9.1.\\r\\n\\r\\n:::\\r\\n\\r\\n### Summary\\r\\n\\r\\nWe learned that AMQP 1.0 link flow control protects individual consumers or queues from being overwhelmed with messages.\\r\\nThe receiver periodically provides feedback to the sender on how many messages it can currently handle.\\r\\n\\r\\nEach link endpoint (sender and receiver) maintains full link flow control state and exchanges this state via [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frames with the other side.\\r\\n\\r\\nThe following link flow control fields are independently determined by the **receiver**:\\r\\n* `link-credit`\\r\\n* `drain`\\r\\n\\r\\nThe following link flow control fields are independently determined by the **sender**:\\r\\n* `delivery-count`\\r\\n* `available`\\r\\n\\r\\n## Session Flow Control\\r\\n\\r\\nBefore diving into [session flow control](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-session-flow-control), let\'s recap what a [session](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#section-sessions) actually is.\\r\\n\\r\\n### Session\\r\\n\\r\\nA client library creates a single TCP connection per [AMQP connection](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#section-connections).\\r\\nAn AMQP 1.0 connection is established using the [open](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-open) frame.\\r\\n\\r\\nWithin an AMQP 1.0 connection, the client can then start multiple AMQP 1.0 sessions.\\r\\nThis is [analogous](/docs/connections#protocol-differences) to how an AMQP 0.9.1 client can open multiple [AMQP 0.9.1 channels](/docs/channels) within an AMQP 0.9.1 connection.\\r\\nAn AMQP 1.0 session is started using the [begin](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-begin) frame.\\r\\n\\r\\nWithin a session, a client can then create [links](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#section-links) by sending the [attach](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-attach) frame.\\r\\n\\r\\n```\\r\\n  Client App                                       RabbitMQ\\r\\n+-------------+                                +-------------+\\r\\n|             |################################|             |\\r\\n|   +---+     |--------------------------------|    +---+    |\\r\\n|   | C |O<===============================+========O| Q |    |\\r\\n|   +-+-+ \\\\   |-------------------+-------|----|   |+-+-+    |\\r\\n|     |    \\\\  |#######+###########|#######|####|   |  |      |\\r\\n+-----|-----\\\\-+       |           |       |    +---|--|------+\\r\\n      |      \\\\        |           |       |        |  |\\r\\n      |     Target    |           |       |    Source |\\r\\n      |               |           |       |           |\\r\\n   Consumer           |           |     Link        Queue\\r\\n                      |       Session\\r\\n                 Connection\\r\\n```\\r\\n\\r\\nA client application could create, for example:\\r\\n* A single connection with a single session, or\\r\\n* A single connection with multiple sessions, or\\r\\n* Multiple connections with one or more sessions each\\r\\n\\r\\nUsually, a single connection with a single session is sufficient.\\r\\n\\r\\nOpening an AMQP connection comes with some overhead:\\r\\nA TCP connection must be established, allocating operating system resources such as sockets and TCP buffers in both the client and server, and incurring latency for the TCP or TLS handshake.\\r\\nAdditionally, on the RabbitMQ node, a [supervision tree](https://www.erlang.org/doc/apps/stdlib/supervisor.html) is created for each incoming AMQP connection.\\r\\n\\r\\nA session can be thought of as a \\"lightweight\\" connection.\\r\\nEach AMQP 1.0 session is currently implemented as its own [Erlang process](https://www.erlang.org/doc/system/ref_man_processes.html).\\r\\nHence, creating a session is inexpensive if the connection is already established.\\r\\n\\r\\nCreating a second session within an AMQP connection might be useful in the following scenarios:\\r\\n* Quickly and cheaply creating another \\"virtual connection\\" without incurring the aforementioned AMQP connection setup overhead.\\r\\n* Ensuring high-priority [transfer](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-transfer) frames (requiring low latency) are not blocked by other transfer frames.\\r\\n* Increasing parallelism when the RabbitMQ [session process](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.6/deps/rabbit/src/rabbit_amqp_session.erl) becomes very busy (for example, routing messages to [queues](/tutorials/amqp-concepts#queues)).\\r\\n\\r\\n### Flow Fields\\r\\n\\r\\n> Sessions provide a flow control scheme based on the number of transfer frames transmitted.\\r\\n> Since frames have a maximum size for a given connection, this provides flow control based on the number of bytes transmitted.\\r\\n\\r\\nRemember that a [large message](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp484080) is split into multiple transfer frames.\\r\\n\\r\\n[Session flow control](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-session-flow-control) in AMQP 1.0 operates at a higher layer than link flow control.\\r\\nWhile link flow control protects individual consumers and queues, session flow control is designed to protect the entire client application and RabbitMQ as a whole.\\r\\n\\r\\nJust as each link endpoint maintains link flow control state and exchanges this state via `flow` frames, each session endpoint maintains session flow control state and exchanges this state within the same `flow` frames.\\r\\nThe remaining fields in the [flow](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-flow) frame are therefore used for session flow control:\\r\\n```xml\\r\\n<field name=\\"next-incoming-id\\" type=\\"transfer-number\\"/>\\r\\n<field name=\\"incoming-window\\" type=\\"uint\\" mandatory=\\"true\\"/>\\r\\n<field name=\\"next-outgoing-id\\" type=\\"transfer-number\\" mandatory=\\"true\\"/>\\r\\n<field name=\\"outgoing-window\\" type=\\"uint\\" mandatory=\\"true\\"/>\\r\\n```\\r\\n\\r\\nThe `incoming-window` is similar to the [link-credit](#link-credit) field in that the receiving side informs the sending side how many \\"units\\" it can tolerate receiving.\\r\\nThe difference is that for `link-credit`, the unit is a potentially large application message, while for `incoming-window`, the unit is a `transfer` frame.\\r\\n\\r\\nTo provide an extreme example for better understanding: if the negotiated `max-frame-size` on the connection is very low and a single message is very large, if the receiver grants one link credit to the sender, the sender might still be blocked by session flow control sending this message in its entirety.\\r\\n\\r\\n`next-incoming-id` and `next-outgoing-id` are sequence numbers and serve the same purpose as the [delivery-count](#delivery-count) in link flow control:\\r\\nthey ensure that the windows are computed correctly on the other side when `transfer` frames are sent in parallel with `flow` frames.\\r\\nTwo sequence numbers are needed for session flow control as opposed to one for link flow control because a session is bidirectional, while a link is unidirectional.\\r\\n\\r\\nInitially, RabbitMQ allows the publisher to send [400](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.6/deps/rabbit/src/rabbit_amqp_session.erl#L60) transfer frames.\\r\\nWhenever the RabbitMQ session process has processed half of that number (200 transfer frames), RabbitMQ expands this window by sending a `flow` frame to the publisher containing `incoming_window = 400`.\\r\\n\\r\\nThe value of `400` is configurable via [advanced.config](/docs/configure#advanced-config-file) setting `rabbit.max_incoming_window`.\\r\\n\\r\\n### RabbitMQ Alarms\\r\\n\\r\\nThe only exception to this rule is when a [memory or disk alarm](/docs/alarms) is triggered.\\r\\nTo protect RabbitMQ from running out of memory or disk space, each session will close its incoming window by sending a `flow` frame with `incoming_window = 0` to publishers, effectively preventing them from sending any further `transfer` frames.\\r\\n\\r\\n:::tip[Benefit #9]\\r\\n\\r\\n**In the event of a cluster wide memory or disk alarm, RabbitMQ will block AMQP 1.0 clients only from publishing `transfer` frames.\\r\\nOther operations, such as AMQP 1.0 clients consuming on the same session or creating new connections that only consume in order to empty queues in RabbitMQ (thereby reducing memory and disk usage), will still be allowed.**\\r\\n\\r\\nIn AMQP 0.9.1, RabbitMQ will block reading from the connection socket entirely and prevent opening new connections until the alarm clears.\\r\\nAMQP 0.9.1 clients must use separate connections for publishing and consuming to continue consuming during an alarm.\\r\\n\\r\\n:::\\r\\n\\r\\n:::tip[Benefit #10]\\r\\n\\r\\nAs described in Benefits #4 and #9, **because clients can safely and efficiently use a single AMQP 1.0 connection for both publishing and consuming, memory usage is reduced in RabbitMQ**.\\r\\n\\r\\nAMQP 0.9.1 practically requires twice the number of connections compared to AMQP 1.0.\\r\\nThe [AMQP 1.0 Benchmarks](/blog/2024/08/21/amqp-benchmarks#many-connections) provide insights into how much memory could be saved.\\r\\n\\r\\n:::\\r\\n\\r\\n### Incoming-Window\\r\\n\\r\\nThe disadvantage of AMQP 1.0 flow control is its complexity.\\r\\nWhile the ideas and motivations behind link flow control and session flow control are sound, implementing one layer (session flow control) on top of another layer (link flow control) can be challenging to get right and efficient in every scenario.\\r\\nConsider that clients can:\\r\\n* Modify session flow control and link flow control independently (either in the same `flow` frame or in separate `flow` frames).\\r\\n* Send a `flow` frame at any time and at different frequencies.\\r\\n* Dynamically increase or decrease either the session window or the link credit.\\r\\n* Grant a link-credit of 0 (causing the queue to stop sending) or a huge number of link credits (up to 4 billion).\\r\\n* Close its session `incoming-window` (causing the server session to stop sending) or open it widely (up to 4 billion).\\r\\n* Stop reading from its socket, applying TCP backpressure to the server.\\r\\n* Add other special logic, such as `drain=true`, into the mix.\\r\\n\\r\\nIn AMQP 1.0 programs, concurrency is desirable.\\r\\nDepending on the programming language, different parts of the client or broker are implemented by different threads or processes.\\r\\n\\r\\nRabbitMQ achieves concurrency by running the [connection reader process](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.6/deps/rabbit/src/rabbit_amqp_reader.erl) (parsing frames), [connection writer process](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.6/deps/rabbit/src/rabbit_amqp_writer.erl) (serializing frames), [session process](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.6/deps/rabbit/src/rabbit_amqp_session.erl) (e.g. routing messages), and [queue process](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.6/deps/rabbit/src/rabbit_amqqueue_process.erl) (storing and forwarding messages) in different [Erlang processes](https://www.erlang.org/doc/system/ref_man_processes.html).\\r\\n\\r\\nIn a scenario where the client grants a huge number of `link-credit` to the sending queue but maintains a very small session `incoming-window`, queue processes are allowed to deliver messages, while the session process is not allowed to forward them to the client.\\r\\nIn this case, messages are buffered in the session process until the client\'s `incoming-window` allows them to be forwarded.\\r\\n\\r\\nTo guard against this scenario - where a large number of messages could be buffered in the session process - RabbitMQ, in its current implementation, internally grants link credits from the session process to the queue process in batches of at most 256 link credits.\\r\\nEven if the client grants a large number of link credits, the queue will only ever see up to 256 credits for a given consumer.\\r\\nOnce these 256 messages have been sent out by the server session process, the server session process will grant the next batch of 256 credits to the queue.\\r\\n\\r\\nThe value of `256` is configurable via [advanced.config](/docs/configure#advanced-config-file) setting `rabbit.max_queue_credit`.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nThis blog post explained how AMQP 1.0 link flow control and session flow control work.\\r\\n\\r\\nWe learned how individual processes within RabbitMQ protect themselves from overload:\\r\\n* Queue processes are protected by link flow control.\\r\\n* Session processes and RabbitMQ as a whole are protected by session flow control.\\r\\n* Connection reader processes are protected by applying TCP backpressure when they cannot read frames quickly enough (which should be rare).\\r\\n\\r\\nThis blog post also highlighted ten benefits of flow control in AMQP 1.0 over flow control in AMQP 0.9.1.\\r\\nThe main advantages include:\\r\\n* Fine-grained control for consumers, allowing them to determine at any point in time the exact number of messages they want to consume from specific queue(s).\\r\\n* Higher throughput for publishing and consuming on a single AMQP connection when a target queue reaches its limits. We ran two benchmarks:\\r\\n  1. Total send throughput of AMQP 1.0 was four times higher than AMQP 0.9.1 when sending to two different target queues.\\r\\n  1. In an extreme case, consumption rate of AMQP 1.0 was 73 times higher than AMQP 0.9.1 when receiving from one queue while sending too fast to another queue.\\r\\n* Safe and efficient usage of a single connection for both publishing and consuming.\\r\\n* The ability for consumers to stop and resume at any time.\\r\\n* Extensibility for future use cases."},{"id":"/2024/08/28/quorum-queues-in-4.0","metadata":{"permalink":"/rabbitmq-website/blog/2024/08/28/quorum-queues-in-4.0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-08-28-quorum-queues-in-4.0/index.md","source":"@site/blog/2024-08-28-quorum-queues-in-4.0/index.md","title":"RabbitMQ 4.0: New Quorum Queue Features","description":"RabbitMQ 4.0 (currently in beta) includes new quorum queue features:","date":"2024-08-28T00:00:00.000Z","tags":[{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"},{"inline":true,"label":"Quorum Queues","permalink":"/rabbitmq-website/blog/tags/quorum-queues"}],"readingTime":11.48,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"RabbitMQ 4.0: New Quorum Queue Features","tags":["RabbitMQ 4.0","Quorum Queues"],"image":"./rabbitmq-4.0-thumbnail.png","authors":["kura"]},"unlisted":false,"prevItem":{"title":"Ten Benefits of AMQP 1.0 Flow Control","permalink":"/rabbitmq-website/blog/2024/09/02/amqp-flow-control"},"nextItem":{"title":"AMQP 1.0 Benchmarks","permalink":"/rabbitmq-website/blog/2024/08/21/amqp-benchmarks"}},"content":"RabbitMQ 4.0 (currently in beta) includes new quorum queue features:\\r\\n* message priorities\\r\\n* consumer priorities combined with Single Active Consumer\\r\\n* default delivery limit is now 20 (breaking change!)\\r\\n* faster recovery of long queues\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Message Priorities\\r\\n\\r\\nSupport for message priorities has been probably the most demanded quorum queue feature,\\r\\nmostly requested by existing classic mirrored queue users who wanted to migrate to quorum queues\\r\\n(remember, [support for classic queue mirroring was removed for 4.0](https://www.rabbitmq.com/docs/3.13/ha)).\\r\\n\\r\\nHowever, the way priorities are supported is significantly different compared to how classic queues\\r\\nhandle them. Classic queues require `x-max-priority` argument to define the maximum\\r\\nnumber of priorities for a given queue (if this argument is not provided, the queue will treat\\r\\nall messages equally). Values from 0 to 255 are technically allowed, although\\r\\nno more than a handful of priorities per queue should really be used. Quorum queues don\'t require\\r\\nany upfront declaration (no need to enable priorities for a given queue), but there are exactly\\r\\ntwo priorities per queue: normal and high. The behavior matches that of AMQP 1.0 specification\\r\\n(see [chapter 3.2.1 of the AMQP 1.0 specification](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-header)):\\r\\n* a priority value between 0 and 4 (inclusive) is treated as the normal priority\\r\\n* any value above 4 is considered a high priority\\r\\n* if the publisher doesn\'t specify the priority of a message, the value of `4` is assumed (normal priority)\\r\\n\\r\\nIf a quorum queue contains both normal and high priority messages, consumers will receive a mix of\\r\\nboth, with a ratio of 2 high priority messages for every 1 normal priority message. This approach\\r\\navoids [starvation](https://en.wikipedia.org/wiki/Starvation_(computer_science)), since regardless\\r\\nof the number of high priority messages, a progress is made on processing the normal priority messages as well.\\r\\nThis is in contrast with the classic queue implementation, which will always deliver higher priority\\r\\nmessages first, if there are any, and therefore the normal priority messages may never get delivered (or, more likely,\\r\\ntheir delivery latency will be very high).\\r\\n\\r\\nHere\'s a visual representation of how this works. In preparation for this test, we first published 100k\\r\\nnormal priority messages and then 100k high priority messages. Since quorum queues were not priority-aware until 4.0,\\r\\nif we did that in an older version and then start a consumer, it would simply receive the normal priority messages first\\r\\n(as they are older) and then all the high priority messages. With 4.0, we can see that the consumer\\r\\nimmediately starts receiving a mix of about 1500 normal priority messages per second and twice as many high priority\\r\\nmessages, for a total of ~4500 messages per second (the actual delivery rates are not important here,\\r\\nthey depend on many factors; the 2:1 high/normal priority ratio is what matters in the context of priorities).\\r\\nOnce the queue delivers all the high priority messages, the consumer starts receiving ~4500 normal priority\\r\\nmessages per second - as many as it can handle in this test scenario. The blue dotted line (with the axis\\r\\nscale on the right) is the number of ready messages in the queue (total for both priorities) - we can see it\\r\\nstarts at 200k and ultimately drops to zero.\\r\\n\\r\\n![Consumer receives a mix of high (yellow) and normal priority (green) messages](message-priorities-low-first.png)\\r\\n\\r\\nLet\'s consider the opposite scenario - what if we publish all the high priority\\r\\nmessages first and only then all the normal priority messages? In this case, the consumer will receive the messages\\r\\nin order of publishing. There\'s simply no reason for a normal priority message to overtake a higher priority message.\\r\\n\\r\\n![Normal priority messages (green) don\'t overtake high priority (yellow) messages published first](message-priorities-high-first.png)\\r\\n\\r\\n<details>\\r\\n    <summary>How Was This Test Performed?</summary>\\r\\n\\r\\n    For this test we used [omq](https://github.com/rabbitmq/omq), a testing client for AMQP 1.0, MQTT and STOMP.\\r\\n    The quorum queue behaviour doesn\'t depend on the protocol used - an AMQP 1.0 was simply used because\\r\\n    `omq` emits message consumption metrics by message priority.\\r\\n    ```\\r\\n    # declare a quorum queue (you can use the Management UI or any other method)\\r\\n    rabbitmqadmin declare queue name=qq queue_type=quorum\\r\\n    # publish normal priority messages (10 publishers, 10k messages each)\\r\\n    omq amqp --publishers 10 --consumers 0 --publish-to /queues/qq --message-priority 1 --pmessages 10000\\r\\n    # publish high priority messages\\r\\n    omq amqp --publishers 10 --consumers 0 --publish-to /queues/qq --message-priority 10 --pmessages 10000\\r\\n    # consume all messages from the queue\\r\\n    omq amqp --publishers 0 --consumers 1 --consume-from /queues/qq --consumer-credits 100\\r\\n    ```\\r\\n    For the second scenario, just run the publishing commands in the reverse order.\\r\\n</details>\\r\\n\\r\\n### What If I Need More Control?\\r\\n\\r\\nIf two priorities with a 2:1 delivery ratio doesn\'t meet your requirements, we can recommend two things:\\r\\n\\r\\n1. Reconsider your requirements. :smile: Reasoning about the message delivery order with many priorities\\r\\nis really hard. It\'s probably easier to make sure that all your messages are delivered sufficiently quickly\\r\\nand use the priorities just to make sure that in case of an occasional long backlog, important messages\\r\\ncan skip the queue.\\r\\n1. If you really need more priorities and/or more control over how different priorities are handled,\\r\\nusing multiple queues is your best bet. You can develop a consumer that subscribes to multiple queues\\r\\nand then decides which queue to consume from.\\r\\n\\r\\n## Consumer Priorities Combined with Single Active Consumer\\r\\n\\r\\nStarting with RabbitMQ 4.0, quorum queues will take the consumer priority into account when selecting the single active consumer.\\r\\nIf a higher priority becomes available (subscribes), a quorum queue will switch over to it.\\r\\nThis is particularly useful if you have multiple queues that should have a single consumer each, but you don\'t want\\r\\na single instance of your application to be the consumer for all of them, which is likely to happen when the first\\r\\napplication instance that starts, subscribes to all those single-active-consumer queues. Now you can pick a different priority\\r\\nwhen subscribing to different queues, to make sure that each instance consumes only from its \\"favorite\\" queue and only serves\\r\\nas a backup consumer for other queues.\\r\\n\\r\\n\\r\\nTo better explain this functionality, let\'s review all the moving parts.\\r\\nA [Single Active Consumer](/docs/consumers#single-active-consumer) is a queue argument which\\r\\nprevents a queue from delivering messages to more than one consumer, regardless of how many\\r\\nsubscribed to the queue. One consumer is active, all other consumers are not. If the active\\r\\nconsumer disconnects, one of the other consumers is activated. This feature is used\\r\\nif a strict message processing order needs to be maintained.\\r\\n\\r\\n[Consumer Priority](/docs/consumers#priority) allows you to specify that rather than delivering\\r\\nmessages to all subscribed consumers in a fair round-robin fashion (which is the default behavior\\r\\nof both classic and quorum queues), a certain consumer should be preferred.\\r\\n\\r\\nUntil version 4.0, these features were effectively mutually exclusive - if Single Active Consumer was enabled,\\r\\na new consumer would never become active, regardless of its priority, as long as the previous consumer remained active.\\r\\nStarting with 4.0, if the new consumer\'s priority is higher than the currently active consumer\'s, the quorum queue\\r\\nwill switch over to the higher priority consumer: it will stop delivering messages to the current\\r\\nconsumer, wait for all the messages to be acknowledged, and then will deactivate the old consumer,\\r\\nand activate the higher priority consumer instead.\\r\\n\\r\\nThe graph below shows this behavior. There are three metrics on this graph:\\r\\n* the green line shows the number of messages consumed by the first (default priority) consumer (which happens to be configured to consume 10 msgs/s)\\r\\n* yellow, shows the same value but for the second, higher priority consumer\\r\\n* blue, shows the number of unacknowledged messages (axis scale on the right)\\r\\n\\r\\n![Single Active Consumer switchover: the normal-priority consumer (green) gets deactivated after it has acknowledged its messages, then the higher-priority consumer (yellow) gets activated](sac-and-consumer-priority.png)\\r\\n\\r\\nInitially, we only have one consumer and as expected, it consumes 9-10 msgs/s (these jumps between 9 and 10\\r\\nare simply a result of how the metrics are emitted and then displayed). This consumer is configured with the prefetch\\r\\nof 1000 messages and since there were many messages in the queue - the prefetch buffer is used to the maximum.\\r\\nThen the yellow line appears, initially at 0 msgs/s. This is the higher priority consumer, which is already connected,\\r\\nbut not yet active. From the moment it connected, we can see the number of unacknowledged messages going down, since the\\r\\nqueue no longer delivers messages to the original consumer. Once all of them are acknowledged, the new consumer\\r\\nbecomes the single active consumer and receives 1000 messages, since that\'s its prefetch value. It then happily\\r\\nconsumes around 10 msgs/s as configured.\\r\\n\\r\\n<details>\\r\\n    <summary>How Was This Test Performed?</summary>\\r\\n\\r\\n    For this test we used [perf-test](https://perftest.rabbitmq.com/), a testing client for AMQP 0.9.1.\\r\\n    ```\\r\\n    # Publish 5000 messages to have a backlog (perf-test will declare a quorum queue `qq-sac`)\\r\\n    perf-test --quorum-queue --queue qq-sac --pmessages 5000 --confirm 100 -qa x-single-active-consumer=true --consumers 0\\r\\n    # Start a consumer with the default priority and prefetch of 1000; consume ~10 msgs/s\\r\\n    perf-test --producers 0 --predeclared --queue qq-sac --consumer-latency 100000 --qos 1000\\r\\n    # In another window, some time after starting the first consumer, start a higher priority consumer\\r\\n    perf-test --producers 0 --predeclared --queue qq-sac --consumer-latency 100000 --qos 1000 --consumer-args x-priority=10\\r\\n    ```\\r\\n    After some time you should see that the first consumer stopped receiving messages (no more output from `perf-test`),\\r\\n    while the second one receives messages.\\r\\n</details>\\r\\n\\r\\n:::note\\r\\nThe settings used in this example were chosen to highlight the switchover process and are not great for\\r\\nreal world scenarios. If a consumer can only process 10 msgs/s, there\'s usually no reason to configure\\r\\nthe prefetch value as high as 1000.\\r\\n:::\\r\\n\\r\\n## Delivery Limit is Now 20 by Default\\r\\n\\r\\n:::warning\\r\\nThis can be a breaking change for some applications\\r\\n:::\\r\\n\\r\\nQuorum queues now have [the delivery limit](https://www.rabbitmq.com/docs/quorum-queues#poison-message-handling) set to 20 by default.\\r\\nIn the past, the limit wasn\'t set and therefore was quorum queues would attempt the delivery forever,\\r\\nuntil the message is either acknowledged or discarded by the consumer. This could lead to a situation\\r\\nwhere a message is stuck in the queue and can never be delivered.\\r\\n\\r\\nThe downside of this change is that if dead lettering is not configured, messages will be dropped after 20 attempts.\\r\\nTherfore, it is highly recommended to configure dead lettering for all quorum queues.\\r\\n\\r\\n## Faster Recovery of Long Queues\\r\\n\\r\\nThis is less of a feature and more an internal change, but certainly worth mentioning. Up until now,\\r\\nif a RabbitMQ node was restarted, all quorum queues on that node had to read through all of their data\\r\\n(the Raft log) since the last snapshot to re-build their in-memory state. For example, if you publish a few million\\r\\nmessages to a quorum queue right now and then restart a node, you will see that after the node is up, the queue\\r\\nwill report `0` ready messages for quite some time (at least a few seconds) and you won\'t be able\\r\\nto start consuming these messages. The queue is simply not yet ready to serve traffic - it\'s still reading\\r\\nthe data from disk (note: this doesn\'t mean that all that data is then kept in memory, a vast majority\\r\\nof it is not, but an index / summary of the queue data is). Starting with RabbitMQ 4.0, quorum queues create\\r\\ncheckpoint files which include the state of the queue at a certain point in time. Upon startup, the queue\\r\\ncan read the most recent checkpoint and only the part of the Raft log from that point in time. These means\\r\\nthat quorum queues take significantly less time to start.\\r\\n\\r\\nFor example, a RabbitMQ node with one quorum queue containing 10 million 12-byte messages, takes\\r\\nabout 30 seconds to start on my machine. With RabbitMQ 4.0, it just takes a fraction of a second.\\r\\n\\r\\nYou may wonder what the difference is between a snapshot and a checkpoint. In many ways, they are the same - they actually\\r\\nshare the code that writes them to disk. The difference is that a snapshot is only created when the Raft log is truncated.\\r\\nFor many common queue use cases, this all that is needed - older messages are consumed, we create a snapshot that no longer\\r\\ncontains them and we truncate the log. At this point the queue has no memory of those messages ever being present.\\r\\nCheckpoints on the other hand, are created periodicailly when we can\'t truncate the log. The test case scenario is a good\\r\\nexample - since we didn\'t consume any messages, the oldest messages are still there, we can\'t just forget about them.\\r\\nBut a checkpoint still allows the queue to start more quickly. A checkpoint can be promoted to a snapshot when the log\\r\\nis truncated (in this example - after some of the older messages are consumed).\\r\\n\\r\\n<details>\\r\\n    <summary>How Can I Try This?</summary>\\r\\n\\r\\n    Once again, we\'ll use [perf-test](https://perftest.rabbitmq.com/) to declare the queue and publish messages\\r\\n    ```\\r\\n    # Publish 10 million 12-byte messages (feel free to play with other values)\\r\\n    perf-test --quorum-queue --queue qq --consumers 0 --pmessages 5000000 --confirm 1000 --producers 2\\r\\n    # restart the node\\r\\n    rabbitmqctl stop_app && rabbitmqctl start_app\\r\\n    # list the queues (repeat this command until the number of messages is 10 million instead of 0)\\r\\n    rabbitmqctl list_queues\\r\\n    ```\\r\\n</details>\\r\\n\\r\\n## Summary\\r\\n\\r\\nRabbitMQ 4.0 is a significant milestone for RabbitMQ. With the removal of classic queue mirroring, quorum queues\\r\\nbecome the only option for highly available, replicated queues (note: [streams are also highly available and replicated,\\r\\nbut technically not queues](https://www.rabbitmq.com/blog/2021/07/13/rabbitmq-streams-overview#what-are-rabbitmq-streams);\\r\\nnevertheless, they might still be a good choice for some use cases where classic mirrored queues were used in the past).\\r\\nQuorum queues have offered higher data safety guarantees and much better performance than mirrored queues for years\\r\\nand with these latest improvements, they become even more robust and performant in a wider range of scenarios.\\r\\n\\r\\nYou can play with RabbitMQ 4.0 beta now:\\r\\nhttps://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0-beta.5"},{"id":"/2024/08/21/amqp-benchmarks","metadata":{"permalink":"/rabbitmq-website/blog/2024/08/21/amqp-benchmarks","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-08-21-amqp-benchmarks/index.md","source":"@site/blog/2024-08-21-amqp-benchmarks/index.md","title":"AMQP 1.0 Benchmarks","description":"This blog post demonstrates that native AMQP 1.0 in RabbitMQ 4.0 provides significant performance and scalability improvements compared to AMQP 1.0 in RabbitMQ 3.13.","date":"2024-08-21T00:00:00.000Z","tags":[{"inline":true,"label":"AMQP 1.0","permalink":"/rabbitmq-website/blog/tags/amqp-1-0"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"},{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":16.905,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"AMQP 1.0 Benchmarks","tags":["AMQP 1.0","RabbitMQ 4.0","Performance"],"authors":["dansari"],"image":"./throughput-classic-queue.svg"},"unlisted":false,"prevItem":{"title":"RabbitMQ 4.0: New Quorum Queue Features","permalink":"/rabbitmq-website/blog/2024/08/28/quorum-queues-in-4.0"},"nextItem":{"title":"Package Repository Updates","permalink":"/rabbitmq-website/blog/2024/08/11/package-repository-updates"}},"content":"This blog post demonstrates that [native AMQP 1.0](/blog/2024/08/05/native-amqp) in RabbitMQ 4.0 provides significant performance and scalability improvements compared to AMQP 1.0 in RabbitMQ 3.13.\\r\\n\\r\\nAdditionally, this blog post suggests that AMQP 1.0 can perform slightly better than AMQP 0.9.1 in RabbitMQ 4.0.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n<details>\\r\\n<summary>Setup</summary>\\r\\n\\r\\nThe following setup applies to all benchmarks in this blog post:\\r\\n* Intel NUC 11\\r\\n* 8 CPU cores\\r\\n* 32 GB RAM\\r\\n* Ubuntu 22.04\\r\\n* Single node RabbitMQ server\\r\\n* Server runs with (only) 3 scheduler threads (set via [runtime flags](https://www.erlang.org/doc/apps/erts/erl_cmd.html#emulator-flags) as `+S 3`)\\r\\n* Erlang/OTP 27.0.1\\r\\n* Clients and server run on the same box\\r\\n\\r\\nWe use the latest RabbitMQ versions at the time of writing:\\r\\n* [v4.0.0-beta.5](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0-beta.5)\\r\\n* [v3.13.6](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.13.6)\\r\\n\\r\\nThe following [advanced.config](/docs/configure#advanced-config-file) is applied:\\r\\n\\r\\n```erl\\r\\n[\\r\\n {rabbit, [\\r\\n  {loopback_users, []}\\r\\n ]},\\r\\n\\r\\n {rabbitmq_management_agent, [\\r\\n  {disable_metrics_collector, true}\\r\\n ]}\\r\\n].\\r\\n```\\r\\n\\r\\nMetrics collection is disabled in the `rabbitmq_management_agent` plugin.\\r\\nFor [production environments](https://www.rabbitmq.com/docs/production-checklist), [Prometheus](https://www.rabbitmq.com/docs/prometheus) is the recommended option.\\r\\n\\r\\nRabbitMQ server is started as follows:\\r\\n```bash\\r\\nmake run-broker \\\\\\r\\n    TEST_TMPDIR=\\"$HOME/scratch/rabbit/test\\" \\\\\\r\\n    RABBITMQ_CONFIG_FILE=\\"$HOME/scratch/rabbit/advanced.config\\" \\\\\\r\\n    PLUGINS=\\"rabbitmq_prometheus rabbitmq_management rabbitmq_amqp1_0\\" \\\\\\r\\n    RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\\"+S 3\\"\\r\\n```\\r\\nThe `rabbitmq_amqp1_0` plugin is a [no-op plugin](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.5/deps/rabbitmq_amqp1_0/README.md) in RabbitMQ 4.0.\\r\\n\\r\\nThe AMQP 1.0 benchmarks run [quiver](https://github.com/ssorj/quiver) in a Docker container:\\r\\n```\\r\\n$ docker run -it --rm --add-host host.docker.internal:host-gateway ssorj/quiver:latest\\r\\nbash-5.1# quiver --version\\r\\nquiver 0.4.0-SNAPSHOT\\r\\n```\\r\\n</details>\\r\\n\\r\\n## Classic Queues\\r\\n\\r\\nThis section benchmarks [classic queues](/docs/classic-queues).\\r\\n\\r\\nWe declare a classic queue called `my-classic-queue`:\\r\\n```bash\\r\\ndeps/rabbitmq_management/bin/rabbitmqadmin declare queue \\\\\\r\\n    name=my-classic-queue queue_type=classic durable=true\\r\\n```\\r\\n\\r\\n### AMQP 1.0 in 4.0\\r\\n\\r\\nThe client sends and receives 1 million messages.\\r\\nEach message contains a payload of 12 bytes.\\r\\nThe receiver repeatedly tops up 200 [link credits](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-flow-control) at a time.\\r\\n\\r\\n```\\r\\n# quiver //host.docker.internal//queues/my-classic-queue \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 200\\r\\n\\r\\nRESULTS\\r\\n\\r\\nCount ............................................. 1,000,000 messages\\r\\nDuration ............................................... 10.1 seconds\\r\\nSender rate .......................................... 99,413 messages/s\\r\\nReceiver rate ........................................ 99,423 messages/s\\r\\nEnd-to-end rate ...................................... 99,413 messages/s\\r\\n\\r\\nLatencies by percentile:\\r\\n\\r\\n          0% ........ 0 ms       90.00% ........ 1 ms\\r\\n         25% ........ 1 ms       99.00% ........ 2 ms\\r\\n         50% ........ 1 ms       99.90% ........ 2 ms\\r\\n        100% ........ 9 ms       99.99% ........ 9 ms\\r\\n```\\r\\n\\r\\n### AMQP 1.0 in 3.13\\r\\n\\r\\n```\\r\\n# quiver //host.docker.internal//amq/queue/my-classic-queue \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 200\\r\\n\\r\\nRESULTS\\r\\n\\r\\nCount ............................................. 1,000,000 messages\\r\\nDuration ............................................... 45.9 seconds\\r\\nSender rate .......................................... 43,264 messages/s\\r\\nReceiver rate ........................................ 21,822 messages/s\\r\\nEnd-to-end rate ...................................... 21,790 messages/s\\r\\n\\r\\nLatencies by percentile:\\r\\n\\r\\n          0% ....... 67 ms       90.00% .... 24445 ms\\r\\n         25% .... 23056 ms       99.00% .... 24780 ms\\r\\n         50% .... 23433 ms       99.90% .... 24869 ms\\r\\n        100% .... 24873 ms       99.99% .... 24873 ms\\r\\n```\\r\\n\\r\\nThe same benchmark against RabbitMQ 3.13 results in 4.5 times lower throughput.\\r\\n\\r\\n<details>\\r\\n<summary>Detailed test execution</summary>\\r\\n```\\r\\n---------------------- Sender -----------------------  --------------------- Receiver ----------------------  --------\\r\\nTime [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Time [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Lat [ms]\\r\\n-----------------------------------------------------  -----------------------------------------------------  --------\\r\\n     2.1        130,814      65,342        8     79.1       2.1          3,509       1,753        1      7.5       777\\r\\n     4.1        206,588      37,849        6     79.1       4.1          5,995       1,242        0      7.5     2,458\\r\\n     6.1        294,650      43,987        6     79.1       6.1          9,505       1,753        1      7.5     5,066\\r\\n     8.1        360,184      32,734        5     79.4       8.1         13,893       2,194        0      7.5     6,190\\r\\n    10.1        458,486      49,102        6     79.4      10.1         15,793         950        1      7.5     9,259\\r\\n    12.1        524,020      32,734        5     79.4      12.1         21,644       2,923        1      7.5    11,163\\r\\n    14.1        622,322      49,102        5     79.4      14.1         25,154       1,753        1      7.5    13,451\\r\\n    16.1        687,856      32,734        4     79.4      16.1         27,639       1,241        1      7.5    15,246\\r\\n    18.1        786,158      49,102        6     81.0      18.1         30,124       1,241        1      7.5    17,649\\r\\n    20.1        884,460      49,102        6     81.0      20.1         32,610       1,242        1      7.5    19,408\\r\\n    22.1        949,994      32,734        4     81.0      22.1         35,535       1,462        0      7.5    21,293\\r\\n    24.1        999,912      24,934        4     81.8      24.1         38,167       1,315        1      7.5    23,321\\r\\n    26.1        999,974          31        2      0.0      26.1        117,745      39,749       11      7.5    24,475\\r\\n       -              -           -        -        -      28.1        202,589      42,380       11      7.5    24,364\\r\\n       -              -           -        -        -      30.1        292,554      44,938       13      7.5    24,244\\r\\n       -              -           -        -        -      32.1        377,691      42,526       15      7.5    23,955\\r\\n       -              -           -        -        -      34.1        469,704      45,961       14      7.5    23,660\\r\\n       -              -           -        -        -      36.1        555,719      42,965       12      7.5    23,463\\r\\n       -              -           -        -        -      38.1        649,048      46,618       12      7.5    23,264\\r\\n       -              -           -        -        -      40.1        737,696      44,280       15      7.5    23,140\\r\\n       -              -           -        -        -      42.1        826,491      44,353       15      7.5    23,100\\r\\n       -              -           -        -        -      44.1        917,187      45,303       16      7.5    23,066\\r\\n       -              -           -        -        -      46.1        999,974      41,394       14      0.0    22,781\\r\\n```\\r\\n</details>\\r\\n\\r\\n### AMQP 0.9.1 in 4.0\\r\\n\\r\\nFor our AMQP 0.9.1 benchmarks we use [PerfTest](https://perftest.rabbitmq.com/).\\r\\nWe try to run a somewhat fair comparison of our previous AMQP 1.0 benchmark.\\r\\n\\r\\nSince an AMQP 1.0 [/queues/:queue](/docs/amqp#target-address-v2) target address sends to the default exchange, we also send to the default exchange via AMQP 0.9.1.\\r\\nSince we used [durable](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-header) messages with AMQP 1.0, we set the `persistent` flag in AMQP 0.9.1.\\r\\nSince RabbitMQ settles with the [released](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-released) outcome when a message cannot be routed, we set the `mandatory` flag in AMQP 0.9.1.\\r\\nSince RabbitMQ `v4.0.0-beta.5` uses a default `rabbit.max_link_credit` of 128 granting 128 more credits to the sending client when remaining credit falls below 0.5 * 128, we configure the AMQP 0.9.1 publisher to have at most 1.5 * 128 = 192 messages unconfirmed at a time.\\r\\nSince we used 200 link credits in the previous run, we configure the AMQP 0.9.1 consumer with a [prefetch](/docs/consumer-prefetch) of 200.\\r\\n\\r\\n```\\r\\n$ java -jar target/perf-test.jar \\\\\\r\\n    --predeclared --exchange amq.default \\\\\\r\\n    --routing-key my-classic-queue --queue my-classic-queue \\\\\\r\\n    --flag persistent --flag mandatory \\\\\\r\\n    --pmessages 1000000 --size 12 --confirm 192 --qos 200 --multi-ack-every 200\\r\\n\\r\\nid: test-151706-485, sending rate avg: 88534 msg/s\\r\\nid: test-151706-485, receiving rate avg: 88534 msg/s\\r\\nid: test-151706-485, consumer latency min/median/75th/95th/99th 99/975/1320/1900/2799 µs\\r\\nid: test-151706-485, confirm latency min/median/75th/95th/99th 193/1691/2113/2887/3358 µs\\r\\n```\\r\\n\\r\\n### Summary {#summary-classic-queues}\\r\\n\\r\\n![Figure 1: Classic queue end-to-end message rate](throughput-classic-queue.svg)\\r\\n\\r\\n## Quorum Queues\\r\\n\\r\\nThis section benchmarks [quorum queues](/docs/quorum-queues).\\r\\n\\r\\nWe declare a quorum queue called `my-quorum-queue`:\\r\\n```bash\\r\\ndeps/rabbitmq_management/bin/rabbitmqadmin declare queue \\\\\\r\\n    name=my-quorum-queue queue_type=quorum durable=true\\r\\n```\\r\\n\\r\\n#### Flow Control Configuration\\r\\n\\r\\nFor highest data safety, quorum queues [fsync](https://man7.org/linux/man-pages/man2/fsync.2.html) all [Ra](https://github.com/rabbitmq/ra) commands including:\\r\\n* [enqueue](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.5/deps/rabbit/src/rabbit_fifo.erl#L144): sender enqueues a message\\r\\n* [settle](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.5/deps/rabbit/src/rabbit_fifo.erl#L149): receiver accepts a message\\r\\n* [credit](https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0-beta.5/deps/rabbit/src/rabbit_fifo.erl#L152): receiver tops up link credit\\r\\n\\r\\nBefore a quorum queue confirms receipt of a message to the publisher, it ensures that any file modifications are flushed to disk, making the data safe even if the RabbitMQ node crashes shortly after.\\r\\n\\r\\nThe SSD of my Linux box is slow, taking 5-15 ms per fsync.\\r\\nSince we want to compare AMQP protocol implementations without being bottlenecked by a cheap disk, the tests in this section increase flow control settings:\\r\\n<details>\\r\\n<summary>`advanced.config`</summary>\\r\\n\\r\\n```\\r\\n[\\r\\n {rabbit, [\\r\\n  {loopback_users, []},\\r\\n\\r\\n  %% RabbitMQ internal flow control for AMQP 0.9.1\\r\\n  %% Default: {400, 200}\\r\\n  {credit_flow_default_credit, {5000, 2500}},\\r\\n\\r\\n  %% Maximum incoming-window of AMQP 1.0 session.\\r\\n  %% Default: 400\\r\\n  {max_incoming_window, 5000},\\r\\n\\r\\n  %% Maximum link-credit RabbitMQ grants to AMQP 1.0 sender.\\r\\n  %% Default: 128\\r\\n  {max_link_credit, 2000},\\r\\n\\r\\n  %% Maximum link-credit RabbitMQ AMQP 1.0 session grants to sending queue.\\r\\n  %% Default: 256\\r\\n  {max_queue_credit, 5000}\\r\\n ]},\\r\\n\\r\\n {rabbitmq_management_agent, [\\r\\n  {disable_metrics_collector, true}\\r\\n ]}\\r\\n].\\r\\n```\\r\\n</details>\\r\\nThis configuration allows more Ra commands to be batched before RabbitMQ calls fsync.\\r\\n**For production use cases, we recommend enterprise-grade high performance disks that fsync faster**, in which case there is likely no need to increase flow control settings.\\r\\n\\r\\nRabbitMQ flow control settings present a trade-off:\\r\\n* Low values ensure stability in production.\\r\\n* High values can result in higher performance for individual connections but may lead to higher memory spikes when many connections publish large messages concurrently.\\r\\n\\r\\nRabbitMQ uses conservative flow control default settings to favour stability in production over winning performance benchmarks.\\r\\n\\r\\n### AMQP 1.0 in 4.0\\r\\n\\r\\n```\\r\\n# quiver //host.docker.internal//queues/my-quorum-queue \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 5000\\r\\n\\r\\nRESULTS\\r\\n\\r\\nCount ............................................. 1,000,000 messages\\r\\nDuration ............................................... 12.0 seconds\\r\\nSender rate .......................................... 83,459 messages/s\\r\\nReceiver rate ........................................ 83,396 messages/s\\r\\nEnd-to-end rate ...................................... 83,181 messages/s\\r\\n\\r\\nLatencies by percentile:\\r\\n\\r\\n          0% ........ 9 ms       90.00% ....... 47 ms\\r\\n         25% ....... 27 ms       99.00% ....... 61 ms\\r\\n         50% ....... 35 ms       99.90% ....... 76 ms\\r\\n        100% ....... 81 ms       99.99% ....... 81 ms\\r\\n```\\r\\n\\r\\n<details>\\r\\n<summary>Default Flow Control Settings</summary>\\r\\n\\r\\nThe previous benchmark calls fsync 1,244 times in the [ra_log_wal](https://github.com/rabbitmq/ra/blob/e95ab7b9df1f8f4ffec8535d60185b3bc33a09bc/src/ra_log_wal.erl#L770) module (that implements the Raft write-ahead log).\\r\\n\\r\\nThe same benchmark with default flow control settings calls fsync 15,493 times resulting in significantly lower throughput:\\r\\n```\\r\\n# quiver //host.docker.internal//queues/my-quorum-queue \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 5000\\r\\n\\r\\nRESULTS\\r\\n\\r\\nCount ............................................. 1,000,000 messages\\r\\nDuration .............................................. 100.2 seconds\\r\\nSender rate ........................................... 9,986 messages/s\\r\\nReceiver rate ......................................... 9,987 messages/s\\r\\nEnd-to-end rate ....................................... 9,983 messages/s\\r\\n\\r\\nLatencies by percentile:\\r\\n\\r\\n          0% ....... 10 ms       90.00% ....... 24 ms\\r\\n         25% ....... 14 ms       99.00% ....... 30 ms\\r\\n         50% ....... 18 ms       99.90% ....... 38 ms\\r\\n        100% ....... 55 ms       99.99% ....... 47 ms\\r\\n```\\r\\n\\r\\nEach fsync took 5.9 ms on average.\\r\\n\\r\\n```\\r\\n(15,493 - 1,244) * 5.9 ms = 84 seconds\\r\\n```\\r\\n\\r\\nTherefore, this benchmark with default flow control settings is blocked for 84 seconds longer executing `fsync` than the previous benchmark with increased flow control settings.\\r\\nThis shows how critical enterprise-grade high performance disks are to get the best results out of quorum queues.\\r\\nFor your production workloads, we recommend using disks with lower `fsync` latency rather than tweaking\\r\\nRabbitMQ flow control settings.\\r\\n\\r\\nIt\'s worth noting that the Raft WAL log is shared by all quorum queue replicas on a given RabbitMQ node.\\r\\nThis means that `ra_log_wal` will automatically batch multiple Raft commands (operations) into a single `fsync`\\r\\ncall when there are dozens of quorum queues with hundreds of connections.\\r\\nConsequently, flushing an individual Ra command to disk becomes cheaper on average when there is more traffic on the node.\\r\\nOur benchmark ran somewhat artificially with a single connection as fast as possible.\\r\\n</details>\\r\\n\\r\\n### AMQP 1.0 in 3.13\\r\\n\\r\\n```\\r\\n# quiver //host.docker.internal//amq/queue/my-quorum-queue \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 5000\\r\\n\\r\\n---------------------- Sender -----------------------  --------------------- Receiver ----------------------  --------\\r\\nTime [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Time [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Lat [ms]\\r\\n-----------------------------------------------------  -----------------------------------------------------  --------\\r\\n     2.1        163,582      81,709       11     84.2       2.1         29,548      14,759        3      7.5       840\\r\\n     4.1        336,380      86,356       12    185.3       4.1         29,840         146        0      7.5     2,331\\r\\n     6.1        524,026      93,729       14    328.0       6.1         29,840           0        0      7.5         0\\r\\n     8.1        687,864      81,837       11    462.3       8.1         31,302         730        1      7.5     6,780\\r\\n    10.1        884,470      98,303       14    605.4      10.1         31,447          72        0      7.5     7,897\\r\\n    12.1        999,924      57,669        7    687.5      12.1         31,447           0        0      7.5         0\\r\\n    14.1        999,924           0        0    687.5      14.1         31,447           0        0      7.5         0\\r\\n    16.1        999,924           0        0    687.5      16.1         31,447           0        1      7.5         0\\r\\n    18.1        999,924           0        1    688.3      18.1         31,447           0        0      7.5         0\\r\\nreceiver timed out\\r\\n    20.1        999,924           0        0    688.3      20.1         31,447           0        0      7.5         0\\r\\n```\\r\\nRabbitMQ 3.13 cannot handle this workload and the benchmark fails.\\r\\n\\r\\n<details>\\r\\n<summary>Default Flow Control Settings</summary>\\r\\n\\r\\nThe benchmark also fails with default flow control settings:\\r\\n```\\r\\n# quiver //host.docker.internal//amq/queue/my-quorum-queue \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 5000\\r\\n\\r\\n---------------------- Sender -----------------------  --------------------- Receiver ----------------------  --------\\r\\nTime [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Time [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Lat [ms]\\r\\n-----------------------------------------------------  -----------------------------------------------------  --------\\r\\n     2.1        130,814      65,342        9     70.0       2.1         26,915      13,437        6      7.5     1,213\\r\\n     4.1        196,348      32,718        5     70.2       4.1         28,084         584        0      7.5     3,093\\r\\n     6.1        261,882      32,734        7     70.2       6.1         30,131       1,022        1      7.5     4,952\\r\\n     8.1        360,184      49,126        6     70.2       8.1         32,325       1,096        0      7.5     6,637\\r\\n    10.1        425,718      32,734        6     70.2      10.1         34,225         949        1      7.5     8,089\\r\\n    12.1        491,252      32,734        5     70.2      12.1         34,225           0        0      7.5         0\\r\\n    14.1        589,554      49,102        7     70.2      14.1         34,225           0        0      7.5         0\\r\\n    16.1        655,088      32,734        5     70.2      16.1         34,225           0        0      7.5         0\\r\\n    18.1        720,622      32,734        6     70.2      18.1         34,225           0        0      7.5         0\\r\\nreceiver timed out\\r\\n```\\r\\n</details>\\r\\n\\r\\n### AMQP 0.9.1 in 4.0\\r\\n\\r\\nSince we set `max_link_credit` to 2,000, we allow for a maximum of 2,000 * 1.5 = 3,000 unconfirmed messages in the publisher.\\r\\n```\\r\\n$ java -jar target/perf-test.jar \\\\\\r\\n    --predeclared --exchange amq.default \\\\\\r\\n    --routing-key my-quorum-queue --queue my-quorum-queue \\\\\\r\\n    --flag persistent --flag mandatory \\\\\\r\\n    --pmessages 1000000 --size 12 --confirm 3000 --qos 5000 --multi-ack-every 5000\\r\\n\\r\\nid: test-085526-136, sending rate avg: 70067 msg/s\\r\\nid: test-085526-136, receiving rate avg: 70067 msg/s\\r\\nid: test-085526-136, consumer latency min/median/75th/95th/99th 8803/33127/40424/53407/62883 µs\\r\\nid: test-085526-136, confirm latency min/median/75th/95th/99th 8551/30323/38317/52103/63131 µs\\r\\n```\\r\\n\\r\\n<details>\\r\\n<summary>Default Flow Control Settings</summary>\\r\\n\\r\\n```\\r\\n$ java -jar target/perf-test.jar \\\\\\r\\n    --predeclared --exchange amq.default \\\\\\r\\n    --routing-key my-quorum-queue --queue my-quorum-queue \\\\\\r\\n    --flag persistent --flag mandatory \\\\\\r\\n    --pmessages 1000000 --size 12 --confirm 192 --qos 5000 --multi-ack-every 5000\\r\\n\\r\\nid: test-084359-441, sending rate avg: 9931 msg/s\\r\\nid: test-084359-441, receiving rate avg: 9931 msg/s\\r\\nid: test-084359-441, consumer latency min/median/75th/95th/99th 7512/17054/26256/34249/38641 µs\\r\\nid: test-084359-441, confirm latency min/median/75th/95th/99th 9432/16586/23918/32636/36858 µs\\r\\n```\\r\\nThese results are similar to the results of the default flow control settings in AMQP 1.0 in 4.0 because both benchmarks are bottlenecked by my slow disk.\\r\\n</details>\\r\\n\\r\\n### Summary {#summary-quorum-queues}\\r\\n\\r\\n![Figure 2: Quorum queue end-to-end message rate](throughput-quorum-queue.svg)\\r\\n\\r\\n## Streams\\r\\n\\r\\nThis sections benchmarks [streams](/docs/streams).\\r\\n\\r\\nWe declare a stream called `my-stream`:\\r\\n```bash\\r\\ndeps/rabbitmq_management/bin/rabbitmqadmin declare queue \\\\\\r\\n    name=my-stream queue_type=stream durable=true\\r\\n```\\r\\n\\r\\n(We run with default RabbitMQ flow control settings.)\\r\\n\\r\\nWe want the receiver to start consuming from the very beginning of the stream.\\r\\nQuiver doesn\'t support passing a `filter` field to the [source](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-source) where we could specify a `rabbitmq:stream-offset-spec` value `first`.\\r\\nTherefore, for this benchmark it\'s easier to patch RabbitMQ to use stream offset spec `first` by default instead of `next`:\\r\\n<details>\\r\\n<summary>git diff</summary>\\r\\n\\r\\n```\\r\\ndiff --git a/deps/rabbit/src/rabbit_stream_queue.erl b/deps/rabbit/src/rabbit_stream_queue.erl\\r\\nindex e36ad708eb..acd193d76f 100644\\r\\n--- a/deps/rabbit/src/rabbit_stream_queue.erl\\r\\n+++ b/deps/rabbit/src/rabbit_stream_queue.erl\\r\\n@@ -344,7 +344,7 @@ consume(Q, Spec, #stream_client{} = QState0)\\r\\n                        {term(), non_neg_integer()}) ->\\r\\n     {ok, osiris:offset_spec()} | {error, term()}.\\r\\n parse_offset_arg(undefined) ->\\r\\n-    {ok, next};\\r\\n+    {ok, first};\\r\\n parse_offset_arg({_, <<\\"first\\">>}) ->\\r\\n     {ok, first};\\r\\n parse_offset_arg({_, <<\\"last\\">>}) ->\\r\\n```\\r\\n</details>\\r\\n\\r\\n### AMQP 1.0 in 4.0\\r\\n```\\r\\n# quiver //host.docker.internal//queues/my-stream \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 5000\\r\\n---------------------- Sender -----------------------  --------------------- Receiver ----------------------  --------\\r\\nTime [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Time [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Lat [ms]\\r\\n-----------------------------------------------------  -----------------------------------------------------  --------\\r\\n     2.1        278,782     139,321       25      8.0       2.1        215,185     107,539       22      7.6       224\\r\\n     4.1        554,492     137,717       25      8.0       4.1        434,027     109,312       24      7.6       651\\r\\n     6.1        825,082     135,160       25      8.0       6.1        650,236     107,997       26      7.6     1,079\\r\\n     8.1        999,992      87,368       17      0.0       8.1        888,973     119,249       29      7.6     1,469\\r\\n       -              -           -        -        -      10.1        999,993      55,455       13      0.0     1,583\\r\\n\\r\\nRESULTS\\r\\n\\r\\nCount ............................................. 1,000,000 messages\\r\\nDuration ................................................ 8.9 seconds\\r\\nSender rate ......................................... 136,705 messages/s\\r\\nReceiver rate ....................................... 112,587 messages/s\\r\\nEnd-to-end rate ..................................... 112,196 messages/s\\r\\n\\r\\nLatencies by percentile:\\r\\n\\r\\n          0% ........ 7 ms       90.00% ..... 1553 ms\\r\\n         25% ...... 519 ms       99.00% ..... 1612 ms\\r\\n         50% ..... 1011 ms       99.90% ..... 1615 ms\\r\\n        100% ..... 1616 ms       99.99% ..... 1616 ms\\r\\n```\\r\\nIt is easy to observe a substantially higher throughput.\\r\\n\\r\\nNote that end-to-end latencies are very high just because the sender can write into the stream at a higher rate than RabbitMQ being able\\r\\nto dispatch messages to the consumer (\\"receiver\\" in `quiver` terms).\\r\\n\\r\\n### AMQP 1.0 in 3.13\\r\\n```\\r\\n# quiver //host.docker.internal//amq/queue/my-stream \\\\\\r\\n    --durable --count 1m --duration 10m --body-size 12 --credit 5000\\r\\n\\r\\n---------------------- Sender -----------------------  --------------------- Receiver ----------------------  --------\\r\\nTime [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Time [s]      Count [m]  Rate [m/s]  CPU [%]  RSS [M]  Lat [ms]\\r\\n-----------------------------------------------------  -----------------------------------------------------  --------\\r\\n     2.1        196,350      98,077       12     70.1       2.1          4,094       2,045        0      7.7       195\\r\\n     4.1        392,956      98,205       13    138.5       4.1          4,094           0        0      7.7         0\\r\\n     6.1        524,026      65,470       10    196.5       6.1          4,094           0        0      7.7         0\\r\\n     8.1        655,096      65,470       11    259.4       8.1          4,094           0        0      7.7         0\\r\\n    10.1        786,166      65,470       10    307.5      10.1          4,094           0        0      7.7         0\\r\\nreceiver timed out\\r\\n    12.1        917,236      65,470        9    355.5      12.1          4,094           0        0      7.7         0\\r\\n```\\r\\nRabbitMQ 3.13 cannot handle this workload and the benchmark fails.\\r\\n\\r\\n### AMQP 0.9.1 in 4.0\\r\\n\\r\\n```\\r\\n$ java -jar target/perf-test.jar \\\\\\r\\n    --predeclared --exchange amq.default \\\\\\r\\n    --routing-key my-stream --queue my-stream \\\\\\r\\n    --flag persistent --flag mandatory \\\\\\r\\n    --pmessages 1000000 --size 12 --confirm 192 --qos 5000 --multi-ack-every 5000\\r\\n\\r\\nid: test-104223-225, sending rate avg: 88912 msg/s\\r\\nid: test-104223-225, receiving rate avg: 88912 msg/s\\r\\nid: test-104223-225, consumer latency min/median/75th/95th/99th 701/1340/1523/2500/4524 µs\\r\\nid: test-104223-225, confirm latency min/median/75th/95th/99th 788/1983/2130/2437/2970 µs\\r\\n```\\r\\n\\r\\nSince streams store messages in AMQP 1.0 format, this workload requires RabbitMQ to translate each message between AMQP 0.9.1 and AMQP 1.0.\\r\\nThis explains why stream throughput is lower when using AMQP 0.9.1 clients compared to AMQP 1.0 clients.\\r\\n\\r\\n### Summary {#summary-streams}\\r\\n\\r\\n![Figure 3: Stream end-to-end message rate](throughput-stream.svg)\\r\\n\\r\\n## Many Connections\\r\\n\\r\\nThis section compares memory usage of connecting 40,000 clients with two AMQP 1.0 sessions / AMQP 0.9.1 channels per connection.\\r\\n\\r\\n<details>\\r\\n<summary>Setup</summary>\\r\\n\\r\\n```bash\\r\\nmake run-broker \\\\\\r\\n    TEST_TMPDIR=\\"$HOME/scratch/rabbit/test\\" \\\\\\r\\n    RABBITMQ_CONFIG_FILE=\\"$HOME/scratch/rabbit/rabbitmq.conf\\" \\\\\\r\\n    PLUGINS=\\"rabbitmq_amqp1_0\\" \\\\\\r\\n    RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\\"+P 3000000 +S 6\\" \\\\\\r\\n    ERL_MAX_PORTS=3000000 \\r\\n```\\r\\n\\r\\nIn the following `rabbitmq.conf`, we use small buffer sizes to better compare the memory usage of the protocol implementations.\\r\\n```ini\\r\\ntcp_listen_options.sndbuf = 2048\\r\\ntcp_listen_options.recbuf = 2048\\r\\nvm_memory_high_watermark.relative = 0.95\\r\\nvm_memory_high_watermark_paging_ratio = 0.95\\r\\nloopback_users = none\\r\\n```\\r\\n\\r\\n<details>\\r\\n<summary>AMQP 1.0</summary>\\r\\n\\r\\n```go\\r\\npackage main\\r\\n\\r\\nimport (\\r\\n\\t\\"context\\"\\r\\n\\t\\"log\\"\\r\\n\\t\\"time\\"\\r\\n\\r\\n\\t\\"github.com/Azure/go-amqp\\"\\r\\n)\\r\\n\\r\\nfunc main() {\\r\\n\\tfor i := 0; i < 40_000; i++ {\\r\\n\\t\\tif i%1000 == 0 {\\r\\n\\t\\t\\tlog.Printf(\\"opened %d connections\\", i)\\r\\n\\t\\t}\\r\\n\\t\\tconn, err := amqp.Dial(\\r\\n\\t\\t\\tcontext.TODO(),\\r\\n\\t\\t\\t\\"amqp://localhost\\",\\r\\n\\t\\t\\t&amqp.ConnOptions{SASLType: amqp.SASLTypeAnonymous()})\\r\\n\\t\\tif err != nil {\\r\\n\\t\\t\\tlog.Fatal(\\"open connection:\\", err)\\r\\n\\t\\t}\\r\\n\\t\\t_, err = conn.NewSession(context.TODO(), nil)\\r\\n\\t\\tif err != nil {\\r\\n\\t\\t\\tlog.Fatal(\\"begin session:\\", err)\\r\\n\\t\\t}\\r\\n\\t\\t_, err = conn.NewSession(context.TODO(), nil)\\r\\n\\t\\tif err != nil {\\r\\n\\t\\t\\tlog.Fatal(\\"begin session:\\", err)\\r\\n\\t\\t}\\r\\n\\t}\\r\\n\\tlog.Println(\\"opened all connections\\")\\r\\n\\ttime.Sleep(5 * time.Hour)\\r\\n}\\r\\n```\\r\\n</details>\\r\\n\\r\\n<details>\\r\\n<summary>AMQP 0.9.1</summary>\\r\\n\\r\\n```go\\r\\npackage main\\r\\n\\r\\nimport (\\r\\n\\t\\"log\\"\\r\\n\\t\\"time\\"\\r\\n\\r\\n\\tamqp \\"github.com/rabbitmq/amqp091-go\\"\\r\\n)\\r\\n\\r\\nfunc main() {\\r\\n\\tfor i := 0; i < 40_000; i++ {\\r\\n\\t\\tif i%1000 == 0 {\\r\\n\\t\\t\\tlog.Printf(\\"opened %d connections\\", i)\\r\\n\\t\\t}\\r\\n\\t\\tconn, err := amqp.Dial(\\"amqp://guest:guest@localhost\\")\\r\\n\\t\\tif err != nil {\\r\\n\\t\\t\\tlog.Fatal(\\"open connection:\\", err)\\r\\n\\t\\t}\\r\\n\\t\\t_, err = conn.Channel()\\r\\n\\t\\tif err != nil {\\r\\n\\t\\t\\tlog.Fatal(\\"open channel:\\", err)\\r\\n\\t\\t}\\r\\n\\t\\t_, err = conn.Channel()\\r\\n\\t\\tif err != nil {\\r\\n\\t\\t\\tlog.Fatal(\\"open channel:\\", err)\\r\\n\\t\\t}\\r\\n\\t}\\r\\n\\tlog.Println(\\"opened all connections\\")\\r\\n\\ttime.Sleep(5 * time.Hour)\\r\\n}\\r\\n```\\r\\n</details>\\r\\n</details>\\r\\n\\r\\nThe examples below directly invoke [`erlang:memory/0`](https://www.erlang.org/doc/apps/erts/erlang.html#memory/0) on the node,\\r\\na function that returns the memory size in bytes for each memory type.\\r\\n\\r\\n<details>\\r\\n<summary>`rabbitmq-diagnostics`</summary>\\r\\n\\r\\nTo retrieve the same information from a running node, use [CLI](/docs/cli) command [rabbitmq-diagnostics](/docs/man/rabbitmq-diagnostics.8) like so:\\r\\n\\r\\n``` shell\\r\\nrabbitmq-diagnostics memory_breakdown\\r\\n```\\r\\n\\r\\nThis command can format the numbers using different information units (e.g. MiB, GiB) and supports JSON\\r\\noutput with `--formatter=json`:\\r\\n\\r\\n``` shell\\r\\n# pipes the output to `jq` for more readable formatting\\r\\nrabbitmq-diagnostics memory_breakdown --formatter=json | jq\\r\\n```\\r\\n</details>\\r\\n\\r\\n### AMQP 1.0 in 4.0\\r\\n\\r\\nHere are the runtime-reported memory footprint numbers:\\r\\n\\r\\n```erlang\\r\\n1> erlang:memory().\\r\\n[{total,5330809208},\\r\\n {processes,4788022888},\\r\\n {processes_used,4787945960},\\r\\n {system,542786320},\\r\\n {atom,999681},\\r\\n {atom_used,974364},\\r\\n {binary,194810368},\\r\\n {code,19328950},\\r\\n {ets,94161808}]\\r\\n\\r\\n2> erlang:system_info(process_count).\\r\\n360312\\r\\n```\\r\\n\\r\\n### AMQP 1.0 in 3.13\\r\\n\\r\\nTo compare, the runtime-reported memory footprint numbers in this test are:\\r\\n\\r\\n```erlang\\r\\n1> erlang:memory().\\r\\n[{total,12066294144},\\r\\n {processes,11156497904},\\r\\n {processes_used,11156461208},\\r\\n {system,909796240},\\r\\n {atom,1089809},\\r\\n {atom_used,1062780},\\r\\n {binary,192784464},\\r\\n {code,22068126},\\r\\n {ets,318872128}]\\r\\n\\r\\n2> erlang:system_info(process_count).\\r\\n1480318\\r\\n```\\r\\n\\r\\nWe observe that the memory usage of `processes` in RabbitMQ 3.13 is 11.1 GB compared to only 4.8 GB in RabbitMQ 4.0 (a reduction of about 56%).\\r\\nAs explained in the [previous](/blog/2024/08/05/native-amqp#amqp-10-in-rabbitmq-313) blog post, the RabbitMQ 3.13 implementation of AMQP 1.0 is resource heavy because each AMQP 1.0 session in the plugin includes an AMQP 0.9.1 client and maintains AMQP 0.9.1 state.\\r\\n\\r\\n### AMQP 0.9.1 in 4.0\\r\\n```erlang\\r\\n1> erlang:memory().\\r\\n[{total,5409763512},\\r\\n {processes,4716150248},\\r\\n {processes_used,4715945080},\\r\\n {system,693613264},\\r\\n {atom,991489},\\r\\n {atom_used,962578},\\r\\n {binary,187229040},\\r\\n {code,19118766},\\r\\n {ets,235605424}]\\r\\n\\r\\n2> erlang:system_info(process_count).\\r\\n600314\\r\\n```\\r\\n\\r\\n### Summary {#summary-many-connections}\\r\\n\\r\\n![Figure 4: Memory usage of 40,000 connections and 80,000 sessions / channels](memory-many-connections.svg)\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nThis blog post demonstrated that the new native AMQP 1.0 implementation in RabbitMQ 4.0 performs multiple times better than AMQP 1.0 in RabbitMQ 3.13.\\r\\n\\r\\nWe also observed that AMQP 1.0 can perform better than AMQP 0.9.1.\\r\\nHowever, it’s challenging to provide a fair comparison.\\r\\nThis blog post used an AMQP 1.0 client written in C and an AMQP 0.9.1 client written in Java.\\r\\nTherefore, we do not claim or promise that you will observe better throughput with your AMQP 1.0 workloads.\\r\\nThe AMQP 0.9.1 implementation in RabbitMQ performs well since it has been stable and optimized for over 15 years.\\r\\n\\r\\nUse cases where AMQP 1.0 will likely outperform AMQP 0.9.1 include:\\r\\n* Sending to or receiving from a stream because a stream encodes messages in AMQP 1.0 format (as covered in this blog post).\\r\\n* Leveraging queue locality using the [RabbitMQ AMQP 1.0 Java client](https://github.com/rabbitmq/rabbitmq-amqp-java-client). (This feature will be covered separately.)\\r\\n* Publishing to or consuming from other queues when one target queue reaches its limits on the same connection (as covered in the [AMQP 1.0 flow control](/blog/2024/09/02/amqp-flow-control) blog post)."},{"id":"/2024/08/11/package-repository-updates","metadata":{"permalink":"/rabbitmq-website/blog/2024/08/11/package-repository-updates","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-08-11-package-repository-updates/index.md","source":"@site/blog/2024-08-11-package-repository-updates/index.md","title":"Package Repository Updates","description":"Team RabbitMQ has two updates related to our Debian and RPM repositories:","date":"2024-08-11T00:00:00.000Z","tags":[{"inline":true,"label":"announcements","permalink":"/rabbitmq-website/blog/tags/announcements"},{"inline":true,"label":"packages","permalink":"/rabbitmq-website/blog/tags/packages"}],"readingTime":1.15,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Package Repository Updates","tags":["announcements","packages"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"AMQP 1.0 Benchmarks","permalink":"/rabbitmq-website/blog/2024/08/21/amqp-benchmarks"},"nextItem":{"title":"Native AMQP 1.0","permalink":"/rabbitmq-website/blog/2024/08/05/native-amqp"}},"content":"Team RabbitMQ has two updates related to our Debian and RPM repositories:\\r\\n\\r\\n1. On August 18, 2024, Team RabbitMQ\'s PackageCloud account will be discontinued\\r\\n2. Cloudsmith mirror repositories now use `*.rabbitmq.com` domains, please update your repository definition files\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Mirrors Now Use `*.rabbitmq.com` Domains\\r\\n\\r\\nThe docs were updated to use `*.rabbitmq.com` for mirror subdomains, please update your repository files. \\r\\nThe previously used domain names won\'t go away, however,\\r\\nthis migration would make your setup more future-proof for large infrastructure changes our team expects\\r\\nto happen in the rest of 2024.\\r\\n\\r\\nSee [Debian](https://www.rabbitmq.com/docs/install-debian) and [RPM](https://www.rabbitmq.com/docs/install-rpm) installation guides.\\r\\n\\r\\n## PackageCloud Will Be Discontinued on Aug 18th, 2024\\r\\n\\r\\nPackageCloud, a great package distribution service we\'ve been using since 2016 IIRC, will be discontinued on Aug 18, 2024.\\r\\nThis means that our PackageCloud repositories will become unavailable shortly after. \\r\\n\\r\\nPlease move to the mirrors used in [Debian](https://www.rabbitmq.com/docs/install-debian) and [RPM](https://www.rabbitmq.com/docs/install-rpm)\\r\\ninstallation guides **as soon as possible**!\\r\\n\\r\\nOn behalf of the RabbitMQ Core Team I would like to thank the PackageCloud team for providing us\\r\\nwith a solid service over the last eight years, during which we only have experienced one minor outage.\\r\\n\\r\\nThis migration has nothing to do with the quality of the service but rather reflects the fact that the core team is\\r\\nin a different corporate environment today compared to 2016-2023, plus we now have our own\\r\\nmirrors for backup."},{"id":"/2024/08/05/native-amqp","metadata":{"permalink":"/rabbitmq-website/blog/2024/08/05/native-amqp","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-08-05-native-amqp/index.md","source":"@site/blog/2024-08-05-native-amqp/index.md","title":"Native AMQP 1.0","description":"We are pleased to announce that RabbitMQ 4.0 supports AMQP 1.0 as a core protocol, providing the following benefits:","date":"2024-08-05T00:00:00.000Z","tags":[{"inline":true,"label":"AMQP 1.0","permalink":"/rabbitmq-website/blog/tags/amqp-1-0"},{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":16.515,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"Native AMQP 1.0","tags":["AMQP 1.0","RabbitMQ 4.0","New Features"],"authors":["dansari"],"image":"./native-amqp.png"},"unlisted":false,"prevItem":{"title":"Package Repository Updates","permalink":"/rabbitmq-website/blog/2024/08/11/package-repository-updates"},"nextItem":{"title":"Announcing Changes to the Open Source RabbitMQ Release and Community Support Policy","permalink":"/rabbitmq-website/blog/2024/05/31/new-community-support-policy"}},"content":"We are pleased to announce that RabbitMQ 4.0 supports [AMQP 1.0](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-overview-v1.0-os.html) as a core protocol, providing the following benefits:\\r\\n* Modernized RabbitMQ to natively support the latest AMQP standard\\r\\n* Support for more AMQP 1.0 features\\r\\n* Significantly better AMQP 1.0 performance and scalability compared to RabbitMQ 3.13\\r\\n* Greater interoperability with other AMQP 1.0 message brokers\\r\\n* AMQP 1.0 is enabled by default in RabbitMQ 4.0\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## AMQP History\\r\\n\\r\\nThe Advanced Message Queuing Protocol (AMQP) is an application layer protocol and a standard for business messaging.\\r\\n\\r\\nAMQP was first developed by John O’Hara at JPMorgan in 2003.\\r\\nIn his article [Toward a Commodity Enterprise Middleware](https://dl.acm.org/doi/pdf/10.1145/1255421.1255424) from 2007, John O’Hara describes the original motivation behind AMQP.\\r\\n\\r\\nThe financial services industry required a high performance messaging middleware (also known as service bus).\\r\\nThis middleware must provide durability to avoid message loss and allow for store-and-forward and publish-subscribe techniques.\\r\\nUse cases include automated trading and buffering of market data events whose arrival rates temporarily exceed the transactional processing rate performed by backend services.\\r\\n\\r\\nSome commercial third-party middleware providers were overly expensive.\\r\\nAt one point, every major investment bank on Wall Street was building its own custom messaging middleware solution.\\r\\nHowever, they encountered the same problems repeatedly.\\r\\nBanks were not software companies, and messaging middleware is complex software that is hard to get right.\\r\\n\\r\\nBanks have managed to collaborate in creating open technical standards such as:\\r\\n* [Society for Worldwide Interbank Financial Telecommunication](https://en.wikipedia.org/wiki/SWIFT) (SWIFT).\\r\\n* [Financial Information eXchange](https://en.wikipedia.org/wiki/Financial_Information_eXchange) (FIX) protocol\\r\\n* [FAST](https://en.wikipedia.org/wiki/FAST_protocol) protocol (FIX Adapted for STreaming)\\r\\n* [Financial products Markup Language](https://en.wikipedia.org/wiki/FpML) (FpML)\\r\\n\\r\\nTherefore, the same organizations should also be capable of creating an open standard for business messaging: That\'s how AMQP was born.\\r\\n\\r\\nThe requirements for the AMQP specification were:\\r\\n* Open standard\\r\\n* Free of patents to enable anyone to implement a compatible implementation\\r\\n* Appealing for commercial implementations (otherwise, the AMQP specification would not succeed)\\r\\n* Should have more than one implementation (to qualify as a standard after all)\\r\\n* AMQP software had to be proven in live systems. Middleware is a critical piece of any system and must be trusted. This trust has to be earned.\\r\\n* Collective effort by many independent companies solving the same problem of connecting systems together\\r\\n\\r\\nFast forward to today, AMQP is used in critical messaging infrastructure by most of the largest corporations in the world across all industries, and RabbitMQ is the most popular open-source AMQP message broker.\\r\\n\\r\\n## AMQP Versions\\r\\n\\r\\nThe following table shows when different AMQP specifications were published:\\r\\n\\r\\n| AMQP version | Release date |\\r\\n| --- | --- |\\r\\n| [0.8](https://www.rabbitmq.com/resources/specs/amqp0-8.pdf) | June 2006 |\\r\\n| [0.9](https://www.rabbitmq.com/resources/specs/amqp0-9.pdf) | December 2006 |\\r\\n| [0.10](https://www.amqp.org/specification/0-10/amqp-org-download) | February 2008 |\\r\\n| [0.9.1](https://www.rabbitmq.com/resources/specs/amqp0-9-1.pdf) | November 2008 |\\r\\n| [1.0](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-overview-v1.0-os.html) | October 2011 |\\r\\n\\r\\nIn his article from 2007, John O\'Hara writes:\\r\\n> The AMQP Working Group is rapidly evolving the protocol and hopes to reach version 1.0 during 2008\\r\\n\\r\\nNot only did the release of version 1.0 take three years longer than anticipated, but the protocol specification also changed completely.\\r\\nThe result is that AMQP 1.0 is a very different protocol compared to its pre-release versions such as AMQP 0.9.1.\\r\\n\\r\\nWhen \\"AMQP\\" is mentioned in conversations or documentation, the version is often omitted, creating a lot of confusion about which protocol is meant.\\r\\nSince RabbitMQ is the most popular message broker, many websites refer to AMQP 0.9.1.\\r\\nOther documentation, in turn, refers to AMQP 1.0.\\r\\n\\r\\nThe rest of this blog post omits AMQP versions 0.8, 0.9, and 0.10 since they are old specifications that aren\'t used anymore.\\r\\nInstead, we focus on the differences between AMQP versions 0.9.1 and 1.0, both of which are heavily used in today\'s message brokers.\\r\\n\\r\\nOn a very high level, the biggest difference between AMQP 0.9.1 and AMQP 1.0 is the following:\\r\\n* AMQP 0.9.1 defines the protocol between client and server as well as server entities such as [exchanges](/tutorials/amqp-concepts#exchanges), [queues](/tutorials/amqp-concepts#queues), and [bindings](/tutorials/amqp-concepts#bindings).\\r\\n* AMQP 1.0 defines only the protocol between client and server.\\r\\n\\r\\n![Figure 1: AMQP 0.9.1 vs AMQP 1.0](091-vs-10.png)\\r\\n\\r\\n## AMQP 0.9.1\\r\\n\\r\\nA client publishes a message to an exchange, which routes the message to a queue.\\r\\nThe queue stores the message until it gets consumed by a client.\\r\\n\\r\\nMore precisely, a publisher sends a message to an instance of an exchange type.\\r\\nThe exchange type defines the routing algorithm.\\r\\nThe AMQP 0.9.1 specification defines different types of exchanges which must be implemented by an AMQP 0.9.1 broker:\\r\\n* [Direct exchange](/tutorials/amqp-concepts#exchange-direct)\\r\\n* [Fanout exchange](/tutorials/amqp-concepts#exchange-fanout)\\r\\n* [Topic exchange](/tutorials/amqp-concepts#exchange-topic)\\r\\n* [Headers exchange](/tutorials/amqp-concepts#exchange-headers)\\r\\n\\r\\nExchanges also offer an extension point.\\r\\nRabbitMQ provides various other exchange types, and third-party plugins can also easily be added to RabbitMQ.\\r\\n\\r\\nDepending on the binding (including the binding key) from a queue to an exchange instance and the routing key (and possibly other headers) of the message, the exchange type algorithm decides to which queue(s) the message gets copied.\\r\\n\\r\\nThe model in AMQP 0.9.1 is therefore simple, yet flexible and powerful.\\r\\nIf needed, complex routing topologies can be created, including [exchange to exchange bindings](/docs/e2e).\\r\\n\\r\\nExchanges, queues, and bindings can be either pre-declared by an administrator or dynamically created via HTTP or, more commonly, directly by the client applications via AMQP 0.9.1.\\r\\nSpecifically, AMQP 0.9.1 defines protocol frames such as `exchange.declare`, `queue.declare`, and `queue.bind`.\\r\\nTherefore, AMQP 0.9.1 client applications are aware of the server topology.\\r\\n\\r\\nThe RabbitMQ Summit 2023 talk [Serving millions of clients with Native MQTT and MQTT 5.0](https://youtu.be/pQEk5TIUCoc?feature=shared&t=445) explained that the AMQ 0.9.1 model is so powerful that it provides much of what an MQTT broker needs. RabbitMQ uses the AMQ 0.9.1 topic exchange type to match topics in incoming MQTT packets against topic filters of MQTT subscriptions.\\r\\n\\r\\n## AMQP 1.0\\r\\n\\r\\nAMQP 1.0 is more generic than AMQP 0.9.1.\\r\\nAMQP 1.0 does not define a server model.\\r\\nIn fact, AMQP 1.0 is so generic that it does not even mandate a central broker to be present.\\r\\nAMQP 1.0 defines peers exchanging messages with each other.\\r\\nThey do so by sending messages to a [target](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-target) and by consuming messages from a [source](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-source).\\r\\n\\r\\nBoth targets and sources contain an [address](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-address-string).\\r\\nWhat internal object an AMQP 1.0 address refers to and how an address is resolved is not defined by the AMQP 1.0 specification because different AMQP 1.0 brokers have different models to receive, store, and send messages.\\r\\n\\r\\nFor example, in an AMQP 1.0 broker that implements the AMQP 0.9.1 model (such as RabbitMQ), an AMQP 1.0 target address refers to an AMQP 0.9.1 exchange, and an AMQP 1.0 source address refers to an AMQP 0.9.1 queue.\\r\\nOther AMQP 1.0 brokers might choose that an address refers to an immutable log (a stream), a topic, some in-memory data structure, or a SQL database.\\r\\nYet another AMQP 1.0 implementation could be just a client library sending messages directly to another client without any central broker being involved where an address could refer to some operating system socket.\\r\\nIt\'s up to the AMQP 1.0 implementation which decides how it resolves an address and how it stores messages.\\r\\n\\r\\nBecause the AMQP 1.0 specification is so generic, it\'s easier for a wide range of brokers to add support for AMQP 1.0 independent of the model they use to store and forward messages.\\r\\nThat\'s why more AMQP 1.0 brokers exist compared to AMQP 0.9.1 brokers.\\r\\n\\r\\n## AMQP 0.9.1 vs. AMQP 1.0\\r\\n\\r\\nThe following table compares AMQP 0.9.1 with AMQP 1.0:\\r\\n\\r\\n| | AMQP 0.9.1 | AMQP 1.0 |\\r\\n| --- | --- | --- |\\r\\n| **Server model defined?** | Yes: exchanges, queues, bindings | No: implementation decides server model |\\r\\n| **Standards** | - | [ISO/IEC 19464](https://www.iso.org/standard/64955.html) <br/> [OASIS](https://www.amqp.org/node/102) |\\r\\n| **Brokers** | RabbitMQ <br/> SwiftMQ <br/> LavinMQ <br/> Apache Qpid Broker-J | RabbitMQ <br/> Azure Service Bus <br/> Azure Event Hubs <br/> Apache ActiveMQ <br/> Apache Qpid Broker-J <br/> Apache Qpid C++ Broker <br/> IBM MQ <br/> Red Hat AMQ <br/> SwiftMQ <br/> Solace |\\r\\n| **Client libraries** | large number of well maintained [client libraries and developer tools](/client-libraries/devtools) | smaller ecosystem, but well maintained client libraries for .NET and Java |\\r\\n| **Complexity** | medium | high |\\r\\n| **Modular architecture?** | No | Yes, layers are: <br/> 1. [Types](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html) <br/> 2. [Transport](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html) <br/> 3. [Messaging](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html) <br/> 4. [Transactions](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transactions-v1.0-os.html) <br/> 5. [Security](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-security-v1.0-os.html) |\\r\\n| **Extensibility** | Although the server model is [extensible](/tutorials/amqp-concepts#amqp-extensibility) via exchange types (and queue types in RabbitMQ) and RabbitMQ itself can be extended with plugins, extensibility of the protocol itself is very limited: RabbitMQ had to define custom AMQP 0.9.1 [protocol extensions](/docs/extensions). | Designed for extensibility: <br/> - Layered architecture allows higher layer to be (re)placed on top of lower layer  <br/> - `properties` and `capabilities` fields in some frames allow for extensibility <br/> - Numerous AMQP 1.0 [extension specifications](https://github.com/oasis-tcs/amqp-specs/) exist. &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |\\r\\n| **Type system** | limited and poorly defined | well defined [types](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-types-v1.0-os.html) |\\r\\n| **Flow control** | simple: e.g. [consumer prefetch](https://www.rabbitmq.com/docs/consumer-prefetch) | sophisticated: [link flow control](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-flow-control) and [session flow control](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-session-flow-control) |\\r\\n| **Features** | defines most important business messaging features | more features compared to AMQP 0.9.1 including (but not limited to): <br/> - [modified outcome](/blog/2024/10/11/modified-outcome) <br/> - [pausing consumers](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp429232) <br/> - [transferring large messages](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp484080) <br/> - [pipelined connection establishment](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#doc-idp157520) <br/> - [sender settle mode](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#type-sender-settle-mode) `mixed` <br/> - [better defined message header sections](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#section-message-format) with immutability of the bare message |\\r\\n\\r\\n#### The Pervasiveness of AMQP 0.9.1\\r\\n\\r\\nNaively thinking, one might expect that the newer AMQP 1.0 protocol version is better, more feature-rich, and more performant, and therefore would obsolete and replace older AMQP 0.9.1 implementations.\\r\\nHowever, this is not the case.\\r\\nIn fact, new AMQP 0.9.1 client libraries are still being created, such as the [C++ library](https://github.com/bloomberg/rmqcpp) open-sourced by Bloomberg just last year.\\r\\nSurprisingly, even entirely new AMQP 0.9.1 broker implementations, such as LavinMQ, have been developed from scratch years after AMQP 1.0 was released.\\r\\n\\r\\nThe reasons that AMQP 0.9.1 is so popular compared to AMQP 1.0 are RabbitMQ\'s strong ecosystem and community, and the fact that AMQP 0.9.1 is less complex.\\r\\nSimplicity usually wins because simplicity leads to developers and users understanding the technology, which in turn results in more client libraries being developed and higher adoption.\\r\\n\\r\\nAs stated previously, AMQP 0.9.1 client applications are aware of exchanges, queues, and bindings.\\r\\nJohn O’Hara even argued in his article from 2007 that interoperability cannot be achieved without the AMQP 0.9.1 protocol defining the model (exchanges, queues, and bindings):\\r\\n> AMQP [0.9.1] is split into two main areas: transport model and queuing model.\\r\\nAMQP [0.9.1] is unusual in that it thoroughly specifies the semantics of the services it provides within the queuing model;\\r\\nsince applications have a very intimate relationship with their middleware, this needs to be well defined or interoperability cannot be achieved.\\r\\n\\r\\nSeventeen years later, we can conclude that he was right.\\r\\n\\r\\nGiven that in 2024 AMQP 0.9.1 is still more pervasive compared to AMQP 1.0, has AMQP 1.0 failed?\\r\\nAs shown in the table above, many brokers have become AMQP 1.0 compliant.\\r\\nAlthough no single broker implements the entire AMQP 1.0 specification due to its complexity, any AMQP 1.0 client can exchange messages with any of these AMQP 1.0 compliant brokers.\\r\\nTherefore, arguably, we can conclude that both AMQP 0.9.1 and AMQP 1.0 have succeeded.\\r\\n\\r\\n#### Why does RabbitMQ 4.0 get an AMQP 1.0 upgrade?\\r\\n\\r\\nThere are several reasons why we have invested in first-class AMQP 1.0 support:\\r\\n1. **Customer Demand**: Both commercial customers and open-source users have requested better AMQP 1.0 support. While not the primary reason for our investment, sometimes conversations occur at such a high, non-technical level that prospective customers prefer to base their central messaging infrastructure on the latest AMQP standard rather than a pre-release AMQP specification. An example can be found [here](https://rabbitmq-users.narkive.com/GLjDgdl5/rabbitmq-discuss-pressured-to-move-to-amqp-1-0).\\r\\n1. **Protocol Features**: The AMQP 1.0 specification has a better-defined type system and more protocol features, as partially shown in the table above. This blog post provides only an overview of AMQP 0.9.1 vs. AMQP 1.0, with subsequent posts covering AMQP 1.0 features in greater detail.\\r\\n1. **Extensibility**: AMQP 1.0 is designed for extensibility. More thought has been put into the protocol specification, and we believe we can leverage this extensibility in future RabbitMQ versions. For example, thanks to this extensibility, RabbitMQ can inform AMQP 1.0 clients about queue locality, allowing clients to publish and consume locally to the RabbitMQ node they are connected to.\\r\\n1. **Improved Performance**: The old RabbitMQ 3.13 plugin was limited in features, suboptimally designed, and slow due to its internal proxying via the AMQP 0.9.1 protocol. Numerous AMQP 1.0 implementation bugs have been fixed in RabbitMQ 4.0.\\r\\n1. **Interoperability**: An open source message broker such as RabbitMQ is all about interoperability. AMQP messages should be able to traverse different brokers and organizations. Since many brokers implement AMQP 1.0, users can more easily migrate to (and from) RabbitMQ. Another interoperability use case was demonstrated by Alvaro Videla in his RabbitMQ Summit 2023 [keynote](https://youtu.be/WpG__E5zafQ?feature=shared&t=2312), where messages were moved from RabbitMQ to Real-Time Intelligence in Microsoft Fabric to analyze application messages using various Azure cloud services.\\r\\n1. **Multi-Protocol Message Broker**: RabbitMQ is the best multi-protocol message broker on the market. It supports AMQP 0.9.1, MQTT, Streams, and, since RabbitMQ 4.0, AMQP 1.0 natively. STOMP is supported via a plugin. RabbitMQ offers users full flexibility in how messages are published and consumed: Messages can be published to and consumed from the same queue using different protocols. RabbitMQ excels by performing [well-documented](/docs/conversions) message protocol conversions. Natively supporting AMQP 1.0 provides even greater flexibility to users.\\r\\n\\r\\n## AMQP 1.0 in RabbitMQ 3.13\\r\\n\\r\\nSince AMQP 1.0 was released in 2011, RabbitMQ has provided limited support for AMQP 1.0 via a plugin:\\r\\n\\r\\n![Figure 2: AMQP 1.0 plugin up to RabbitMQ 3.13](amqp10-plugin.png)\\r\\n\\r\\nThe AMQP 1.0 plugin up to RabbitMQ 3.13 proxies AMQP 1.0 internally via AMQP 0.9.1.\\r\\nIn other words, the plugin translates each AMQP 1.0 message received from the client to an AMQP 0.9.1 message and then sends this translated message via the AMQP 0.9.1 protocol to RabbitMQ core.\\r\\nThis approach has major drawbacks:\\r\\n1. **Limited Feature Support:** Support for AMQP 1.0 is limited to the subset of features provided by the AMQP 0.9.1 protocol.\\r\\n2. **Slow Performance:** Each message must be translated between AMQP 0.9.1 and AMQP 1.0.\\r\\n3. **Resource Heavy:** This approach is resource-intensive in terms of memory and CPU usage, as each AMQP 1.0 [session](https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-transport-v1.0-os.html#section-sessions) in the plugin includes an AMQP 0.9.1 client and maintains AMQP 0.9.1 state.\\r\\n\\r\\nAs explained in the [Serving Millions of Clients with Native MQTT](https://www.rabbitmq.com/blog/2023/03/21/native-mqtt#overview) blog post, the MQTT plugin worked conceptually the same way up to RabbitMQ 3.11:\\r\\nit also proxied internally via the AMQP 0.9.1 protocol.\\r\\n\\r\\n## AMQP 1.0 in RabbitMQ 4.0\\r\\n\\r\\nWith RabbitMQ 4.0, native AMQP 1.0 support replaces the AMQP 1.0 plugin:\\r\\n\\r\\n![Figure 3: Native AMQP 1.0 in RabbitMQ 4.0](native-amqp.png)\\r\\n\\r\\nAMQP 1.0 clients send messages directly to exchanges (AMQP 1.0 targets) and receive messages directly from queues (AMQP 1.0 sources).\\r\\nIn other words, native AMQP 1.0 no longer proxies via the AMQP 0.9.1 **protocol** but continues to utilize the simple, flexible, and powerful AMQ 0.9.1 **model**.\\r\\nThis transition brings several benefits:\\r\\n1. **Enhanced Feature Support:** More AMQP 1.0 features are supported. This mirrors how the introduction of Native MQTT in RabbitMQ 3.12 facilitated the addition of more protocol features, such as MQTT 5.0 in RabbitMQ 3.13.\\r\\n2. **Fast Performance:** Native AMQP 1.0 offers better throughput and lower latency.\\r\\n3. **Resource Light:** Lower memory and CPU usage on the broker, with a single Erlang process used per AMQP 1.0 session compared to 15 Erlang processes in RabbitMQ 3.13.\\r\\n\\r\\nNative AMQP 1.0 thus follows the success story of Native MQTT.\\r\\n\\r\\nObsoleting the AMQP 1.0 plugin, which seems straightforward in the diagram, actually required 12 months of engineering work.\\r\\nThis extensive effort was due to several factors:\\r\\n* **Complexity of the AMQP 1.0 Protocol:** AMQP 1.0 is the most complex protocol supported by RabbitMQ, more intricate than both AMQP 0.9.1 and MQTT.\\r\\n* **Queue modifications:** AMQP 1.0 clients can directly consume from each queue type, necessitating changes to classic queues, quorum queues, and stream implementations.\\r\\n* **Rolling Upgrades:** We support rolling upgrades from RabbitMQ 3.13 to 4.0, allowing you to upgrade your AMQP 1.0 workloads without downtime.\\r\\n\\r\\nEven though RabbitMQ 4.0 supports AMQP 1.0 natively, this does not imply that RabbitMQ supports all AMQP 1.0 features.\\r\\nLike any other AMQP 1.0 broker, RabbitMQ\'s AMQP 1.0 implementation has [documented limitations](/docs/amqp#limitations).\\r\\n\\r\\n## RabbitMQ AMQP 1.0 clients\\r\\n\\r\\nWe have developed two new AMQP 1.0 client libraries specifically for RabbitMQ:\\r\\n* [RabbitMQ AMQP 1.0 **Java** client](https://github.com/rabbitmq/rabbitmq-amqp-java-client)\\r\\n* [RabbitMQ AMQP 1.0 **.NET** client](https://github.com/rabbitmq/rabbitmq-amqp-dotnet-client)\\r\\n\\r\\nThese client libraries have the following characteristics:\\r\\n* **Thin Wrappers:** They are thin wrappers containing RabbitMQ-specific logic built around existing open-source AMQP 1.0 client libraries.\\r\\n* **Opinionated API:** They offer a simple and safe API designed to help application developers easily get started with sending and receiving messages via AMQP 1.0.\\r\\n* **RabbitMQ Model Integration:** They enable applications to manage RabbitMQ’s AMQ 0.9.1 model (such as declaring and deleting exchanges, queues, and bindings) through AMQP 1.0. This feature leverages the [HTTP over AMQP 1.0](https://github.com/oasis-tcs/amqp-specs/blob/master/http-over-amqp-v1.0-wd06a.docx) extension specification.\\r\\n* **Best of Both Worlds:** Applications can maintain an \\"intimate relationship with their middleware\\" by dynamically creating server topologies while enjoying a straightforward experience with the otherwise complex AMQP 1.0 protocol. Additionally, applications can optionally bypass the thin RabbitMQ-specific wrapper and interact directly with the underlying AMQP 1.0 client library to access more advanced AMQP 1.0 features.\\r\\n* **Reduced Network Traffic:** In some scenarios, they can reduce intra-RabbitMQ cluster traffic by identifying the RabbitMQ nodes on which a given queue is located, allowing applications to publish and consume \\"locally\\" from these nodes.\\r\\n* **Optional:** These client libraries are not required for interacting with RabbitMQ via AMQP 1.0. Any other AMQP 1.0 client should also be able to communicate with RabbitMQ.\\r\\n\\r\\n## RabbitMQ Modernizations\\r\\n\\r\\nRabbitMQ 4.0 completes its modernization journey, which began with RabbitMQ 3.8 in 2019.\\r\\nThese modernizations include:\\r\\n* [**Quorum Queues**](/docs/quorum-queues): Using the Raft consensus algorithm to provide a safe, replicated queue type resilient to network partitions.\\r\\n* [**Prometheus Metrics and Grafana Dashboards**](/docs/prometheus): Offering first-class observability integrations and [alerts](/blog/2021/05/03/alerting).\\r\\n* [**RabbitMQ on Kubernetes**](https://youtu.be/GxdyQSUEj5U): Operators to run RabbitMQ anywhere.\\r\\n* [**Streams**](/docs/streams): An immutable log providing message replay and high message throughput with the [stream protocol](https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbitmq_stream/docs/PROTOCOL.adoc).\\r\\n* **[Classic Queue Storage Version 2](/docs/classic-queues#classic-queue-implementation-version-2)**: Providing higher message throughput and lower memory usage.\\r\\n* **Commercial [Disaster Recovery Solution](https://docs.vmware.com/en/VMware-Tanzu-RabbitMQ-for-Kubernetes/3.13/tanzu-rabbitmq-kubernetes/standby-replication.html)**: Ensuring business continuity when the entire data center goes down.\\r\\n* **[Native MQTT](/blog/2023/03/21/native-mqtt) and [MQTT 5.0](/blog/2023/07/21/mqtt5)**: Transforming RabbitMQ into an IoT broker.\\r\\n* [**Khepri**](https://rabbitmq.github.io/khepri/): Using the Raft consensus algorithm to provide a safe and scalable metadata store resilient to network partitions.\\r\\n* **Native AMQP 1.0:** Upgrading RabbitMQ\'s core protocol to the latest AMQP standard (as covered in this blog post).\\r\\n\\r\\nWe encourage you to try and test AMQP 1.0 in RabbitMQ 4.0 and provide [feedback](/contact).\\r\\nYou can use the latest [`rabbitmq:4.0`](https://hub.docker.com/layers/library/rabbitmq/4.0/images/sha256-a1fb6ba3eff9a226074940f27beccfd2e4de989d3d4ebb0b1272e9f78aa44dd4) docker image.\\r\\nWhile we encourage you to build new applications with AMQP 1.0, we will continue to support and maintain AMQP 0.9.1 in RabbitMQ 4.x.\\r\\n\\r\\nWatch our [RabbitMQ Summit 2024 talk on Native AMQP 1.0](https://youtu.be/LFu-kOOTLvs?feature=shared) and read more technical [blog posts on AMQP 1.0](/blog/tags/amqp-1-0) features and performance benchmarks."},{"id":"/2024/05/31/new-community-support-policy","metadata":{"permalink":"/rabbitmq-website/blog/2024/05/31/new-community-support-policy","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-05-31-new-community-support-policy/index.md","source":"@site/blog/2024-05-31-new-community-support-policy/index.md","title":"Announcing Changes to the Open Source RabbitMQ Release and Community Support Policy","description":"Effective June 1st, the RabbitMQ community support and release policies will change for the open source distributions of RabbitMQ.","date":"2024-05-31T00:00:00.000Z","tags":[{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"},{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x"}],"readingTime":1.865,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Announcing Changes to the Open Source RabbitMQ Release and Community Support Policy","tags":["Announcements","RabbitMQ 3.13.x"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Native AMQP 1.0","permalink":"/rabbitmq-website/blog/2024/08/05/native-amqp"},"nextItem":{"title":"Erlang/OTP 27 Is Currently Not Supported","permalink":"/rabbitmq-website/blog/2024/05/23/erlang27-support"}},"content":"Effective June 1st, the RabbitMQ community support and release policies will change for the open source distributions of RabbitMQ.\\r\\nThe goal of these changes is to ensure that the RabbitMQ team has time to focus on developing new features for the Open Source and commercial versions of RabbitMQ. \\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n### What is Community Support?\\r\\n\\r\\nCommunity support is defined as all questions, root cause analysis requests, issue reports, and other interactions the RabbitMQ core team\\r\\nhas with open source RabbitMQ users on GitHub and our [community forums](/contact).\\r\\n\\r\\n## Community Support Policy Changes\\r\\n\\r\\nEffective immediately, a new community support policy is adopted for Open Source distributions of RabbitMQ.\\r\\nThe policy seeks to ensure that RabbitMQ remains a sustainable open source project.\\r\\n\\r\\nUnder the new policy, only the following groups of users will receive support directly from the RabbitMQ core team:\\r\\n\\r\\n * Users with [VMware Tanzu RabbitMQ commercial](https://tanzu.vmware.com/rabbitmq) licenses\\r\\n * Active RabbitMQ community contributors. A definition of a “Contribution\\" is provided in the [community support eligibility document](https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md)\\r\\n * Users and community members who report certain types of RabbitMQ issues and provide all the details necessary to reproduce the reported issue\\r\\n\\r\\n## Release Policy Changes\\r\\n\\r\\nEffective June 1st 2024, the RabbitMQ team will adopt a new release policy for the Open Source distribution.\\r\\nThe changes do not impact the current RabbitMQ Open Source License. The RabbitMQ core team will continue\\r\\ndeveloping Open Source RabbitMQ under the Mozilla Public License 2.0 on GitHub.\\r\\n\\r\\nWith the new policy, older [Open Source release](/release-information) versions (for example, RabbitMQ 3.12.x and older)\\r\\nwill no longer receive patches through community support.\\r\\nPatches for older versions of both the Open Source and Commercial versions will be available to customers that have VMware Tanzu RabbitMQ commercial licenses.\\r\\n\\r\\nIn practical terms this means that once RabbitMQ 4.x is released, all new contributions will eventually ship as part of\\r\\n\\r\\n * Open Source RabbitMQ 4.x \\r\\n * VMware Tanzu RabbitMQ 4.x\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nUsers who contribute to the RabbitMQ open source distribution, and/or stay current with the latest RabbitMQ release will still\\r\\nhave the ability to collaborate with the RabbitMQ team.\\r\\n\\r\\nAll other users seeking assistance with the RabbitMQ Open Source distribution will be required to obtain commercial licenses\\r\\nfor RabbitMQ support or seek RabbitMQ-related help elsewhere."},{"id":"/2024/05/23/erlang27-support","metadata":{"permalink":"/rabbitmq-website/blog/2024/05/23/erlang27-support","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-05-23-erlang27-support/index.md","source":"@site/blog/2024-05-23-erlang27-support/index.md","title":"Erlang/OTP 27 Is Currently Not Supported","description":"Erlang/OTP 27.0 was released on May 20th, 2024.","date":"2024-05-23T00:00:00.000Z","tags":[{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"},{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x"}],"readingTime":0.44,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"Erlang/OTP 27 Is Currently Not Supported","tags":["Announcements","RabbitMQ 3.13.x"],"authors":["kura"]},"unlisted":false,"prevItem":{"title":"Announcing Changes to the Open Source RabbitMQ Release and Community Support Policy","permalink":"/rabbitmq-website/blog/2024/05/31/new-community-support-policy"},"nextItem":{"title":"RabbitMQ 3.13.0 Is Here!","permalink":"/rabbitmq-website/blog/2024/03/11/rabbitmq-3.13.0-announcement"}},"content":"[Erlang/OTP 27.0 was released on May 20th, 2024](https://www.erlang.org/blog/highlights-otp-27/).\\r\\nWhile it contains a lot of exciting features and improvements, unfortunately RabbitMQ currently\\r\\ndoesn\'t work well with this version.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nOur team has discovered significant performance regressions on Erlang 27,\\r\\nas high as 30% lower message throughput in many common workloads.\\r\\n\\r\\nWe are investigating the root cause of the regressions.\\r\\nPlease do not use Erlang/OTP 27 with RabbitMQ at this time.\\r\\n\\r\\nWe will announce support for Erlang/OTP 27 when we are confident that it works well with RabbitMQ."},{"id":"/2024/03/11/rabbitmq-3.13.0-announcement","metadata":{"permalink":"/rabbitmq-website/blog/2024/03/11/rabbitmq-3.13.0-announcement","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-03-11-rabbitmq-3.13.0-announcement/index.md","source":"@site/blog/2024-03-11-rabbitmq-3.13.0-announcement/index.md","title":"RabbitMQ 3.13.0 Is Here!","description":"RabbitMQ 3.13 is now available","date":"2024-03-11T00:00:00.000Z","tags":[{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"},{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x"}],"readingTime":4.045,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"RabbitMQ 3.13.0 Is Here!","tags":["Announcements","RabbitMQ 3.13.x"],"authors":["kura"]},"unlisted":false,"prevItem":{"title":"Erlang/OTP 27 Is Currently Not Supported","permalink":"/rabbitmq-website/blog/2024/05/23/erlang27-support"},"nextItem":{"title":"RabbitMQ 3.13: Classic Queues Changes","permalink":"/rabbitmq-website/blog/2024/01/11/3.13-release"}},"content":"[RabbitMQ 3.13 is now available](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.13.0)\\r\\nwith support for MQTTv5, stream filtering and significant improvements to\\r\\nclassic queue performance, especially for larger messages.\\r\\n\\r\\nRead dedicated blog posts for more details about these changes:\\r\\n\\r\\n* [support for version 5 of the MQTT protocol](/blog/2023/07/21/mqtt5)\\r\\n* [support for stream filtering](/blog/2023/10/16/stream-filtering)\\r\\n* [performance improvements](/blog/2024/01/11/3.13-release)\\r\\n\\r\\nRabbitMQ 3.13 is the final minor release in the 3.x series. The next release\\r\\nwill be 4.0!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Experimental Support For Khepri (Mnesia Replacement)\\r\\n\\r\\nApart from the new features mentioned in the first paragraph, RabbitMQ 3.13\\r\\nincludes experimental support for [Khepri](https://github.com/rabbitmq/khepri). Khepri is a new storage backend for\\r\\nRabbitMQ metadata that is designed to replace Mnesia. It is not yet ready for\\r\\nproduction use but we encourage users to try it out in test environments and\\r\\nprovide feedback.\\r\\n\\r\\nOur plan is to completely remove Mnesia in the future. This should\\r\\nsignificantly improve RabbitMQ\'s tolerance to network partitions. Once we switch\\r\\nto Khepri, there will be no partition handling strategy configuration\\r\\n(`pause_minority`, `autoheal`, etc) — Khepri is based on the Raft protocol,\\r\\njust like quorum queues and therefore the semantics of what to do when a\\r\\npartition occurs are well defined and not configurable.\\r\\n\\r\\nA recorded talk about [Khepri](https://www.youtube.com/watch?v=whVqpgvep90) is available.\\r\\n\\r\\n:::warning\\r\\nThe command below enables an experimental feature that cannot be disabled.\\r\\nDo not use it in production unless you have tested it thoroughly!\\r\\n\\r\\nTo enable Khepri (**experimental in 3.13 and non-reversible!**) run:\\r\\n```\\r\\nrabbitmqctl enable_feature_flag khepri_db\\r\\n```\\r\\n:::\\r\\n\\r\\nYou shouldn\'t really notice any difference after enabling Khepri. The main\\r\\ndifference is what happens internally when you declare exchanges, queues,\\r\\nbindings and so on. We encourage experimentation such as declaring your actual\\r\\ntopology first and then enabling Khepri (to validate that everything works as\\r\\nexpected), inducing failures to validate the cluster remains available (as long\\r\\nas the majority of the nodes is up and connected) and so on. Please report any\\r\\nissues you run into.\\r\\n\\r\\n## Feature Flags\\r\\n\\r\\nRabbitMQ 3.13.0 includes a few new [feature flags](/docs/feature-flags/). It doesn\'t however, set any\\r\\nolder flags as required (apart from those that were already required in 3.12 of\\r\\ncourse). Therefore, if you have some feature flags disabled, upgrading from\\r\\n3.12 to 3.13 will still work. In the 3.11 -> 3.12 upgrade, some users ran into\\r\\nissues if not all feature flags were enabled. Such issues won\'t happen when\\r\\nmoving from 3.12 to 3.13.\\r\\n\\r\\n:::tip\\r\\nYou should always enable all non-experimental feature flags after a successful\\r\\nupgrade.\\r\\n:::\\r\\n\\r\\n## Classic Queues: Version 1 Remains The Default\\r\\n\\r\\nWe had intended to change the default version of classic queues to v2 in 3.13\\r\\nbut ultimately decided against it. Therefore, v1 is still the default and v2\\r\\nremains an opt-in feature. However, **classic queues v2 are highly\\r\\nrecommended**! You can upgrade your queues by setting `x-queue-version=2` in a\\r\\npolicy. To make sure new queues are created as v2 by default, you can set\\r\\n\\r\\n``` ini\\r\\nclassic_queue.default_version = 2\\r\\n```\\r\\n\\r\\nin [`rabbitmq.conf`](/docs/configure).\\r\\n\\r\\nThe reason v1 remains the default has nothing to do with any v2 shortcomings\\r\\nbut rather with the fact that changing the node default led to some back and\\r\\nforth migrations between v1 and v2 in certain scenarios. In particular, a\\r\\nmirrored queue would be upgraded and downgraded back and forth between v1 and\\r\\nv2 during a rolling upgrade, since the default would be different on different\\r\\nnodes. To avoid any risk of such scenarios, we decided against this change.\\r\\n\\r\\nClassic queues v2 will become the only option in the future. By then, queue\\r\\nmirroring will be removed and therefore there will be no risk of\\r\\nmirroring-related issues.\\r\\n\\r\\n## Message Containers\\r\\n\\r\\n[Message Containers](https://github.com/rabbitmq/rabbitmq-server/pull/5077) are\\r\\na mostly invisible change in how messages are handled internally. RabbitMQ was\\r\\noriginally built as an AMQP 0-9-1 broker. However, over the years, support for\\r\\nAMQP 1.0, MQTT, STOMP and Streams was added. This led to some internal message\\r\\nformat conversions since different protocols have mostly similar concepts, but\\r\\ndiffer in the details such as available data types.\\r\\n\\r\\nMessage containers are based on a message format from AMQP 1.0 and\\r\\nmodernize internal message representation with today\'s multi-protocol\\r\\nassumptions and makes all the conversions between protocols explicit.\\r\\n\\r\\nThese conversions are now [documented](https://www.rabbitmq.com/docs/conversions).\\r\\n\\r\\n## That\'s A Wrap For 3.x!\\r\\n\\r\\nRabbitMQ 3.0.0 was released in November 2012. For various historical reasons,\\r\\nthe major version has not been incremented since then. However, it\'s time to\\r\\nsay goodbye to the 3.x series and move on to 4.0 later this year. Version 4.0\\r\\nwill include a number of breaking changes but most importantly, it will no\\r\\nlonger support mirroring of classic queues. Policy keys related to mirroring\\r\\nwill be ignored and queues will become single-node queues. This is a final call\\r\\nfor users requiring highly available queues: migrate to quorum queues, or\\r\\nstreams if applicable, as soon as possible. You will enjoy much higher data\\r\\nsafety, reliability and better performance than mirrored queues ever offered."},{"id":"/2024/01/11/3.13-release","metadata":{"permalink":"/rabbitmq-website/blog/2024/01/11/3.13-release","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-01-11-3.13-release/index.md","source":"@site/blog/2024-01-11-3.13-release/index.md","title":"RabbitMQ 3.13: Classic Queues Changes","description":"We\'ve already announced two major new features of 3.13 in separate blog posts:","date":"2024-01-11T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x"}],"readingTime":10.565,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"RabbitMQ 3.13: Classic Queues Changes","tags":["Performance","RabbitMQ 3.13.x"],"authors":["kura"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.13.0 Is Here!","permalink":"/rabbitmq-website/blog/2024/03/11/rabbitmq-3.13.0-announcement"},"nextItem":{"title":"New website for RabbitMQ 3.13.0","permalink":"/rabbitmq-website/blog/2024/01/04/new-website"}},"content":"We\'ve already announced two major new features of 3.13 in separate blog posts:\\r\\n\\r\\n* [support for version 5 of the MQTT protocol](/blog/2023/07/21/mqtt5)\\r\\n* [support for stream filtering](/blog/2023/10/16/stream-filtering)\\r\\n\\r\\nThis post focuses on the changes to the classic queues in this release:\\r\\n* classic queue storage format version 1 is deprecated\\r\\n* new implementation of the classic queue message store\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Classic Queues Storage Primer \\r\\n\\r\\nBefore we get into the changes, it\'s worth explaining briefly how classic queues store messages. For each message, we\\r\\nneed to store the message payload and some metadata about the message (eg. whether this message was delivered to a\\r\\nconsumer). It makes sense to separate the message data (an opaque binary blob, potentially of a significant size) from\\r\\nthe metadata (small key-value map). However, for small messages, performing two separate writes, one for metadata and\\r\\nanother one for the contents of the message, is wasteful. Therefore, classic queues handle small messages differently than\\r\\nlarge messages.\\r\\n\\r\\nHistorically, in what we now refer to as version 1 of the classic queues, this process is called embedding the message\\r\\nin the index and the property `queue_index_embed_msgs_below` controls what constitutes a small enough message to be\\r\\nembedded (the default is 4kB). Messages above this threshold are stored separately in the message store - a separate\\r\\nkey-value structure with a different on-disk representation. For messages stored in the store, the index contains the\\r\\nmetadata and the message store ID, which allows to retrieve the payload when needed. There is one message store per\\r\\nvirtual host, while each queue has a separate index.\\r\\n\\r\\nVersion 2 of the classic queue storage, introduced in 3.10, is logically very similar: there\'s still the same per-vhost\\r\\nmessage store and a separate per-queue message store for metadata and small messages. However, the structure of what we store\\r\\nper-queue is completely different and therefore we don\'t call it just an index anymore - small messages are not embedded\\r\\nin the index, but stored in separate files within the per-queue message store.\\r\\n\\r\\nThe per-vhost message store is still there for larger messages, but version 3.13 changes its behaviour significantly.\\r\\n\\r\\nFor backwards compatibility `queue_index_embed_msgs_below` still controls whether a message is large enough to be stored\\r\\nin the per-vhost message store and the default is still 4kB.\\r\\n\\r\\n## Classic Queues Version 2 (CQv2)\\r\\n\\r\\nA few years ago, we started a journey to re-implement classic queues for better performance. A lot of things have\\r\\nchanged since the original implementation, which is now almost 20 years old! Here\'s a rundown of the steps\\r\\non this journey:\\r\\n\\r\\n1. Since 3.10, queues with `queue-version=2` use the new index storage format (we store per-queue data differently)\\r\\n1. Since 3.12, classic queues (both v1 and v2) [never store more than a small set of messages in\\r\\nmemory](/blog/2023/05/17/rabbitmq-3.12-performance-improvements#classic-queues-changes-to-the-lazy-mode)\\r\\n1. Since 3.12, messages below `queue_index_embed_msgs_below` (4kb by default) are handled much more efficiently\\r\\n\\r\\nWith 3.13, we are getting close to the end of this journey:\\r\\n1. Starting from 3.13, messages above `queue_index_embed_msgs_below` are handled in a more efficient way\\r\\n1. Starting from 3.13, classic queues v1 are deprecated\\r\\n\\r\\nIn RabbitMQ 4.0 we will remove the mirroring feature of classic queues. As we\'ve said many times before, if you need\\r\\nhighly available replicated queues, you should be using quorum queues that have been available since 3.8. Removing the\\r\\nmirroring feature will enable further optimisations to the implementation.\\r\\n\\r\\nMoreover, in 4.0 we\'ll most likely remove the v1 implementation of the queue index (this may be delayed based on your\\r\\nfeedback!). When you upgrade to 4.0 in the future, all the classic queues that are still using v1 will need to be\\r\\nconverted to v2 during startup. This can take a long time if there are many messages and/or many queues. It\'s therefore\\r\\na good idea to go through the conversion process deliberately.\\r\\n\\r\\n### What If I Don\'t Feel Ready for CQv2?\\r\\n\\r\\nUntil version 1 of the index implementation is removed, you can still use it.\\r\\n\\r\\nThere\'s no such choice for the message store implementation - 3.13 contains significant improvements, especially when\\r\\nused in combination with a v2 index. However, there may also be minor regressions when combined with v1. Users are\\r\\nrecommended to test their applications thoroughly and report situations where a v2 index is worse than v1.\\r\\n\\r\\n## CQv1 -> CQv2 Conversion\\r\\n\\r\\nSince v1 and v2 use a different file format, a conversion is needed if a queue is changed from v1 to v2 (or vice versa -\\r\\ndowngrading is supported). If you have an existing classic queue v1 and apply a policy with `x-queue-version=2`, this\\r\\nqueue will become unavailable for the duration of the conversion - the queue needs to have a moment to rewrite the files\\r\\ninto the new format. Such conversions shouldn\'t take more than a few seconds - if you see it taking longer, please\\r\\nreport this.\\r\\n\\r\\nSince the queue version can be changed through a policy, it\'s also possible to gradually migrate from v1 to v2. You can\\r\\ndeclare a policy that only matches a subset of the queues and once they are converted, you can either extend the regular\\r\\nexpression to match more queues or declare another policy matching a different subset of the queues. Even if the policy\\r\\nmatches a lot of queues, the migration is strictly a per-queue operation - any queue that completed the conversion\\r\\nbecomes available to serve client applications immediately after the conversion, even if other queues are still\\r\\nrewriting their files.\\r\\n\\r\\nYou can go through this conversion already on 3.12 (or even 3.10 or 3.11). If you do, the removal of v1 in 4.0 won\'t\\r\\nreally affect you, since all your queues will be v2 already.\\r\\n\\r\\n## Performance Comparison\\r\\n\\r\\nLet\'s see the results comparing RabbitMQ 3.12.11 with 3.13.0-rc.4. Please refer to [previous blog\\r\\nposts](/blog/2023/05/17/rabbitmq-3.12-performance-improvements#the-environment) for details\\r\\nabout the benchmarking setup and the way we run these tests or check out the repository, where we keep\\r\\n[the environments configuration](https://github.com/rabbitmq/testing/blob/main/main/scenario-3.12-vs-3.13.yaml)\\r\\nand [the script](https://github.com/rabbitmq/testing/blob/main/main/script.sh) with the workloads.\\r\\n\\r\\nAll tests were performed with 100B and 5kB messages.\\r\\n\\r\\n### Publishing And Consuming\\r\\n\\r\\nIn this test, we have a single publisher and a single consumer and just try to deliver messages as quickly as possible\\r\\nthrough a single queue.\\r\\n\\r\\nAs you can see, classic queues v2 offer a significantly better performance compared with CQv1 and 3.13 improves the\\r\\nperformance of both versions. For the users still using CQv1, moving to CQv2 on 3.13 may almost double the throughput\\r\\nfor small messages!\\r\\n\\r\\n\\r\\n![1 publisher, 1 queue, 1 consumer, 100B messages](cq-publish-consume-100b.png)\\r\\n\\r\\n![1 publisher, 1 queue, 1 consumer, 5kB messages](cq-publish-consume-5kb.png)\\r\\n\\r\\n### Publish Only\\r\\n\\r\\nIn this test, we publish to a queue at full speed, with 2 publishers, while not consuming the messages at all.\\r\\nThe queue grows from empty to 5 million messages.\\r\\n\\r\\nWith 100B messages, CQv2 blows CQv1 out of the water with more than 250% higher throughput compared to 3.12.\\r\\n\\r\\n![2 publishers, 1 queue, no consumers, 100B messages](cq-publish-only-100b.png)\\r\\n\\r\\nThe 5kB test is more nuanced. 3.13 with CQv2 wins by a large margin and CQv2 superiority is visible even in 3.12.\\r\\nHowever, the combination of the new message store with the old index doesn\'t perform consistently - it has a good\\r\\nthroughput most of the time, but with significant slow downs (latency spikes). This is unfortunate but something we\\r\\ndecided to keep this way, given the number of factors required to trigger this behaviour and the fact that users should\\r\\nmove to CQv2 anyway. We saw this behaviour only in this test, so the following conditions need to be met: a 3.13 node\\r\\nrunning a CQv1 queue with messages larger than 4kb (or whatever the value of `queue_index_embed_msgs_below` is),\\r\\npublishers significantly faster than consumers (or consumers not present at all) and a high throughput of messages.\\r\\nIf you have such a workload, moving to CQv2 should not only prevent this regression but give you a significantly better\\r\\nperformance than CQv1 could ever achieve.\\r\\n\\r\\n![2 publishers, 1 queue, no consumers, 5kB messages](cq-publish-only-5kb.png)\\r\\n\\r\\n### Consume Only\\r\\n\\r\\nIn this test we consume the long backlog of messages from the previous test. There are 5 million messages to consume\\r\\n(hopefully your queues are much shorter!).\\r\\n\\r\\nWith 100B messages, you can see that CQv2 offers ~30% higher consumption rate early on. Over time, as the queue\\r\\nbecomes shorter, CQv1 gets faster but CQv2 environment still empties the queue long before CQv1 (when\\r\\nconsumption rate goes down to zero, that means the queue is empty):\\r\\n\\r\\n![1 publisher, 1 queue, 1 consumer, 100B messages](cq-consume-backlog-100b.png)\\r\\n\\r\\nWith 5kB messages, handled by the per-vhost message store, you can see the main benefit of the 3.13 changes.\\r\\nSince the message store implementation is shared by v1 and v2, in this test both 3.13 environments are significantly\\r\\nahead of 3.12, even a 3.12 with CQv2. We can see a ~50% higher throughput in 3.13:\\r\\n\\r\\n![1 publisher, 1 queue, 1 consumer, 5kB messages](cq-consume-backlog-5kb.png)\\r\\n\\r\\n### Multiple Queues\\r\\n\\r\\nIn this test, rather than pushing a single queue to its limit, we have 5 concurrent message flows: 5 publishers,\\r\\neach publishing to a different queue, and 5 consumers, one for each queue. Each publisher sends 10000 messages\\r\\nper second so the total expected throughput is 50000 messages. With 100B messages, all environments reached the\\r\\nexpected throughput, while with 5kB messages, all oscillated around 27000 messages/s. The more interesting part here\\r\\nis the end-to-end latency - how long does it take from the moment a message is sent until the message is consumed.\\r\\n\\r\\nFor 100B messages, we can see that the CQv2 environments can deliver the messages much faster. For users moving\\r\\nfrom CQv1 on 3.12 to CQv2 on 3.13, that a 75% reduction of the mean latency **and** a 50% of reduction in\\r\\nmemory usage.\\r\\n\\r\\n![5 publishers, 5 queue, 5 consumers, 100B messages, 50k msgs/s achieved](cq-multiple-queues-100b.png)\\r\\n\\r\\nFor 5kB messages, the results are much closer and in fact, 3.12 wins this particular test (something we may\\r\\nlook into in the future). However, 3.13 can still achieve similar results while using 100MB less memory:\\r\\n\\r\\n![5 publishers, 5 queue, 5 consumers, 5kB messages, 50k msgs/s attempted](cq-multiple-queues-5kb.png)\\r\\n\\r\\n### Publisher Confirm Latency\\r\\n\\r\\nLastly, let\'s take a look at a very different test. Rather than flooding queue(s) with messages, we only publish one\\r\\nmessage at a time, wait for [the publisher confirm](/docs/confirms) and then publish the\\r\\nnext one (a consumer is present but not really relevant here, since it can easily consume the incoming messages).\\r\\n\\r\\nWith 100B messages, we can once again see how much faster CQv2s are, with well over 200% speed up compared to\\r\\nCQv1 on 3.12:\\r\\n\\r\\n![1 publishers, 1 queue, 1 consumer, 100B messages](cq-latency-100b.png)\\r\\n\\r\\nWith 5kB messages, the benefits of the new per-vhost message store implementation in 3.13 are apparent, with\\r\\nmore than 350% improvement:\\r\\n\\r\\n![1 publisher, 1 queue, 1 consumer, 5kB messages](cq-latency-5kb.png)\\r\\n\\r\\nYou may notice that the throughput is actually a bit higher with 5kB messages than it is with 100B messages.\\r\\nThis is counter-intuitive but actually not that strange. 5kB is still a tiny amount of data to send over the wire,\\r\\nwhile the message store is designed to handle such messages better. As with everything else, this difference\\r\\nmay change in the future with further optimisations and perhaps a change to the default value of\\r\\n`queue_index_embed_msgs_below` that we will consider.\\r\\n\\r\\n## Caveat\\r\\n\\r\\nBoth version 2 of the index and the new message store implementation should provide significant benefits for most users.\\r\\nHowever, these implementations already focus on non-mirrored use cases and the new message store implementation was\\r\\ndesigned with the v2 of the index in mind. While it is backwards compatible and can be used with classic queues v1,\\r\\nthere are some cases where using v1 of the index with the new message store may provide worse performance or a different\\r\\nperformance profile than in the past, as seen in the publish-only test. It is therefore highly recommended to:\\r\\n1. Test and benchmark your application with 3.13\\r\\n2. Compare performance with v1 and v2\\r\\n3. If v1 behaves better **without mirroring**, please report that, so we can take a look\\r\\n\\r\\nRemaining on v1 can be a workaround for the cases where it provides better performance. However, that old implementation\\r\\nwill be removed in the future, so you can\'t rely on that workaround for long. Please report such cases so that you can\\r\\nupgrade to v2 in the future.\\r\\n\\r\\n## Final Word\\r\\n\\r\\nRedesigning and replacing such a core component of a widely used piece of software is a very hard task.\\r\\nSpecial thanks to [Loïc Hoguin](https://github.com/essen) for embarking on this project, scavenging through the code,\\r\\nsometimes dating all the way back to the very first release of RabbitMQ, before the world heard about iPhones.\\r\\nAs always, we welcome testing and feedback and we hope the upgrade will provide you similar benefits as shown above."},{"id":"/2024/01/04/new-website","metadata":{"permalink":"/rabbitmq-website/blog/2024/01/04/new-website","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2024-01-04-new-website/index.md","source":"@site/blog/2024-01-04-new-website/index.md","title":"New website for RabbitMQ 3.13.0","description":"We have been working for several weeks on a new website for RabbitMQ. We plan","date":"2024-01-04T00:00:00.000Z","tags":[{"inline":true,"label":"Documentation","permalink":"/rabbitmq-website/blog/tags/documentation"}],"readingTime":4.97,"hasTruncateMarker":true,"authors":[{"name":"Jean-Sébastien Pédron","url":"https://github.com/dumbbell","imageURL":"https://github.com/dumbbell.png","key":"jpedron","page":null}],"frontMatter":{"title":"New website for RabbitMQ 3.13.0","tags":["Documentation"],"authors":["jpedron"],"image":"./thumbnail.png"},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.13: Classic Queues Changes","permalink":"/rabbitmq-website/blog/2024/01/11/3.13-release"},"nextItem":{"title":"Stream Filtering Internals","permalink":"/rabbitmq-website/blog/2023/10/24/stream-filtering-internals"}},"content":"import ThemedImage from \'@theme/ThemedImage\';\\r\\nimport useBaseUrl from \'@docusaurus/useBaseUrl\';\\r\\n\\r\\nWe have been working for several weeks on a new website for RabbitMQ. We plan\\r\\nto release this significant upgrade shortly after RabbitMQ 3.13.0 is released!\\r\\nAt this point, we would love **you to [visit the new\\r\\nwebsite](/)** and tell us what you think :-)\\r\\n\\r\\nIn this blog post, I will go over the reasons we are doing this and what\\r\\nimprovements it will bring to you.\\r\\n\\r\\n<figure>\\r\\n[![Screenshot of the new homepage](homepage-light.png#gh-light-mode-only)](/)\\r\\n[![Screenshot of the new homepage](homepage-dark.png#gh-dark-mode-only)](/?docusaurus-theme=dark)\\r\\n<figcaption>Screenshot of the new homepage</figcaption>\\r\\n</figure>\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Limitations of the current website\\r\\n\\r\\n### Only the latest RabbitMQ version is documented\\r\\n\\r\\nAs of this writing, the www.rabbitmq.com website contains the documentation of\\r\\nthe RabbitMQ server, some AMQP clients and it offers tutorials to get started\\r\\nwith RabbitMQ.\\r\\n\\r\\nThe documentation covers the latest version of RabbitMQ only ‑ currently\\r\\n3.12.x. That was ok-ish so far because new releases series usually come with\\r\\nnew additions. However, with the upcoming RabbitMQ 4.0.x, significant\\r\\ndeprecated features will be removed! If we continue like this, it means the\\r\\ndocumentation for these dropped features will go away. This is a real problem\\r\\nfor people who will still be running RabbitMQ 3.12.x for some time.\\r\\n\\r\\nThis is the first and main reason we want to upgrade the website: we want the\\r\\ndocumentation to cover many versions of RabbitMQ: old, current and upcoming.\\r\\n\\r\\nWe could take a snapshot of the website and publish it somewhere else, like\\r\\n[previous.rabbitmq.com](https://previous.rabbitmq.com) in the past. But the Git\\r\\nrepository/workflow and the home-grown framework don\'t make this easy, that\'s\\r\\nwhy we stopped keeping snapshots of older versions. We would make a better job\\r\\nif the workflow and the tooling had room for maintaining several versions\\r\\neasily and all of them would be published to www.rabbitmq.com in a way that it\\r\\nis easy for users to switch to whatever version they are running.\\r\\n\\r\\nThis brings me to the second reason behind the big upgrade.\\r\\n\\r\\n### In-house framework\\r\\n\\r\\nThe website is statically generated and published to a Cloudflare worker. The\\r\\nstatic generator we used was developed by the RabbitMQ team a decade ago and\\r\\nbarely evolved ever since.\\r\\n\\r\\nMaking or maintaining a website framework is definitely not the best way to\\r\\ninvest our time. There is still plenty of work on RabbitMQ itself :-) So\\r\\ninstead of adding multiple versions support to it, we looked at existing FOSS\\r\\nstatic website generators that had this feature built-in and evaluated a few of\\r\\nthem.\\r\\n\\r\\nWe chose [Docusaurus](https://docusaurus.io/). It supports multiple versions ‑\\r\\nour primary criteria ‑ and it uses Markdown as the markup language, thus we\\r\\ndon\'t have to rewrite anything. This would make the conversion easier.\\r\\n\\r\\n## “What\'s in it for me?”\\r\\n\\r\\nWith Docusaurus, we, the RabbitMQ team, make our life easier, yay \\\\o/ But “are\\r\\nthere any benefits for you”, you may ask?\\r\\n\\r\\n### Multiple versions documented\\r\\n\\r\\nOf course, you will be able to read documentation of past and new versions of\\r\\nRabbitMQ, even the future one while it is being worked on.\\r\\n\\r\\n<figure>\\r\\n![Screenshot of the version selection drop-down menu](versions-dropdown-light.png#gh-light-mode-only)\\r\\n![Screenshot of the version selection drop-down menu](versions-dropdown-dark.png#gh-dark-mode-only)\\r\\n<figcaption>Screenshot of the version selection drop-down menu</figcaption>\\r\\n</figure>\\r\\n\\r\\nInitially, it will only cover RabbitMQ 3.13.x because we didn\'t convert\\r\\nprevious versions to Docusaurus. A snapshot of RabbitMQ 3.12.x documentation\\r\\nwill be published on previous.rabbitmq.com instead.\\r\\n\\r\\nWe plan to keep all supported RabbitMQ versions docs on the new website. When\\r\\nan old release series reaches end-of-life, its documentation will also move to\\r\\nprevious.rabbitmq.com. This is to avoid that the version dropdown becomes too\\r\\ncluttered or that the search feature brings too many results which are less\\r\\nrelevant.\\r\\n\\r\\nSpeaking of search...\\r\\n\\r\\n### Integrated search feature\\r\\n\\r\\nDocusaurus integrates several solutions to provide an internal search feature.\\r\\nWe picked Algolia because it is very efficient and works well with multiple\\r\\nversions.\\r\\n\\r\\n<figure>\\r\\n![Screenshot of the search popup](search-light.png#gh-light-mode-only)\\r\\n![Screenshot of the search popup](search-dark.png#gh-dark-mode-only)\\r\\n<figcaption>Screenshot of the search popup</figcaption>\\r\\n</figure>\\r\\n\\r\\nThe entire website, including the blog, will be indexed and searchable. In the\\r\\nexample above, I searched \\"MQTT\\" and Algolia returns blog posts and\\r\\ndocumentation pages in the results.\\r\\n\\r\\nWhat is not obvious on the screenshot however is that it only returned docs\\r\\nfrom the current version I\'m browsing! So if I selected an hypothetical\\r\\nRabbitMQ 5.2.x in the dropdown version menu, I would only get results relevant\\r\\nto that version.\\r\\n\\r\\n### Integrated blog\\r\\n\\r\\nAs mentionned above, Docusaurus provides a blog. We will switch to it and stop\\r\\nusing blog.rabbitmq.com. This way, all RabbitMQ-related content will be in a\\r\\nsingle place:\\r\\n* It will be easier for you to browse and move between blog posts and docs.\\r\\n* As said, the internal search will consider both docs and blog posts.\\r\\n* For content writers, it will be easier to cross-reference between blog posts\\r\\n  and docs.\\r\\n\\r\\n### Mobile version and dark mode\\r\\n\\r\\nDocusaurus being *slightly* more modern than our in-house framework, the new\\r\\nwebsite should be browsable comfortably on a small screen and on mobile\\r\\ndevices.\\r\\n\\r\\nIt also comes with a dark mode!\\r\\n\\r\\n<figure>\\r\\n![Screenshot of the dark mode](dark-mode.png)\\r\\n<figcaption>Screenshot of the dark mode</figcaption>\\r\\n</figure>\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nWe are very excited with this move to Docusaurus and everything that the new\\r\\nwebsite will bring to you! Beside the conversion to a new framework, we also\\r\\nplan many improvements to the content itself! Things like... No, let\'s talk\\r\\nabout this in a future blog post on the new website once we have something to\\r\\nshow :-)\\r\\n\\r\\n<div style={{textAlign: \'center\',}}>\\r\\n![](under-construction.gif)\\r\\n</div>\\r\\n\\r\\nMeanwhile, we would love your feedback! We know there are some rough edges\\r\\nafter the conversion, some parts we couldn\'t map easily to Docusaurus\\r\\nalternatives. So, do you find the new website comfortable? Anything you lose\\r\\nthat you love on the old one?\\r\\n\\r\\nHere are a couple links to help you with this:\\r\\n* [The new website](/)\\r\\n* [The pull request to share comments and feedback](https://github.com/rabbitmq/rabbitmq-website/pull/1783)\\r\\n\\r\\nThank you so much for any constructive positive or negative comments you might\\r\\nshare!"},{"id":"/2023/10/24/stream-filtering-internals","metadata":{"permalink":"/rabbitmq-website/blog/2023/10/24/stream-filtering-internals","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2023-10-24-stream-filtering-internals/index.md","source":"@site/blog/2023-10-24-stream-filtering-internals/index.md","title":"Stream Filtering Internals","description":"A previous post gave an introduction to stream filtering, a new and exciting feature in RabbitMQ 3.13.","date":"2023-10-24T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x"}],"readingTime":9.045,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"Stream Filtering Internals","tags":["Streams","Programming Languages","New Features","RabbitMQ 3.13.x"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"New website for RabbitMQ 3.13.0","permalink":"/rabbitmq-website/blog/2024/01/04/new-website"},"nextItem":{"title":"Stream Filtering","permalink":"/rabbitmq-website/blog/2023/10/16/stream-filtering"}},"content":"<!-- diagrams: https://drive.google.com/drive/folders/1ViVE309sdIcZyd23qMfF_m5hq2TQfum-?usp=drive_link -->\\r\\n\\r\\nA [previous post](/blog/2023/10/16/stream-filtering) gave an introduction to stream filtering, a new and exciting feature in RabbitMQ 3.13.\\r\\nIn this post we cover the internals of stream filtering.\\r\\nKnowing the design and implementation will help you to configure and use stream filtering in the most optimal way for your use cases.\\r\\n\\r\\n<!-- truncate -->\\r\\n## Concepts\\r\\n\\r\\nThe idea of stream filtering is to provide a first level of efficient filtering on the broker side, _without_ the broker needing to interpret messages.\\r\\nThis way consumers that need only a subset of the stream do not need to get all the data and handle all the filtering by themselves.\\r\\nThis can drastically reduce the data transmitted to consumers.\\r\\n\\r\\nWith filtering a _filter value_ can be associated to each message.\\r\\nIt can be geographical information, like the region of the world each message comes from, as illustrated in the next figure:\\r\\n\\r\\n![Each message can have a filter value associated to it, like the region of the world it comes from.](stream-filtering-stream.svg)\\r\\n\\r\\nSo our stream has 1 `AMER` (green) message, 1 `APAC` (dark blue) message, 2 `EMEA` (purple) messages, then 2 `AMER` messages.\\r\\n\\r\\n### Message Publishing\\r\\n\\r\\nPublishers get to associate each outbound message with its filter value:\\r\\n\\r\\n![A publisher provides the filter value for each outbound message.](stream-filtering-publisher.svg)\\r\\n\\r\\nIn the figure above, the publisher publishes 1 `AMER` (green) message and 2 `EMEA` (purple) messages that will be added to the stream.\\r\\n\\r\\n### Message Consuming\\r\\n\\r\\nWhen a consumer subscribes, it can specify one or several filter values and the broker is expected to dispatch only the messages with this or these filter value(s).\\r\\nWe will see soon this is a bit different in practice but this is enough to understand the concepts.\\r\\n\\r\\nIn the figure below, the consumer at the top specified it only wants `AMER` (green) messages and the broker dispatches only those.\\r\\nSame thing for the consumer in the middle with `EMEA` messages and the consumer at the bottom with `APAC` messages.\\r\\n\\r\\n![A consumer can specify it only wants messages with given filter value(s) and the broker will do its best to dispatch messages accordingly.](stream-filtering-consumers.svg)\\r\\n\\r\\nThat\'s it for the concepts, let\'s discover the implementation details now.\\r\\n\\r\\n## Structure of a Stream\\r\\n\\r\\nWe need to know how a stream is structured to understand stream filtering internals.\\r\\nA stream is a directory with segment files in it.\\r\\nEach segment file has an associated index file (used to know where to attach a consumer at a given offset in the segment file, among others).\\r\\nHaving several \\"small\\" segment files is better than having a large monolithic file for the whole stream: it is for example more efficient and safer to delete \\"old\\" segment files to truncate the stream than removing the beginning of a large file.\\r\\n\\r\\nA segment file is made of chunks that contain messages.\\r\\nThe number of messages in a chunk depends on the ingress rate (high ingress rate means many messages in a chunk, low ingress rate means fewer messages in a chunk).\\r\\nThe number of messages in a chunk varies from a few (even 1) to a few thousands.\\r\\n\\r\\nWhat is the deal with chunks?\\r\\nChunks are the unit of work in streams: they are used for replication and, more importantly for our topic, for _consumer delivery_.\\r\\nThe broker sends chunks to consumers, one at a time, using the [`sendfile` system call](https://man7.org/linux/man-pages/man2/sendfile.2.html) (to send a whole chunk from the file system to the network socket, without copying the data into userspace).\\r\\n\\r\\nThe following figure illustrates the structure of a stream:\\r\\n\\r\\n![A stream is made of segment files. A segment file contains chunks, a chunk contains messages. The broker dispatches chunks to consumers, not individual messages.](stream-filtering-segments-chunks-messages.svg)\\r\\n\\r\\nWith this in place, let\'s see how the broker can know whether to dispatch a chunk or not.\\r\\n\\r\\n## Filtering On The Broker Side\\r\\n\\r\\nImagine we have a consumer that wants only `AMER` (green) messages.\\r\\nWhen a broker is about to dispatch a chunk, it needs to know whether the chunk contains `AMER` messages or not.\\r\\nIf it does, it can send the chunk to the consumer, if it does not, the broker can skip the chunk, move on to the next one, and re-iterate.\\r\\n\\r\\nEach chunk has a header that can contain a _Bloom filter_, which tells the broker whether the chunk contains a message with a given filter value.\\r\\nA [Bloom filter](https://en.wikipedia.org/wiki/Bloom_filter) is _a space-efficient probabilistic data structure, used to test whether an element is a member of a set_.\\r\\nIn our example the set contains `AMER`, `EMEA`, and `APAC` and the element is `AMER`.\\r\\n\\r\\nThe following figure illustrates the broker-side filtering process for our 3 chunks:\\r\\n\\r\\n![Filtering on the broker side. The broker uses a Bloom filter contained in each chunk to know whether it contains messages with a given filter value. A Bloom filter is efficient but it can return false positives, so the broker may return chunks that do not contain messages with the requested filter value(s).](stream-filtering-dispatch.svg)\\r\\n\\r\\nAs shown in the figure above, the filter can return false positives, that is chunks that do not contain messages with the expected filter value(s).\\r\\nThis is normal, as Bloom filters are probabilistic.\\r\\nThey do not return false negative though: if the filter says there is no `AMER` (green) messages, we can be sure it is true.\\r\\nWe have to live with this uncertainty: we may dispatch some chunks for nothing sometimes, but it is better than dispatching _all_ the chunks.\\r\\n\\r\\nSomething certain is that a consumer can receive messages it does not want: look at our first chunk on the left, it contains `AMER` (green) messages that the consumer asked for, but also `EMEA` (purple), and `APAC` (dark blue) messages.\\r\\nThis is why there must be filtering on the client side as well.\\r\\n\\r\\n## Filtering On The Client Side\\r\\n\\r\\nThe broker handles a first level of filtering when delivering messages, but as the unit of delivery is the chunk, the consumer can still receive messages it does not want.\\r\\nSo the client must do some filtering as well, which obviously must be consistent with the filter value(s) set at subscription time.\\r\\n\\r\\nThe following figure illustrates a consumer that wants only `AMER` (green) messages and that must do a last step of filtering:\\r\\n\\r\\n![As a chunk can contain unwanted messages, the client must filter out messages as well.](stream-filtering-client-side-filtering.svg)\\r\\n\\r\\nLet\'s see how this translates into application code.\\r\\n\\r\\n## API Examples\\r\\n\\r\\nFiltering is not intrusive and can be handled as a cross-cutting concern, minimizing the impact on application code.\\r\\nHere is how to set the logic to extract the filter value from a message when declaring a producer with the [stream Java client](https://github.com/rabbitmq/rabbitmq-stream-java-client/) (`filterValue(Function<Message,String>)` method):\\r\\n\\r\\n```java\\r\\nProducer producer = environment.producerBuilder()\\r\\n  .stream(\\"invoices\\")\\r\\n  .filterValue(msg -> msg.getApplicationProperties().get(\\"region\\").toString())  \\r\\n  .build();\\r\\n```\\r\\n\\r\\nOn the consuming side, the stream Java client provides the `filter().values(String... filterValues)` method to set the filter value(s) and the `filter().postFilter(Predicate<Message> filter)` method to set the client-side filtering logic.\\r\\nBoth methods must be called when declaring the consumer:\\r\\n\\r\\n```java\\r\\nConsumer consumer = environment.consumerBuilder()\\r\\n  .stream(\\"invoices\\")\\r\\n  .filter()\\r\\n    .values(\\"AMER\\")  \\r\\n    .postFilter(msg -> \\"AMER\\".equals(msg.getApplicationProperties().get(\\"region\\")))  \\r\\n  .builder()\\r\\n  .messageHandler((ctx, msg) -> {\\r\\n    // message processing code\\r\\n  })\\r\\n  .build();\\r\\n```\\r\\n\\r\\nAs you can see, filtering does not change the publishing and consuming code, just the declaration of producers and consumers.\\r\\n\\r\\nLet\'s see now how to configure stream filtering in the most appropriate way for a use case.\\r\\n\\r\\n## Stream Filtering Configuration\\r\\n\\r\\nThe [first post on stream filtering](/blog/2023/10/16/stream-filtering#trying-it-out) provided some numbers (about 80% bandwidth savings with filtering compared to no filtering).\\r\\nBenefits of stream filtering depend heavily on the use case: ingress rate, cardinality and distribution of filter values, but also _filter size_.\\r\\nThe larger the filter, the better (error rate gets smaller).\\r\\nIt is possible to set a value between 16 and 255 bytes for the size of the filter used in chunks, the default being 16 bytes.\\r\\n\\r\\nThe stream Java client provides the `filterSize(int)` method to set the filter size when creating a stream (it sets the `stream-filter-size-bytes` parameter internally):\\r\\n\\r\\n```java\\r\\nenvironment.streamCreator()\\r\\n  .stream(\\"invoices\\")\\r\\n  .filterSize(32)\\r\\n  .create()\\r\\n```\\r\\n\\r\\nHow to estimate the size of the filter?\\r\\nThere are many Bloom filter calculators available online.\\r\\nThe parameters are the number of hash functions (2 for RabbitMQ stream filtering), the number of expected elements, the error rate, and the size.\\r\\nYou usually have an idea of the number of elements, so you need to find a trade-off between the error rate and the filter size.\\r\\n\\r\\nHere are some examples:\\r\\n\\r\\n* 10 values, 16 bytes => 2 % error rate\\r\\n* 30 values, 16 bytes => 14 % error rate\\r\\n* 200 values, 128 bytes => 10 % error rate\\r\\n\\r\\nSo, the larger the filter, the better?\\r\\nNot exactly: even though a Bloom filter is very efficient in terms of storage, as it does not store elements, just whether elements are in the set, the filter size is pre-allocated.\\r\\nIf you set the filter size to 255 and each chunk contains at least one message with a filter value, there will be 255 bytes allocated in each chunk header.\\r\\nThis is fine if chunks contain many large messages, as the filter size is negligible compared to the chunk size.\\r\\nBut with a degenerated case like a single-message chunk with a 10-byte message and a 10-byte filter value, you end up with a filter larger than the actual data.\\r\\n\\r\\nYou\'ll have to experiment with your own use cases to estimate the impact of the filter size on your stream size.\\r\\nThe [first post on stream filtering](/blog/2023/10/16/stream-filtering#trying-it-out) provides a trick to estimate the size of a stream with Stream PerfTest (read the whole stream without filtering and consult the `rabbitmq_stream_read_bytes_total` metric).\\r\\n\\r\\n## Bonus: Stream Filtering On AMQP\\r\\n\\r\\nEven though the preferred way to access streams is the stream protocol, other protocols are supported, like AMQP.\\r\\nStream filtering is also supported with any AMQP client library:\\r\\n\\r\\n* Declaration: set the `x-queue-type` argument to `stream` and use the `x-stream-filter-size-bytes` to set the filter size when you declare a stream.\\r\\n* Publishing: use the `x-stream-filter-value` header to set the filter value for outbound messages.\\r\\n* Consuming: use the `x-stream-filter` consumer argument to set the expected filter value(s) (string or array of strings) and optionally the `x-stream-match-unfiltered` consumer argument to receive messages without any filter value as well (default is `false`). Client-side filtering is still necessary!\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nThis blog post provided an in-depth description of stream filtering in RabbitMQ 3.13.\\r\\nIt complements a [first post](/blog/2023/10/16/stream-filtering) that gives an introduction on the usage and a demonstration of stream filtering.\\r\\n\\r\\nStream filtering is easy to use and to benefit from, but some knowledge on the internals can be useful to optimize its usage, especially for tricky use cases.\\r\\nRemember that client-side filtering is necessary and must be consistent with the configured filter value(s).\\r\\nThis is usually straightforward to implement.\\r\\nIt is also possible to set the filter size in the most appropriate way for a given use case."},{"id":"/2023/10/16/stream-filtering","metadata":{"permalink":"/rabbitmq-website/blog/2023/10/16/stream-filtering","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2023-10-16-stream-filtering/index.md","source":"@site/blog/2023-10-16-stream-filtering/index.md","title":"Stream Filtering","description":"Stream filtering is a new feature in RabbitMQ 3.13.","date":"2023-10-16T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x"}],"readingTime":5.2,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"Stream Filtering","tags":["Streams","Programming Languages","New Features","RabbitMQ 3.13.x"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Stream Filtering Internals","permalink":"/rabbitmq-website/blog/2023/10/24/stream-filtering-internals"},"nextItem":{"title":"MQTT 5.0 support is coming in RabbitMQ 3.13","permalink":"/rabbitmq-website/blog/2023/07/21/mqtt5"}},"content":"Stream filtering is a new feature in RabbitMQ 3.13.\\r\\nIt allows to save bandwidth between the broker and consuming applications when those applications need only a subset of the messages of a stream.\\r\\n\\r\\nKeep reading to find out how stream filtering works and see it in action.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Concepts of Stream Filtering\\r\\n\\r\\nImagine you have a stream containing data from all around the world and an application that needs to process only a subset of this data, let\'s say messages for a given region.\\r\\nThe application can read the whole stream and filter out the data to only process the messages it is interested in.\\r\\nThis works but it means the whole stream content will go through the network.\\r\\n\\r\\nStream filtering provides a first level of efficient filtering on the broker side, _without_ the broker needing to interpret messages.\\r\\nIt can dramatically reduce the amount of data exchanged on the network for some use cases.\\r\\nLet\'s discover the semantics of this new exciting feature.\\r\\n\\r\\n## On The Publishing Side\\r\\n\\r\\nStream filtering is based on a _filter value_: a publishing application can associate each message with a string value.\\r\\nFilter values can be anything, but they should meet some criteria for filtering to work properly.\\r\\nA defined set of values shared across the messages is a good candidate: geographical locations (e.g. countries, states), document types in a stream that stores document information (e.g. payslip, invoice, order), categories of products (e.g. book, luggage, toy).\\r\\n\\r\\nHow a message is associated to a filter value depends on the client library.\\r\\nHere is an example with the [stream Java client](https://github.com/rabbitmq/rabbitmq-stream-java-client/):\\r\\n\\r\\n```java\\r\\nProducer producer = environment.producerBuilder()\\r\\n  .stream(\\"invoices\\")\\r\\n  .filterValue(msg -> msg.getApplicationProperties().get(\\"region\\").toString())  \\r\\n  .build();\\r\\n```\\r\\n\\r\\nIn this example the application developer provides some logic to extract the filter value from the message application properties.\\r\\nUsing filtering is as simple as this: no need to change the actual message publishing code, you just need to provide the filter value logic when creating a `Producer`.\\r\\n\\r\\nLet\'s see now how it works for consumers.\\r\\n\\r\\n## On The Consumer Side\\r\\n\\r\\nHere is a Java code snippet to declare a consumer that is only interested in messages from the `emea` region:\\r\\n\\r\\n```java\\r\\nConsumer consumer = environment.consumerBuilder()\\r\\n  .stream(\\"invoices\\")\\r\\n  .filter()\\r\\n    .values(\\"emea\\")  \\r\\n    .postFilter(msg -> \\"emea\\".equals(msg.getApplicationProperties().get(\\"region\\")))  \\r\\n  .builder()\\r\\n  .messageHandler((ctx, msg) -> {\\r\\n    // message processing code\\r\\n  })\\r\\n  .build();\\r\\n```\\r\\n\\r\\nFiltering is configured in two places:\\r\\n\\r\\n* `filter().values(String... filterValues)` tells the broker we are interested in messages associated with these values (we can specify several values, not only one)\\r\\n* `filter().postFilter(Predicate<Message> filter)` provides some client-side logic to filter out messages that would _not_ be associated with the expected filter value(s)\\r\\n\\r\\nWhy the need for this client-side filtering logic?\\r\\nThe broker-side filtering logic uses a [Bloom filter](https://en.wikipedia.org/wiki/Bloom_filter):\\r\\n\\r\\n> A Bloom filter is a space-efficient probabilistic data structure, used to test whether an element is a member of a set.\\r\\n\\r\\nA Bloom filter is very efficient in terms of storage and speed, but it is probabilistic: it can return _false positives_.\\r\\nBecause of this, the broker can send messages it believes match the expected filter values whereas they do not.\\r\\nThat\'s why some client-side filtering logic is necessary.\\r\\n\\r\\nThis is something to be aware of, but that is a minor caveat compared to the benefits stream filtering brings.\\r\\n\\r\\nA [subsequent blog post](/blog/2023/10/24/stream-filtering-internals) covers the internals of stream filtering for those interested in technical details.\\r\\nYou can also have a look at the [stream Java client documentation on filtering](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#filtering) for more information.\\r\\nIt covers among others that a message does not always have to be associated to a filter value and a consumer can choose to receive messages with given filter value(s) _and_ messages _without_ a filter value (with `filter().matchUnfiltered()`).\\r\\n\\r\\n## Trying It Out \\r\\n\\r\\nLet\'s see stream filtering in action.\\r\\nStart a RabbitMQ 3.13+ node:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --name rabbitmq -p 5552:5552 \\\\\\r\\n    -e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\'-rabbitmq_stream advertised_host localhost\' \\\\\\r\\n    rabbitmq:3.13\\r\\n```\\r\\n\\r\\nEnable the stream plugin:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_stream\\r\\n```\\r\\n\\r\\nDownload [Stream PerfTest](https://github.com/rabbitmq/rabbitmq-stream-perf-test/) (it requires Java 11 or more to run):\\r\\n\\r\\n```shell\\r\\ncd /tmp\\r\\nwget -O stream-perf-test.jar \\\\\\r\\n  https://github.com/rabbitmq/rabbitmq-java-tools-binaries-dev/releases/download/v-stream-perf-test-latest/stream-perf-test-latest.jar\\r\\n```\\r\\n\\r\\nLet\'s publish messages for 10 seconds:\\r\\n\\r\\n```shell\\r\\njava -jar stream-perf-test.jar --producers 1 --consumers 0 --rate 100 --filter-value-set 1..50 --size 10000 --time 10\\r\\n```\\r\\n\\r\\nThe messages are 10 KB long and `--filter-value-set 1..50` means a random filter value between `\\"1\\"` and `\\"50\\"` is associated with each message.\\r\\n\\r\\nLet\'s consume all the messages (without any filtering):\\r\\n\\r\\n```shell\\r\\njava -jar stream-perf-test.jar --producers 0 --consumers 1 --offset first --prometheus\\r\\n```\\r\\n\\r\\nThe output should stop after a few seconds, when the consumer reaches the end of the stream.\\r\\nDo not stop the application, open another terminal tab instead, and query Stream PerfTest metrics to see how much data it read:\\r\\n\\r\\n```shell\\r\\ncurl --silent localhost:8080/metrics | grep rabbitmq_stream_read_bytes_total\\r\\n```\\r\\n\\r\\nYou should get something like the following:\\r\\n\\r\\n```properties\\r\\n# HELP rabbitmq_stream_read_bytes_total\\r\\n# TYPE rabbitmq_stream_read_bytes_total counter\\r\\nrabbitmq_stream_read_bytes_total 1.0046894E7\\r\\n```\\r\\n\\r\\nThis is about 10 MB.\\r\\nThe client had to transfer the entire stream.\\r\\n\\r\\nNow stop Stream PerfTest (`Ctrl-C`) and start it again, this time with filtering enabled:\\r\\n\\r\\n```shell\\r\\njava -jar stream-perf-test.jar --producers 0 --consumers 1 --offset first --prometheus --filter-values 5\\r\\n```\\r\\n\\r\\nHere we ask to get only messages with the `\\"5\\"` filter value (`--filter-values 5`).\\r\\nAgain, wait for the output to stop and check the number of bytes read:\\r\\n\\r\\n```shell\\r\\ncurl --silent localhost:8080/metrics | grep rabbitmq_stream_read_bytes_total\\r\\n```\\r\\n\\r\\nYou should get something like:\\r\\n\\r\\n```properties\\r\\n# HELP rabbitmq_stream_read_bytes_total\\r\\n# TYPE rabbitmq_stream_read_bytes_total counter\\r\\nrabbitmq_stream_read_bytes_total 1957641.0\\r\\n```\\r\\n\\r\\nThis is less than 2 MB.\\r\\nIt is 8 MB of bandwidth saved, about 80%, not bad!\\r\\n\\r\\nOf course this is somewhat artificial: Stream PerfTest is not a real application and it is unlikely it distributes messages and filter values the way real applications do.\\r\\nBut still, it gives an idea of what the bandwidth savings can be with stream filtering.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nWe had a quick overview of stream filtering in RabbitMQ 3.13.\\r\\nIt allows to save bandwidth when messages are dispatched from the broker to consuming applications.\\r\\nNot all use cases can benefit from stream filtering, but the benefits in terms of bandwidth for those that can are quite compelling.\\r\\n\\r\\nStay tuned for a [subsequent blog post](/blog/2023/10/24/stream-filtering-internals) that will cover the internal details of stream filtering to help you use it and configure it in the most optimal way."},{"id":"/2023/07/21/mqtt5","metadata":{"permalink":"/rabbitmq-website/blog/2023/07/21/mqtt5","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2023-07-21-mqtt5/index.md","source":"@site/blog/2023-07-21-mqtt5/index.md","title":"MQTT 5.0 support is coming in RabbitMQ 3.13","description":"Native MQTT released in RabbitMQ 3.12 has delivered substantial scalability and performance improvements for IoT use cases.","date":"2023-07-21T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"Technical Deep Dive","permalink":"/rabbitmq-website/blog/tags/technical-deep-dive"},{"inline":true,"label":"MQTT","permalink":"/rabbitmq-website/blog/tags/mqtt"},{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x"}],"readingTime":26.08,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"MQTT 5.0 support is coming in RabbitMQ 3.13","tags":["New Features","Technical Deep Dive","MQTT","RabbitMQ 3.13.x"],"authors":["dansari"]},"unlisted":false,"prevItem":{"title":"Stream Filtering","permalink":"/rabbitmq-website/blog/2023/10/16/stream-filtering"},"nextItem":{"title":"RabbitMQ 3.12 Performance Improvements","permalink":"/rabbitmq-website/blog/2023/05/17/rabbitmq-3.12-performance-improvements"}},"content":"[Native MQTT](/blog/2023/03/21/native-mqtt) released in RabbitMQ 3.12 has delivered substantial scalability and performance improvements for IoT use cases.\\r\\n\\r\\nRabbitMQ 3.13 will support [MQTT 5.0](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html) and will therefore be the next big step in our journey to make RabbitMQ one of the leading MQTT brokers.\\r\\n\\r\\nThis blog post explains how the new MQTT 5.0 features are used in RabbitMQ.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## MQTT Overview\\r\\n\\r\\nMQTT is the standard protocol for the Internet of Things (IoT).\\r\\n\\r\\nIoT remote devices can have a poor network quality when connecting to the broker.\\r\\nTherefore, MQTT is lightweight: MQTT protocol headers are small to save network bandwidth.\\r\\n\\r\\nSince IoT devices might often disconnect and reconnect - imagine a car driving through a tunnel - MQTT is also efficient: Clients are connected and authenticated with a handshake that is shorter compared to other messaging protocols.\\r\\n\\r\\nThe MQTT protocol has been around for many years.\\r\\nAs shown in the following table, the latest MQTT protocol version is 5.0.\\r\\n\\r\\n| MQTT version | Protocol version in CONNECT packet | MQTT spec release year | RabbitMQ support since year (version) |\\r\\n| --- | --- | --- | --- |\\r\\n| [3.1](https://public.dhe.ibm.com/software/dw/webservices/ws-mqtt/mqtt-v3r1.html) | 3 | 2010 | 2012 (3.0) |\\r\\n| [3.1.1](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html) | 4 | 2014 | 2014 (3.3) |\\r\\n| [5.0](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html) | [5](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901037) | 2019 | 2024 (3.13) |\\r\\n\\r\\nIt is worth mentioning that there is a difference between the user facing protocol version and the \\"internal\\" protocol version (also known as the protocol level).\\r\\nThe latter is sent from client to server in the [CONNECT](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901033) packet.\\r\\nBecause user facing protocol version 3.1.1 maps to internal protocol version 4, to avoid further confusion, the MQTT committee decided to skip user facing version 4.0 such that user facing version 5.0 maps to internal protocol version 5.\\r\\n\\r\\n## MQTT 5.0 Features\\r\\n\\r\\n[Appendix C. Summary of new features in MQTT v5.0](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901293) provides a complete list of new MQTT 5.0 features.\\r\\n\\r\\nSince you find great MQTT 5.0 resources including illustrative diagrams and usage patterns on the web, this blog post focuses solely on RabbitMQ specifics.\\r\\nThis section explains the most significant features implemented in PR [#7263](https://github.com/rabbitmq/rabbitmq-server/pull/7263).\\r\\nFor each feature, we provide an example how it is used with RabbitMQ or outline a high level description of how it is implemented in RabbitMQ.\\r\\n\\r\\nTo run the examples by yourself, start RabbitMQ server 3.13,\\r\\nfor example, using [this Docker image tag](https://hub.docker.com/layers/library/rabbitmq/3.13.0-management/images/sha256-ba26f50715029bb709cbe8831cfd07a5473da00557a0720269fa69c1fb66c6d6?context=explore):\\r\\n\\r\\n```bash\\r\\ndocker run -it --rm --name rabbitmq -p 1883:1883 -p 15672:15672 -p 15692:15692 rabbitmq:3.13.0-management\\r\\n```\\r\\n\\r\\nIn another terminal window, enable the [MQTT plugin](/docs/mqtt):\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_mqtt\\r\\n```\\r\\n\\r\\nSince the MQTT plugin got enabled dynamically, [feature flags defined by the MQTT plugin](/docs/feature-flags#rabbitmq_mqtt-feature-flags) are disabled.\\r\\nEnable all feature flags including feature flag `mqtt_v5`:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl enable_feature_flag all\\r\\n```\\r\\nListing the feature flags should now show that all feature flags are enabled:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl list_feature_flags --formatter=pretty_table\\r\\n```\\r\\n\\r\\nBelow examples use [MQTTX CLI](https://mqttx.app/cli) version 1.9.4.\\r\\nWe use a CLI rather than a graphical UI so that you can easily run the examples by copy pasting the commands.\\r\\n\\r\\nAll new features also apply to the [RabbitMQ Web MQTT Plugin](/docs/web-mqtt).\\r\\n\\r\\nHere is the list of MQTT 5.0 features covered in this blog post:\\r\\n* [Feature 1: Message Expiry](#feature-1-message-expiry)\\r\\n* [Feature 2: Subscription Identifier](#feature-2-subscription-identifier)\\r\\n* [Feature 3: Subscription Options](#feature-3-subscription-options)\\r\\n* [Feature 4: Reason code on all ACKs](#feature-4-reason-code-on-all-acks)\\r\\n* [Feature 5: User properties](#feature-5-user-properties)\\r\\n* [Feature 6: Payload Format and Content Type](#feature-6-payload-format-and-content-type)\\r\\n* [Feature 7: Request / Response](#feature-7-request--response)\\r\\n* [Feature 8: Assigned Client Identifier](#feature-8-assigned-client-identifier)\\r\\n* [Feature 9: Topic Alias](#feature-9-topic-alias)\\r\\n* [Feature 10: Flow control](#feature-10-flow-control)\\r\\n* [Feature 11: Maximum Packet Size](#feature-11-maximum-packet-size)\\r\\n* [Feature 12: Server initiated DISCONNECT](#feature-12-server-initiated-disconnect)\\r\\n* [Feature 13: Session Expiry](#feature-13-session-expiry)\\r\\n* [Feature 14: Will delay](#feature-14-will-delay)\\r\\n* [Feature 15: Optional Server feature availability](#feature-15-optional-server-feature-availability)\\r\\n\\r\\n### Feature 1: [Message Expiry](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901112)\\r\\n\\r\\n#### Description\\r\\nAn expiry interval in seconds can be set for each message being published to the broker.\\r\\nIf the message is not consumed within that expiry interval, the message is discarded or dead lettered.\\r\\n#### Example\\r\\nCreate a subscription for topic `t/1`.\\r\\nThis creates a queue in RabbitMQ.\\r\\nDisconnect the client by typing `Ctrl+C` in the terminal.\\r\\nSince we use a [Session Expiry Interval](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901048) of 600 seconds, this queue will exist for 10 more minutes.\\r\\n```bash\\r\\nmqttx sub --client-id sub-1 --topic t/1 --session-expiry-interval 600 --qos 1\\r\\n…  Connecting...\\r\\n✔  Connected\\r\\n…  Subscribing to t/1...\\r\\n✔  Subscribed to t/1\\r\\n^C\\r\\n```\\r\\n\\r\\nPublish a message to the same topic with a message expiry interval of 30 seconds:\\r\\n```bash\\r\\nmqttx pub --topic t/1 --message m1 --message-expiry-interval 30 --qos 1\\r\\n…  Connecting...\\r\\n✔  Connected\\r\\n…  Message publishing...\\r\\n✔  Message published\\r\\n```\\r\\n\\r\\nWithin the next 30 seconds, list the queues:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl --quiet --formatter=pretty_table list_queues name type messages\\r\\n┌─────────────────────────────┬─────────┬──────────┐\\r\\n│ name                        │ type    │ messages │\\r\\n├─────────────────────────────┼─────────┼──────────┤\\r\\n│ mqtt-subscription-sub-1qos1 │ classic │ 1        │\\r\\n└─────────────────────────────┴─────────┴──────────┘\\r\\n```\\r\\n\\r\\nWait for 30 seconds, and list the queues again:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl --quiet --formatter=pretty_table list_queues\\r\\n┌─────────────────────────────┬─────────┬──────────┐\\r\\n│ name                        │ type    │ messages │\\r\\n├─────────────────────────────┼─────────┼──────────┤\\r\\n│ mqtt-subscription-sub-1qos1 │ classic │ 0        │\\r\\n└─────────────────────────────┴─────────┴──────────┘\\r\\n```\\r\\n\\r\\nThe message expired since client `sub-1` has not connected to the broker to consume the message.\\r\\nIf a [dead lettering](/docs/dlx) policy is set up, the message will be dead lettered to an exchange.\\r\\nIn our case, dead lettering is disabled.\\r\\nQuerying the Prometheus endpoint proves that 1 message expired from a classic queue.\\r\\n```bash\\r\\ncurl --silent localhost:15692/metrics | grep rabbitmq_global_messages_dead_lettered_expired_total\\r\\n# TYPE rabbitmq_global_messages_dead_lettered_expired_total counter\\r\\n# HELP rabbitmq_global_messages_dead_lettered_expired_total Total number of messages dead-lettered due to message TTL exceeded\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"disabled\\"} 1\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_least_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\n```\\r\\n\\r\\nAnother interesting feature is the following requirement:\\r\\n> The PUBLISH packet sent to a Client by the Server MUST contain a Message Expiry Interval set to the received value minus the time that the Application Message has been waiting in the Server.\\r\\n\\r\\nSend a second message to the broker with a Message Expiry Interval of 60 seconds:\\r\\n```bash\\r\\nmqttx pub --topic t/1 --message m2 --message-expiry-interval 60 --qos 1\\r\\n```\\r\\n\\r\\nWait for 20 seconds before reconnecting the subscribing client:\\r\\n```bash\\r\\nmqttx sub --client-id sub-1 --topic t/1 --no-clean --session-expiry-interval 0  --qos 1 --output-mode clean\\r\\n{\\r\\n  \\"topic\\": \\"t/1\\",\\r\\n  \\"payload\\": \\"m2\\",\\r\\n  \\"packet\\": {\\r\\n    ...\\r\\n    \\"properties\\": {\\r\\n      \\"messageExpiryInterval\\": 40\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\nAs mandated by the MQTT 5.0 protocol specification, the client receives the second message with a Message Expiry Interval set to 40 seconds:\\r\\n60 seconds as received by the broker minus the 20 seconds the message has been waiting in the broker.\\r\\n\\r\\n#### Implementation\\r\\nMQTT 5.0 Message Expiry is implemented in RabbitMQ using [per-message TTL](/docs/ttl#per-message-ttl-in-publishers) similar to the `expiration` field in AMQP 0.9.1 publishers.\\r\\n\\r\\n### Feature 2: [Subscription Identifier](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901166)\\r\\n\\r\\n#### Description\\r\\nA client can set a subscription identifier in a [SUBSCRIBE](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901161) packet.\\r\\nIf the client is being sent a message due to that subscription, the broker will include that subscription identifier into the [PUBLISH](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901100) packet.\\r\\n\\r\\nUse cases for subscription identifiers are listed in section [SUBSCRIBE Actions](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901170).\\r\\n\\r\\n#### Example\\r\\nSend 3 separate SUBSCRIBE packets from the same client to the server, each with a different topic filter and different subscription identifier:\\r\\n```bash\\r\\nmqttx sub --client-id sub-2 --topic t/1 --subscription-identifier 1 --session-expiry-interval 600\\r\\n^C\\r\\nmqttx sub --client-id sub-2 --topic t/2 --subscription-identifier 2 --session-expiry-interval 600 --no-clean\\r\\n^C\\r\\nmqttx sub --client-id sub-2 --topic \\"t/#\\" --subscription-identifier 3 --session-expiry-interval 0 --no-clean --output-mode clean\\r\\n```\\r\\n\\r\\nIn a 2nd terminal window, we see 3 bindings from the same queue to the same topic exchange, each with a different routing key:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl --quiet --formatter=pretty_table list_bindings \\\\\\r\\n    source_name source_kind destination_name destination_kind routing_key\\r\\n┌─────────────┬─────────────┬─────────────────────────────┬──────────────────┬─────────────────────────────┐\\r\\n│ source_name │ source_kind │ destination_name            │ destination_kind │ routing_key                 │\\r\\n├─────────────┼─────────────┼─────────────────────────────┼──────────────────┼─────────────────────────────┤\\r\\n│             │ exchange    │ mqtt-subscription-sub-2qos0 │ queue            │ mqtt-subscription-sub-2qos0 │\\r\\n├─────────────┼─────────────┼─────────────────────────────┼──────────────────┼─────────────────────────────┤\\r\\n│ amq.topic   │ exchange    │ mqtt-subscription-sub-2qos0 │ queue            │ t.#                         │\\r\\n├─────────────┼─────────────┼─────────────────────────────┼──────────────────┼─────────────────────────────┤\\r\\n│ amq.topic   │ exchange    │ mqtt-subscription-sub-2qos0 │ queue            │ t.1                         │\\r\\n├─────────────┼─────────────┼─────────────────────────────┼──────────────────┼─────────────────────────────┤\\r\\n│ amq.topic   │ exchange    │ mqtt-subscription-sub-2qos0 │ queue            │ t.2                         │\\r\\n└─────────────┴─────────────┴─────────────────────────────┴──────────────────┴─────────────────────────────┘\\r\\n```\\r\\nThe first entry is the implicit binding to the default exchange.\\r\\n\\r\\nEach MQTT subscription with its MQTT topic filter corresponds to one AMQP 0.9.1 binding with a binding key.\\r\\nTo be precise, table column `routing_key` is misnamed: It should be called `binding_key` instead.\\r\\nThe topic level separator in MQTT is the \\"`/`\\" character whereas the topic level separator in AMQP 0.9.1 topic exchanges is the \\"`.`\\" character.\\r\\n\\r\\nAgain in the 2nd terminal window, send a message to topic `t/1`:\\r\\n```bash\\r\\nmqttx pub --topic t/1 --message m1\\r\\n```\\r\\n\\r\\nThe 1st terminal window (of the subscribing client) receives the following PUBLISH packet:\\r\\n```bash\\r\\n{\\r\\n  \\"topic\\": \\"t/1\\",\\r\\n  \\"payload\\": \\"m1\\",\\r\\n  \\"packet\\": {\\r\\n    ...\\r\\n    \\"properties\\": {\\r\\n      \\"subscriptionIdentifier\\": [\\r\\n        1,\\r\\n        3\\r\\n      ]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\nIt contains subscription identifiers 1 and 3 because both topic filters `t/1` and `t/#` match topic `t/1`.\\r\\n\\r\\nLikewise, if you send a 2nd message to topic `t/2`, the subscribing client will receive a PUBLISH packet containing subscription identifiers 2 and 3.\\r\\n\\r\\n#### Implementation\\r\\nSubscription identifiers are part of the MQTT session state.\\r\\nTherefore, subscription identifiers must be persisted in the server\'s database while the client is disconnected and until the MQTT session ends.\\r\\nRabbitMQ stores the subscription identifiers in the binding arguments:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl --quiet --formatter=pretty_table list_bindings routing_key arguments\\r\\n┌─────────────────────────────┬───────────────────────────────────────────────────────────────────────────────────┐\\r\\n│ routing_key                 │ arguments                                                                         │\\r\\n├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────┤\\r\\n│ mqtt-subscription-sub-2qos0 │                                                                                   │\\r\\n├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────┤\\r\\n│ t.#                         │ {mqtt_subscription_opts,0,false,false,0,3}{<<\\"x-binding-key\\">>,longstr,<<\\"t.#\\">>} │\\r\\n├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────┤\\r\\n│ t.1                         │ {mqtt_subscription_opts,0,false,false,0,1}{<<\\"x-binding-key\\">>,longstr,<<\\"t.1\\">>} │\\r\\n├─────────────────────────────┼───────────────────────────────────────────────────────────────────────────────────┤\\r\\n│ t.2                         │ {mqtt_subscription_opts,0,false,false,0,2}{<<\\"x-binding-key\\">>,longstr,<<\\"t.2\\">>} │\\r\\n└─────────────────────────────┴───────────────────────────────────────────────────────────────────────────────────┘\\r\\n```\\r\\nThe exact structure of the binding arguments is not important and will likely change in a future RabbitMQ version.\\r\\nHowever, you can see integers 1, 2, and 3 in the binding arguments which correspond to the subscription identifiers.\\r\\n\\r\\nWhen the topic exchange routes a message, the publishing Erlang process will include all matched binding keys into the message.\\r\\nThe Erlang process of the subscribing MQTT client compares the matched binding keys with the MQTT topic filters it knows about and includes the subscription identifiers into the PUBLISH packet sent to the MQTT client.\\r\\n\\r\\nThe publishing Erlang process can be an MQTT connection process or a AMQP 0.9.1 channel process.\\r\\nAs always, RabbitMQ excels in cross protocol interoperability: When an AMQP 0.9.1 (or STOMP or AMQP 1.0) client sends a message to the topic exchange,\\r\\nthe correct subscription identifier will be included in the PUBLISH packet sent to the MQTT client.\\r\\n\\r\\n### Feature 3: [Subscription Options](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901169)\\r\\n#### Description\\r\\nMQTT 5.0 comes with 3 new subscription options:\\r\\n1. No Local\\r\\n2. Retain as Published\\r\\n3. Retain Handling\\r\\n\\r\\nAll subscription options are implemented by RabbitMQ.\\r\\nHere, we focus only on the Retain Handling option:\\r\\n> This option specifies whether retained messages are sent when the subscription is established.  \\r\\nThe values are:  \\r\\n0 = Send retained messages at the time of the subscribe  \\r\\n1 = Send retained messages at subscribe only if the subscription does not currently exist  \\r\\n2 = Do not send retained messages at the time of the subscribe  \\r\\n\\r\\n#### Example\\r\\n\\r\\nSend a retained message:\\r\\n```bash\\r\\nmqttx pub --topic mytopic --message m --retain\\r\\n```\\r\\n\\r\\nRetain Handling value 0 will receive the retained message while value 2 will not:\\r\\n```bash\\r\\nmqttx sub --topic mytopic --retain-handling 0\\r\\n…  Connecting...\\r\\n✔  Connected\\r\\n…  Subscribing to mytopic...\\r\\n✔  Subscribed to mytopic\\r\\npayload: m\\r\\nretain: true\\r\\n^C\\r\\n\\r\\nmqttx sub --topic mytopic --retain-handling 2\\r\\n…  Connecting...\\r\\n✔  Connected\\r\\n…  Subscribing to mytopic...\\r\\n✔  Subscribed to mytopic\\r\\n```\\r\\n\\r\\n### Feature 4: Reason code on all ACKs\\r\\n\\r\\n#### Description\\r\\nPackets CONNACK, PUBACK, SUBACK, UNSUBACK, and DISCONNECT contain a reason code.\\r\\n\\r\\n#### Implementation\\r\\nOne implementation example is that RabbitMQ will reply with a reason code `No matching subscribers` in the PUBACK packet if the message is not routed to any queues.\\r\\nMQTT 5.0 reason code `No matching subscribers` corresponds conceptually to the [mandatory](/docs/publishers#unroutable) message property and `BasicReturn` handler in AMQP 0.9.1.\\r\\n\\r\\n### Feature 5: User properties\\r\\n\\r\\n#### Description\\r\\nMost MQTT packets can contain user properties.\\r\\nThe meaning of user properties is not defined by the MQTT specification.\\r\\n\\r\\n#### Example PUBLISH packet\\r\\nUser properties in the PUBLISH packet are defined by client applications and forwarded unaltered by the server.\\r\\n\\r\\nSubscribe in the 1st terminal window:\\r\\n```bash\\r\\nmqttx sub --topic t/5\\r\\n```\\r\\n\\r\\nPublish a message with user properties in the 2nd terminal window:\\r\\n```bash\\r\\nmqttx pub --topic t/5 --message m --user-properties \\"key1: value1\\"\\r\\n```\\r\\n\\r\\nThe 1st terminal window will receive the user properties unaltered:\\r\\n```bash\\r\\npayload: m\\r\\nuserProperties: [ { key: \'key1\', value: \'value1\' } ]\\r\\n```\\r\\n\\r\\nUser properties in an MQTT 5.0 PUBLISH packet are similar to the `headers` message property in AMQP 0.9.1.\\r\\n\\r\\n#### Example CONNECT packet\\r\\n\\r\\nConnect with a user property:\\r\\n```bash\\r\\nmqttx conn --client-id myclient --user-properties \\"connecting-from: London\\"\\r\\n```\\r\\n\\r\\nOpen the Management UI [http://localhost:15672/#/connections](http://localhost:15672/#/connections) in your browser (both username and password is `guest`) and click on the MQTT connection:\\r\\n\\r\\n![Figure 1: User Property in the CONNECT packet](user-property.png)\\r\\n\\r\\nRabbitMQ will display the user property from the CONNECT packet in the Management UI.\\r\\n\\r\\n### Feature 6: [Payload Format](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901111) and [Content Type](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901118)\\r\\n\\r\\n#### Description\\r\\nThe publisher can specify a MIME content type.\\r\\nIt can also set a payload format indicator indicating whether the payload consists of UTF-8 encoded character data or unspecified binary data.\\r\\n\\r\\n#### Example\\r\\n\\r\\nIn the 1st terminal window, subscribe to a topic:\\r\\n```bash\\r\\nmqttx sub --topic t/6 --output-mode clean\\r\\n```\\r\\n\\r\\nIn the 2nd terminal window, send a message with a content type and payload format indicator:\\r\\n```bash\\r\\nmqttx pub --topic t/6 --message \\"my UTF-8 encoded data 🙂\\" --content-type text/plain --payload-format-indicator\\r\\n```\\r\\n\\r\\nThe 1st terminal window will receive the content type and payload format indicator unaltered:\\r\\n```bash\\r\\n{\\r\\n  \\"topic\\": \\"t/6\\",\\r\\n  \\"payload\\": \\"my UTF-8 encoded data 🙂\\",\\r\\n  \\"packet\\": {\\r\\n    ...\\r\\n    \\"properties\\": {\\r\\n      \\"payloadFormatIndicator\\": true,\\r\\n      \\"contentType\\": \\"text/plain\\"\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n\\r\\n### Feature 7: [Request / Response](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901253)\\r\\n\\r\\n#### Description\\r\\nMQTT 5.0 formalizes the Request / Response pattern.\\r\\n\\r\\nBefore publishing a message, an MQTT client (the requester) subscribes to a response topic.\\r\\nThe requester includes the response topic and some correlation data into the request message.\\r\\n\\r\\nAnother MQTT client (the responder) receives the request message, takes some action, and publishes a response message with the same correlation data to the response topic.\\r\\n\\r\\nThe MQTT 5.0 Request / Response feature corresponds to [Remote Procedure Calls in AMQP 0.9.1](/tutorials/tutorial-six-go).\\r\\nHowever, in AMQP 0.9.1 the requester will include the name of a callback queue in the AMQP 0.9.1 message property `reply_to`.\\r\\nThe MQTT protocol does not define the concept of queues. Therefore, in MQTT the \\"address\\" being replied to is a topic name.\\r\\n\\r\\nDespite the incompatibilities between the protocol specifications, RabbitMQ shines at protocol interoperability:\\r\\nRequest / Response interactions are therefore supported by RabbitMQ across protocols.\\r\\n\\r\\nFor example an MQTT client can include a response topic and correlation data in the request message.\\r\\nIf an AMQP 0.9.1 client created a queue bound to the topic exchange `amq.topic` with a binding key matching the topic of the request message, it will receive an AMQP 0.9.1 message with property `correlation_id` set to the\\r\\ncorrelation data sent by the MQTT client and a header called `x-opt-reply-to-topic`.\\r\\nThe AMQP 0.9.1 client can then respond to the MQTT 5.0 client by using the same `correlation_id` and publishing the response message to the topic exchange `amq.topic` with the topic that was present in the `x-opt-reply-to-topic` header.\\r\\n\\r\\n#### Example\\r\\n\\r\\nThis example focuses solely on MQTT clients.\\r\\n\\r\\nIn the 1st terminal window, the responding MQTT client subscribes to topic `t/7`;\\r\\n\\r\\n```bash\\r\\nmqttx sub --client-id responder --topic t/7 --session-expiry-interval 600 --output-mode clean --qos 1\\r\\n```\\r\\n\\r\\nIn the 2nd terminal window, the requesting MQTT client subscribes to a topic called `my/response/topic`:\\r\\n```bash\\r\\nmqttx sub --client-id requester --topic my/response/topic --session-expiry-interval 600 --qos 1\\r\\n…  Connecting...\\r\\n✔  Connected\\r\\n…  Subscribing to my/response/topic...\\r\\n✔  Subscribed to my/response/topic\\r\\n^C\\r\\n```\\r\\n\\r\\nIn the 2nd terminal window, the requester then publishes a request message:\\r\\n```bash\\r\\nmqttx pub --client-id requester --topic t/7 --message \\"my request\\" \\\\\\r\\n    --correlation-data abc-123 --response-topic my/response/topic \\\\\\r\\n    --session-expiry-interval 600 --no-clean\\r\\n```\\r\\n\\r\\nIn the 1st terminal window, the responder receives the request message:\\r\\n```bash\\r\\n{\\r\\n  \\"topic\\": \\"t/7\\",\\r\\n  \\"payload\\": \\"my request\\",\\r\\n  \\"packet\\": {\\r\\n    ...\\r\\n    \\"properties\\": {\\r\\n      \\"responseTopic\\": \\"my/response/topic\\",\\r\\n      \\"correlationData\\": {\\r\\n        \\"type\\": \\"Buffer\\",\\r\\n        \\"data\\": [\\r\\n          97,\\r\\n          98,\\r\\n          99,\\r\\n          45,\\r\\n          49,\\r\\n          50,\\r\\n          51\\r\\n        ]\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n^C\\r\\n```\\r\\n\\r\\nIn the 1st terminal window, the responder responds to the requester by copying the correlation data and publishing to the response topic:\\r\\n```bash\\r\\nmqttx pub --client-id responder --topic my/response/topic --message \\"my response\\" --correlation-data abc-123\\r\\n```\\r\\n\\r\\nIn the 2nd terminal window, the requester receives the response.\\r\\n```bash\\r\\nmqttx sub --client-id requester --topic my/response/topic --no-clean --qos 1 --output-mode clean\\r\\n{\\r\\n  \\"topic\\": \\"my/response/topic\\",\\r\\n  \\"payload\\": \\"my response\\",\\r\\n  \\"packet\\": {\\r\\n    ...\\r\\n    \\"properties\\": {\\r\\n      \\"correlationData\\": {\\r\\n        \\"type\\": \\"Buffer\\",\\r\\n        \\"data\\": [\\r\\n          97,\\r\\n          98,\\r\\n          99,\\r\\n          45,\\r\\n          49,\\r\\n          50,\\r\\n          51\\r\\n        ]\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\nThe correlation data is useful to correlate the response to the request.\\r\\nThe requester usually picks unique correlation data per request it publishes.\\r\\n\\r\\n### Feature 8: [Assigned Client Identifier](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901087)\\r\\n\\r\\n#### Description\\r\\n\\r\\n> If the Client connects using a zero length Client Identifier, the Server MUST respond with a CONNACK containing an Assigned Client Identifier.\\r\\n\\r\\nCompared to MQTT 3.1.1 this lifts the restriction that server assigned client IDs can only be used with `Clean Session = 1` connections.\\r\\n\\r\\n#### Implementation\\r\\n\\r\\nRabbitMQ will generate some random client ID (for example `dcGB2kSwS0JlXnaBa1A6QA`) and return it in the CONNACK packet.\\r\\n\\r\\n### Feature 9: [Topic Alias](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901113)\\r\\n\\r\\n#### Description\\r\\n\\r\\n> A Topic Alias is an integer value that is used to identify the Topic instead of using the Topic Name.\\r\\nThis reduces the size of the PUBLISH packet, and is useful when the Topic Names are long and the same Topic Names are used repetitively within a Network Connection.\\r\\n\\r\\n#### Implementation\\r\\n\\r\\nThe default [Topic Alias Maximum](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901088) in RabbitMQ is 16.\\r\\nYou can configure this value in `rabbitmq.conf`, for example:\\r\\n```ini\\r\\nmqtt.topic_alias_maximum = 32\\r\\n```\\r\\nThis configured value maps to the Topic Alias Maximum in the CONNACK packet sent from RabbitMQ to the client.\\r\\nIt limits the number of topic aliases in either direction, that is from client to RabbitMQ and RabbitMQ to client.\\r\\nSetting a higher value will require more memory usage in RabbitMQ if clients send to or receive from many different topics.\\r\\n\\r\\nA RabbitMQ operator can disallow the usage of Topic Aliases by setting:\\r\\n```ini\\r\\nmqtt.topic_alias_maximum = 0\\r\\n```\\r\\n\\r\\n### Feature 10: [Flow control](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901251)\\r\\n\\r\\n#### Description\\r\\n\\r\\nThe MQTT 5.0 property Receive Maximum defines an upper limit of unacknowledged QoS 1 PUBLISH packets.\\r\\n\\r\\n#### Implementation\\r\\n\\r\\nThe maximum number of unacknowledged QoS 1 PUBLISH packets sent from RabbitMQ to the client is determined by the minimum value of\\r\\nthe Receive Maximum sent from client to RabbitMQ in the CONNECT packet and the configured `mqtt.prefetch` value:\\r\\n```ini\\r\\nmqtt.prefetch = 10\\r\\n```\\r\\nThe default value of `mqtt.prefetch` is 10.\\r\\n\\r\\nThe `mqtt.prefetch` value has already existed before RabbitMQ 3.13 for MQTT 3.1 and 3.1.1.\\r\\nIt maps to [consumer prefetch](/docs/consumer-prefetch) in RabbitMQ.\\r\\nIn other words, it defines how many in-flight messages the queue sends to its MQTT connection process.\\r\\n\\r\\n### Feature 11: Maximum Packet Size\\r\\n\\r\\n#### Description\\r\\n\\r\\nClient and server can independently specify the maximum packet size they support.\\r\\n\\r\\n#### Example\\r\\n\\r\\nThis example demonstrates how to limit the maximum MQTT packet size sent from a client to RabbitMQ.\\r\\n\\r\\nLet\'s assume that after successful authentication a RabbitMQ operator does not want RabbitMQ to accept any MQTT packets larger than 1 KiB.\\r\\nWrite the following configuration to [rabbitmq.conf](/docs/configure#config-file) (in your current working directory):\\r\\n```ini\\r\\nmqtt.max_packet_size_authenticated = 1024\\r\\n```\\r\\nAfter stopping RabbitMQ server, start RabbitMQ server with the new configuration being applied:\\r\\n```bash\\r\\ndocker run -it --rm --name rabbitmq -p 1883:1883 -p 15672:15672 -p 15692:15692 \\\\\\r\\n    --mount type=bind,source=\\"$(pwd)\\"/rabbitmq.conf,target=/etc/rabbitmq/conf.d/11-blog-post.conf \\\\\\r\\n    rabbitmq:3.13.0-beta.2-management\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_mqtt\\r\\ndocker exec rabbitmq rabbitmqctl enable_feature_flag all\\r\\n```\\r\\n\\r\\nIn the 1st terminal window, subscribe to a topic:\\r\\n```bash\\r\\nmqttx sub --topic t/11\\r\\n```\\r\\n\\r\\nIn the 2nd terminal window, send a message with a payload of 3 bytes to that topic:\\r\\n```bash\\r\\npayload=$(head --bytes 3 < /dev/zero | tr \'\\\\0\' x)\\r\\nmqttx pub --topic t/11 -m \\"$payload\\"\\r\\n```\\r\\n\\r\\nThe first line reads 3 bytes (3 null characters) from the special file `/dev/zero`, translates each null character to ASCII character `x` and saves the result `xxx` in the variable `payload`.\\r\\n\\r\\nThe 1st terminal window will receive that message:\\r\\n```bash\\r\\npayload: xxx\\r\\n```\\r\\n\\r\\nNext, in the 2nd terminal window, send a message with a payload of 2,000 bytes:\\r\\n```bash\\r\\npayload=$(head --bytes 2000 < /dev/zero | tr \'\\\\0\' x)\\r\\nmqttx pub --topic t/11 -m \\"$payload\\"\\r\\n```\\r\\n\\r\\nThis time, the 1st terminal window does not receive the message because the PUBLISH packet sent from client to RabbitMQ is larger than the configured maximum packet size of 1024 bytes.\\r\\n\\r\\nInstead, RabbitMQ logs a descriptive error message:\\r\\n```\\r\\n[error] <0.836.0> MQTT packet size (2007 bytes, type 3) exceeds mqtt.max_packet_size_authenticated (1024 bytes)\\r\\n```\\r\\nThe log message states 2,007 bytes because 7 bytes are needed for the fixed and variable headers of the PUBLISH packet (out of which 4 bytes are needed for the topic name `t/11`).\\r\\n\\r\\n### Feature 12: Server initiated [DISCONNECT](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901205)\\r\\n\\r\\n#### Description\\r\\nIn MQTT 5.0, the DISCONNECT packet can not only be sent from client to server, but also from server to client.\\r\\n\\r\\n#### Implementation\\r\\nPrior to terminating the connection, RabbitMQ will send a DISCONNECT packet to the client in the following situations:\\r\\n\\r\\n| DISCONNECT Reason Code Name | Situation |\\r\\n| --- | --- |\\r\\n| Session taken over | Another client connected with the same client ID. |\\r\\n| Server shutting down | RabbitMQ enters [maintenance mode](/docs/upgrade#maintenance-mode). |\\r\\n| Keep Alive timeout | The Client fails to communicate within the [Keep Alive](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901045) time. |\\r\\n| Packet too large | RabbitMQ receives a packet whose size exceeds `mqtt.max_packet_size_authenticated` |\\r\\n\\r\\n### Feature 13: [Session Expiry](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901048)\\r\\n\\r\\n#### Description\\r\\n\\r\\nIn MQTT 5.0, the client can suggest a Session Expiry Interval to the server in the CONNECT packet.\\r\\nThe server can accept the proposed Session Expiry Interval or mandate a different one in the CONNACK packet.\\r\\n\\r\\n> The session can continue across a sequence of Network Connections. It lasts as long as the latest Network Connection plus the Session Expiry Interval.\\r\\n\\r\\nWhen the Session Expiry Interval expires, both client and server will delete any session state.\\r\\n\\r\\n#### Implementation\\r\\n\\r\\nClient and server keep session state for as long as the session lasts.\\r\\n\\r\\nSession state in the server includes messages that have been sent to the client but not yet acknowledged, messages that are pending to be sent to the client, and a client\'s subscriptions.\\r\\nRabbitMQ models this MQTT session state in the form of queues and bindings.\\r\\n\\r\\nTherefore, Session Expiry Interval maps to [queue TTL](/docs/ttl#queue-ttl) in RabbitMQ.\\r\\nWhen an MQTT session expires, the queue and therefore its messages and bindings will be deleted.\\r\\n\\r\\n#### Example\\r\\nBy default the maximum session expiry interval allowed by the server is 1 day.\\r\\nIf an MQTT client does not reconnect within 1 day, its session state will be deleted in RabbitMQ.\\r\\n\\r\\nThis value is configurable.\\r\\nFor the purpose of this example, let\'s set a very low Session Expiry Interval of 1 minute in `rabbitmq.conf`:\\r\\n```ini\\r\\nmqtt.max_session_expiry_interval_seconds = 60\\r\\n```\\r\\nThe setting name contains the prefix `max` because an MQTT 5.0 client can choose a lower value by sending a Session Expiry Interval in the CONNECT packet.\\r\\nAs done in the [example of Maximum Packet Size](#example-5) restart the RabbitMQ node such that the new setting gets applied.\\r\\n\\r\\nConnect to RabbitMQ with a Session Expiry Interval of 20 seconds and create a subscription:\\r\\n```bash\\r\\nmqttx sub --client-id sub-13 --topic t/13 --session-expiry-interval 20 --qos 1\\r\\n…  Connecting...\\r\\n✔  Connected\\r\\n…  Subscribing to t/13...\\r\\n✔  Subscribed to t/13\\r\\n^C\\r\\n```\\r\\nType `Ctrl+C` into the terminal to disconnect the client.\\r\\n\\r\\nWithin the next 20 seconds, list queues and bindings:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl list_queues name\\r\\nTimeout: 60.0 seconds ...\\r\\nListing queues for vhost / ...\\r\\nname\\r\\nmqtt-subscription-sub-13qos1\\r\\n\\r\\ndocker exec rabbitmq rabbitmqctl list_bindings source_name destination_name routing_key --formatter=pretty_table\\r\\nListing bindings for vhost /...\\r\\n┌─────────────┬──────────────────────────────┬──────────────────────────────┐\\r\\n│ source_name │ destination_name             │ routing_key                  │\\r\\n├─────────────┼──────────────────────────────┼──────────────────────────────┤\\r\\n│             │ mqtt-subscription-sub-13qos1 │ mqtt-subscription-sub-13qos1 │\\r\\n├─────────────┼──────────────────────────────┼──────────────────────────────┤\\r\\n│ amq.topic   │ mqtt-subscription-sub-13qos1 │ t.13                         │\\r\\n└─────────────┴──────────────────────────────┴──────────────────────────────┘\\r\\n```\\r\\n\\r\\nAfter 20 seconds, list queues and bindings again:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl list_queues name\\r\\nTimeout: 60.0 seconds ...\\r\\nListing queues for vhost / ...\\r\\n\\r\\ndocker exec rabbitmq rabbitmqctl list_bindings source_name destination_name routing_key --formatter=pretty_table\\r\\nListing bindings for vhost /...\\r\\n```\\r\\nThe queue and its bindings were deleted by RabbitMQ because our client did not connect to RabbitMQ with `Clean Session = 0` within the Session Expiry Interval of 20 seconds.\\r\\n\\r\\nNext, do the same test, but with a high Session Expiry Interval, e.g. 1 hour:\\r\\n```bash\\r\\nmqttx sub --client-id sub-13 --topic t/13 --session-expiry-interval 3600 --qos 1\\r\\n…  Connecting...\\r\\n✔  Connected\\r\\n…  Subscribing to t/13...\\r\\n✔  Subscribed to t/13\\r\\n^C\\r\\n```\\r\\nYou should observe that the queue and its bindings will be deleted after 1 minute because the effective Session Expiry Interval\\r\\nis the minimum of what the client requested (1 hour) and the value of `mqtt.max_session_expiry_interval_seconds` configured in RabbitMQ (1 minute).\\r\\n\\r\\n### Feature 14: [Will delay](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901062)\\r\\n\\r\\n#### Description\\r\\n\\r\\nThe client can define a Will Delay Interval in the CONNECT packet.\\r\\n\\r\\n> The Server delays publishing the Client’s Will Message until the Will Delay Interval has passed or the Session ends, whichever happens first.\\r\\nIf a new Network Connection to this Session is made before the Will Delay Interval has passed, the Server MUST NOT send the Will Message.\\r\\nOne use of this is to avoid publishing Will Messages if there is a temporary network disconnection and the Client succeeds in reconnecting and continuing its Session before the Will Message is published.\\r\\n\\r\\nAnother use case of Will Delay Interval is to notify about session expiry:\\r\\n> The Client can arrange for the Will Message to notify that Session Expiry has occurred by setting the Will Delay Interval to be longer than the Session Expiry Interval and sending DISCONNECT with Reason Code 0x04 (Disconnect with Will Message).\\r\\n\\r\\n#### Implementation\\r\\n\\r\\nAlthough the will message payload is usually small, the MQTT specification allows a will message payload size of up to 64 KiB.\\r\\n\\r\\nTo avoid storing large binary data in [Khepri](//rabbitmq.github.io/khepri/) (RabbitMQ\'s future meta data store), RabbitMQ creates a classic queue containing this single will message.\\r\\nWe call this queue the Will queue.\\r\\nThis message has a [per-message TTL](/docs/ttl#per-message-ttl-in-publishers) set which is defined in milliseconds and corresponds to the Will Delay Interval in seconds.\\r\\nAdditionally, the Will queue has a [queue TTL](/docs/ttl#queue-ttl) set which is defined in milliseconds and corresponds to the Session Expiry Interval in seconds.\\r\\nThe effective per-message TTL is at least a few milliseconds lower than the queue TTL such that the message will be published shortly before the queue (session) expires.\\r\\n\\r\\nThe Will queue also defines `amq.topic` (the default topic exchange used by the MQTT plugin) to be the [dead letter exchange](/docs/dlx) and the [will topic](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901069)\\r\\nto be the [dead letter routing key](/docs/dlx#routing).\\r\\n\\r\\nIf the MQTT client does not reconnect within its Will Delay Interval, the message in the Will queue will be dead lettered to the topic exchange.\\r\\n\\r\\nLet\'s illustrate this with an example.\\r\\n\\r\\n#### Example\\r\\n\\r\\nIn the 1st terminal window, create a subscription that will consume the will message:\\r\\n```bash\\r\\nmqttx sub --client-id sub-14 --topic t/14\\r\\n```\\r\\n\\r\\nIn the 2nd terminal window, create a connection with a Will Delay Interval of 20 seconds:\\r\\n```bash\\r\\nmqttx conn --client-id conn-14 --will-topic t/14 --will-message my-will-message --will-delay-interval 20 --session-expiry-interval 40\\r\\n```\\r\\n\\r\\nIn the 3rd terminal window, we see that so far a single queue got created by the subscribing MQTT client:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl --quiet --formatter=pretty_table list_queues name type messages arguments\\r\\n┌──────────────────────────────┬────────────┬──────────┬───────────┐\\r\\n│ name                         │ type       │ messages │ arguments │\\r\\n├──────────────────────────────┼────────────┼──────────┼───────────┤\\r\\n│ mqtt-subscription-sub-14qos0 │ MQTT QoS 0 │ 0        │           │\\r\\n└──────────────────────────────┴────────────┴──────────┴───────────┘\\r\\n```\\r\\n\\r\\nIn the 2nd terminal window, type `Ctrl+C` to disconnect the MQTT connection with client ID `conn-14`.\\r\\n\\r\\nThis time, listing the queues shows that the Will queue got created:\\r\\n```bash\\r\\ndocker exec rabbitmq rabbitmqctl --quiet --formatter=pretty_table list_queues name type messages arguments\\r\\n┌──────────────────────────────┬────────────┬──────────┬────────────────────────────────────────────────────────────┐\\r\\n│ name                         │ type       │ messages │ arguments                                                  │\\r\\n├──────────────────────────────┼────────────┼──────────┼────────────────────────────────────────────────────────────┤\\r\\n│ mqtt-subscription-sub-14qos0 │ MQTT QoS 0 │ 0        │                                                            │\\r\\n├──────────────────────────────┼────────────┼──────────┼────────────────────────────────────────────────────────────┤\\r\\n│ mqtt-will-conn-14            │ classic    │ 1        │ {<<\\"x-expires\\">>,long,40000}                               │\\r\\n│                              │            │          │ {<<\\"x-dead-letter-exchange\\">>,longstr,<<\\"amq.topic\\">>}     │\\r\\n│                              │            │          │ {<<\\"x-dead-letter-routing-key\\">>,longstr,<<\\"t.14\\">>}       │\\r\\n└──────────────────────────────┴────────────┴──────────┴────────────────────────────────────────────────────────────┘\\r\\n```\\r\\n\\r\\nThe Will queue has the naming pattern `mqtt-will-<MQTT Client ID>`.\\r\\nIt contains a single message: the will message.\\r\\n\\r\\nAs explained in the previous section, the queue TTL (`x-expires`) is 40,000 ms and therefore matches the 40 seconds Session Expiry Interval from our command above.\\r\\nIf you wait for 20 seconds, your 1st terminal window should receive the will message because our client did not reconnect within the Will Delay Interval:\\r\\n```bash\\r\\n› payload: my-will-message\\r\\n```\\r\\n\\r\\n### Feature 15: Optional Server feature availability\\r\\n\\r\\n#### Description\\r\\n\\r\\n> Define a set of features which the Server does not allow and provide a mechanism for the Server to specify this to the Client.\\r\\nThe features which can be specified in this way are:\\r\\n* Maximum QoS\\r\\n* Retain Available\\r\\n* Wildcard Subscription Available\\r\\n* Subscription Identifier Available\\r\\n* Shared Subscription Available\\r\\n\\r\\n> It is an error for the Client to use features that the Server has declared are not available.\\r\\n\\r\\n#### Implementation\\r\\n\\r\\nRabbitMQ 3.13 includes [Maximum QoS](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901084) = 1 and [Shared Subscription Available](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901093) = 0 in the [CONNACK properties](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901080).\\r\\n\\r\\n[QoS 2](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901237) has not been supported by RabbitMQ.\\r\\n\\r\\nAs described in the next section, [shared subscriptions](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901250) will be supported in a future RabbitMQ release.\\r\\n\\r\\n## Limitations\\r\\n\\r\\nThis section lists limitations of the RabbitMQ MQTT implementation.\\r\\n\\r\\n### MQTT 5.0 specific limitations\\r\\n\\r\\n#### Shared Subscriptions\\r\\n[Shared subscriptions](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901250) will be added in a future RabbitMQ release.\\r\\nAlthough this feature maps nicely to a queue in RabbitMQ, shared subscriptions are part of the session state and some RabbitMQ database migrations are necessary to efficiently query shared subscriptions for a given MQTT client ID.\\r\\n\\r\\n#### Delayed and retained Will Message\\r\\nA Will Message that is both [delayed](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901062) and [retained](https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901042) will not be retained.\\r\\nThis is because the delayed will message will be dead lettered to the topic exchange, but the retainer process does currently not consume from a queue.\\r\\nThis limitation can be resolved in the future with a new store for retained messages.\\r\\n\\r\\n### Non-MQTT 5.0 specific limitations\\r\\n\\r\\nFor completeness, this section lists limitations that have existed before supporting MQTT 5.0 in RabbitMQ 3.13 and before Native MQTT shipped in RabbitMQ 3.12.\\r\\n\\r\\n#### Retained messages\\r\\nThe feature of retained messages is [limited](/docs/mqtt#retained) in RabbitMQ.\\r\\n\\r\\nRetained messages are stored and queried only node local.\\r\\n\\r\\nAn example that works is the following:\\r\\nAn MQTT Client publishes a retained message to node A with topic `topic/1`. Thereafter another client subscribes with topic filter `topic/1` on node A. The new subscriber will receive the retained message.\\r\\n\\r\\nHowever, if the topic filter contains wildcards (the multi-level wildcard character \\"`#`\\" or the single-level wildcard character \\"`+`\\"), no retained messages are sent (issue [#8824](https://github.com/rabbitmq/rabbitmq-server/issues/8824)).\\r\\n\\r\\nFurthermore, if a client publishes a retained message on node A and another client subsequently subscribes on node B, that subscribing client will not receive any retained message stored on node A (issue [#8096](https://github.com/rabbitmq/rabbitmq-server/issues/8096)).\\r\\n\\r\\nA future RabbitMQ release will replicate retained messages in the cluster and also send retained messages matching topic filters containing wildcards.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nTo sum up, RabbitMQ\\r\\n* is the leading AMQP 0.9.1 broker\\r\\n* is a [streaming](/docs/streams) broker\\r\\n* excels in cross-protocol interoperability\\r\\n* is becoming one of the leading MQTT brokers thanks to support for MQTT 5.0 released in 3.13 and [Native MQTT](/blog/2023/03/21/native-mqtt) released in 3.12\\r\\n\\r\\nOur journey to turn RabbitMQ into a full-fledged IoT broker is not yet finished and more development efforts are planned to be done in the upcoming months and years.\\r\\nStay tuned!"},{"id":"/2023/05/17/rabbitmq-3.12-performance-improvements","metadata":{"permalink":"/rabbitmq-website/blog/2023/05/17/rabbitmq-3.12-performance-improvements","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2023-05-17-rabbitmq-3.12-performance-improvements/index.md","source":"@site/blog/2023-05-17-rabbitmq-3.12-performance-improvements/index.md","title":"RabbitMQ 3.12 Performance Improvements","description":"RabbitMQ 3.12 will be released soon with many new features and improvements.","date":"2023-05-17T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":12.27,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"RabbitMQ 3.12 Performance Improvements","tags":["Performance"],"authors":["kura"]},"unlisted":false,"prevItem":{"title":"MQTT 5.0 support is coming in RabbitMQ 3.13","permalink":"/rabbitmq-website/blog/2023/07/21/mqtt5"},"nextItem":{"title":"Announcing RabbitMQ Community Discord Server","permalink":"/rabbitmq-website/blog/2023/04/04/announcing-rabbitmq-community-discord-server"}},"content":"RabbitMQ 3.12 will be released soon with many new features and improvements.\\r\\nThis blog post focuses on the the performance-related differences.\\r\\nThe most important change is that the `lazy` mode for classic queues is now the standard behavior (more on this below).\\r\\nThe new implementation should be even more memory efficient\\r\\nwhile proving higher throughput and lower latency than both `lazy` or `non-lazy` implementations did in earlier versions.\\r\\n\\r\\nFor even better performance, we highly recommend switching to classic queues version 2 (CQv2).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nLet\'s quickly go through the most important performance-related improvements in RabbitMQ 3.12.\\r\\n\\r\\n###  Classic Queues: Changes to the Lazy Mode\\r\\n\\r\\nStarting with 3.12, the `x-queue-mode=lazy` argument is ignored. All classic queues will now behave similarly to the way lazy queues behaved previously.\\r\\nThat is, messages tend to be written to disk and only a small subset is kept in memory. The number of messages in memory depends on the consumption rate.\\r\\nThis change affects all users of classic queues. Based on our testing, for the vast majority of them,\\r\\nthe new implementation should bring significant improvements in performance and should lower the memory usage. Keep reading for some benchmark results,\\r\\nbut also make sure to test your system [using PerfTest](https://rabbitmq.github.io/rabbitmq-perf-test/stable/htmlsingle/) before upgrading.\\r\\n\\r\\n### Classic Queues: Massively Improved Classic Queues v2 (CQv2)\\r\\n\\r\\n:::note\\r\\nThis paragraph was updated to reflect the changes to the roadmap. Classic queues version 2 will become the\\r\\ndefault and only option in RabbitMQ 4.0 (perviously we planned to make it the default in 3.13).\\r\\n:::\\r\\n\\r\\nSince RabbitMQ 3.10, we have had [two implementation of classic queues](/docs/persistence-conf#queue-version): the original\\r\\none (CQv1) and a new one (CQv2). The difference between them is mostly around on-disk storage.\\r\\n\\r\\nMost users still use CQv1, but starting with 3.12 we highly recommend switching to,\\r\\nor at least evaluating, CQv2. Version 2 will become the the only implementation available in RabbitMQ 4.0.\\r\\n\\r\\nThe migration process is easy: add a new policy key or an optional queue argument, `x-queue-version=2`, when declaring the queue.\\r\\nTo switch to CQv2 globally, set `classic_queue.default_version` to `2` in the config file:\\r\\n\\r\\n```\\r\\nclassic_queue.default_version = 2\\r\\n```\\r\\n\\r\\nIt is possible to go back by setting the version back to 1. Every time the value changes, RabbitMQ will convert the on-disk representation of the queue.\\r\\nFor mostly empty queues, the process is instantaneous. For reasonable backlogs, it can take a few seconds.\\r\\n\\r\\nIn many use cases, switching to CQv2 will result in a 20-40% throughput improvement\\r\\nand lower memory usage at the same time. Those who still use classic queue mirroring ([you shouldn\'t, it\'ll be removed soon!](/blog/2023/03/02/quorum-queues-migration)),\\r\\nneed to test your system more thoroughly as there are a few cases where version 1 works better with mirrored classic queues,\\r\\nbut there are also many scenarios where version 2 is much better, despite not having any mirroring-specific code optimizations.\\r\\n\\r\\n### New MQTT implementation: Significant Memory Savings Per Connection, Supports Millions of Connections per Node\\r\\n\\r\\nThe [MQTT plugin](/docs/mqtt) has been completely reworked and provides much lower memory usage,\\r\\nlower latency and can handle many more connections than before.\\r\\n\\r\\nWe\'ve published [a separate blog post about the MQTT-related improvements](/blog/2023/03/21/native-mqtt).\\r\\n\\r\\n### Significant improvements to quorum queues\\r\\n\\r\\nThe work on making quorum queues more efficient continues. RabbitMQ 3.12 brings a number of improvements so all quorum queue users should see better performance.\\r\\nThe biggest change will be observed in the environments with long quorum queues.\\r\\nPreviously, as the queue got longer, its throughput decreased. This should no longer be a problem.\\r\\n\\r\\n### Nodes Should Stop and Start Faster\\r\\n\\r\\nRabbitMQ nodes with many classic queues (tens of thousands or more) should stop and start faster. That means shorter node unavailability during an upgrade\\r\\nand other maintenance operations.\\r\\n\\r\\n## Benchmarking Setup\\r\\n\\r\\nAll the data present below compares 3.11.7 and 3.12-rc.2. Some, mostly smaller, optimizations have been backported to more recent 3.11 patch releases,\\r\\nwhich is why this comparison does not use the latest 3.11 patch release.\\r\\n\\r\\n## Benchmark Tests\\r\\n\\r\\nAt the moment of writing, Team RabbitMQ\'s standard performance test suite contains 14 tests. Each test runs for 5 minutes.\\r\\nSeparate environments go through the same tests at the same time with different message sizes,\\r\\nso that it is easy to see the impact of the message size and/or to compare different queue types or versions under the same workload.\\r\\n\\r\\nHere is a list of the tests, in the order they appear in the Grafana dashboard:\\r\\n\\r\\n1. One publisher publishes as fast as it can, while one consumer consumes as fast as it can\\r\\n2. Two publishers and no consumers (performance as the queue gets longer)\\r\\n3. One consumer consumes a long queue from the previous test (performance of consumers unaffected by publishers)\\r\\n4. Five queues, each has 1 publisher publishing at 10k messages/s and 1 consumer (the total expected throughput is 50k/s, we look at the latency)\\r\\n5. Fanout to 10 queues - 1 publishers and 10 consumers, a fanout exchange\\r\\n6. One publisher, one consumer, but only 1 unconfirmed message (the publisher waits for the confirmation of the previous message before sending the next one)\\r\\n7. Fan-in: 7000 publishers publishing 1 message per second, to a single queue\\r\\n8. 1000 publishers publish 10 messages/s, each to a different queue; each queue has a consumer as well (total expected throughput: 10k/s)\\r\\n9. One publisher without consumers creates a backlog of messages, then 10 consumers join to drain the queue\\r\\n10. Similar to the previous one, but 50 consumers join, but a single-active-consumer is set (so only one starts draining the queue)\\r\\n11. Similar to the first test, but multi-ack of 1000 is used on the consumer-side\\r\\n12. Messages with TTL are published and expire quickly (they never get consumed)\\r\\n13. Messages get published to be negatively acknowledged later (this is just a setup for the next test)\\r\\n14. Messages from the previous test are negatively acknowledged\\r\\n\\r\\nThe last few tests are less interesting. They were introduced to look for issues in some specific areas.\\r\\n\\r\\n### The Environment\\r\\n\\r\\nThese tests were conducted using the following environment:\\r\\n\\r\\n* A GKE cluster with e2-standard-16 nodes\\r\\n* RabbitMQ clusters deployed using [our Kubernetes Operator](/kubernetes/operator/operator-overview) with the following resources and configuration\\r\\n\\r\\n```yaml\\r\\napiVersion: rabbitmq.com/v1beta1\\r\\nkind: RabbitmqCluster\\r\\nmetadata:\\r\\n  name: ...\\r\\nspec:\\r\\n  replicas: 1 # or 3 for mirrored and quorum queues\\r\\n  image: rabbitmq:3.11.7-management # or rabbitmq:3.12.0-rc.2-management\\r\\n  resources:\\r\\n    requests:\\r\\n      cpu: 14\\r\\n      memory: 12Gi\\r\\n    limits:\\r\\n      cpu: 14\\r\\n      memory: 12Gi\\r\\n  persistence:\\r\\n    storageClassName: premium-rwo\\r\\n    storage: \\"150Gi\\"\\r\\n  rabbitmq:\\r\\n    advancedConfig: |\\r\\n      [\\r\\n      {rabbit, [\\r\\n          {credit_flow_default_credit,{0,0}}\\r\\n      ]}\\r\\n      ].\\r\\n```\\r\\n\\r\\nSome notes on the environment:\\r\\n\\r\\n1. For many tests (or even production workloads), these resource settings are excessive. This is simply a configuration we happen to use for performance testing, it is not a recommendation\\r\\n2. You should be able to reach higher values with better hardware. `e2-standard-16` is far from the best hardware money can buy/rent\\r\\n3. The credit flow was disabled because otherwise a single fast publisher will be throttled (to prevent overload and to give a fair chance to other publishers);\\r\\n   flow control is important in systems with many users/connections, but usually not something we want when benchmarking\\r\\n\\r\\n\\r\\n## Test Results\\r\\n\\r\\n### New Lazy-like Default Behavior of Classic Queues and Classic Queues v2\\r\\n\\r\\nInitial version of RabbitMQ was released in 2007. Back then, disk access was very slow compared to any other operation.\\r\\nHowever, as the storage technology evolved over the years, there was less and less need to avoid writing data to disk. In version 3.6.0, back in 2015,\\r\\n[lazy queues](/docs/lazy-queues) were added as an option. Lazy queues store all messages on disk to save memory, which is particularly important for queues that can become long.\\r\\nThese days, writing messages to disk is a pretty cheap operation (unless you perform `fsync` to guarantee high data safety, as quorum queues do).\\r\\nBy storing messages on disk, we can use much less memory. That means lower costs, fewer memory alarms and fewer headaches caused by sudden memory spikes in your cluster.\\r\\nWe\'ve therefore made this the only option for classic queues going forward.\\r\\n\\r\\n#### 3.11 non-lazy vs 3.12\\r\\n\\r\\nLet\'s start by looking at what we expect to happen for users that currently use non-lazy classic queues version 1 (CQv1), after the upgrade.\\r\\nThe screenshot was taken from 12 bytes message sizes test.\\r\\n\\r\\n![Classic queues: non-lazy classic queues in 3.11 vs 3.12](lazy-3.11-vs-3.12.png)\\r\\n\\r\\nAs you can see, 3.12 performs better in every single test: higher throughput, lower latency, less variability (fewer spikes in rates).\\r\\nAt the same time, 3.12 has a much lower memory usage (similar to lazy queues). On the last panel you can see 3.11 memory spikes whenever the queues get longer,\\r\\nwhile 3.12 only exceeds 1GB memory usage in the tests that involve many connections (it\'s the connections that use the memory, not the queues).\\r\\n\\r\\n#### 3.12 CQv1 vs CQv2\\r\\n\\r\\nAbove, we saw some of the benefits that most users should get after upgrading to RabbitMQ 3.12, but we are just getting started! Let\'s add classic queues version 2\\r\\nto the comparison:\\r\\n\\r\\n![Classic queues: non-lazy classic queues in 3.11 vs 3.12 v1 and v2](lazy-3.11-vs-3.12-v1-and-v2.png)\\r\\n\\r\\nWith CQv2, we observe even higher throughput and even lower latency. Especially in the second test when the queue gets long, version 2 doesn\'t exceed 50ms latency,\\r\\nwhile 3.11 can spike into multiple seconds.\\r\\n\\r\\nPlease do not hesitate to give classic queues version 2 a try. All you need to do is set the `x-queue-version=2` policy key.\\r\\nTo switch to CQv2 globally, set `classic_queue.default_version` to `2` in the config file:\\r\\n\\r\\n```\\r\\nclassic_queue.default_version = 2\\r\\n```\\r\\n\\r\\nVersion 2 will become the default version starting with RabbitMQ 3.13.\\r\\n\\r\\n### Classic Mirrored Queues\\r\\n\\r\\nAs mentioned above, classic queues version 1 contain a few optimizations specifically implemented to improve the behaviour when a queue is mirrored.\\r\\nAs we prepare to [remove the mirroring feature](https://blog.rabbitmq.com/blog/2023/03/21/quorum-queues-migration), version 2 no longer performs any special mirroring tricks.\\r\\nTherefore, the results are mixed, but version 2 is so efficient that even without special considerations, it can outperform version 1 in most scenarios, even with mirroring.\\r\\n\\r\\n![Mirrored queues: 3.11 lazy and non-lazy vs 3.12 v2; 1kb messages](mirrored-3.11-vs-3.12.png)\\r\\n\\r\\nYou can see whether version 2 works better for you but more importantly, please [start migrating to quorum queues](https://blog.rabbitmq.com/blog/2023/03/21/quorum-queues-migration)\\r\\nand [streams](/docs/streams) ASAP.\\r\\n\\r\\n### Quorum Queues\\r\\n\\r\\n[Quorum queues](/docs/quorum-queues) have offered much better performance and data safety than queue mirroring for several years now,\\r\\nand they only get better.\\r\\n\\r\\nThe biggest improvement in 3.12 is in how quorum queues handle long backlogs.\\r\\n\\r\\n![Quorum queues: 3.11 vs 3.12; 5kb messages](qq-3.11-vs-3.12-5kb.png)\\r\\n\\r\\n#### Publishing to a Long Quorum Queue\\r\\n\\r\\nPrior to RabbitMQ 3.12, if a quorum queue had a long backlog, publishing latency could increase significantly, lowering throughput.\\r\\nStarting with 3.12, the length of the queue should no longer matter much for latency and throughput.\\r\\n\\r\\nYou can see this in the second test: while both versions start at about 25k messages/s,\\r\\n3.11 quickly degrades to 10k/s or so. Meanwhile, 3.12 remains above 20k/s.\\r\\n\\r\\nThe 3.12 performance is not as smooth as we wish it was, but it\'s\\r\\nmuch better already and could be improved further. It\'s also important to remember that in these tests, we are effectively overloading\\r\\nthe queues: the messages keep flowing in as fast as possible and therefore any garbage collection or periodic operation (eg. Raft write-ahead log\\r\\nroll-over) will be observable as a latency spike.\\r\\n\\r\\n#### Consumption Throughput\\r\\n\\r\\nConsuming messages from quorum queues is also much faster than it used to be. In particular, consuming messages from a very long queue can up to 10 times faster in our tests.\\r\\nQueues are still meant to be kept relatively short (you can use [streams](/docs/streams) if you need to store a lot of messages),\\r\\nbut with these improvements, quorum queues should cope well with all kinds of message backlogs.\\r\\n\\r\\nTake a look at the third test on the last panel (Messages consumed / s). 3.12 starts at over 15k messages/s and gets even faster as the queue\\r\\ngets shorter. Meanwhile, 3.11 can hardly exceed 1000 messages per second. In this test, we are consuming a queue with a backlog of 5 million messages,\\r\\nso you have hopefully never seen quorum queues struggle like this, but the good news is: even in these situations,\\r\\nquorum queues should now perform better and more predictably.\\r\\n\\r\\nA more likely scenario is a situation where the consumers were unavailable for some time and need to catch up. Let\'s focus on these tests:\\r\\n\\r\\n![Quorum queues: 3.11 vs 3.12](qq-3.11-vs-3.12-consumption.png)\\r\\n\\r\\nIn the first phase of each test, consumers are off and a backlog of messages is created. Then the consumers start. In the first test 10 of them,\\r\\nin the second test 50, but only one is active (as a [Single Active Consumer](/docs/consumers#single-active-consumer)).\\r\\nIn both cases, 3.12 offers a significantly higher consumption\\r\\nrate and the queue is drained much more quickly. In the case of 3.11, we can see that it gets progressively faster as the queue backlog gets shorter.\\r\\n\\r\\n### Faster Node Restarts\\r\\n\\r\\nThis one shouldn\'t affect most users, but should be very good news for users with many classic queues (eg. MQTT users with many subscriptions).\\r\\nIn our test, we started a node, imported 100,000 classic queues version 2 and then restarted the node. 3.12 was up and running within 3 minutes,\\r\\nwhile 3.11 needed 15 minutes to start serving clients again. 3.11 hit a memory alarm on startup, which made the boot\\r\\nprocess particularly slow. There was a client running just to see when it loses the connection and can establish it again.\\r\\n\\r\\n![Node restart with 100k classic queues v2: 3.11 vs 3.12](100k-queues-restart.png)\\r\\n\\r\\n### No More Periodic Resource Usage Spikes With Many Idle Queues\\r\\n\\r\\nYou may have noticed on the screenshot above, that 3.11 not only took much longer to restart, but also that the publishing rate was spiky, even\\r\\nthough it was a very light workload (just 100 messages a second). The spikes are caused by an internal process which checks the health of the queues\\r\\nto prevent stale queue metrics being emitted. Before 3.12, it\'d query each queue for its status to decide if the queue is healthy. However,\\r\\nidle classic queues hibernate (their Erlang process is stopped and its memory compacted) and need to be awaken just to reply that they are healthy.\\r\\nStarting with 3.12, hibernated queues are considered healthy without waking them up, so CPU and memory usage should be lower and more consistent,\\r\\neven on nodes with many queues.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nRabbitMQ 3.12 should improve the performance for virtually all users, often significantly. As always, we wholeheartedly recommend\\r\\ntesting release candidates and new versions before you upgrade. We are also always interested in learning how people use RabbitMQ\\r\\nin [GitHub Discussions](https://github.com/rabbitmq/rabbitmq-server/discussions) and our [community Discord server](https://www.rabbitmq.com/discord).\\r\\n\\r\\nIf you can share information about your workload, [ideally as a perf-test command](https://perftest.rabbitmq.com/), it will help\\r\\nus make RabbitMQ better for you."},{"id":"/2023/04/04/announcing-rabbitmq-community-discord-server","metadata":{"permalink":"/rabbitmq-website/blog/2023/04/04/announcing-rabbitmq-community-discord-server","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2023-04-04-announcing-rabbitmq-community-discord-server/index.md","source":"@site/blog/2023-04-04-announcing-rabbitmq-community-discord-server/index.md","title":"Announcing RabbitMQ Community Discord Server","description":"RabbitMQ now has an official Discord server started by the core team.","date":"2023-04-04T00:00:00.000Z","tags":[{"inline":true,"label":"announcements","permalink":"/rabbitmq-website/blog/tags/announcements"}],"readingTime":1.895,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Announcing RabbitMQ Community Discord Server","tags":["announcements"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.12 Performance Improvements","permalink":"/rabbitmq-website/blog/2023/05/17/rabbitmq-3.12-performance-improvements"},"nextItem":{"title":"Serving Millions of Clients with Native MQTT","permalink":"/rabbitmq-website/blog/2023/03/21/native-mqtt"}},"content":"RabbitMQ now has an official [Discord server](https://www.rabbitmq.com/discord) started by the core team.\\r\\nIf you prefer Discord to [Slack](https://www.rabbitmq.com/slack), feel free to join it and discuss all things RabbitMQ!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Introducing RabbitMQ Community Discord Server\\r\\n\\r\\nThanks to Gavin Roy, the RabbitMQ community has had a place to communicate, help each other and collaborate:\\r\\nour [community Slack](https://www.rabbitmq.com/slack).\\r\\n\\r\\nToday we introduce an official Discord server. It will be an alternative to Slack.\\r\\n\\r\\n## Why come up with an alternative?\\r\\n\\r\\nSlack is a great tool that works for many teams and companies. However, open source project communities\\r\\noperate differently from how corporations operate.\\r\\n\\r\\nMost importantly for us, open source community members\\r\\ndecide to join or leave at will. The process of joining a chat platform should be quick\\r\\nand involve the core team of the project as little as possible.\\r\\nSlack was built around the idea of a tightly controlled environment where a small group of people invites others.\\r\\nThis approach has its merits but not how open source communities work.\\r\\n\\r\\nOver the years, open source projects have come up with several applications and strategies for\\r\\nusers to invite themselves to Slack. This usually works reasonably well but said applications have\\r\\nto be deployed, monitored, maintained. For a small core team with a several orders of magnitude larger\\r\\ncommunity this can become a pain point.\\r\\n\\r\\n## Why Discord?\\r\\n\\r\\n[Discord](https://discord.com/) is a community platform successfully used by various open source projects,\\r\\nfor example, Elixir and Rust.\\r\\n\\r\\nThere is no need to maintain a self-invitation app and invitation links can be configured to never expire.\\r\\n\\r\\nOn top of that, Discord has several features that make a lot of sense for open source communities:\\r\\na public catalog of server, tools that help you describe and communicate code of conduct to the new members,\\r\\na very flexible member permission system, and more.\\r\\n\\r\\nThis sounded like an exciting alternative to try, so our team decided to set up an [official server for RabbitMQ](https://www.rabbitmq.com/discord).\\r\\n\\r\\n## When will community Slack be shut down?\\r\\n\\r\\nAssuming that Slack does not limit the free tier plan in ways incompatible with our needs,\\r\\nthere are no plans to shut down our community Slack.\\r\\nIt will co-exist with Discord, just like it co-exists with the official RabbitMQ IRC channel on [Libera Chat](https://libera.chat/)."},{"id":"/2023/03/21/native-mqtt","metadata":{"permalink":"/rabbitmq-website/blog/2023/03/21/native-mqtt","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2023-03-21-native-mqtt/index.md","source":"@site/blog/2023-03-21-native-mqtt/index.md","title":"Serving Millions of Clients with Native MQTT","description":"RabbitMQ\'s core protocol has been AMQP 0.9.1.","date":"2023-03-21T00:00:00.000Z","tags":[{"inline":true,"label":"Technical Deep Dive","permalink":"/rabbitmq-website/blog/tags/technical-deep-dive"},{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"MQTT","permalink":"/rabbitmq-website/blog/tags/mqtt"}],"readingTime":23.345,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"Serving Millions of Clients with Native MQTT","tags":["Technical Deep Dive","Performance","MQTT"],"authors":["dansari"]},"unlisted":false,"prevItem":{"title":"Announcing RabbitMQ Community Discord Server","permalink":"/rabbitmq-website/blog/2023/04/04/announcing-rabbitmq-community-discord-server"},"nextItem":{"title":"Migrating from Mirrored Classic Queues to Quorum Queues","permalink":"/rabbitmq-website/blog/2023/03/02/quorum-queues-migration"}},"content":"RabbitMQ\'s core protocol has been AMQP 0.9.1.\\r\\nTo support MQTT, STOMP, and AMQP 1.0, the broker transparently proxies via its core protocol.\\r\\nWhile this is a simple way to extend RabbitMQ with support for more messaging protocols,\\r\\nit degrades scalability and performance.\\r\\n\\r\\nIn the last 9 months, we re-wrote the [MQTT plugin](/docs/mqtt) to not proxy via AMQP 0.9.1 anymore.\\r\\nInstead, the MQTT plugin parses MQTT messages and sends them directly to queues.\\r\\nThis is what we call **Native MQTT**.\\r\\n\\r\\nThe results are spectacular:\\r\\n1. Memory usage drops by up to 95% and hundreds of GBs with many connections.\\r\\n1. For the first time ever, RabbitMQ is able to handle millions of connections.\\r\\n1. End-to-end latency drops by 50% - 70%.\\r\\n1. Throughput increases by 30% - 40%.\\r\\n\\r\\nNative MQTT turns RabbitMQ into an MQTT broker opening the door for a broader set of IoT use cases.\\r\\n\\r\\nNative MQTT ships in RabbitMQ 3.12.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nAs depicted in Figure 1, up to RabbitMQ 3.11 the MQTT plugin worked by parsing MQTT messages and forwarding them via the AMQP 0.9.1 protocol to the [channel](/docs/channels) which in turn routes messages to [queues](/docs/queues).\\r\\nEach blue dot in Figure 1 represents an [Erlang process](https://www.erlang.org/doc/reference_manual/processes.html#processes).\\r\\nA total of 22 Erlang processes are created for each incoming MQTT connection.\\r\\n\\r\\n![Figure 1: RabbitMQ 3.11 - MQTT proxied via AMQP 0.9.1 - 22 Erlang processes per MQTT connection](mqtt-proxy-amqp-091.svg)\\r\\n\\r\\n16 Erlang processes per MQTT connection are created in the MQTT plugin (that is Erlang application [`rabbitmq_mqtt`](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_mqtt)) including one process that is responsible for [MQTT Keep Alive](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Keep_Alive) and a bunch of processes that act as an AMQP 0.9.1 client.\\r\\n\\r\\n6 Erlang processes per MQTT connection are created in the Erlang application [`rabbit`](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbit).\\r\\nThey implement the per-client part of the core AMQP 0.9.1 server.\\r\\n\\r\\nFigure 2 shows that Native MQTT requires a single Erlang process per incoming MQTT connection.\\r\\n\\r\\n![Figure 2: RabbitMQ 3.12 - Native MQTT - 1 Erlang process per MQTT connection](native-mqtt.svg)\\r\\n\\r\\nThat single Erlang process is responsible for parsing MQTT messages, respecting MQTT Keep Alive, performing [authentication and authorization](/docs/access-control), and routing messages to queues.\\r\\n\\r\\nA usual MQTT workload consists of many Internet of Things (IoT) devices sending data periodically to an MQTT broker.\\r\\nFor example, there could be hundreds of thousands or even millions of devices that each send a status update every few seconds or minutes.\\r\\n\\r\\nWe learnt in last year\'s RabbitMQ Summit talk [RabbitMQ Performance Improvements](https://youtu.be/CRDmKZhYmxw) that creating Erlang processes is cheap.\\r\\n(An Erlang process is much more lightweight than a Java thread. An Erlang process might be compared with a [Goroutine](https://go.dev/tour/concurrency/1) in Golang.)\\r\\nHowever, for 1 million incoming MQTT client connections, it makes a big scalability difference whether RabbitMQ creates 22 million Erlang processes (up to RabbitMQ 3.11) or just 1 million Erlang processes (RabbitMQ 3.12).\\r\\nThis difference is analysed in sections [Memory Usage](#memory-usage) and [Latency and Throughput](#latency-and-throughput).\\r\\n\\r\\nNot only was the `rabbitmq_mqtt` plugin re-written, but also the [rabbitmq_web_mqtt](/docs/web-mqtt) plugin.\\r\\nThis means, starting in 3.12, there will also be a single Erlang process per incoming [MQTT over WebSocket](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718127) connection.\\r\\nTherefore, all performance improvements outlined in this blog post also apply to MQTT over WebSockets.\\r\\n\\r\\nThe term \\"Native MQTT\\" is not an official term of the MQTT specification.\\r\\n\\"Native MQTT\\" refers to the new RabbitMQ 3.12 implementation where RabbitMQ supports MQTT \\"natively\\", i.e. where MQTT traffic is not proxied via AMQP 0.9.1 anymore.\\r\\n\\r\\n## New MQTT QoS 0 Queue Type\\r\\n\\r\\nNative MQTT ships with a new RabbitMQ queue type called `rabbit_mqtt_qos0_queue`.\\r\\nTo have the MQTT plugin create queues of that new queue type, the 3.12 [feature flag](/docs/feature-flags) with the same name `rabbit_mqtt_qos0_queue` must be enabled.\\r\\n(Remember that feature flags are not meant to be used as a form of cluster configuration.\\r\\nAfter a successful rolling upgrade, you should enable all feature flags.\\r\\nEach feature flag will become mandatory in a future RabbitMQ version.)\\r\\n\\r\\nBefore explaining the new queue type, we should first understand how queues relate to MQTT subscribers.\\r\\n\\r\\nIn all RabbitMQ versions, the MQTT plugin creates a dedicated queue per MQTT subscriber.\\r\\nTo be more precise, there could be 0, 1, or 2 queues per MQTT connection:\\r\\n* There are 0 queues for an MQTT connection if the MQTT client never sends a [SUBSCRIBE](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718063) packet. The MQTT client is only publishing messages.\\r\\n* There is 1 queue for an MQTT connection if the MQTT client creates one or multiple subscriptions with the same [Quality of Service (QoS) level](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718099).\\r\\n* There are 2 queues for an MQTT connection if the MQTT client creates one or multiple subscriptions with both [QoS 0 (at most once)](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718100) and [QoS 1 (at least once)](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718101).\\r\\n\\r\\nWhen listing queues you will observe the queue naming pattern `mqtt-subscription-<MQTT client ID>qos[0|1]`\\r\\nwhere `<MQTT client ID>` is the [MQTT client identifier](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc385349242) and `[0|1]` is either `0` for a QoS 0 subscription or `1` for a QoS 1 subscription.\\r\\nHaving a separate queue per MQTT subscriber makes sense because every MQTT subscriber receives its own copy of the application message.\\r\\n\\r\\nBy default, the MQTT plugin creates classic queues.\\r\\n\\r\\nThe MQTT plugin creates queues transparently for MQTT subscribing clients.\\r\\nThe MQTT specification does not define the concept of queues, and MQTT clients are not aware that these queues exist.\\r\\nA queue is an implementation detail of how RabbitMQ implements the MQTT protocol.\\r\\n\\r\\nFigure 3 shows an MQTT subscriber that connects with `CleanSession=1` and subscribes with QoS 0.\\r\\n[Clean session](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Ref362965194) means that the MQTT session lasts only as long as the network connection between client and server.\\r\\nWhen the session ends, all session state in the server is deleted, which implies the queue gets auto deleted.\\r\\n\\r\\nAs seen in Figure 3, each classic queue results in two additional Erlang processes: one [supervisor](https://www.erlang.org/doc/design_principles/des_princ.html#supervision-trees) process, and one worker process.\\r\\n\\r\\n![Figure 3: Native MQTT - Feature flag rabbit_mqtt_qos0_queue disabled](mqtt-qos0-queue-disabled.svg)\\r\\n\\r\\nThe new queue type optimisation works as follows: If\\r\\n1. feature flag `rabbit_mqtt_qos0_queue` is enabled, and\\r\\n2. an MQTT client connects with `CleanSession=1`, and\\r\\n3. the MQTT client subscribes with QoS 0\\r\\n\\r\\nthen, the MQTT plugin will create a queue of type `rabbit_mqtt_qos0_queue` instead of a classic queue.\\r\\n\\r\\nFigure 4 shows that the new queue type is a \\"pseudo\\" queue or \\"virtual\\" queue:\\r\\nIt is very different from the queue types you know (classic queues, [quorum queues](/docs/quorum-queues), and [streams](/docs/streams)) in the sense that this new queue type is neither a separate Erlang process nor does it store messages on disk.\\r\\nInstead, this queue type is a subset of the Erlang process mailbox.\\r\\nMQTT messages are directly sent to the MQTT connection process of the subscribing client.\\r\\nIn other words, MQTT messages are sent to any \\"online\\" MQTT subscribers.\\r\\n\\r\\nIt is more accurate to think of the queue being skipped (as indicated in the last line `no queue at all? 🤔` in [this slide from the RabbitMQ summit 2022 talk](https://youtu.be/CRDmKZhYmxw?t=596)).\\r\\nThe fact that sending messages directly to the MQTT connection process is implemented as a queue type is to simplify routing of messages and protocol interoperability, such that messages\\r\\ncan not only be sent from the MQTT publishing connection process, but also from the channel process.\\r\\nThe latter enables sending messages from an AMQP 0.9.1, AMQP 1.0 or STOMP client directly to the MQTT subscriber connection process skipping a dedicated queue process.\\r\\n\\r\\n![Figure 4: Native MQTT - Feature flag rabbit_mqtt_qos0_queue enabled](mqtt-qos0-queue-enabled.svg)\\r\\n\\r\\nWe now understand that this new queue type skips the queue process.\\r\\nHowever, what are the advantages of doing so in the context of MQTT?\\r\\nMQTT workloads are characterised by many devices sending data to and receiving data from the broker.\\r\\nHere are four reasons in decreasing importance how the new queue type provides optimisations:\\r\\n\\r\\n### Benefit 1: large fan-outs\\r\\n\\r\\nEnable large fan-outs sending a message from the \\"cloud\\" (MQTT broker) to all devices.\\r\\n\\r\\nFor classic queues and quorum queues, each queue client (i.e. the channel process or MQTT connection process) keeps state for all destination queues for the purpose of flow control.\\r\\nFor example, the channel process holds the number of credits from each destination queue in its [process dictionary](https://www.erlang.org/doc/reference_manual/processes.html#process-dictionary).\\r\\n(Read [our blog post about credit-based flow control](//blog.rabbitmq.com/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts#credit-based-flow-control) to learn more.)\\r\\n\\r\\n* If there is 1 channel process that sends to 3 million MQTT devices, 3 million entries (hundreds of MBs of memory) are kept in the channel process dictionary.\\r\\n* If there are 100 channel processes each sending to 3 million devices, there are in total 300 million entries in the process dictionaries (better not try this).\\r\\n* If there are a few thousand channels or MQTT connection processes each sending a message to 3 million devices, RabbitMQ will run out of memory and crash.\\r\\n\\r\\nEven if these huge fan-outs happen extremely rarely, e.g. once a day, the state from the sending Erlang process to all destination queues is always kept in memory (until the destination queue gets deleted).\\r\\n\\r\\nThe most important characteristic of the new queue type is that its queue type client is stateless.\\r\\nThis means that the MQTT connection or channel process can send a message (\\"fire & forget\\") to 3 million MQTT connection processes (which still temporarily requires significant amount of memory) without\\r\\nkeeping any state to the destination queues. Once garbage collection kicked in, the queue client process memory usage drops to 0 MB.\\r\\n\\r\\n### Benefit 2: lower memory usage\\r\\n\\r\\nNot only for large fan-outs, but also in 1:1 topologies (where each publisher sends to exactly one subscriber), the new queue type `rabbit_mqtt_qos0_queue` saves substantial amount of memory by skipping queue processes.\\r\\n\\r\\nEven with Native MQTT in 3.12, with feature flag `rabbit_mqtt_qos0_queue` disabled, 3 million MQTT devices subscribing with QoS 0 results in 9 million Erlang processes.\\r\\nWith feature flag `rabbit_mqtt_qos0_queue` enabled, the same workload results in only 3 million Erlang processes because the additional queue supervisor and queue worker processes per MQTT subscriber are skipped saving several GBs of process memory.\\r\\n\\r\\n### Benefit 3: lower publisher confirm latency\\r\\n\\r\\nDespite an MQTT client subscribing with QoS 0, another MQTT client can still send messages with QoS 1 (or equivalently the channel from an AMQP 0.9.1 sending client can be put in confirm mode).\\r\\nIn that case, the publishing client requires a publisher confirmation from the broker.\\r\\n\\r\\nThe new queue type\'s client (part of the MQTT publisher connection process or channel process) auto-confirms directly on behalf of the \\"queue server process\\" because the at-most-once QoS 0 message might be lost anyway on the way from broker to MQTT subscriber.\\r\\nThis results in lower publisher confirm latency.\\r\\n\\r\\nIn RabbitMQ a message is only confirmed back to the publishing client once **all** destination queues confirmed they received the message.\\r\\nTherefore, even more importantly, the publishing process only awaits confirmation from queues that potentially have at-least-once consumers.\\r\\nWith the new queue type the publishing process is not blocked on sending the confirmation back to the publishing client in a scenario where one message is routed to an important quorum queue as well as to one million MQTT QoS 0 subscribers while a single out of the million MQTT connection processes is overloaded (and would therefore reply very slowly).\\r\\n\\r\\n### Benefit 4: lower end-to-end latency\\r\\n\\r\\nBecause the queue process is skipped, there is one fewer message hop resulting in lower end-to-end latency.\\r\\n\\r\\n### Overload protection\\r\\n\\r\\nBecause the new queue type has no flow control, MQTT messages might arrive faster in the MQTT connection process mailbox than they can be delivered to the MQTT subscribing client from the MQTT connection process.\\r\\nThis can happen when the network connection between MQTT subscribing client and RabbitMQ is poor or in a large fan-in scenario where many publishers overload a single MQTT subscribing client.\\r\\n\\r\\nTo protect against high memory usage due to MQTT QoS 0 messages piling up in the MQTT connection process mailbox, RabbitMQ intentionally drops QoS 0 messages from the `rabbit_mqtt_qos0_queue` if both conditions are true:\\r\\n\\r\\n1. the number of messages in the MQTT connection process mailbox exceeds the setting `mqtt.mailbox_soft_limit` (defaults to 200), and\\r\\n1. the socket sending to the MQTT client is busy (not sending fast enough).\\r\\n\\r\\nNote that there can be other messages in the process mailbox (e.g. applications messages sent from the MQTT subscribing client to RabbitMQ or confirmations from another queue type to the MQTT connection process) which are obviously not dropped.\\r\\nHowever, these other messages also contribute to the `mqtt.mailbox_soft_limit`.\\r\\n\\r\\nSetting `mqtt.mailbox_soft_limit` to 0 disables the overload protection mechanism meaning QoS 0 messages are never dropped intentionally by RabbitMQ.\\r\\nSetting `mqtt.mailbox_soft_limit` to a very high value decreases the likelihood of intentionally dropping QoS 0 messages while increasing the risk of causing a cluster wide [memory alarm](/docs/memory) (especially if the message payloads are large or if there are many overloaded queues of type `rabbit_mqtt_qos0_queue`).\\r\\n\\r\\nThe `mqtt.mailbox_soft_limit` can be thought of a [queue length limit](/docs/maxlength) although not precisely because, as mentioned previously, the Erlang process mailbox can contain other messages than MQTT application messages.\\r\\nThis is why the configuration key `mqtt.mailbox_soft_limit` contains the word `soft`.\\r\\nThe described overload protection mechanism corresponds roughly to overflow behaviour `drop-head` that you already know from classic queues and quorum queues.\\r\\n\\r\\n### Queue type naming\\r\\n\\r\\nDo not rely on the name of this new queue type.\\r\\nThe name of the feature flag `rabbit_mqtt_qos0_queue` will not change.\\r\\nHowever, we might change the name of queue type `rabbit_mqtt_qos0_queue` in the future in case we decide to reuse part of its design in other RabbitMQ use cases (such as [Direct Reply-to](/docs/direct-reply-to)).\\r\\n\\r\\nIn fact, neither MQTT client applications nor RabbitMQ core (the Erlang application `rabbit`) are aware of the new queue type.\\r\\nEnd users will not be aware of the new queue type either except when listing queues in the Management UI or via `rabbitmqctl`.\\r\\n\\r\\nGiven that we now understand the architecture of Native MQTT and the intent of the MQTT QoS 0 queue type, we can move on with performance benchmarks.\\r\\n\\r\\n## Memory Usage\\r\\n\\r\\nThis section compares memory usage of MQTT in RabbitMQ 3.11 and Native MQTT in RabbitMQ 3.12.\\r\\nThe complete test setup can be found in [ansd/rabbitmq-mqtt](https://github.com/ansd/rabbitmq-mqtt/tree/blog-post-native-mqtt).\\r\\n\\r\\nThe two tests in this section were done against a 3-node cluster with the following subset of RabbitMQ configuration:\\r\\n```\\r\\nmqtt.tcp_listen_options.sndbuf = 1024\\r\\nmqtt.tcp_listen_options.recbuf = 1024\\r\\nmqtt.tcp_listen_options.buffer = 1024\\r\\nmanagement_agent.disable_metrics_collector = true\\r\\n```\\r\\n\\r\\nTCP buffer sizes are configured to be small such that they do not cause high binary memory usage.\\r\\n\\r\\nMetrics collection is disabled in the `rabbitmq_management` plugin.\\r\\nFor production use cases, Prometheus should be used.\\r\\nThe `rabbitmq_management` plugin is not designed to handle a high number of stats emitting objects such as queues and connections.\\r\\n\\r\\n### 1 million MQTT connections\\r\\n\\r\\nThe first test uses 1,000,000 MQTT connections that send only MQTT Keep Alives after connection establishment.\\r\\nNo MQTT application messages are sent or received.\\r\\n\\r\\nAs shown in Figure 5, the 3-node cluster requires 108.0 + 100.7 + 92.4 = 301.1 GiB in 3.11 and only 6.1 + 6.3 + 6.3 = 18.7 GiB of memory in 3.12.\\r\\nTherefore 3.11 requires 16 times (or 282 GiB) more memory than 3.12.\\r\\nNative MQTT reduces memory usage by 94%.\\r\\n\\r\\n![Figure 5: Memory usage connecting 1 million MQTT clients](native-mqtt-memory-1mio-conn.png)\\r\\n\\r\\nThe biggest part contributing to memory usage in 3.11 is **process** memory.\\r\\nAs explained in the [Overview](#overview) section, Native MQTT in 3.12 uses 1 Erlang process per MQTT connection while 3.11 uses 22 Erlang processes per MQTT connection.\\r\\nSome of the 3.11 processes keep large states causing high memory usage.\\r\\n\\r\\nNative MQTT\'s low memory usage is not only achieved by using a single Erlang process, but also by reducing the state of that single Erlang process.\\r\\nNumerous memory optimisations are implemented in PR [#5895](https://github.com/rabbitmq/rabbitmq-server/pull/5895) such as removing long lists and unnecessary function references from the process state.\\r\\n\\r\\nFurther tests on development environments show that Native MQTT requires around 56 GB of memory per node in a 3-node cluster for a total of 9 million MQTT connections.\\r\\n\\r\\n### 100k publishers, 100k subscribers\\r\\n\\r\\nThe second test uses 100,000 publishers and 100,000 subscribers.\\r\\nThey send and receive in a 1:1 topology meaning each publisher sends a QoS 0 application message every 2 minutes to exactly one QoS 0 subscriber.\\r\\n\\r\\nAs shown in Figure 6, the 3-node cluster requires 21.6 + 21.5 + 21.7 = 64.8 GiB in 3.11 and only 2.6 + 2.6 + 2.6 = 7.8 GiB of memory in 3.12.\\r\\n\\r\\n![Figure 6: Memory usage connecting 100,000 publishers and 100,000 subscribers](native-mqtt-memory-100k-pub-100k-sub.png)\\r\\n\\r\\nFurther tests on development environments show that Native MQTT requires around 47 GB of memory per node in a 3-node cluster for the following scenario:\\r\\n* 3 million MQTT connections in total\\r\\n* 1:1 topology\\r\\n* 1.5 million publishers sending QoS 1 messages with 64 bytes of payload every 3 minutes\\r\\n* 1.5 million QoS 1 subscribers (i.e. 1.5 million classic queues [version 2](/docs/persistence-conf#queue-version))\\r\\n\\r\\nPR [#6684](https://github.com/rabbitmq/rabbitmq-server/pull/6684) that shipped in RabbitMQ 3.11.6 substantially reduces memory usage of many classic queues benefitting the use case\\r\\nof many MQTT QoS 1 or `CleanSession=0` subscribers.\\r\\n\\r\\n## Latency and Throughput\\r\\n\\r\\nTo compare latency between MQTT in 3.11 and Native MQTT in 3.12 we use [mqtt-bm-latency](https://github.com/ansd/mqtt-bm-latency/tree/blog-post-native-mqtt).\\r\\n\\r\\nThe following latency benchmarks were executed on a physical Ubuntu 22.04 box with 8 CPUs and 32 GB of RAM.\\r\\nClients and single node RabbitMQ server run on the same machine.\\r\\n\\r\\nIn the root directory of [rabbitmq-server](https://github.com/rabbitmq/rabbitmq-server) start the server with 4 scheduler threads:\\r\\n```bash\\r\\nmake run-broker PLUGINS=\\"rabbitmq_mqtt\\" RABBITMQ_CONFIG_FILE=\\"rabbitmq.conf\\" RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\\"+S 4\\"\\r\\n```\\r\\n\\r\\nThe server runs with the following `rabbitmq.conf`:\\r\\n```ini\\r\\nmqtt.mailbox_soft_limit = 0\\r\\nmqtt.tcp_listen_options.nodelay = true\\r\\nmqtt.tcp_listen_options.backlog = 128\\r\\nmqtt.tcp_listen_options.sndbuf = 87380\\r\\nmqtt.tcp_listen_options.recbuf = 87380\\r\\nmqtt.tcp_listen_options.buffer = 87380\\r\\nclassic_queue.default_version = 2\\r\\n```\\r\\nThe first line is only used in RabbitMQ 3.12 and disables overload protection ensuring all QoS 0 messages are delivered to the subscribers.\\r\\n\\r\\nThe 3.11 benchmarks use Git tag `v3.11.10`.\\r\\nThe 3.12 benchmarks use Git tag `v3.12.0-beta.2`.\\r\\n\\r\\n### Latency and Throughput QoS 1\\r\\n\\r\\nThe first benchmark compares latency and throughput of QoS 1 messages sent to QoS 1 subscribers.\\r\\n\\r\\n```bash\\r\\n./mqtt-bm-latency -clients 100 -count 10000 -pubqos 1 -subqos 1 -size 100 -keepalive 120 -topic t\\r\\n```\\r\\n\\r\\nThis benchmark uses 100 MQTT client \\"pairs\\" sending in a 1:1 topology.\\r\\nIn other words, there are a total of 200 MQTT clients: 100 publishers and 100 subscribers.\\r\\nEach publisher sends 10,000 messages to a single subscriber.\\r\\n\\r\\nAll MQTT clients run concurrently.\\r\\nHowever, application messages are sent synchronously from publishing client to RabbitMQ:\\r\\nEach publisher sends a QoS 1 message and waits until it receives the [PUBACK](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718043) from RabbitMQ before sending the next one.\\r\\n\\r\\nThe subscribing client also replies with a PUBACK packet for each [PUBLISH](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718037) packet it receives.\\r\\n\\r\\nThe topic `t` in above command is just a topic prefix.\\r\\nEach publishing client publishes to a different topic by appending its index to the given topic (e.g. the first publisher publishes to topic `t-0`, the second to `t-1`, etc.).\\r\\n\\r\\nResults for 3.11:\\r\\n```\\r\\n================= TOTAL PUBLISHER (100) =================\\r\\nTotal Publish Success Ratio:   100.000% (1000000/1000000)\\r\\nTotal Runtime (sec):           75.835\\r\\nAverage Runtime (sec):         75.488\\r\\nPub time min (ms):             0.167\\r\\nPub time max (ms):             101.331\\r\\nPub time mean mean (ms):       7.532\\r\\nPub time mean std (ms):        0.037\\r\\nAverage Bandwidth (msg/sec):   132.475\\r\\nTotal Bandwidth (msg/sec):     13247.470\\r\\n\\r\\n================= TOTAL SUBSCRIBER (100) =================\\r\\nTotal Forward Success Ratio:      100.000% (1000000/1000000)\\r\\nForward latency min (ms):         0.177\\r\\nForward latency max (ms):         94.045\\r\\nForward latency mean std (ms):    0.032\\r\\nTotal Mean forward latency (ms):  6.737\\r\\n```\\r\\n\\r\\nResults for 3.12:\\r\\n```\\r\\n================= TOTAL PUBLISHER (100) =================\\r\\nTotal Publish Success Ratio:   100.000% (1000000/1000000)\\r\\nTotal Runtime (sec):           55.955\\r\\nAverage Runtime (sec):         55.570\\r\\nPub time min (ms):             0.175\\r\\nPub time max (ms):             96.725\\r\\nPub time mean mean (ms):       5.550\\r\\nPub time mean std (ms):        0.031\\r\\nAverage Bandwidth (msg/sec):   179.959\\r\\nTotal Bandwidth (msg/sec):     17995.888\\r\\n\\r\\n================= TOTAL SUBSCRIBER (100) =================\\r\\nTotal Forward Success Ratio:      100.000% (1000000/1000000)\\r\\nForward latency min (ms):         0.108\\r\\nForward latency max (ms):         51.421\\r\\nForward latency mean std (ms):    0.028\\r\\nTotal Mean forward latency (ms):  2.880\\r\\n```\\r\\n\\r\\n`Total Publish Success Ratio` and `Total Forward Success Ratio` validate that a total of `100 publishers * 10,000 messages = 1,000,000 messages` were processed by RabbitMQ.\\r\\n\\r\\n`Total Runtime` and `Average Runtime` show the first huge performance difference:\\r\\nWith Native MQTT each publisher receives all 10,000 publisher confirmations (PUBACKs) from the server within 55 seconds.\\r\\nMQTT in 3.11 requires 75 seconds.\\r\\n\\r\\n`Pub time mean mean` demonstrates that the average publisher confirm latency drops from 7.532 milliseconds in 3.11 by 1.982 milliseconds or 26% to 5.550 milliseconds in 3.12.\\r\\n\\r\\nAs depicted in Figure 7, the throughput of 100 concurrent clients each synchronously publishing MQTT QoS 1 messages to RabbitMQ increases from 13,247 messages per second in 3.11 by 4,748 messages per second or 36% to 17,995 messages per second in 3.12.\\r\\n\\r\\n![Figure 7: Publish Throughput with QoS 1 (3.12 performs better because throughput is higher)](native-mqtt-bandwidth.svg)\\r\\n\\r\\nThe `forward latency` statistics represent the end-to-end latency, i.e. how long it takes from publishing the message to receiving the message in the clients.\\r\\nIt is measured by having the publisher include a timestamp in each message payload.\\r\\n\\r\\nFigure 8 illustrates that the `Total mean forward latency` drops from 6.737 milliseconds in 3.11 by 3.857 milliseconds or 57% to 2.880 milliseconds in 3.12.\\r\\n\\r\\n![Figure 8: End-to-end latency with QoS 1 (3.12 performs better because latency is lower)](native-mqtt-latency.svg)\\r\\n\\r\\n### Latency QoS 0\\r\\n\\r\\nThe second latency benchmark looks very similar to the first but uses QoS 0 for messages being published and QoS 0 for subscriptions.\\r\\n\\r\\n```bash\\r\\n./mqtt-bm-latency -clients 100 -count 10000 -pubqos 0 -subqos 0 -size 100 -keepalive 120 -topic t\\r\\n```\\r\\n\\r\\nSince clients connect with `CleanSession=1` RabbitMQ creates one `rabbit_mqtt_qos0_queue` per subscriber.\\r\\nThe queue process is therefore skipped.\\r\\n\\r\\nPublisher results are omitted here for 3.11 and 3.12 because they are very low (`Pub time mean mean` is 5 microseconds).\\r\\nPublishing clients send (\\"fire & forget\\") all 1 million messages to the server at once without waiting for a PUBACK response.\\r\\n\\r\\nResults for 3.11:\\r\\n```\\r\\n================= TOTAL SUBSCRIBER (100) =================\\r\\nTotal Forward Success Ratio:      100.000% (1000000/1000000)\\r\\nForward latency min (ms):         3.907\\r\\nForward latency max (ms):         12855.600\\r\\nForward latency mean std (ms):    883.343\\r\\nTotal Mean forward latency (ms):  7260.071\\r\\n```\\r\\n\\r\\nResults for 3.12:\\r\\n```\\r\\n================= TOTAL SUBSCRIBER (100) =================\\r\\nTotal Forward Success Ratio:      100.000% (1000000/1000000)\\r\\nForward latency min (ms):         0.461\\r\\nForward latency max (ms):         5003.936\\r\\nForward latency mean std (ms):    596.133\\r\\nTotal Mean forward latency (ms):  2426.867\\r\\n```\\r\\n\\r\\nThe `Total mean forward latency` drops from 7,260.071 milliseconds in 3.11 by 4,833.204 milliseconds or 66% to 2,426.867 milliseconds in 3.12.\\r\\n\\r\\nCompared to the QoS 1 benchmarks, the end-to-end latency of 7.2 seconds in 3.11 and 2.4 seconds in 3.12 is very high, because the broker is temporarily flooded with all 1 million MQTT messages at once.\\r\\n\\r\\nDisabling credit flow (by setting `{credit_flow_default_credit, {0, 0}}` in `advanced.config`) does not improve latency in 3.11.\\r\\n\\r\\nAn exercise left for the interested reader is to run the same benchmark against 3.12 with feature flag `rabbit_mqtt_qos0_queue` disabled to see the latency difference of skipping the queue process.\\r\\n\\r\\n## What else improves with Native MQTT in 3.12?\\r\\n\\r\\nThe following list contains miscellaneous items that change with Native MQTT in 3.12:\\r\\n* The MQTT 3.1.1 feature of allowing the [SUBACK](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html#_Toc398718068) packet to include a failure return code (0x80) is implemented.\\r\\n* The AMQP 0.9.1 header `x-mqtt-dup` is removed because its usage within the MQTT plugin was wrong up to 3.11. This is a breaking change if your AMQP 0.9.1 clients depend on this header.\\r\\n* All queues created by the MQTT plugin are durable. This is done to ease the transition to [Khepri](https://github.com/rabbitmq/khepri) in a future RabbitMQ version.\\r\\n* The MQTT plugin creates [exclusive](/docs/queues#exclusive-queues) (instead of [auto-delete](/docs/queues#temporary-queues)) queues for clean sessions.\\r\\n* MQTT client ID tracking (to terminate an existing MQTT connection if a new client connects with the same client ID) is implemented in [pg](https://www.erlang.org/doc/man/pg.html). The previous [Ra](https://github.com/rabbitmq/ra) cluster that used to track MQTT client IDs is deleted when feature flag `delete_ra_cluster_mqtt_node` gets enabled. The old Ra cluster required a lot of memory and became a bottleneck when disconnecting too many clients at once.\\r\\n* Prometheus metrics are implemented using [global counters](https://github.com/rabbitmq/rabbitmq-server/blob/main/deps/rabbitmq_prometheus/metrics.md#global-counters). The protocol label has the value `mqtt310` or `mqtt311`. An example of such a metric is: `rabbitmq_global_messages_routed_total{protocol=\\"mqtt311\\"} 10`.\\r\\n* The MQTT parser got optimised.\\r\\n* MQTT clients that have never published application messages are not blocked during [memory and disk alarms](/docs/alarms) such that subscribers can continue emptying queues.\\r\\n\\r\\n## Should I use RabbitMQ as an MQTT broker?\\r\\n\\r\\nNative MQTT enables many new use cases as it allows an order of magnitude more IoT devices to connect to RabbitMQ.\\r\\nThe set of use cases is broad.\\r\\n\\r\\nRabbitMQ is only one MQTT broker on the market.\\r\\nThere are other good MQTT brokers out there and some will be able to handle even more MQTT client connections than RabbitMQ because other brokers are specialised in MQTT only.\\r\\n\\r\\nThe strength of RabbitMQ is that it is more than just an MQTT broker.\\r\\nIt is a general-purpose multi-protocol broker.\\r\\nThe real power of RabbitMQ is protocol interoperability in combination with flexible routing and choice of queue types.\\r\\n\\r\\nTo provide an example: As a payment processing company, you could connect hundreds of thousands or a few million cash terminals distributed all over the world to a central RabbitMQ cluster where each cash\\r\\nterminal sends MQTT QoS 1 messages every few minutes to RabbitMQ (whenever a customer does a payment).\\r\\n\\r\\nThese MQTT messages containing payment data are of high importance to your business.\\r\\nUnder no circumstances (node failure, disk failure, network partitions) are the messages allowed to be lost.\\r\\nThey also need to be processed by one or more microservices.\\r\\n\\r\\nOne solution is to bind a few quorum queues to the topic exchange where each quorum queue binds with a different routing key such that load is spread across the queues.\\r\\nEach quorum queue is replicated across 3 or 5 RabbitMQ nodes providing high data safety by using the Raft consensus algorithm underneath.\\r\\nThe messages within each quorum queue can be processed by different microservices using more specialised messaging protocols than MQTT, such as AMQP 0.9.1 or AMQP 1.0.\\r\\n\\r\\nAlternatively, the MQTT plugin could forward the MQTT payment messages to a [super stream](//blog.rabbitmq.com/blog/2022/07/13/rabbitmq-3-11-feature-preview-super-streams) that is replicated across multiple RabbitMQ nodes.\\r\\nOther clients can then do different forms of data analytics by consuming the same messages from the streams multiple times using the [RabbitMQ Streams protocol](https://github.com/rabbitmq/rabbitmq-server/blob/v3.12.0-beta.2/deps/rabbitmq_stream/docs/PROTOCOL.adoc).\\r\\n\\r\\nThe flexibility that RabbitMQ offers is almost endless, and there is no other message broker on the market that provides such a wide range of protocol interoperability, data safety, fault tolerance, scalability, and performance.\\r\\n\\r\\n## Future Work\\r\\nNative MQTT shipping in 3.12 is a crucial step for RabbitMQ to be used as an MQTT broker.\\r\\nHowever, the MQTT journey does not end here.\\r\\nIn the future, we plan (no promises!) to add the following MQTT improvements:\\r\\n\\r\\n* Add support for [MQTT 5.0 (v5)](https://docs.oasis-open.org/mqtt/mqtt/v5.0/mqtt-v5.0.html) - a feature that is highly asked for by the community. You can track the current progress in PR [#7263](https://github.com/rabbitmq/rabbitmq-server/pull/7263). As of 3.12, RabbitMQ supports only [MQTT 3.1.1 (v4)](https://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html) and [MQTT 3.1.0 (v3)](https://public.dhe.ibm.com/software/dw/webservices/ws-mqtt/mqtt-v3r1.html). Native MQTT has been a prerequisite to develop support for MQTT 5.0.\\r\\n* Improve resiliency when upgrading RabbitMQ nodes that handle millions of MQTT connections and improve resiliency of mass client disconnections (e.g. due to a load balancer crash).\\r\\n* Support huge fan-outs for QoS 1 sending a message at-least-once to all devices. The new queue type `rabbit_mqtt_qos0_queue` improves large fan-outs by not keeping any state in sending and receiving Erlang processes. However, as of today, sending a message that requires queue confirmations (QoS 1 in MQTT or publisher confirms in AMQP 0.9.1) to millions of queues should be done with extreme care: always use the same publisher and do so very rarely (every few minutes). Note that 1:1 topologies and large fan-ins are not problematic for RabbitMQ.\\r\\n\\r\\n## Wrapping up\\r\\n\\r\\nAlthough RabbitMQ has supported MQTT in 3.11, scalability with regards to the number of client connections has been poor and memory usage has been excessive.\\r\\n\\r\\nNative MQTT shipping in 3.12 turns RabbitMQ into an MQTT broker.\\r\\nIt allows connecting millions of clients to RabbitMQ.\\r\\nEven if you do not plan to connect that many clients, by upgrading your MQTT workload to 3.12, you will substantially save infrastructure costs because memory usage drops by up to 95%.\\r\\n\\r\\nAs next step, we plan to add support for MQTT 5.0."},{"id":"/2023/03/02/quorum-queues-migration","metadata":{"permalink":"/rabbitmq-website/blog/2023/03/02/quorum-queues-migration","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2023-03-02-quorum-queues-migration/index.md","source":"@site/blog/2023-03-02-quorum-queues-migration/index.md","title":"Migrating from Mirrored Classic Queues to Quorum Queues","description":"Quorum Queues are a superior replacement for Classic Mirrored Queues","date":"2023-03-02T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":13.9,"hasTruncateMarker":true,"authors":[{"name":"Alexey Lebedeff","url":"https://github.com/binarin","imageURL":"https://github.com/binarin.png","key":"alebedeff","page":null}],"frontMatter":{"title":"Migrating from Mirrored Classic Queues to Quorum Queues","tags":["HowTo"],"authors":["alebedeff"]},"unlisted":false,"prevItem":{"title":"Serving Millions of Clients with Native MQTT","permalink":"/rabbitmq-website/blog/2023/03/21/native-mqtt"},"nextItem":{"title":"High Initial Memory Consumption of RabbitMQ Nodes on Centos Stream 9","permalink":"/rabbitmq-website/blog/2022/08/30/high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9"}},"content":"Quorum Queues are a superior replacement for Classic Mirrored Queues\\r\\nthat were introduced in RabbitMQ version 3.8. And there are two\\r\\ncomplementary reasons why you would need to migrate. \\r\\n\\r\\nFirst of all, Classic Mirrored Queues were deprecated in 3.9, with [a\\r\\nformal announcement posted on August 21, 2021](/blog/2021/08/21/4.0-deprecation-announcements). They will be removed\\r\\nentirely in 4.0\\r\\n\\r\\nBut also they are more reliable and predictable, faster for most\\r\\nworkloads and require less maintenance - so you shouldn\'t feel that\\r\\nyour hand is being forced without no apparent reason.\\r\\n\\r\\nQuorum Queues are better in all regards, but they are not\\r\\n100%-compatible feature-wise with Mirrored Queues. Thus the migration\\r\\ncan look like a daunting task.\\r\\n\\r\\nAfter a sneak peek into the future performance improvements, this post outlines a few possible migration strategies and includes guidance on how to deal with incompatible features.\\r\\nThe [Migrate your RabbitMQ Mirrored Classic Queues to Quorum Queues documentation](/docs/3.13/migrate-mcq-to-qq) is also available to help you through the migration process.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Performance improvements\\r\\n\\r\\nIn [RabbitMQ 3.10 Performance\\r\\nImprovements](/blog/2022/05/16/rabbitmq-3.10-performance-improvements)\\r\\nblog post, performance benefits of Quorum Queues were already discussed in some detail.\\r\\n\\r\\nAnd on the following graph you can see what new levels of performance\\r\\none can expect from yet-to-be-released RabbitMQ 3.12:\\r\\n\\r\\n![Quorum Queues vs Mirrored Queues Performance Showcase](qq-migration-3.12-perf-improvements.png)\\r\\n\\r\\nThis graph shows throughput under different workloads, using 1kB messages.\\r\\nHigher is better, although in some tests the maximum throughput is capped (in such tests we look at the latency and/or whether the throughput is stable).\\r\\n\\r\\nThe colors are as follows:\\r\\n- orange - quorum queues\\r\\n- green - mirrored classic queues v1 (non-lazy)\\r\\n- yellow - mirrored classic queues v1 (lazy)\\r\\n- blue - mirrored classic queues v2\\r\\n\\r\\nWithout digging into too much detail, we can see that quorum queues\\r\\noffer a significantly higher throughput in almost all cases. For\\r\\nexample, the first test is a single queue, single publisher, single\\r\\nconsumer test. A quorum queue can sustain a 30000 msg/s throughput\\r\\n(again, using 1kb messages), while offering high levels of data safety\\r\\nand replicating data to all 3 nodes in the cluster. Meanwhile, classic\\r\\nmirrored queues offer only a third of that throughput, yet providing\\r\\nway lower data safety guarantees. In some tests we can see quorum\\r\\nqueues (orange line) completely flat, meaning they can sustain the\\r\\nworkload and still have some capacity left (otherwise they performance\\r\\nwould start fluctuating), while mirrored queues offer lower and less\\r\\nstable throughput.\\r\\n\\r\\nThe astute reader can notice that in the second test quorum\\r\\nqueues initially provide very high publisher throughput but quickly\\r\\ndegrade. This is something we are working on right now and we hope\\r\\nto improve very soon. This is only a corner case when there are no\\r\\nconsumers, and the queue quickly becomes very long (millions of\\r\\nmessages).\\r\\n\\r\\n## Compatibility considerations\\r\\n\\r\\nThe RabbitMQ documentation has a dedicated page on [Quorum Queues](/docs/quorum-queues).\\r\\nSpecifically in this document there is a\\r\\n[feature matrix](/docs/quorum-queues#feature-matrix) which provides a\\r\\nlist with all differences between Mirrored Classic Queues and Mirrored\\r\\nQueues. These differences can require a different amount of work for a\\r\\nsuccessful migration. Some of [them](#trivial-changes) can be trivial\\r\\nto change, while [others](#breaking-changes) can require changes in\\r\\nthe way an application interacts with RabbitMQ. All of them are\\r\\nthoroughly documented further.\\r\\n\\r\\nAnd it goes without saying that migrated applications should be\\r\\nthoroughly tested against quorum queues, as behaviour can be somewhat\\r\\ndifferent under the load and in edge cases.\\r\\n\\r\\nThere are 2 migration strategies described in this post:\\r\\n\\r\\n- [First one](#new-vhost-migration) involves creating a new vhost, and\\r\\n  migrating with minimal loss of uptime with the help of\\r\\n  federation. If all incompatible features are cleaned up or moved to\\r\\n  policies, this is also the happy path migration - the existing code\\r\\n  will be able to work both with mirrored and quorum queues by only changing\\r\\n  connection parameters.\\r\\n- [Another one](#in-place-migration) trades uptime for re-using the\\r\\n  same virtual host, and requires the ability to stop all the\\r\\n  consumers and producers for a given queue.\\r\\n\\r\\n## General requirements\\r\\n1. There should be at least 3 nodes in the cluster - there is no sense\\r\\n   in using quorum queues with a smaller amount of replicas.\\r\\n2. Management plugin should be running on at least one node - it\'s\\r\\n   being used for exporting/importing definitions for a single host,\\r\\n   which can greatly simplify definitions cleanup. (And\\r\\n   `rabbitmqadmin` CLI command is also using the plugin behind the\\r\\n   scenes).\\r\\n3. Shovel plugin should be enabled.\\r\\n\\r\\n## Finding the queues and features being used\\r\\n\\r\\nAll mirrored classic queues have `ha-mode` in their effective policy\\r\\ndefinition. The policies that apply it can be found via the following script:\\r\\n\\r\\n```bash\\r\\n#!/bin/sh\\r\\nprintf \\"%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s\\\\t%s\\\\n\\" vhost policy_name pattern apply_to definition priority\\r\\nfor vhost in $(rabbitmqctl -q list_vhosts | tail -n +2) ; do\\r\\n  rabbitmqctl -q list_policies -p \\"$vhost\\" |\\r\\n    grep \'ha-mode\'\\r\\ndone\\r\\n```\\r\\n\\r\\nBut it can be easier to just list the queues that are actually\\r\\nmirrored on the running system. That way there is no need to guess\\r\\nwhether HA-policies are actually applied:\\r\\n\\r\\n```bash\\r\\n#!/bin/sh\\r\\nprintf \\"%s\\\\t%s\\\\t%s\\\\n\\" vhost queue_name mirrors\\r\\nfor vhost in $(rabbitmqctl -q list_vhosts | tail -n +2) ; do\\r\\n  rabbitmqctl -q list_queues -p \\"$vhost\\" name durable policy effective_policy_definition arguments mirror_pids type |\\r\\n\\tsed -n \'/\\\\t\\\\[[^\\\\t]\\\\+\\\\tclassic$/{s/\\\\t\\\\[[^\\\\t]\\\\+\\\\tclassic$//; p}\' |\\r\\n\\txargs -x -r -L1 -d \'\\\\n\' printf \\"%s\\\\t%s\\\\n\\" \\"$vhost\\"\\r\\ndone\\r\\n```\\r\\n\\r\\nNote that the above command uses `effective_policy_definition` argument,\\r\\nwhich is only available since 3.10.13/3.11.5. If it\'s not available,\\r\\nit\'s possible to either use `rabbitmqctl` from a fresh version of\\r\\nRabbitMQ, or manually match policy name to its definition.\\r\\n\\r\\n## Breaking changes {#breaking-changes}\\r\\n\\r\\nWhen one or more of the following features are being used,\\r\\nstraightforward migration to quorum queues is not possible. The way\\r\\nthat application interacts with a broker needs to be changed.\\r\\n\\r\\nThis section outlines how to find whether some of these features are\\r\\nbeing used in a running system, and what changes need to be made for\\r\\neasier migration.\\r\\n\\r\\n### Priority queues\\r\\n\\r\\nClassic mirrored queues actually create a separate queue for every\\r\\npriority behind the scenes. For migration it’s necessary for the\\r\\napplications to explicitly handle creation of those queues, and also\\r\\npublishing/consuming to and from them. \\r\\n\\r\\nThis feature can be detected by the presence of `x-max-priority` in\\r\\nthe queue list output from above. The same exact string can be\\r\\nsearched for in the source code. Priority queues can’t be created via\\r\\npolicy, so no policy changes are involved.\\r\\n\\r\\n### Overflow dead lettering\\r\\n\\r\\nOverflow mode\\r\\n[`reject-publish-dlx`](/docs/maxlength#overflow-behaviour) is not\\r\\nsupported by quorum queues. The code needs to be updated to use\\r\\npublisher confirms and to do dead lettering by itself.\\r\\n\\r\\nThis feature can be detected by the presence of `reject-publish-dlx`\\r\\nin the queue list output from above. The same exact string can be\\r\\nsearched for in the source code.\\r\\n\\r\\n### Global QoS for consumers\\r\\n\\r\\n[Global QoS for\\r\\nconsumers](/docs/quorum-queues#global-qos) is not\\r\\nsupported for quorum queues. A decision needs to be made about how\\r\\nnecessary results can be achieved using alternative means, e.g. by\\r\\nusing a lower per-consumer QoS that can give approximately the same\\r\\nresults (given the known application load pattern).\\r\\n\\r\\nTo detect whether this feature is used, the following command can be\\r\\nexecuted agains a running system and checked for a non-empty output:\\r\\n\\r\\n```bash\\r\\nrabbitmqctl list_channels pid name global_prefetch_count | sed -n \'/\\\\t0$/!p\'\\r\\n```\\r\\n\\r\\nIt will give a list of channel PIDs that have global QoS enabled,\\r\\nwhich then can be mapped to a queue name and checked for being a\\r\\nmirrored queue:\\r\\n\\r\\n```bash\\r\\nrabbitmqctl list_consumers queue_name channel_pid\\r\\n```\\r\\n\\r\\n\\r\\n### `x-cancel-on-ha-failover` for consumers\\r\\n\\r\\nMirrored queues consumers can be [automatically\\r\\ncancelled](/docs/3.13/ha#cancellation) when a queue\\r\\nleader fails over. This can cause a loss of information about which\\r\\nmessages were sent to which consumer, and redelivery of such messages.\\r\\n\\r\\nQuorum queues are less exposed to such behaviour - the only case when\\r\\nit still can happen is when a whole node goes down. For other leader\\r\\nchanges (e.g. caused by rebalancing), there will be no redeliveries.\\r\\n\\r\\nAnd redeliveries can also happen for inflight messages when the\\r\\nconsumer is cancelled or the channel is closed. So application needs\\r\\nto be prepared for redeliveries anyway, without specifically asking\\r\\nfor such information.\\r\\n\\r\\n## Trivial changes {#trivial-changes}\\r\\n\\r\\nThese features don\'t do anything when quorum queues are being\\r\\nused. The best way to handle them is to remove them from the source\\r\\ncode completely, or move them to a policy instead.\\r\\n\\r\\n### Lazy queues\\r\\n\\r\\nClassic queue can optionally operate in [lazy\\r\\nmode](/docs/lazy-queues), but for quorum\\r\\nqueues this is the only way of operation. The best way to handle this\\r\\nfor migration is to move `x-queue-mode` from source code to a policy.\\r\\n\\r\\n### Non-durable queues\\r\\n\\r\\nNon-durable queues will be deleted on a node/cluster boot. Having\\r\\nextra durability guarantees that mirroring provides is a bit\\r\\npointless.\\r\\n\\r\\nNon-durable queues concept is also going away in the future releases:\\r\\nthe only option for ephemeral queues will be exclusive queues. This\\r\\naffects only durability of queue definitions, messages can still be marked\\r\\ntransient.\\r\\n\\r\\nFor such queues a decision have to be made one way or another: is this\\r\\nqueue content important enough to get availability guarantees of\\r\\nquorum queues, or it\'s better to downgrade it to a classic (but\\r\\ndurable) queue.\\r\\n\\r\\n### Exclusive queues\\r\\n\\r\\nExclusive queues are not mirrored even if the policy says so. But\\r\\nattempt to declare an exclusive quorum queue will result in an\\r\\nerror. This is clearly one of the cases where migration is not needed,\\r\\nbut care must be taken as to avoid exclusive queue declarations with\\r\\nan explicit `x-queue-type: quorum` argument.\\r\\n\\r\\n## Migrate the Queues One Virtual Host at a Time {#new-vhost-migration}\\r\\n\\r\\nThe procedure to migrate from classic mirrored queues to quorum queues\\r\\nis similar to a [blue-green cluster upgrade](/docs/blue-green-upgrade),\\r\\nexcept that migration can happen to a new virtual host on the same\\r\\nRabbitMQ cluster. [Federation Plugin](/docs/federation) is then being\\r\\nused to seamlessly migrate from the old to the new one.\\r\\n\\r\\nOne important aspect of this migration path is that it\'s possible to\\r\\nspecify the default queue type for a new virtual host. Setting it to\\r\\n`quorum` makes all the queues without explicit type created as\\r\\nquorum queues (except for exclusive, non-durable or auto-delete queues).\\r\\n\\r\\nIf all incompatible features were cleaned up from the source code (and\\r\\nthere is no explicit `x-queue-type` arguments in the source code), then\\r\\nit\'ll be possible to use exactly the same code to work both to the old\\r\\nvirtual host with classical mirrored queues, and with a new virtual\\r\\nhost with quorum queues - only the virtual host in the connection\\r\\nparameters needs to be changed.\\r\\n\\r\\n### Create destination virtual host\\r\\n\\r\\nSpecial attention needs to be paid that the new virtual host is\\r\\ncreated with proper default queue type. It should be selected from the\\r\\nqueue type dropdown when new virtual host is being added via\\r\\nmanagement UI. It can also be created using CLI interface, specifying\\r\\nthe default queue type, and adding some permissions:\\r\\n\\r\\n```bash\\r\\nrabbitmqctl add_vhost NEW_VHOST --default-queue-type quorum\\r\\nrabbitmqctl set_permissions -p NEW_VHOST USERNAME \'.*\' \'.*\' \'.*\'\\r\\n```\\r\\n\\r\\n### Create federation upstream\\r\\n\\r\\nA new federation upstream should be created for the NEW\\\\_VHOST, with\\r\\nURI pointing to the OLD\\\\_VHOST: `amqp:///OLD_VHOST`. (Note that\\r\\ndefault vhost URI is `amqp:///%2f`).\\r\\n\\r\\nThe upstream can be created via management UI, or via CLI:\\r\\n```bash\\r\\nrabbitmqctl set_parameter federation-upstream quorum-migration-upstream \\\\\\r\\n    --vhost NEW_VHOST \\\\\\r\\n    \'{\\"uri\\":\\"amqp:///OLD_VHOST\\", \\"trust-user-id\\":true}\'\\r\\n```\\r\\n\\r\\nWhen this form of URI, with an empty hostname is used, there is no\\r\\nneed to specify credentials, but connection is only possible within\\r\\nbounds of a single cluster.\\r\\n\\r\\nIf `user-id` in messages is being used for any purpose, it can also be\\r\\npreserved as shown in the CLI example above.\\r\\n\\r\\n### Moving definitions\\r\\n\\r\\nExport definitions of the source virtual host to a file. This is\\r\\navailable on the \\"Overview\\" page of the management UI (don\'t forget to\\r\\nselect a single virtual host). Or use the following CLI command:\\r\\n\\r\\n```bash\\r\\nrabbitmqadmin export -V OLD_VHOST OLD_VHOST.json\\r\\n```\\r\\n\\r\\nThe following changes needs to be made to this file before loading it back into a NEW_VHOST:\\r\\n\\r\\n1. Remove `x-queue-type` declarations for queues that you want to have\\r\\n   as classic ones in the old virtual host, and as quorum ones in the\\r\\n   new virtual host.\\r\\n2. Other changes that need to be applied to queue definitions:\\r\\n   - Remove `x-max-priority` argument\\r\\n   - Change `x-overlow` argument when it is set to `reject-publish-dlx`\\r\\n   - Remove `x-queue-mode` argument\\r\\n   - Change `durable` attribute to `true`\\r\\n3. Change the following keys in policies:\\r\\n   - Remove everything starting with `ha-`: `ha-mode`, `ha-params`,\\r\\n     `ha-sync-mode`, `ha-sync-batch-size`, `ha-promote-on-shutdown`,\\r\\n     `ha-promote-on-failure`\\r\\n   - Remove `queue-mode`\\r\\n   - Change `overflow` when it is set to `reject-publish-dlx`\\r\\n4. Policies that ended empty after the previous step should be dropped.\\r\\n5. Federation with the old vhost should be added to any remaining\\r\\n   policies, pointing to the federation upstream created earlier:\\r\\n   `\\"federation-upstream-set\\":\\"quorum-migration-upstream\\"`\\r\\n6. If there is no catch-all policy (applying to queues with pattern\\r\\n   `.*`), it needs to be created and also point to the federation\\r\\n   upstream. This ensures that every queue in the old vhost will be\\r\\n   federated.\\r\\n7. Policies that apply federation rules to exchanges need to be\\r\\n   removed for the period of the migration, to avoid duplicate\\r\\n   messages.\\r\\n\\r\\n\\r\\nNow the modified schema can be loaded into the new virtual host from\\r\\nUI or using CLI tools:\\r\\n\\r\\n```bash\\r\\n# Import definitions for a single virtual host using rabbitmqadmin.\\r\\n# See https://www.rabbitmq.com/docs/definitions to learn more.\\r\\nrabbitmqadmin import -V NEW_VHOST NEW_VHOST.json\\r\\n```\\r\\n\\r\\n### Point consumers to the new vhost\\r\\n\\r\\nAt this point it should be possible to point consumers to the new\\r\\nvirtual host by only updating the connection parameters.\\r\\n\\r\\n### Point producers to the new vhost\\r\\n\\r\\nProducers can now be also pointed to the new virtual host.\\r\\n\\r\\nThe time when consumers are stopped is also the time where federated\\r\\nexchanges should be disabled in the old vhost, and enabled in the new\\r\\none.\\r\\n\\r\\nUnder sufficient system load messages from the old virtual host will\\r\\nnot be picked up. If message ordering is important, than this should\\r\\nbe done in steps: stop producers, shovel remaining messages to the new\\r\\nvirtual host, start consumers on the new virtual host.\\r\\n\\r\\n### Shovel remaining messages to the new vhost\\r\\n\\r\\nFor every non-empty queue in the old host a shovel needs to be configured:\\r\\n\\r\\n```bash\\r\\nrabbitmqctl set_parameter shovel migrate-QUEUE_TO_MIGRATE \\\\\\r\\n  \'{\\"src-protocol\\": \\"amqp091\\", \\"src-uri\\": \\"amqp:///OLD_VHOST\\", \\"src-queue\\": \\"QUEUE_TO_MIGRATE\\",\\r\\n    \\"dest-protocol\\": \\"amqp091\\", \\"dest-uri\\": \\"amqp:///NEW_VHOST\\", \\"dest-queue\\": \\"QUEUE_TO_MIGRATE\\"}\'\\r\\n```\\r\\n\\r\\nAfter the queue has been drained, the shovel can be deleted:\\r\\n```bash\\r\\nrabbitmqctl clear_parameter shovel migrate-QUEUE_TO_MIGRATE\\r\\n```\\r\\n\\r\\n### Ensure future queue declarations succeed\\r\\n\\r\\nMany applications declare queues before they use them, in multiple places. When it comes to\\r\\nmigrating away from classic mirrored queues, this presents a channel: if clients declare queues\\r\\nwithout explicitly providing a queue type, after the [Moving Definitions](#moving-definitions)\\r\\nstep, all future declaration attempts would hit a `PRECONDITION_FAILURE` channel error\\r\\nwhen an existing queue is re-declared.\\r\\n\\r\\nTo avoid this scenario, there are three options:\\r\\n\\r\\n1. Add the `x-queue-type` declarations back to all clients using quorum queues.\\r\\n2. set the default queue type node-wide using `default_queue_type`, a `rabbitmq.conf`\\r\\n   setting that is available [in RabbitMQ `3.13.3`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.13.3)\\r\\n   and later versions\\r\\n3. Set `quorum_queue.property_equivalence.relaxed_checks_on_redeclaration = true`, a `rabbitmq.conf`\\r\\n   setting available since [RabbitMQ `3.11.16`](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.11.16)\\r\\n\\r\\nThe third option, `quorum_queue.property_equivalence.relaxed_checks_on_redeclaration` set to `true`,\\r\\ncan be adopted at any time during the migration process.\\r\\n\\r\\n## Migrate in place {#in-place-migration}\\r\\n\\r\\nIn this version of the process, we trade uptime for the ability to\\r\\nperform the migration in an existing virtual host and cluster.\\r\\n\\r\\nFor each queue (or some group of queues) being migrated, it should be\\r\\npossible to stop all the consumers and producers for the time of the\\r\\nmigration.\\r\\n\\r\\n### Preparing producers and consumers\\r\\n\\r\\nAll incompatible features should be cleaned up. In addition to that,\\r\\nin every place where queues are being declared, it\'d be nice to make\\r\\n`x-queue-type` argument configurable without changing application code.\\r\\n\\r\\n### Migration steps\\r\\n\\r\\n1. First, the consumers and producers will need to be stopped.\\r\\n2. The messages should be shoveled to a new, temporary queue.\\r\\n3. The old queue should be deleted.\\r\\n4. A new quorum queue with the same name as the original queue should be created.\\r\\n5. The contents of the temporary queue should now be shoveled over to the new quorum queue.\\r\\n6. The consumers can now be reconfigured to use `x-queue-type` of `quorum` and started.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nHopefully this blog post has shown that with a proper preparation the\\r\\nmigration can be fruitful and a relatively simple endeavour.\\r\\n\\r\\nThe migration has a lot of benefits. But one should also keep in mind\\r\\nthat Classic Mirrored Queues have been deprecated for more than a year\\r\\nand are going to be removed entirely in an upcoming release. So even\\r\\nif you don\'t plan to do the migration right now, doing these\\r\\npreparations beforehand can be a good idea.\\r\\n\\r\\nAnd we\'ve tried to provide you the comprehesive guide for this\\r\\npurpose. Maybe it\'s time to do something now?"},{"id":"/2022/08/30/high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9","metadata":{"permalink":"/rabbitmq-website/blog/2022/08/30/high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-08-30-high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9/index.md","source":"@site/blog/2022-08-30-high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9/index.md","title":"High Initial Memory Consumption of RabbitMQ Nodes on Centos Stream 9","description":"Team RabbitMQ and community members have recently identified a curious scenario where a freshly started node could","date":"2022-08-30T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":1.11,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"High Initial Memory Consumption of RabbitMQ Nodes on Centos Stream 9","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Migrating from Mirrored Classic Queues to Quorum Queues","permalink":"/rabbitmq-website/blog/2023/03/02/quorum-queues-migration"},"nextItem":{"title":"RabbitMQ 3.11.0 release calendar","permalink":"/rabbitmq-website/blog/2022/08/01/rabbitmq-3.11.0-release-calendar"}},"content":"Team RabbitMQ and community members have recently identified a curious scenario where a freshly started node could\\r\\nconsume a surprisingly high amount of memory, say, 1.5 GiB or so. We\'d like to share our findings with the community\\r\\nand explain what short term and longer term workarounds are available.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nSome recent Linux distributions, such as ArchLinux, [RHEL 9](https://access.redhat.com/solutions/1479623), and CentOS Stream 9, ship a recent version of systemd\\r\\n[that sets the default open file handle limit is set to 1073741816](https://github.com/systemd/systemd/commit/a8b627aaed409a15260c25988970c795bf963812) or about one billion.\\r\\nThis is much higher than the default used by older distributions such as CentOS 8.\\r\\n\\r\\nFor a lot of software this doesn\'t change anything. However, the Erlang runtime will allocate more memory upfront on systems with a very high limit.\\r\\nThis leads to surprisingly high footprint of newly started RabbitMQ nodes without any data or meaningful client activity.\\r\\n\\r\\n[There are two ways to mitigate](https://github.com/docker-library/rabbitmq/issues/545#issuecomment-1224977154) this problem:\\r\\n\\r\\n * Lower the file handle limit for user that runs the node (usually named `rabbitmq`)\\r\\n * [Set the `ERL_MAX_PORTS` environment variable](/docs/configure#customise-environment) to a lower value\\r\\n\\r\\nWhat value would be more appropriate for your given environment depends on the workload. Default values in the 50,000 to 100,000 range\\r\\nshould support plenty of concurrent client connections, queues and streams for many cases without causing\\r\\nexcessive upfront memory allocation by the runtime."},{"id":"/2022/08/01/rabbitmq-3.11.0-release-calendar","metadata":{"permalink":"/rabbitmq-website/blog/2022/08/01/rabbitmq-3.11.0-release-calendar","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-08-01-rabbitmq-3.11.0-release-calendar/index.md","source":"@site/blog/2022-08-01-rabbitmq-3.11.0-release-calendar/index.md","title":"RabbitMQ 3.11.0 release calendar","description":"We intend to release RabbitMQ 3.11.0 on 5 September 2022. While we have been testing","date":"2022-08-01T00:00:00.000Z","tags":[],"readingTime":2.025,"hasTruncateMarker":true,"authors":[{"name":"Mirah Gary","url":"https://github.com/MirahImage","imageURL":"https://github.com/MirahImage.png","key":"mgary","page":null}],"frontMatter":{"title":"RabbitMQ 3.11.0 release calendar","tags":[],"authors":["mgary"]},"unlisted":false,"prevItem":{"title":"High Initial Memory Consumption of RabbitMQ Nodes on Centos Stream 9","permalink":"/rabbitmq-website/blog/2022/08/30/high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9"},"nextItem":{"title":"OIDC Integration","permalink":"/rabbitmq-website/blog/2022/07/22/oidc-integration"}},"content":"We intend to release RabbitMQ 3.11.0 on 5 September 2022. While we have been testing\\r\\nit internally for some time, with production-like workloads, we need your help to\\r\\ncheck that it is as stable and reliable as we believe it is.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThis is the timeline that we have to work together on making 3.11.0 the best release for\\r\\nyou:\\r\\n\\r\\n| Milestone              | Anticipated Date | Notes                                                                         |\\r\\n| ---                    | ---                | ---                                                                         |\\r\\n| 3.11.0-beta.1 produced | 8 August 2022      | Feature preview of Single Active Consumer and Super Streams                 |\\r\\n| Code freeze            | 19 August 2022     | No new features or refactorings before the final release                    |\\r\\n| 3.11.0-rc.1 produced   | 19 August 2022     | All artefacts built & published                                             |\\r\\n| 3.11.0-rc.1 announced  | 22 August 2022     | First release candidate (RC) is announced & made public for testing         |\\r\\n| 3.11.0 produced        | 2 September 2022   | Final release is built & published                                          |\\r\\n| 3.11.0 announced       | 5 September 2022   | Final release is announced & made public                                    |\\r\\n\\r\\nThe above release calendar is a point-in-time snapshot. For latest updates\\r\\nplease refer to the [Release Series](/release-information)\\r\\npage.\\r\\n\\r\\nRabbitMQ 3.11.0 introduces some highly requested functionality:\\r\\n* [Single Active Consumer for Streams](https://blog.rabbitmq.com/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams)\\r\\n* [Super Streams](https://blog.rabbitmq.com/blog/2022/07/13/rabbitmq-3-11-feature-preview-super-streams)\\r\\n* [Management UI OAuth2 and OIDC support](https://blog.rabbitmq.com/blog/2022/07/22/oidc-integration)\\r\\n\\r\\nAdditionally, RabbitMQ 3.11.0 will make [all feature flags introduced during the life of RabbitMQ 3.8.x required](https://blog.rabbitmq.com/blog/2022/07/22/mandatory-feature-flags-in-rabbitmq-3.11). Please ensure all feature flags are enabled before atttempting to upgrade to 3.11.0.\\r\\n\\r\\nThis release calendar is meant to communicate what to expect, and when.\\r\\nBased on your feedback during the pre-release timeline, we may add additional\\r\\nrelease candidates, and extend the release timeline.\\r\\n\\r\\nOur intention is to give you the opportunity to find issues with this release\\r\\nbefore we publish the final version. We all want important new releases, such\\r\\nas 3.11.0, to be as stable and reliable as possible. While we have gone to great\\r\\nlengths to ensure that this is the case, more eyes and experiments will always\\r\\nhelp, especially with a community as experienced and battle-hardened as ours.\\r\\n\\r\\n**Help us make RabbitMQ 3.11.0 the best release for you!**\\r\\n\\r\\n\\r\\n## Intent to remove capabilities in RabbitMQ 4.0\\r\\n\\r\\nWe are intending to remove some aged and suboptimal capabilities of RabbitMQ (see [blog post here](/blog/2021/08/21/4.0-deprecation-announcements)).\\r\\n\\r\\nWe have not yet set a release date for 4.0.\\r\\n\\r\\nIf you have further comments, please complete the survey linked in the [blog post](/blog/2021/08/21/4.0-deprecation-announcements)."},{"id":"/2022/07/22/oidc-integration","metadata":{"permalink":"/rabbitmq-website/blog/2022/07/22/oidc-integration","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-07-22-oidc-integration/index.md","source":"@site/blog/2022-07-22-oidc-integration/index.md","title":"OIDC Integration","description":"Today when we use the rabbitmq-management with the rabbitmqauthbackendoauth2 plugin, the only supported Authorization server is UAA, making it difficult to connect to other OAuth  2.0 servers. Additionally, rabbitmq-management_ plugin uses the OAuth 2.0 implicit flow which is no longer recommended for security reasons.","date":"2022-07-22T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"},{"inline":true,"label":"Security","permalink":"/rabbitmq-website/blog/tags/security"}],"readingTime":2.915,"hasTruncateMarker":true,"authors":[{"name":"Marcial Rosales","url":"https://github.com/MarcialRosales","imageURL":"https://github.com/MarcialRosales.png","key":"mrosales","page":null}],"frontMatter":{"title":"OIDC Integration","tags":["HowTo","Security"],"authors":["mrosales"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.11.0 release calendar","permalink":"/rabbitmq-website/blog/2022/08/01/rabbitmq-3.11.0-release-calendar"},"nextItem":{"title":"Required feature flags in RabbitMQ 3.11.0","permalink":"/rabbitmq-website/blog/2022/07/20/required-feature-flags-in-rabbitmq-3.11"}},"content":"Today when we use the _rabbitmq-management_ with the _rabbitmq_auth_backend_oauth2_ plugin, the only supported Authorization server is [UAA](https://docs.cloudfoundry.org/concepts/architecture/uaa.html), making it difficult to connect to other OAuth  2.0 servers. Additionally, _rabbitmq-management_ plugin uses the [OAuth 2.0 implicit](https://oauth.net/2/grant-types/implicit/) flow which is no longer recommended for security reasons.\\r\\n\\r\\nRabbitMQ 3.11 will support practically any Authorization server compliant with OpenID Connect and OAuth 2.0 protocols.\\r\\nFurthermore, OAuth 2.0 [authorization code grant](https://oauth.net/2/grant-types/authorization-code/) becomes the default grant and [implicit](https://oauth.net/2/grant-types/implicit/) grant is no longer supported.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nPrior to RabbitMQ 3.11, when using OAuth 2.0 with the Management UI, RabbitMQ only supported UAA as an OAuth 2.0 server due to the use of a javascript library provided by UAA. Furthermore, this library only supported _implicit_ grant type and targeted custom UAA\'s HTTP endpoints, which do not follow any standard such as OpenID Connect.\\r\\n\\r\\nRabbitMQ 3.11 delegates all OAuth 2.0 and OpenID Connect protocols to the [oidc-client-ts](https://authts.github.io/oidc-client-ts/) library and no longer depends on the UAA client library. With this change, RabbitMQ no longer supports the _implicit_ grant type but now supports _authorization code_ grant type. Additionally, the old settings with the prefix `uaa_`, such as `uaa_location`, are deprecated and replaced by a new set of settings with the prefix `oauth_`, as clarified in the next section, [Usage](#usage).\\r\\n\\r\\n\\r\\n## Usage\\r\\n\\r\\nTo configure _rabbitmq-management_ to authenticate users with any OAuth 2.0 server we need to provide the following settings:\\r\\n* `oauth_enabled` replaces `enable_uaa`\\r\\n* `oauth_client_id` replaces `uaa_client_id`\\r\\n* `oauth_client_secret` contains the secret corresponding to the `oauth_client_id`. This is a new setting, as the _implicit_ grant flow did not require a secret.\\r\\n* `oauth_provider_url` replaces `uaa_location`. It is the OpenID Connect endpoint URL, and through this endpoint, RabbitMQ discovers all the other OAuth 2.0 endpoints.\\r\\n\\r\\nHere is an example configuration of the plugin with the above settings:\\r\\n```erlang\\r\\n  { rabbitmq_management,\\r\\n     ...\\r\\n\\r\\n     {oauth_enabled, true},\\r\\n     {oauth_client_id, \\"PUT YOUR AUTH CLIENT ID\\"},\\r\\n     {oauth_client_secret, \\"PUT YOUR AUTH CLIENT SECRET\\"},\\r\\n     {oauth_provider_url, \\"PUT YOUR OpenID Connect URL\\"}\\r\\n     ...\\r\\n  }\\r\\n```\\r\\n\\r\\nIn addition to the four mandatory settings above, there is an additional optional setting:\\r\\n\\r\\n* `oauth_scopes` sets the _scopes_ RabbitMQ requests on behalf of the user accessing the management UI. The default value is `openid profile` when `enable_uaa` is not set or false, and `openid profile <rabbitmq_auth_backend_oauth2.resource_server_id>.*` when `enable_uaa` is true\\r\\n\\r\\n*When do we need to set `oauth_scopes`?*\\r\\n\\r\\nThere are some OAuth 2.0 servers which can automatically grant _scopes_ to users regardless of the scopes requested by RabbitMQ during the authorization request. Should your OAuth 2.0 server have this capability, you do not need to specify all the scopes in `oauth_scopes`.\\r\\n\\r\\nOn the contrary, if your OAuth 2.0 server only grants those _scopes_ requested during the authorization request, then\\r\\nthey must be specified within the `oauth_scopes` setting.\\r\\n\\r\\n\\r\\n## How are existing clusters affected by this change?\\r\\n\\r\\nOnly RabbitMQ clusters which are currently configured to authenticate with UAA are affected by this change.\\r\\nThey will stop working unless these changes are made:\\r\\n\\r\\n* Add `{oauth_enabled, true},`\\r\\n* Add `{oauth_client_secret, \\"UAA_CLIENT_SECRET\\"},` , where `UAA_CLIENT_SECRET` is the client secret associated with the previously configured `uaa_client_id`\\r\\n\\r\\nHowever, it is highly recommended that existing clusters configured to use UAA for OAuth 2.0 be completely reconfigured with the new settings, as the old configuration is deprecated and will be removed in a future release.\\r\\n\\r\\n## What OAuth 2.0 servers are currently supported?\\r\\n\\r\\nIn theory, any OAuth 2.0 server which is OpenID Connect compliant should be supported. RabbitMQ has been tested\\r\\nagainst the following OAuth 2.0 servers:\\r\\n\\r\\n* Keycloak\\r\\n* Auth0\\r\\n* Azure Active Directory"},{"id":"/2022/07/20/required-feature-flags-in-rabbitmq-3.11","metadata":{"permalink":"/rabbitmq-website/blog/2022/07/20/required-feature-flags-in-rabbitmq-3.11","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-07-20-required-feature-flags-in-rabbitmq-3.11/index.md","source":"@site/blog/2022-07-20-required-feature-flags-in-rabbitmq-3.11/index.md","title":"Required feature flags in RabbitMQ 3.11.0","description":"RabbitMQ 3.11.0 will make all [feature","date":"2022-07-20T00:00:00.000Z","tags":[],"readingTime":3.26,"hasTruncateMarker":true,"authors":[{"name":"Jean-Sébastien Pédron","url":"https://github.com/dumbbell","imageURL":"https://github.com/dumbbell.png","key":"jpedron","page":null}],"frontMatter":{"title":"Required feature flags in RabbitMQ 3.11.0","tags":[],"authors":["jpedron"]},"unlisted":false,"prevItem":{"title":"OIDC Integration","permalink":"/rabbitmq-website/blog/2022/07/22/oidc-integration"},"nextItem":{"title":"RabbitMQ 3.11 Feature Preview: Super Streams","permalink":"/rabbitmq-website/blog/2022/07/13/rabbitmq-3-11-feature-preview-super-streams"}},"content":"RabbitMQ 3.11.0 will make all [feature\\r\\nflags](/docs/feature-flags) introduced during the life\\r\\nof RabbitMQ 3.8.x required.\\r\\n\\r\\nPeople who initially created clusters using RabbitMQ 3.8.9 or older should\\r\\nenable all feature flags before upgrading to RabbitMQ 3.11! If the feature\\r\\nflags are not enabled, RabbitMQ 3.11.0+ will refuse to start.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nFeature flags are a mechanism to make breaking changes to RabbitMQ while still\\r\\nmaintaining the compatibility between several versions of RabbitMQ. They\\r\\nusually come with code to migrate data structures in the internal schema\\r\\ndatabase or on disk for instance. There is also compatibility code scattered in\\r\\nthe code to support the old and new behaviors and structures at the same time\\r\\nat runtime.\\r\\n\\r\\nIn other words, feature flags are really meant to allow rolling cluster\\r\\nupgrades. They are not there to let you decide e.g. \\"I don\'t want quorum\\r\\nqueues, so I will never enable the corresponding feature flag\\". Enabling the\\r\\nfeature flag does not force you to use the feature behind it. And most feature\\r\\nflags protect an internal change which has no visible impact to end users.\\r\\nConsider that all feature flags should generally be enabled as soon as possible\\r\\nbecause they allow you to upgrade RabbitMQ.\\r\\n\\r\\nThis benefit obviously comes with a cost for us to maintain and test however.\\r\\nFurthermore, this may interfere with new changes and slow us down.\\r\\n\\r\\nRabbitMQ 3.11.0 will therefore be the first release where we mark some feature\\r\\nflags as required and remove their corresponding compatibility and migration\\r\\ncode. The affected feature flags are:\\r\\n* `quorum_queue` (support for [quorum\\r\\n  queues](/docs/quorum-queues))\\r\\n* `implicit_default_bindings` (default bindings now implicit, instead of being\\r\\n  stored in the database, to speed up creation of queues and exchanges)\\r\\n* `virtual_host_metadata` (ability to add metadata to virtual host metadata;\\r\\n  description, tags, etc)\\r\\n* `maintenance_mode_status` (ability to switch RabbitMQ to a maintenance mode)\\r\\n* `user_limits` (ability to configure connection and channel limits for a user)\\r\\n\\r\\nFor you as an end user, it means the following things:\\r\\n\\r\\n1.  When starting a fresh RabbitMQ node for the first time, required feature\\r\\n    flags will always be enabled, even if the `$RABBITMQ_FEATURE_FLAGS`\\r\\n    environment says otherwise for instance.\\r\\n\\r\\n2.  When restarting or upgrading a RabbitMQ, if the required feature flags are\\r\\n    not already enabled, the node will refuse to start. Here is an example of\\r\\n    the logged error message in this case:\\r\\n\\r\\n    ```\\r\\n    2022-07-13 11:29:28.366877+02:00 [error] <0.232.0> Feature flags: `implicit_default_bindings`: required feature flag not enabled! It must be enabled before upgrading RabbitMQ.\\r\\n    2022-07-13 11:29:28.366905+02:00 [error] <0.232.0> Failed to initialize feature flags registry: {disabled_required_feature_flag,\\r\\n    2022-07-13 11:29:28.366905+02:00 [error] <0.232.0>                                               implicit_default_bindings}\\r\\n    2022-07-13 11:29:28.372830+02:00 [error] <0.232.0>\\r\\n    2022-07-13 11:29:28.372830+02:00 [error] <0.232.0> BOOT FAILED\\r\\n    2022-07-13 11:29:28.372830+02:00 [error] <0.232.0> ===========\\r\\n    2022-07-13 11:29:28.372830+02:00 [error] <0.232.0> Error during startup: {error,failed_to_initialize_feature_flags_registry}\\r\\n    2022-07-13 11:29:28.372830+02:00 [error] <0.232.0>\\r\\n    ```\\r\\n\\r\\nBy default, all feature flags are enabled out-of-the-box when starting a brand\\r\\nnew node or cluster. So there is great chance you won\'t be affected because\\r\\nthey are probably already enabled.\\r\\n\\r\\nHowever, if you initially created your cluster using RabbitMQ 3.8.9 or older\\r\\nand you never enabled the feature flags, make sure to enable all of them before\\r\\nyou upgrade to RabbitMQ 3.11! If you are still on RabbitMQ 3.7.x or an early\\r\\n3.8.x, you may need to:\\r\\n1. upgrade to the latest 3.8.x, 3.9.x or 3.10.x first\\r\\n2. enable the feature flags\\r\\n3. upgrade to RabbitMQ 3.11.0+\\r\\n\\r\\nIf you don\'t do that, RabbitMQ 3.11.0+ will refuse to start. If this happens,\\r\\nyou will have to downgrade RabbitMQ back to the version you were using before\\r\\nswitching to 3.11.0+ and apply the same procedure as above. But RabbitMQ does\\r\\nnot support downgrades, you say! True and I\'m glad you read the docs carefully.\\r\\nThis one is a specific situation: the ability to start is verified very early\\r\\nin the process and no data structure migration was performed at that stage.\\r\\nThat\'s why, it\'s still possible to reinstall the previous package and restart\\r\\nRabbitMQ to enable the required feature flags."},{"id":"/2022/07/13/rabbitmq-3-11-feature-preview-super-streams","metadata":{"permalink":"/rabbitmq-website/blog/2022/07/13/rabbitmq-3-11-feature-preview-super-streams","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-07-13-rabbitmq-3-11-feature-preview-super-streams/index.md","source":"@site/blog/2022-07-13-rabbitmq-3-11-feature-preview-super-streams/index.md","title":"RabbitMQ 3.11 Feature Preview: Super Streams","description":"RabbitMQ 3.11 will bring a feature with one of the coolest names in its history: super streams.","date":"2022-07-13T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":5.675,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"RabbitMQ 3.11 Feature Preview: Super Streams","tags":["Streams","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Required feature flags in RabbitMQ 3.11.0","permalink":"/rabbitmq-website/blog/2022/07/20/required-feature-flags-in-rabbitmq-3.11"},"nextItem":{"title":"RabbitMQ 3.11 Feature Preview: Single Active Consumer for Streams","permalink":"/rabbitmq-website/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams"}},"content":"RabbitMQ 3.11 will bring a feature with one of the coolest names in its history: super streams.\\r\\nSuper streams are a way to scale out by partitioning a large stream into smaller streams.\\r\\nThey integrate with [single active consumer](/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams) to preserve message order within a partition. \\r\\n\\r\\nThis blog post gives an overview of super streams and the use cases they unlock.\\r\\nRead on to learn more, we value [your feedback](/contact) to make this feature the best it can be.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nA super stream is a logical stream made of individual, regular [streams](/blog/2021/07/13/rabbitmq-streams-overview#what-are-rabbitmq-streams).\\r\\nIt is a way to _scale out publishing and consuming_ with RabbitMQ Streams: a large logical stream is divided into partition streams, splitting up the storage and the traffic on several cluster nodes.\\r\\n\\r\\nA super stream remains a logical entity: applications see it as one \\"big\\" stream, thanks to the smartness of client libraries.\\r\\nThe topology of a super stream is based on the [AMQP 0.9.1 model](/tutorials/amqp-concepts), that is exchange, queues, and bindings between them.\\r\\n\\r\\nThe following figure shows an `invoices` super stream made of 3 partitions.\\r\\nIt is defined by an `invoices` exchange with 3 streams bound to it.\\r\\n\\r\\n![A super stream is a structure that sits above streams, allowing to logically group a set of streams. AMQP 0.9.1 resources define its physical topology.](super-streams-topology.png)\\r\\n\\r\\nMessages do not go through the exchange, they go directly to the partition streams.\\r\\nBut [client libraries](https://rabbitmq.github.io/rabbitmq-stream-java-client/snapshot/htmlsingle/#super-streams) use the topology information to figure out where to route messages to and where to consume them from.\\r\\n\\r\\nLet\'s talk about the elephant in the room: how does it compare to Kafka?\\r\\nWe can compare a super stream to a Kafka topic and a stream to a partition of a Kafka topic.\\r\\nA RabbitMQ stream is a first-class, individually-named object though, whereas a Kafka partition is a subordinate of a Kafka topic.\\r\\nThis explanation leaves _a lot_ of details out, there is no real 1-to-1 mapping, but it is accurate enough for our point in this post. \\r\\n\\r\\nSuper streams also leverage [single active consumer](/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams) to preserve the order of messages within a partition during the consumer processing.\\r\\nMore on this below.\\r\\n\\r\\nDon\'t get us wrong, super streams do not deprecate individual streams or make them useless.\\r\\nThey are not streams version 2.0 either, because we made streams wrong in the first place.\\r\\nSuper streams sit on top of streams, they bring their own set of features and capabilities.\\r\\nYou can keep using individual streams where they fit the bill and you can explore super streams for more demanding use cases.\\r\\n\\r\\n## Publishing To a Super Stream\\r\\n\\r\\nA message an application publishes to a super stream must go to one of the partitions.\\r\\nThe application gets to choose the partition, with some help from the client library, the broker does not handle the routing.\\r\\nThis is flexible and avoids a bottleneck on the server side.\\r\\n\\r\\nThe application must provide at least one piece of information: a routing key extracted from the message.\\r\\nThe following snippet shows how an application provides this code with the stream Java client library:\\r\\n\\r\\n```java\\r\\nProducer producer = environment.producerBuilder()\\r\\n    .superStream(\\"invoices\\") // set the super stream name\\r\\n    .routing(message -> message.getProperties().getMessageIdAsString()) // extract routing key \\r\\n    .producerBuilder()\\r\\n    .build();\\r\\n\\r\\nproducer.send(...);\\r\\n```\\r\\n\\r\\nPublishing remains the same as with a [regular stream](/blog/2021/07/19/rabbitmq-streams-first-application#publishing-to-a-stream), the producer configuration is just a bit different.\\r\\nPublishing to a stream or a super stream does not impact the code of the application much.\\r\\n\\r\\nWhere does the message go? In this case, the library chooses the stream partition by hashing the routing key using [MurmurHash3](https://en.wikipedia.org/wiki/MurmurHash).\\r\\nThis hash function provides good uniformity, performance, and portability, making it a good default choice.\\r\\nThe routing key is an invoice ID in our case, so the invoices should be spread uniformly across the partitions.\\r\\nIf the routing key was the customer ID, we would have the guarantee that all the invoices for a given customer would be on the same partition.\\r\\nHere is a use case that can take advantage of this: per-customer reporting on a given period of time with the appropriate [timestamp-based offset specification](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#specifying-an-offset).\\r\\n\\r\\nSpeaking about processing, let\'s see how to consume from a super stream.\\r\\n\\r\\n## Consuming From a Super Stream\\r\\n\\r\\nThe partitions of a super stream are regular streams, so applications could consume from them as usual.\\r\\nBut this implies knowing about the topology of the super stream, whereas we sold it as a logical entity, something applications see as an individual stream.\\r\\nFortunately, the client library can make it so, with some help from the broker, making it all transparent for applications.\\r\\n\\r\\nA client library can implement a [well-known design pattern](https://en.wikipedia.org/wiki/Composite_pattern) and provide a composite consumer that consumes from all the partitions of a super stream at the same time:\\r\\n\\r\\n![A client library provides a composite consumer that consumes from all partitions at the same time. Applications then see the super stream as an individual stream. This is not enough though.](super-streams-composite-consumer.png)\\r\\n\\r\\nThe composite consumer implemented this way has limitations: if you spin up several instances of the same application for redundancy and scalability, they will consume the same messages, duplicating the processing.\\r\\nAll this needs coordination and luckily we can apply the semantics of [single active consumer](/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams) to our super stream composite consumers.\\r\\n\\r\\nNow with single active consumer enabled, the instances of our composite consumers coordinate with the broker to make sure there is only one consumer on a given partition at a time.\\r\\n\\r\\n![Combining super stream consumers and single active consumer. There is only one active consumer on a partition at a time for a given group.](super-streams-sac.png)\\r\\n\\r\\nThe good news is that all these are implementation details.\\r\\nApplication instances can come up and down, the consumers will be activated or deactivated according to the single-active-consumer semantics.\\r\\n\\r\\nHow does it translate into code? Here is an example with the stream Java client:\\r\\n\\r\\n```java\\r\\nConsumer consumer = environment.consumerBuilder()\\r\\n    .superStream(\\"invoices\\") // set the super stream name \\r\\n    .name(\\"application-1\\") // set the consumer name (mandatory) \\r\\n    .singleActiveConsumer() // enable single active consumer\\r\\n    .messageHandler((context, message) -> {\\r\\n        // message processing\\r\\n    })\\r\\n    .build();\\r\\n```\\r\\n\\r\\nThis stays similar to a [consumer of a regular stream](/blog/2021/07/19/rabbitmq-streams-first-application#consuming-the-messages), only the configuration changes, and more importantly the message handling code remains the same.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nWe covered _super streams_ in this blog post, a new feature in the upcoming RabbitMQ 3.11 release.\\r\\nSuper streams are partitioned streams, they bring scalability to RabbitMQ Stream.\\r\\nTogether with [single active consumer](/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams), they offer the guarantee of processing messages in their publishing order within a partition.\\r\\n\\r\\nThis blog post has a [companion sample project](https://github.com/acogoluegnes/rabbitmq-stream-single-active-consumer#super-streams), that provides a step-by-step demonstration to illustrate the features covered.\\r\\nDo not hesitate to have a look at it!\\r\\n\\r\\n\\r\\nWe are excited to share this new feature with the RabbitMQ community and we can\'t wait to hear [some feedback](/contact) before RabbitMQ 3.11 goes GA later this year."},{"id":"/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams","metadata":{"permalink":"/rabbitmq-website/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-07-05-rabbitmq-3-11-feature-preview-single-active-consumer-for-streams/index.md","source":"@site/blog/2022-07-05-rabbitmq-3-11-feature-preview-single-active-consumer-for-streams/index.md","title":"RabbitMQ 3.11 Feature Preview: Single Active Consumer for Streams","description":"RabbitMQ 3.11 will bring a noteworthy feature to streams: single active consumer.","date":"2022-07-05T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":9.045,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"RabbitMQ 3.11 Feature Preview: Single Active Consumer for Streams","tags":["Streams","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.11 Feature Preview: Super Streams","permalink":"/rabbitmq-website/blog/2022/07/13/rabbitmq-3-11-feature-preview-super-streams"},"nextItem":{"title":"Improving RabbitMQ Performance with Flame Graphs","permalink":"/rabbitmq-website/blog/2022/05/31/flame-graphs"}},"content":"RabbitMQ 3.11 will bring a noteworthy feature to streams: single active consumer.\\r\\nSingle active consumer provides _exclusive consumption_ and _consumption continuity_ on a stream.\\r\\nIt is also critical to get the most out of [super streams](/blog/2022/07/13/rabbitmq-3-11-feature-preview-super-streams), our solution for partitioning, that provide scalability for streams.\\r\\n\\r\\nRead on to find out more about single active consumer for streams and don\'t hesitate to experiment with what is already available: [try it](/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams#setting-up-the-sample-project), break it, [tell us](/contact) what you like and don\'t like, what\'s missing.\\r\\nYour feedback is essential to make this feature the best it can be.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nSo, _exclusive consumption_, _consumption continuity_, what does this mean?\\r\\nImagine you want to make sure your stream processing does not stop, even though the application instances handling this processing come and go.\\r\\nYou spin up several instances of the same processing application, with the single active consumer flag enabled on your stream consumer.\\r\\nThe broker will make sure only one instance gets messages at a time: the _active_ one.\\r\\n\\r\\n![Only one instance receives messages in a group of consumers when single active consumer is enabled.](stream-sac-active-inactive.png)\\r\\n\\r\\nThe broker will automatically fall back to the instance next in line and starts dispatching messages to it when the active consumer goes away (closes or crashes).\\r\\n\\r\\n![The broker dispatches messages to the next consumer when the active one goes away.](stream-sac-fallback.png)\\r\\n\\r\\nSo with single active consumer on, you don\'t have to worry about having multiple instances doing the same processing in parallel, the broker takes care of everything.\\r\\n\\r\\nNote there can be as many single active consumer groups as you want on a given stream: applications must provide a name for a consumer and this name acts as the identifier for the group of consumers.\\r\\nThe single active consumer semantics will apply to the consumer instances sharing the same name.\\r\\n\\r\\nLet\'s go through a demo to see how single active consumer for streams works.\\r\\n\\r\\n## Single Active Consumer for Stream in Action\\r\\n\\r\\nWe are going to start 3 consumers simulating the instances of the same application.\\r\\nWe\'ll see that only one consumer instance gets activated and receives messages, the 2 other instances will remain idle.\\r\\nWe\'ll close the connection of the active consumer and see another instance takes over.\\r\\n\\r\\nWe\'ll start the 3 consumers in the same process for simplicity\'s sake.\\r\\nHere is the definition of a consumer with the stream Java client:\\r\\n\\r\\n\\r\\n```java\\r\\nSystem.out.println(\\"Starting consumer instance \\" + i);\\r\\nConsumer consumer = environment.consumerBuilder()\\r\\n    .stream(stream)\\r\\n    .name(reference)\\r\\n    .singleActiveConsumer()\\r\\n    .autoTrackingStrategy()\\r\\n        .messageCountBeforeStorage(10)\\r\\n    .builder()\\r\\n    .messageHandler((context, message) -> {\\r\\n        System.out.printf(\\r\\n            \\"Consumer instance %d received a message (%d).%n\\",\\r\\n            i, sequence.incrementAndGet()\\r\\n        );\\r\\n    })\\r\\n    .build();\\r\\n```\\r\\n\\r\\nThe code to declare a single active consumer is almost the same as for a regular consumer: you must provide a name and use `ConsumerBuilder#singleActiveConsumer()`.\\r\\nThe `i` and `sequence` variables are just there to help understand what\'s going on.\\r\\n\\r\\nIf you want to run the code as you are reading, you can move on to the next section.\\r\\nNote you can follow the remaining of the post without running anything, so you can skip the next section if you don’t want to try out the code.\\r\\n\\r\\n### Setting Up The Sample Project\\r\\n\\r\\nRunning the samples requires Docker, Git, and Java 11 or higher installed.\\r\\nRemove the Docker image if it\'s already there locally, to make sure to pull the latest image later:\\r\\n\\r\\n```shell\\r\\ndocker rmi pivotalrabbitmq/rabbitmq-stream\\r\\n```\\r\\n\\r\\nAnd then start the broker:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --name rabbitmq -p 5552:5552 -p 5672:5672 -p 15672:15672 \\\\\\r\\n   -e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\'-rabbitmq_stream advertised_host localhost\' \\\\\\r\\n   pivotalrabbitmq/rabbitmq-stream\\r\\n```\\r\\n\\r\\nThe container starts listening on several ports: 5552 for the stream plugin, 5672 for AMQP, 15672 for the HTTP management plugin.\\r\\n\\r\\nThe sample project code is [hosted on GitHub](https://github.com/acogoluegnes/rabbitmq-stream-single-active-consumer).\\r\\nClone the project locally and start the application that simulates 3 consumer instances:\\r\\n\\r\\n```shell\\r\\ncd /tmp\\r\\ngit clone https://github.com/acogoluegnes/rabbitmq-stream-single-active-consumer.git\\r\\ncd rabbitmq-stream-single-active-consumer\\r\\n```\\r\\n\\r\\nThe setup is done, let\'s start our single active consumers.\\r\\n\\r\\n### Starting The Consumers\\r\\n\\r\\nStart the consumer instances with the following command:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=com.rabbitmq.stream.SingleActiveConsumer\\r\\n```\\r\\n\\r\\nThe application confirms it registered 3 consumers:\\r\\n\\r\\n```\\r\\nCreated stream single-active-consumer\\r\\nStarting consumer instance 0\\r\\nStarting consumer instance 1\\r\\nStarting consumer instance 2\\r\\n```\\r\\n\\r\\nThese consumers would be running on separate hosts in a real system.\\r\\nBut running them in the same process is simpler for our demonstration and makes our point as well.\\r\\n\\r\\nWe are all set, let\'s publish to the stream.\\r\\n\\r\\n### Publishing Messages\\r\\n\\r\\nWe have an application running, it registered 3 identical consumers instances, with single active consumer enabled.\\r\\nWe are using the [stream performance tool](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#the-performance-tool) to publish a message every second:\\r\\n\\r\\n```shell\\r\\ncd /tmp\\r\\nwget -O stream-perf-test.jar \\\\\\r\\n  https://github.com/rabbitmq/rabbitmq-java-tools-binaries-dev/releases/download/v-stream-perf-test-latest/stream-perf-test-latest.jar\\r\\njava -jar /tmp/stream-perf-test.jar --rate 1 -x 1 -y 0 --streams single-active-consumer\\r\\n```\\r\\n\\r\\nThe performance tool starts publishing (it emits a warning about the stream creation, this is expected):\\r\\n\\r\\n```\\r\\nStarting producer\\r\\n1, published 0 msg/s, confirmed 0 msg/s, consumed 0 msg/s, latency min/median/75th/95th/99th 0/0/0/0/0 ms, chunk size 0\\r\\n2, published 1 msg/s, confirmed 1 msg/s, consumed 0 msg/s, latency min/median/75th/95th/99th 0/0/0/0/0 ms, chunk size 0\\r\\n3, published 1 msg/s, confirmed 1 msg/s, consumed 0 msg/s, latency min/median/75th/95th/99th 0/0/0/0/0 ms, chunk size 0\\r\\n4, published 1 msg/s, confirmed 1 msg/s, consumed 0 msg/s, latency min/median/75th/95th/99th 0/0/0/0/0 ms, chunk size 0\\r\\n5, published 1 msg/s, confirmed 1 msg/s, consumed 0 msg/s, latency min/median/75th/95th/99th 0/0/0/0/0 ms, chunk size 0\\r\\n...\\r\\n```\\r\\n\\r\\nThe first consumer instance gets the messages from the stream:\\r\\n\\r\\n```\\r\\nCreated stream single-active-consumer\\r\\nStarting consumer 0\\r\\nStarting consumer 1\\r\\nStarting consumer 2\\r\\nConsumer instance 0 received a message (1).\\r\\nConsumer instance 0 received a message (2).\\r\\nConsumer instance 0 received a message (3).\\r\\nConsumer instance 0 received a message (4).\\r\\n...\\r\\n```\\r\\n\\r\\nWithout single active consumer enabled, each consumer instance would get the messages in the stream and you would see 3 lines for each message.\\r\\nSo our application is working as expected, only one consumer is active.\\r\\nLet\'s see if we can learn more about our consumers...\\r\\n\\r\\n### Inspecting the Consumers\\r\\n\\r\\nThe `list_stream_consumers` CLI command lists the consumers for all streams in a virtual host:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmqctl list_stream_consumers \\\\\\r\\n  connection_pid,stream,messages_consumed,active,activity_status\\r\\n```\\r\\n\\r\\nWe see our consumers with their respective state:\\r\\n\\r\\n```\\r\\nListing stream consumers ...\\r\\n┌────────────────┬────────────────────────┬───────────────────┬────────┬─────────────────┐\\r\\n│ connection_pid │ stream                 │ messages_consumed │ active │ activity_status │\\r\\n├────────────────┼────────────────────────┼───────────────────┼────────┼─────────────────┤\\r\\n│ <11771.870.0>  │ single-active-consumer │ 259               │ true   │ single_active   │\\r\\n├────────────────┼────────────────────────┼───────────────────┼────────┼─────────────────┤\\r\\n│ <11771.882.0>  │ single-active-consumer │ 0                 │ false  │ waiting         │\\r\\n├────────────────┼────────────────────────┼───────────────────┼────────┼─────────────────┤\\r\\n│ <11771.894.0>  │ single-active-consumer │ 0                 │ false  │ waiting         │\\r\\n└────────────────┴────────────────────────┴───────────────────┴────────┴─────────────────┘\\r\\n```\\r\\n\\r\\nLet\'s imagine we have many streams, with many groups of consumers for each of them.\\r\\nA concise view of this would be welcome.\\r\\nLet\'s use the `list_stream_consumer_groups` command:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmqctl list_stream_consumer_groups stream,reference,consumers\\r\\n```\\r\\n\\r\\nOur `my-app` group shows up, with the number of consumers registered:\\r\\n\\r\\n```\\r\\nListing stream consumer groups ...\\r\\n┌────────────────────────┬───────────┬───────────┐\\r\\n│ stream                 │ reference │ consumers │\\r\\n├────────────────────────┼───────────┼───────────┤\\r\\n│ single-active-consumer │ my-app    │ 3         │\\r\\n└────────────────────────┴───────────┴───────────┘\\r\\n```\\r\\n\\r\\nWe can drill down into our group with the `list_stream_group_consumers` command:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmqctl list_stream_group_consumers --stream single-active-consumer --reference my-app\\r\\n```\\r\\n\\r\\nAnd the consumers of the group show up:\\r\\n\\r\\n```\\r\\nListing group consumers ...\\r\\n┌─────────────────┬─────────────────────────────────────┬──────────┐\\r\\n│ subscription_id │ connection_name                     │ state    │\\r\\n├─────────────────┼─────────────────────────────────────┼──────────┤\\r\\n│ 0               │ 172.17.0.1:58370 -> 172.17.0.2:5552 │ active   │\\r\\n├─────────────────┼─────────────────────────────────────┼──────────┤\\r\\n│ 0               │ 172.17.0.1:58376 -> 172.17.0.2:5552 │ inactive │\\r\\n├─────────────────┼─────────────────────────────────────┼──────────┤\\r\\n│ 0               │ 172.17.0.1:58380 -> 172.17.0.2:5552 │ inactive │\\r\\n└─────────────────┴─────────────────────────────────────┴──────────┘\\r\\n```\\r\\n\\r\\nNice, we have CLI commands to get some insight about consumers that enabled the single active consumer flag.\\r\\n\\r\\n### Looking at the Management UI\\r\\n\\r\\nWe have also something more graphical than the CLI with the [page of the stream in the management UI](http://localhost:15672/#/queues/%2F/single-active-consumer) (username/password: `guest`/`guest`):\\r\\n\\r\\n![The stream page in the management UI lists the consumers with their status.](stream-sac-stream-consumers.png)\\r\\n\\r\\nThe consumers `channel` column does not exactly show AMQP channels: our sample uses the stream protocol, where the channel concept does not exist.\\r\\nThe management UI adapts and shows the _connections_ of the consumers.\\r\\nWe can get even more details if we click on the link to the channel/connection of the active consumer:\\r\\n\\r\\n![The connection page shows details about the active consumer.](stream-sac-active-consumer-connection.png)\\r\\n\\r\\nIt\'s time to experiment with the single active consumer semantics.\\r\\n\\r\\n### Terminating the Active Consumer\\r\\n\\r\\nLet\'s close the connection of the active consumer with the `Force Close` button at the bottom of the connection page.\\r\\n\\r\\nWe see from our consuming application console output that the active consumer is gone and the next consumer took over:\\r\\n\\r\\n```\\r\\n...\\r\\nConsumer instance 0 received a message (130).\\r\\nConsumer instance 0 received a message (131).\\r\\nConsumer instance 0 received a message (132).\\r\\nConsumer instance 1 received a message (133).    <---- Instance #1 got activated\\r\\nConsumer instance 1 received a message (134).\\r\\nConsumer instance 1 received a message (135).\\r\\n...\\r\\n```\\r\\n\\r\\nThe failover worked as expected: the active consumer died and the next in line got activated.\\r\\nIn the real world, the active consumer instance could have restarted after an OS upgrade or its connection could have been closed after a network glitch.\\r\\nWe just closed the connection on purpose in this example.\\r\\n\\r\\nLet\'s list the consumers of the group to confirm our findings:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmqctl list_stream_group_consumers --stream single-active-consumer --reference my-app\\r\\n```\\r\\n\\r\\nWe still have 3 consumers, because the client library recovered the closed connection automatically:\\r\\n\\r\\n```\\r\\nListing group consumers ...\\r\\n┌─────────────────┬─────────────────────────────────────┬──────────┐\\r\\n│ subscription_id │ connection_name                     │ state    │\\r\\n├─────────────────┼─────────────────────────────────────┼──────────┤\\r\\n│ 0               │ 172.17.0.1:58376 -> 172.17.0.2:5552 │ active   │\\r\\n├─────────────────┼─────────────────────────────────────┼──────────┤\\r\\n│ 0               │ 172.17.0.1:58380 -> 172.17.0.2:5552 │ inactive │\\r\\n├─────────────────┼─────────────────────────────────────┼──────────┤\\r\\n│ 0               │ 172.17.0.1:58388 -> 172.17.0.2:5552 │ inactive │\\r\\n└─────────────────┴─────────────────────────────────────┴──────────┘\\r\\n```\\r\\n\\r\\nThe consumer from the `172.17.0.1:58376 -> 172.17.0.2:5552` connection is now the active one.\\r\\nIt was the second in line before we closed the first active consumer and it got promoted.\\r\\nThe `172.17.0.1:58388 -> 172.17.0.2:5552` connection is the connection the client library recovered, it sits now at the bottom of the list.\\r\\n\\r\\nThe demonstration is over, you can now close the running programs with `Ctrl-C`: `stream-perf-test`, the consumer, and the broker Docker container. \\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nWe covered _single active consumers for streams_ in this blog post, a new feature in the upcoming RabbitMQ 3.11 release.\\r\\nIt allows attaching several consumer instances to a stream and having only one instance active at a time.\\r\\nIf the active consumer instance goes down, the next instance will automatically take over, this way the processing goes on with as little interruption as possible.\\r\\n\\r\\nDon\'t hesitate to [run the demonstration](#setting-up-the-sample-project), the [source code is available](https://github.com/acogoluegnes/rabbitmq-stream-single-active-consumer).\\r\\nYou can also experiment on your own, the support for single active consumer in the stream Java client is [documented](https://rabbitmq.github.io/rabbitmq-stream-java-client/snapshot/htmlsingle/#single-active-consumer) and the continuously-built [Docker image is available](#setting-up-the-sample-project).\\r\\nWe are excited to share this new feature with the RabbitMQ community and we can\'t wait to hear [some feedback](/contact) before RabbitMQ 3.11 goes GA later this year.\\r\\n\\r\\nWe will follow up shortly with a blog post on another RabbitMQ 3.11 feature: [super streams](/blog/2022/07/13/rabbitmq-3-11-feature-preview-super-streams), our solution to scale out streams.\\r\\nStay tuned!"},{"id":"/2022/05/31/flame-graphs","metadata":{"permalink":"/rabbitmq-website/blog/2022/05/31/flame-graphs","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-05-31-flame-graphs/index.md","source":"@site/blog/2022-05-31-flame-graphs/index.md","title":"Improving RabbitMQ Performance with Flame Graphs","description":"Recent Erlang/OTP versions ship with Linux perf support.","date":"2022-05-31T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":15.035,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null}],"frontMatter":{"title":"Improving RabbitMQ Performance with Flame Graphs","tags":["Performance"],"authors":["dansari"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.11 Feature Preview: Single Active Consumer for Streams","permalink":"/rabbitmq-website/blog/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams"},"nextItem":{"title":"RabbitMQ 3.10 Performance Improvements","permalink":"/rabbitmq-website/blog/2022/05/16/rabbitmq-3.10-performance-improvements"}},"content":"Recent Erlang/OTP versions ship with [Linux perf](https://perf.wiki.kernel.org/index.php/Main_Page) support.\\r\\nThis blog post provides step by step instructions on how you can create CPU and memory [flame graphs](https://www.brendangregg.com/flamegraphs.html) in RabbitMQ to quickly and accurately detect performance bottlenecks.\\r\\nWe also provide examples of how flame graphs have helped us to increase message throughput in RabbitMQ.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nPrior to Erlang/OTP 24, many tools including\\r\\n[fprof](https://www.erlang.org/doc/man/fprof.html),\\r\\n[eprof](https://www.erlang.org/doc/man/eprof.html), and\\r\\n[cprof](https://www.erlang.org/doc/man/cprof.html)\\r\\nhave been available to [profile Erlang code](https://www.erlang.org/doc/efficiency_guide/profiling.html).\\r\\nHowever, none of these tools can generate call graphs with minimal overhead.\\r\\n\\r\\nErlang/OTP 24 introduces the [just-in-time (JIT) compiler](https://www.erlang.org/blog/my-otp-24-highlights/#beamasm---the-jit-compiler-for-erlang).\\r\\nInstead of interpreting code, the JIT compiler produces machine code.\\r\\nThat machine code can be instrumented by native tooling.\\r\\nSpecifically, Erlang/OTP 24 ships with Linux perf support.\\r\\nPerf can profile machine code and generate call graphs with low overhead since profiling takes place within the Linux kernel.\\r\\n\\r\\nThis is a big feature in Erlang/OTP 24 because it allows any Erlang program to efficiently and precisely detect bottlenecks in its source code.\\r\\n\\r\\nOnce a program was profiled and its call graphs generated, these stack traces can then be visualized and analysed by a variety of tools.\\r\\nThe most popular tool is flame graphs.\\r\\nFlame graphs were invented by [Brendan Gregg](https://www.brendangregg.com) in 2011.\\r\\n\\r\\nWhile it was possible to create flame graphs for profiled Erlang code many years ago, what is new is that these flame graphs can now be\\r\\ncreated with accurate call stack reporting without a noticeable slowdown of the Erlang program.\\r\\n\\r\\nIn this blog post, we demonstrate how to create CPU and memory flame graphs, explain how to interpret them, and show how they have helped us improving RabbitMQ performance.\\r\\n\\r\\n## CPU Flame Graphs\\r\\n\\r\\nIn order to profile RabbitMQ with Linux perf, we need to run RabbitMQ on a Linux operating system.\\r\\n(The commands in this blog post were run on Ubuntu 22.04 LTS.)\\r\\n\\r\\nA physical Linux box is best because more hardware counters will be present.\\r\\nHowever, a Linux virtual machine (VM) is good enough to start with.\\r\\nKeep in mind that a VM can come with some limitations.\\r\\nFor example, the [fsync](https://man7.org/linux/man-pages/man2/fdatasync.2.html) system call which is heavily used\\r\\nin RabbitMQ might be a no-op in certain virtualised environments.\\r\\n\\r\\nExecute the following steps to create our first flame graph:\\r\\n\\r\\n1. Install Erlang/OTP 25.0 (which includes [supports frame pointers in JIT](https://github.com/erlang/otp/pull/4676)).\\r\\nHere, we use [kerl](https://github.com/kerl/kerl):\\r\\n```bash\\r\\nkerl build 25.0 25.0\\r\\nkerl install 25.0 ~/kerl/25.0\\r\\nsource ~/kerl/25.0\\r\\n```\\r\\n\\r\\n2. Install Elixir. Here, we use [kiex](https://github.com/taylor/kiex):\\r\\n```bash\\r\\nkiex install 1.12.3\\r\\nkiex use 1.12.3\\r\\n```\\r\\n\\r\\n3. Clone RabbitMQ server:\\r\\n```bash\\r\\ngit clone git@github.com:rabbitmq/rabbitmq-server.git\\r\\ncd rabbitmq-server\\r\\ngit checkout v3.10.1\\r\\nmake fetch-deps\\r\\ngit -C $(pwd)/deps/seshat checkout 68f2b9d4ae7ea730cef613fd5dc4456e462da492\\r\\n```\\r\\n\\r\\n4. Since we are going to stress test RabbitMQ and we do not want RabbitMQ to artificially slow down our performance tests\\r\\nby protecting itself against overload, we increase the memory threshold to not hit [memory alarms](/docs/memory),\\r\\nand increase credit [flow control](/docs/flow-control) settings by a factor of 4 compared to their default settings.\\r\\nYou can also try out setting `credit_flow_default_credit` to `{0, 0}` which disables credit based flow control altogether.\\r\\nCreate the following [advanced.config](/docs/configure#advanced-config-file) file:\\r\\n```\\r\\n[\\r\\n {rabbit,[\\r\\n  {vm_memory_high_watermark, {absolute, 15_000_000_000}},\\r\\n  {credit_flow_default_credit, {1600, 800}}\\r\\n ]}\\r\\n].\\r\\n```\\r\\n\\r\\n5. Start RabbitMQ server. We do not enable any RabbitMQ plugins (since plugins can have a negative impact on performance, especially\\r\\nsome plugins that query statistics in scenarios with many thousand objects such as queues, exchanges, channels, etc).\\r\\nWe set Erlang emulator flags `+JPperf true` to enable support for Linux perf and\\r\\n`+S 4` to create 4 scheduler threads.\\r\\n```bash\\r\\nmake run-broker PLUGINS=\\"\\" RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\\"+JPperf true +S 4\\" \\\\\\r\\n                RABBITMQ_CONFIG_FILE=\\"advanced.config\\" TEST_TMPDIR=\\"test-rabbit\\"\\r\\n```\\r\\n\\r\\n6. In a 2nd shell window, start [RabbitMQ PerfTest](https://rabbitmq.github.io/rabbitmq-perf-test/stable/htmlsingle/).\\r\\nIn our example PerfTest creates one producer publishing with at most 2,000 unconfirmed messages in flight to a stream called `my-stream` for 60 seconds.\\r\\n\\r\\n```bash\\r\\n# Install PerfTest\\r\\nwget -O perf-test https://github.com/rabbitmq/rabbitmq-perf-test/releases/download/v2.17.0/perf-test_linux_x86_64\\r\\nchmod +x perf-test\\r\\n# Start PerfTest client generating load against RabbitMQ server\\r\\n./perf-test --queue my-stream --queue-args x-queue-type=stream --auto-delete false --flag persistent \\\\\\r\\n            --producers 1 --confirm 2000 --consumers 0 --time 60\\r\\n```\\r\\n\\r\\n7. While PerfTest is running, in a 3rd shell window, record a profile which samples CPU stack traces of the RabbitMQ server process (`--pid`)\\r\\nat 999 hertz (`--freq`) recording call-graph for both kernel space and user space (`-g`) for 30 seconds.\\r\\n```bash\\r\\n# Install perf, e.g. on Ubuntu:\\r\\n# sudo apt-get install linux-tools-common linux-tools-generic linux-tools-`uname -r`\\r\\nsudo perf record --pid $(cat \\"test-rabbit/rabbit@$(hostname --short)/rabbit@$(hostname --short).pid\\") --freq 999 -g -- sleep 30\\r\\n```\\r\\n\\r\\n8. Once the 60 seconds PerfTest run finishes in the 2nd shell window, check the results.\\r\\nOn this machine, we get a sending rate average of ~103,000 messages per second.\\r\\nThis result can be slower or faster on your machine.\\r\\n\\r\\n```bash\\r\\ntest stopped (Reached time limit)\\r\\nid: test-114336-500, sending rate avg: 103132 msg/s\\r\\nid: test-114336-500, receiving rate avg: 0 msg/s\\r\\n```\\r\\n\\r\\n9. The previous perf command outputs a file `perf.data`.\\r\\nCreate a CPU flame graph from this data as described in the Erlang [documentation](https://www.erlang.org/doc/apps/erts/beamasm#flame-graph):\\r\\n```bash\\r\\ngit clone git@github.com:brendangregg/FlameGraph.git\\r\\n# Convert perf.data (created by perf record) to trace output\\r\\nsudo perf script > out.perf\\r\\n# Collapse multiline stacks into single lines\\r\\n./FlameGraph/stackcollapse-perf.pl out.perf > out.folded\\r\\n# Merge scheduler profile data\\r\\nsed -e \'s/^[0-9]\\\\+_//\' -e \'s/^erts_\\\\([^_]\\\\+\\\\)_[0-9]\\\\+/erts_\\\\1/\' out.folded > out.folded_sched\\r\\n# Create the SVG file\\r\\n./FlameGraph/flamegraph.pl --title=\\"CPU Flame Graph\\" out.folded_sched > cpu.svg\\r\\n```\\r\\nOpening the resulting `cpu.svg` file in your browser should show you a CPU flame graph similar to the following:\\r\\n\\r\\n![Figure 1: CPU Flame Graph - RabbitMQ v3.10.1 - 1 producer publishing to a stream](flame-graph-cpu-3-10-1.png)\\r\\n\\r\\nIf you did not run above steps, click [here](flame-graph-cpu-3-10-1.svg) to open Figure 1 as SVG file in your browser.\\r\\n\\r\\nA CPU flame graph is interpreted as follow:\\r\\n* Each box is a stack frame.\\r\\n* The SVG is interactive. Try to click on a stack frame to zoom into a particular call graph.\\r\\nOn the top left of the SVG click on `Reset Zoom` to go back.\\r\\n* Colours (yellow, orange, red) have no meaning.\\r\\n* The height represents how deep the call stacks are. High \\"towers\\" can represent recursive function calls.\\r\\nMost of the time it is perfectly okay to have a certain level of recursion.\\r\\nIn above SVG click on a stack frame in the highest tower (on the left half of the graph) and you will see that\\r\\na function called `lists:foldr_1/3` causes this recursion.\\r\\n* The horizontal order of stack frames on the same level is alphabetically ordered.\\r\\nHence, the horizontal order does not represent time.\\r\\n* The most important characteristic to watch out for is the width of the boxes.\\r\\nThe width determines how often a function was on CPU.\\r\\nIn particular, look for wide stack frames at the top of the graph because they consume\\r\\ndirectly a lot of CPU cycles!\\r\\n* All Erlang functions are prefixed by the dollar sign (`$`).\\r\\n* At the top right of the flame graph, you can click on the grey `Search` icon.\\r\\nIf you enter the regular expression `^\\\\$` into the search box (meaning \\"match everything starting with the dollar sign\\"), all Erlang functions will be highlighted in purple.\\r\\n\\r\\nUnsurprisingly, the hardest part is to optimize performance based on the insights a flame graph provides.\\r\\nIn general, two strategies have proven to be successful:\\r\\n1. Run a workload which you know is problematic for RabbitMQ.\\r\\nFor example, if RabbitMQ runs slow, or eats a lot of memory for a particular client workload, run that client workload (e.g. with PerfTest),\\r\\nrecord RabbitMQ server\'s profile with Linux perf, and create a flame graph. Chances are high that the flame graph will present the bottleneck. \\r\\n2. Try to optimize performance exploratively. This is what we are going to do in this blog post.\\r\\n\\r\\nWe started PerfTest where one publisher sends messages to a stream without being aware of any performance issues.\\r\\nClicking on some stack frames and examining what functions consume CPU time, it is astonishing that function `rabbit_exchange:route/2` spends 9.5% on the CPU.\\r\\nSearch for that function in above SVG to highlight it purple, then click on the purple box to zoom in (or click [here](flame-graph-cpu-3-10-1.svg?s=rabbit_exchange%3Aroute%2F2&x=744.8&y=1397)).\\r\\nIt will show you the following image:\\r\\n\\r\\n![Figure 2: CPU Flame Graph - RabbitMQ v3.10.1 - zoomed into function rabbit_exchange:route/2](flame-graph-cpu-3-10-1-rabbit-exchange-route.png)\\r\\n\\r\\n\\r\\nExecute the following command in a shell to list RabbitMQ bindings:\\r\\n```bash\\r\\n./sbin/rabbitmqctl list_bindings --formatter=pretty_table\\r\\n\\r\\nListing bindings for vhost /...\\r\\n┌─────────────┬─────────────┬──────────────────┬──────────────────┬──────────────────────────────────────┬───────────┐\\r\\n│ source_name │ source_kind │ destination_name │ destination_kind │ routing_key                          │ arguments │\\r\\n├─────────────┼─────────────┼──────────────────┼──────────────────┼──────────────────────────────────────┼───────────┤\\r\\n│             │ exchange    │ my-stream        │ queue            │ my-stream                            │           │\\r\\n├─────────────┼─────────────┼──────────────────┼──────────────────┼──────────────────────────────────────┼───────────┤\\r\\n│ direct      │ exchange    │ my-stream        │ queue            │ f809d879-b5ad-4159-819b-b39d6b50656a │           │\\r\\n└─────────────┴─────────────┴──────────────────┴──────────────────┴──────────────────────────────────────┴───────────┘\\r\\n```\\r\\nPerfTest client created a stream (queue) `my-stream`.\\r\\nThe first binding shows that every queue is automatically bound to the default exchange (the exchange with the empty string `\\"\\"`).\\r\\nPerfTest also created a direct exchange called `direct` and bound the stream to this exchange with some random routing key.\\r\\n\\r\\nAlthough there are merely 2 bindings (routes), RabbitMQ spends a lot of CPU time (9.5%) in function `rabbit_exchange:route/2` - a function routing messages -\\r\\nand it spends 6.69% of CPU time in function [ets:select/2](https://www.erlang.org/doc/man/ets.html#select-2).\\r\\n\\r\\nWe also see in the function stack trace a wide box `db_match_compile` meaning the same [match specification](https://www.erlang.org/doc/apps/erts/match_spec.html)\\r\\ngets compiled for every message being routed.\\r\\n\\r\\nPull Request (PR) [#4606](https://github.com/rabbitmq/rabbitmq-server/pull/4606) follows\\r\\nthe [Tables and Databases efficiency guide](https://www.erlang.org/doc/efficiency_guide/tablesdatabases):\\r\\n> An Ets table is a single-key table (either a hash table or a tree ordered by the key) and is to be used as one. In other words, use the key to look up things whenever possible. \\r\\n\\r\\nThis PR adds an Mnesia index table whose table key is the Erlang tuple `{SourceExchange, RoutingKey}` so that routing destinations will be looked up by that key.\\r\\n\\r\\nIn our example, this means instead of calling `ets:select/2` which uses an expensive match specification, the routing destination `my-stream` is looked up\\r\\nusing [ets:loookup_element/3](https://www.erlang.org/doc/man/ets.html#lookup_element-3) by providing the table key `{direct, f809d879-b5ad-4159-819b-b39d6b50656a}`.\\r\\n\\r\\nStop RabbitMQ server with `Ctrl+g q` and delete its data directory:\\r\\n```bash\\r\\nrm -rf test-rabbit\\r\\n```\\r\\n\\r\\nLet us check out a commit from the `master` branch (in May 2022 at the time of writing) which includes PR #4606:\\r\\n\\r\\n```bash\\r\\ngit checkout c22e1cb20e656d211e025c417d1fc75a9067b717\\r\\n```\\r\\n\\r\\nRe-run the same scenario by repeating steps 5 - 9 above.\\r\\n\\r\\nOpen the new CPU flame graph and search for stack frame `rabbit_exchange:route/2` (or click [here](flame-graph-cpu-c22e1cb.svg?s=rabbit_exchange%3Aroute%2F2)):\\r\\n\\r\\n![Figure 3: reduced CPU usage in rabbit_exchange:route/2 on RabbitMQ master branch (May 2022)](flame-graph-cpu-c22e1cb.png)\\r\\n\\r\\nWith the new optimisation CPU usage for that function dropped from 9.5% down to only 2.5%.\\r\\n\\r\\nAs a result of this optimisation PerfTest outputs a sending rate average of ~129,000 messages per second.\\r\\nCompared to ~103,000 messages before this change this is a sending throughput improvement of 26,000 messages per second or 25% for a single publisher.\\r\\nThis speed-up applies to publishers sending via AMQP 0.9.1, AMQP 1.0, STOMP, and MQTT via a direct exchange.\\r\\n\\r\\nAs described in the PR, the end-to-end (from client to RabbitMQ server) sending throughput improvement is lower (20,000 messages per second or 15%) when sending to a classic or quorum queue (since they store messages slower than a stream)\\r\\nand the throughput improvement is higher (90,000 messages per second or 35%) when there are many bindings because after this change routing table lookup happens via a table key in constant time.\\r\\n\\r\\nTo sum up, in this section we created a CPU flame graph for a usual RabbitMQ workload.\\r\\nA CPU flame graph shows precisely what functions require CPU usage: the wider the boxes the more CPU time is required.\\r\\nJust by exploring the stack frames we were able to detect routing to be a bottleneck.\\r\\nBeing aware of this bottleneck we could subsequently speed up routing via the direct exchange type and therefore sending throughput by 15% - 35%.\\r\\n\\r\\nFurther examples of reducing CPU usage in RabbitMQ by analysing CPU flame graphs can be found in PRs\\r\\n[#4787](https://github.com/rabbitmq/rabbitmq-server/pull/4787),\\r\\n[#3934](https://github.com/rabbitmq/rabbitmq-server/pull/3934), and\\r\\n[rabbitmq/ra #272](https://github.com/rabbitmq/ra/pull/272).\\r\\n\\r\\n## Memory Flame Graphs\\r\\n\\r\\nFlame graphs visualize hierarchical data.\\r\\nIn the previous section this data represented code paths consuming CPU time.\\r\\nThis section is about data representing code paths causing memory usage.\\r\\n\\r\\nBrendan Gregg suggests different tracing approaches to analyze memory usage:\\r\\n1. Allocators such as the [malloc()](https://man7.org/linux/man-pages/man3/malloc.3.html) library function.\\r\\nThe glibc\'s `malloc()` implementation requests memory using system calls [brk()](https://man7.org/linux/man-pages/man2/brk.2.html) and [mmap()](https://man7.org/linux/man-pages/man2/mmap.2.html).\\r\\n2. `brk()` system call typically indicating memory growth.\\r\\n3. `mmap()` system call used by glibc for larger allocations. `mmap()` creates a new mapping in the virtual address space.\\r\\nUnless subsequently freed using `munmap()`, a `mmap()` flame graph may detect functions that grow or leak memory.\\r\\n4. Page faults indicating physical memory usage.\\r\\n\\r\\nNot all Erlang memory allocations can be traced by one of these approaches.\\r\\nFor example, memory that is already preallocated by the Erlang VM (at boot time) cannot be traced.\\r\\nAlso, to reduce the number of system calls, some memory segments allocated via `mmap()` are [cached](https://www.erlang.org/doc/man/erts_alloc.html#allocators) before being destroyed.\\r\\nNewly allocated segments are served from that cache and can therefore not be traced with Linux perf.\\r\\n\\r\\nIn this section we create a `mmap()` flame graph (approach 3).\\r\\n\\r\\nStop RabbitMQ server, delete its data directory, checkout tag `v3.10.1`, and start RabbitMQ server as done\\r\\nin step 5 in the previous section.\\r\\n\\r\\nIn the 2nd shell window, start PerfTest with 1 publisher sending messages to a stream for 4 minutes:\\r\\n```bash\\r\\n./perf-test --queue my-stream --queue-args x-queue-type=stream --auto-delete false --flag persistent \\\\\\r\\n            --producers 1 --consumers 0 --time 240\\r\\n```\\r\\n\\r\\nAfter the 4 minutes we see that PerfTest client published more than 32 million messages.\\r\\n\\r\\n```bash\\r\\n./sbin/rabbitmqctl list_queues name type messages --formatter=pretty_table\\r\\n\\r\\nTimeout: 60.0 seconds ...\\r\\nListing queues for vhost / ...\\r\\n┌───────────┬────────┬──────────┐\\r\\n│ name      │ type   │ messages │\\r\\n├───────────┼────────┼──────────┤\\r\\n│ my-stream │ stream │ 32748214 │\\r\\n└───────────┴────────┴──────────┘\\r\\n```\\r\\n\\r\\nStart 4 consumers each consuming these messages for 90 seconds.\\r\\n\\r\\n```bash\\r\\n./perf-test --queue my-stream --queue-args x-queue-type=stream --auto-delete false --flag persistent \\\\\\r\\n            --producers 0 --consumers 4 --qos 10000 --multi-ack-every 1000 -consumer-args x-stream-offset=first --time 90\\r\\n```\\r\\n\\r\\nWhile PerfTest is running, in the 3rd shell window, record a profile which traces `mmap()` system calls:\\r\\n```bash\\r\\nsudo perf record --pid $(cat \\"test-rabbit/rabbit@$(hostname --short)/rabbit@$(hostname --short).pid\\") \\\\\\r\\n                 --event syscalls:sys_enter_mmap -g -- sleep 60\\r\\n```\\r\\n\\r\\nAfter 90 seconds PerfTest outputs a receiving rate average of ~287,000 messages per second.\\r\\n\\r\\n```bash\\r\\ntest stopped (Reached time limit)\\r\\nid: test-102129-000, sending rate avg: 0 msg/s\\r\\nid: test-102129-000, receiving rate avg: 287086 msg/s\\r\\n```\\r\\n\\r\\nThe previous Linux perf command writes file `perf.data`.\\r\\nCreate a `mmap()` flame graph:\\r\\n```bash\\r\\nsudo perf script > out.perf\\r\\n# Collapse multiline stacks into single lines\\r\\n./FlameGraph/stackcollapse-perf.pl out.perf > out.folded\\r\\n# Merge scheduler profile data\\r\\nsed -e \'s/^[0-9]\\\\+_//\' out.folded > out.folded_sched\\r\\n# Create the SVG file\\r\\n./FlameGraph/flamegraph.pl --title=\\"mmap() Flame Graph\\" --color=mem --countname=\\"calls\\" out.folded_sched > mmap.svg\\r\\n```\\r\\nOpening the resulting `mmap.svg` file in your browser and searching for `amqp10_binary_parser` should show you a `mmap()` flame graph similar to the following:\\r\\n\\r\\n![Figure 4: mmap() Flame Graph - RabbitMQ v3.10.1 - 4 consumers reading from a stream](flame-graph-mmap-3-10-1.png)\\r\\n\\r\\nIf you did not run above steps, click [here](flame-graph-mmap-3-10-1.svg?s=amqp10_binary_parser) to open Figure 4 as SVG file in your browser.\\r\\n\\r\\nAs in CPU flame graphs, except for the purple color highlighting search matches, colors (green, blue) have no meaning in memory flame graphs.\\r\\n\\r\\nThe flame graph reveals that 10.1% of all `mmap()` system calls happen in module `amqp10_binary_parser`.\\r\\nPR [#4811](https://github.com/rabbitmq/rabbitmq-server/pull/4811) optimises the code in that module by following the\\r\\n[Matching Binaries efficiency guide](https://www.erlang.org/doc/efficiency_guide/binaryhandling.html), that is by reusing match contexts instead of creating new sub-binaries.\\r\\n\\r\\nStop RabbitMQ server. Without deleting its data directory, checkout tag `v3.10.2` which includes PR #4811.\\r\\nRepeat the previous steps by starting RabbitMQ server and consuming from the stream with 4 consumers while recording `mmap()` system calls with Linux perf.\\r\\n\\r\\nWhen PerfTest finishes after 90 seconds, this time it outputs a receiving rate average of ~407,000 messages per second.\\r\\nCompared to the 287,000 messages in v3.10.1 this is a receiving throughput improvement of ~120,000 messages per second or ~42%.\\r\\n\\r\\nCreate again a `mmap()` flame graph as done before and search for `amqp10_binary_parser`.\\r\\n\\r\\n![Figure 5: mmap() Flame Graph - RabbitMQ v3.10.2 - 4 consumers reading from a stream](flame-graph-mmap-3-10-2.png)\\r\\n\\r\\nIf you did not run above steps, click [here](flame-graph-mmap-3-10-2.svg?s=amqp10_binary_parser) to open Figure 5 as SVG file in your browser.\\r\\n\\r\\nThe binary matching optimisations decreased `mmap()` system calls of module `amqp10_binary_parser` from 10.1% in v3.10.1 to 1.3% in v3.10.2.\\r\\n\\r\\nTo sum up, in this section we created a `mmap()` memory flame graph for a usual RabbitMQ workload.\\r\\nA `mmap()` flame graph shows precisely what functions cause `mmap()` system calls: the wider the boxes the more `mmap()` system calls they trigger.\\r\\nJust by exploring the stack frames, we were able to detect AMQP 1.0 binary parsing to be a bottleneck.\\r\\nBeing aware of this bottleneck we could subsequently speed up AMQP 1.0 binary parsing and therefore receiving throughput from a stream via AMQP 0.9.1 by ~42%.\\r\\n\\r\\nAnother example of reducing `mmap()` system calls in RabbitMQ by exploring `mmap()` flame graphs can be found in PR [#4801](https://github.com/rabbitmq/rabbitmq-server/pull/4801).\\r\\n\\r\\nCreating a page fault flame graph (approach 4) works the same way as creating a `mmap()` flame graph (approach 3).\\r\\nThe only difference is to replace Linux perf flag `--event syscalls:sys_enter_mmap` with `--event page-faults`.\\r\\nAn example of how a page fault flame graph helped improve RabbitMQ performance can be found in PR [#4110](https://github.com/rabbitmq/rabbitmq-server/pull/4110) where less physical\\r\\nmemory is consumed by a new queue implementation maintaining its own queue length.\\r\\n\\r\\n## Wrapping Up\\r\\nSince Erlang/OTP 25 we can efficiently and precisely detect stack traces in RabbitMQ that consume a lot of CPU or memory by using Linux perf and creating flame graphs.\\r\\nOnce the bottlenecks are identified, we can optimise code paths and therefore improve RabbitMQ performance.\\r\\n\\r\\nDifferent client workload will cause different CPU and memory usage patterns of RabbitMQ server.\\r\\nWhether you experience RabbitMQ to run slow, suspect RabbitMQ to leak memory, or just want to speed up RabbitMQ, we encourage you to create flame graphs\\r\\nto pin down performance bottlenecks.\\r\\n\\r\\nAs opposed to one-off profiling a single RabbitMQ node as done in this blog post, we are also experimenting with continuous profiling across multiple nodes in a RabbitMQ cluster.\\r\\nIn the future, a potential way to continuously profile RabbitMQ in production is deploying RabbitMQ on Kubernetes using the [rabbitmq/cluster-operator](https://github.com/rabbitmq/cluster-operator)\\r\\nwhile profiling with [Parca Agent](https://github.com/parca-dev/parca-agent)."},{"id":"/2022/05/16/rabbitmq-3.10-performance-improvements","metadata":{"permalink":"/rabbitmq-website/blog/2022/05/16/rabbitmq-3.10-performance-improvements","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-05-16-rabbitmq-3.10-performance-improvements/index.md","source":"@site/blog/2022-05-16-rabbitmq-3.10-performance-improvements/index.md","title":"RabbitMQ 3.10 Performance Improvements","description":"RabbitMQ 3.10 was released on the 3rd of May 2022, with many new features and improvements.","date":"2022-05-16T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":11.02,"hasTruncateMarker":true,"authors":[{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null}],"frontMatter":{"title":"RabbitMQ 3.10 Performance Improvements","tags":["Performance"],"authors":["kura"]},"unlisted":false,"prevItem":{"title":"Improving RabbitMQ Performance with Flame Graphs","permalink":"/rabbitmq-website/blog/2022/05/31/flame-graphs"},"nextItem":{"title":"Rabbitmq 3.10 Release Overview","permalink":"/rabbitmq-website/blog/2022/05/05/rabbitmq-3.10-release-overview"}},"content":"RabbitMQ 3.10 was released on the 3rd of May 2022, with [many new features and improvements](/blog/2022/05/05/rabbitmq-3.10-release-overview).\\r\\nThis blog post gives an overview of the performance improvements\\r\\nin that release. Long story short, you can expect higher throughput, lower latency and faster node startups,\\r\\nespecially with large definitions files imported on startup.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nFirst, have a look at [3.10 release overview blog post](/blog/2022/05/05/rabbitmq-3.10-release-overview) for a high-level overview of what\'s new in that release.\\r\\nHere, we\'ll only focus on the performance improvements and features that have performance implications.\\r\\nSome of the improvements covered here have been backported to 3.9.x,\\r\\nso to demonstrate the difference, we will use 3.9.0 as a point of reference.\\r\\n\\r\\nIf you can\'t upgrade to 3.10 just yet, make sure you are at least running a latest 3.9.x patch release\\r\\nto take advantage of these optimizations.\\r\\n\\r\\n## RabbitMQ 3.9 vs 3.10\\r\\n\\r\\nLet\'s compare RabbitMQ 3.9 and 3.10 in a few different scenarios. Please keep in mind that these are specific benchmarks\\r\\nthat may or may not reflect the nature and performance of your workload.\\r\\n\\r\\nYou can run these or similar tests on your own using RabbitMQ load testing tools, [perf-test](https://github.com/rabbitmq/rabbitmq-perf-test)\\r\\nand [stream-perf-test](https://github.com/rabbitmq/rabbitmq-stream-java-client).\\r\\n\\r\\n### The Environment\\r\\n\\r\\nThese tests were executed using:\\r\\n\\r\\n* A GKE cluster with e2-standard-16 nodes\\r\\n* RabbitMQ clusters deployed using [our Kubernetes Operator](/kubernetes/operator/operator-overview) with the following resources and configuration\\r\\n\\r\\n```yaml\\r\\napiVersion: rabbitmq.com/v1beta1\\r\\nkind: RabbitmqCluster\\r\\nmetadata:\\r\\n  name: ...\\r\\nspec:\\r\\n  replicas: 1 # or 3\\r\\n  image: rabbitmq:3.10.1-management # or rabbitmq:3.9.0-management\\r\\n  resources:\\r\\n    requests:\\r\\n      cpu: 8\\r\\n      memory: 16Gi\\r\\n    limits:\\r\\n      cpu: 8\\r\\n      memory: 16Gi\\r\\n  persistence:\\r\\n    storageClassName: premium-rwo\\r\\n    storage: \\"3000Gi\\"\\r\\n  rabbitmq:\\r\\n    advancedConfig: |\\r\\n      [\\r\\n      {rabbit, [\\r\\n          {credit_flow_default_credit,{0,0}}\\r\\n      ]}\\r\\n      ].\\r\\n```\\r\\n\\r\\nSome notes on the environment:\\r\\n\\r\\n1. For many tests (or even production workloads), these resource settings are excessive. This, however, is the standard configuration for RabbitMQ load tests on our team.\\r\\n2. You should be able to reach higher values with better hardware, including in Google Cloud\\r\\n3. The credit flow was disabled because otherwise a single fast publisher will be throttled (to prevent overload and to give a fair chance to other publishers),\\r\\n   which is the right thing to do in a production environment but doesn\'t make sense in a server load test.\\r\\n\\r\\n### Scenario 1: One Queue, Fast Publishers and Consumers\\r\\n\\r\\nIn the first scenario, we will use just 1 queue, with 2 publishers and 2 consumers.\\r\\nWe will test with message sizes of 10, 100, 1000 and 5000 bytes.\\r\\n\\r\\nWe are using 2 publishers, because a single publisher is unable to fully utilize the queue in some configurations, especially with very small messages.\\r\\nNote that RabbitMQ 3.11 (currently in `master`) already has some [routing efficiency improvements](https://github.com/rabbitmq/rabbitmq-server/pull/4606),\\r\\nso perhaps this will not be the case for future releases.\\r\\n\\r\\nThe following [`perf-test` flags](https://rabbitmq.github.io/rabbitmq-perf-test/stable/htmlsingle/) were used in this workload:\\r\\n\\r\\n```shell\\r\\n# classic queues (with an exactly=3 mirroring policy where applicable)\\r\\nperf-test --producers 2 --consumers 2 --confirm 3000 --multi-ack-every 3000 --qos 3000 \\\\\\r\\n          --variable-size 10:900 --variable-size 100:900 --variable-size 1000:900 --variable-size 5000:900 \\\\\\r\\n          --auto-delete false --flag persistent --queue cq\\r\\n\\r\\n# quorum queues\\r\\nperf-test --producers 2 --consumers 2 --confirm 3000 --multi-ack-every 3000 --qos 3000 \\\\\\r\\n          --variable-size 10:900 --variable-size 100:900 --variable-size 1000:900 --variable-size 5000:900 \\\\\\r\\n          --quorum-queue --queue qq\\r\\n```\\r\\n\\r\\n![Scenario 1: 1 queue, 2 publishers and 2 consumers; message size of 10, 100, 1000 and 5000 bytes (15 minutes each)](single-queue-throughput.png)\\r\\n\\r\\nObservations:\\r\\n\\r\\n* quorum queues throughput is several times higher than that of classic mirrored queues (CMQs)\\r\\n* quorum queues in 3.10 can achieve even 50% higher throughput in some scenarios\\r\\n* classic queues v2 are already a bit better than v1 in some scenarios\\r\\n* CMQs do not get any new improvements and will be removed in RabbitMQ 4.0; please migrate to quorum queues, [streams](/docs/stream)\\r\\n  or non-mirrored classic queues where appropriate\\r\\n\\r\\n### Scenario 2: One Queue, 10000 msg/s\\r\\n\\r\\nIn the previous scenario, some code paths in RabbitMQ were running at or close to its maximum speed at all times.\\r\\nThis time, we\'ll set a fixed target throughput of 10000 msg/s\\r\\nand compare whether different environments can sustain this workload, as the message size increases over time.\\r\\n\\r\\nSince the expected throughput is known, we will focus on measuring latency and its variability.\\r\\n\\r\\nThe following perf-test flags were used in this scenario:\\r\\n\\r\\n```shell\\r\\n# classic queues (with an exactly=3 mirroring policy where applicable)\\r\\nperf-test --rate 10000 --confirm 3000 --multi-ack-every 3000 --qos 3000 \\\\\\r\\n          --variable-size 10:900 --variable-size 100:900 --variable-size 1000:900 --variable-size 5000:900 \\\\\\r\\n          --auto-delete false --flag persistent --queue cq\\r\\n\\r\\n# quorum queues\\r\\nperf-test --rate 10000 --confirm 3000 --multi-ack-every 3000 --qos 3000 \\\\\\r\\n          --variable-size 10:900 --variable-size 100:900 --variable-size 1000:900 --variable-size 5000:900 \\\\\\r\\n          --quorum-queue --queue qq\\r\\n```\\r\\n\\r\\nOnce again, quorum queues confidently beat classic mirrored queues (CMQs):\\r\\n\\r\\n![Scenario 2: 1 queue, 1 publisher and 1 consumer; message size of 10, 100, 1000 and 5000 bytes (15 minutes each)](one-queue-10k-all.png)\\r\\n\\r\\nLet\'s zoom in on non-mirrored classic queues to compare the v1 and v2 message store and queue index implementations.\\r\\nWe can see that CQv2 offer lower and more consistent latency:\\r\\n\\r\\n![Scenario 2: 1 queue, 1 publisher and 1 consumer; message size of 10, 100, 1000 and 5000 bytes (15 minutes each)](one-queue-10k-cq.png)\\r\\n\\r\\nSingle-node quorum queues 3.9 and 3.10 performed very similarly in this test (see the legend on the first graph).\\r\\nLet\'s focus on the 3-node clusters:\\r\\n\\r\\n![Scenario 2: 1 queue, 1 publisher and 1 consumer; message size of 10, 100, 1000 and 5000 bytes (15 minutes each)](one-queue-10k-qq.png)\\r\\n\\r\\nAs you can see, quorum queues in version 3.10 offer a significantly lower and more consistent latency. There are still spikes, due to the batching or periodic\\r\\nnature of some quorum queues operations. This is an area of improvement for future releases.\\r\\n\\r\\n### Scenario 3: 500 Queues, 5000 msg/s Total\\r\\n\\r\\nIn this scenario, we will have 500 queues, each queue with 1 publisher publishing 10 messages per second and a consumer that consumes these messages. The total expected\\r\\nthroughput is therefore 5000 messages per second. Once again, we ran this scenario for one hour, changing message size every 15 minutes (10, 100, 1000 and 5000 bytes).\\r\\n\\r\\n```shell\\r\\n# classic queues (with an exactly=3 mirroring policy where applicable)\\r\\nperf-test --producers 500 --consumers 500 --publishing-interval 0.1 --confirm 10 --multi-ack-every 100 --qos 100 \\\\\\r\\n          --variable-size 10:900 --variable-size 100:900 --variable-size 1000:900 --variable-size 5000:900 \\\\\\r\\n          --queue-pattern cq-%d --queue-pattern-from 1 --queue-pattern-to 500 \\\\\\r\\n          --auto-delete false --flag persistent\\r\\n\\r\\n# quorum queues\\r\\nperf-test --producers 500 --consumers 500 --publishing-interval 0.1 --confirm 10 --multi-ack-every 100 --qos 100 \\\\\\r\\n          --variable-size 10:900 --variable-size 100:900 --variable-size 1000:900 --variable-size 5000:900 \\\\\\r\\n          --quorum-queue --queue-pattern qq-%d --queue-pattern-from 1 --queue-pattern-to 500\\r\\n```\\r\\n\\r\\n![Scenario 3: 500 queues, 1 publisher, 1 consumer, 10 messages per queue; message size of 10, 100, 1000 and 5000 bytes (15 minutes each)](500-queues.png)\\r\\n\\r\\nObservations:\\r\\n\\r\\n1. Only CMQs struggled to sustain the expected 5000 msg/s throughput\\r\\n2. Classic queues v2 had the lowest and most consistent latency throughout the test \\r\\n3. A 3.9.0 CMQ environment had a crazy high publishing latency; I did not investigate why, simply use quorum queues or streams!\\r\\n\\r\\nSince classic queues, especially the mirrored 3.9.0 environment, dominated the graph so much,\\r\\nhere is the same graph but focused on classic queues v2 and 3.10 quorum queues:\\r\\n\\r\\n![Scenario 3: 3.10 environments only](500-queues-2.png)\\r\\n\\r\\nAs explained above, quorum queues latency is not as consistent as we would like it to be, but most of the time they stay within 25ms.\\r\\nThat\'s still with 500 queues, at 5000 msg/s total with 10/100/1000 byte messages, and not much higher with 5000-byte messages.\\r\\n\\r\\nIn the case of a 3-node quorum queue, this was a degenerate (edge case) cluster with all queue leaders\\r\\nand all connections on a single node. This was done intentionally to make test results more comparable between runs and between single-node and 3-node clusters.\\r\\n\\r\\n### Scenario 4: Long Quorum Queues\\r\\n\\r\\nPrior to 3.10, quorum queues did not perform very well when they were long -- retrieving the oldest messages for the consumers was a costly operation.\\r\\nIn this scenario we\'ll first publish 10 million messages using 2 publishers and then will consume all of them using two consumers.\\r\\n\\r\\n```shell\\r\\n# publish 10 milion messages\\r\\nperf-test --producers 2 --consumers 0 --confirm 3000 --pmessages 5000000 \\\\\\r\\n          --queue-args x-max-in-memory-length=0 --quorum-queue --queue qq\\r\\n\\r\\n# consume 10 milion messages\\r\\nperf-test --producers 0 --consumers 2 --multi-ack-every 3000 --qos 3000 --exit-when empty \\\\\\r\\n          --queue-args x-max-in-memory-length=0 --quorum-queue --queue qq\\r\\n```\\r\\n\\r\\nNote that starting with 3.10, quorum queues ignore the  `x-max-in-memory-length` property.\\r\\nIt can still be configured via a policy but will have no effect -- the queues will behave as if it was set to `0`.\\r\\n\\r\\n![Scenario 4: 10 million messages published and then consumed](long-queue.png)\\r\\n\\r\\nObservations:\\r\\n\\r\\n1. In 3.10.1, it took roughly the same time to publish and consume the messages (about 3 minutes each)\\r\\n2. 3.9.0 needed twice as much time to publish the messages (about 6 minutes)\\r\\n3. A singe node 3.9.1 needed almost 15 minutes to empty the queue and a 3-node cluster needed additional 2 minutes\\r\\n4. Both 3.9 instances started consumption at about 10000 msg/s and slowly improved over time. The consumption rate for the 3-node 3.9.0 cluster\\r\\n   increased significantly at the end, when the queue was short\\r\\n\\r\\nWorth noting are the two dips in the 3.9 publisher\'s graph (the orange line). The cluster hit a memory alarm, so the publishers were temporarily blocked.\\r\\nThis didn\'t happen to the 3.10 environment, despite 3.10 performing more work at that time (publishing and consuming faster).\\r\\n\\r\\nQuorum queues in 3.10 test used more memory on average than classic queues\\r\\nbecause they keep metadata about messages in memory, but they use less memory than they used to in 3.9.\\r\\n\\r\\nHere\'s a direct comparison between the two nodes that did most of the work (hosted all queue leaders and all connections):\\r\\n\\r\\n![Scenario 4: 10 million messages published and then consumed, memory usage](long-queue-memory.png)\\r\\n\\r\\n\\r\\n## Faster Import and Declarations\\r\\n\\r\\nFor those who [import definitions on startup](/docs/definitions), nodes should take less time to start after upgrading to 3.10.\\r\\nThere are multiple changes and features that lead to that and the expected behaviour depends on your definitions, and which features you use and will use/configure. Here\'s a summary:\\r\\n\\r\\n1. If you use `load_definitions` configuration option, and have many definitions in the JSON file, nodes should be able to start faster without you doing anything.\\r\\nThis can save minutes on every node start for users with many thousands of queues. The main difference here is that in 3.10, re-declaring an already existing entity should\\r\\nbe much quicker. Nodes in the cluster usually share the same configuration file, so each would attempt the same import but all but the first node would effectively re-import\\r\\nexisting entities. On node restarts, assuming you do not delete those entities, all nodes can boot faster.\\r\\n\\r\\n2. If you [set a new property, `definitions.skip_if_unchanged = true`](/docs/definitions#import-on-boot-skip-if-unchanged),\\r\\nRabbitMQ will skip the import altogether if the checksum of the definitions file is the same as it was when previously imported. This can save minutes\\r\\nper node for clusters with large definition files. This is similar to the previous point, except you need to opt-in (set the property) and the\\r\\nspeed-up is even higher because not attempting the import is obviously even faster than checking if the entities already exist.\\r\\n\\r\\n## Other Improvements\\r\\n\\r\\n### Erlang 25\\r\\n\\r\\nThis release supports [Erlang 25](https://www.erlang.org/blog/my-otp-25-highlights/), which introduces a number of compiler and runtime efficiency\\r\\nimprovements. This would be most visible on 64-bit ARM CPUs because the JIT in Erlang 25 now supports that architecture.\\r\\n\\r\\n### Definition Import on Boot\\r\\n\\r\\nIn clusters where nodes [import definitions on boot](/docs/definitions#import-on-boot),\\r\\nevery node in a cluster will import the same definitions in practice because all nodes use identical or almost identical configuration files.\\r\\n\\r\\nThis usually leads to one of two problems, based on the exact timing of events:\\r\\n\\r\\n  * if nodes start one by one, all queues will generally end up on a single node, since there is only one node in the cluster at the time of import\\r\\n  * if nodes start in parallel, there is a lot of contention with multiple nodes trying to declare the same definitions\\r\\n\\r\\nIn RabbitMQ 3.10, a number of re-import optimizations generally helps with the second problem.\\r\\n\\r\\nIn addition, `cluster_formation.target_cluster_size_hint` is a new setting that can now be set to tell RabbitMQ how many nodes are expected\\r\\nto be in the cluster once it is fully formed.\\r\\n\\r\\nWith this additional information, only the last node to join the cluster will import the definitions.\\r\\nThe main benefit is that quorum queues should be well balanced between the nodes (subject to leader placement settings).\\r\\nIn the past, if the import took place as soon as the first node started,\\r\\nthe other nodes would effectively start empty, since all the queues were already running when they started.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nMany improvements have been shipped in RabbitMQ 3.10 and some of them were also backported to the recent patch released of 3.9.\\r\\n\\r\\nWe are always on the lookout to make things faster. However, RabbitMQ can be configured\\r\\nand used in many different ways and many improvements are specific to the workload.\\r\\nWe would really appreciate your help -- if you wish RabbitMQ was faster in a certain scenario, please reach out and tell us about your workload.\\r\\nIdeally, if you can reproduce the problem with [perf-test](https://github.com/rabbitmq/rabbitmq-perf-test),\\r\\nwe would be happy to see what we can do to increase the throughput, lower the latency or reduce the memory usage."},{"id":"/2022/05/05/rabbitmq-3.10-release-overview","metadata":{"permalink":"/rabbitmq-website/blog/2022/05/05/rabbitmq-3.10-release-overview","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-05-05-rabbitmq-3.10-release-overview/index.md","source":"@site/blog/2022-05-05-rabbitmq-3.10-release-overview/index.md","title":"Rabbitmq 3.10 Release Overview","description":"RabbitMQ 3.10 has recently been released and has some major new features","date":"2022-05-05T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"},{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.79,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null},{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Rabbitmq 3.10 Release Overview","tags":["Updates","Announcements","New Features"],"authors":["acogoluegnes","mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.10 Performance Improvements","permalink":"/rabbitmq-website/blog/2022/05/16/rabbitmq-3.10-performance-improvements"},"nextItem":{"title":"CentOS 7 Support is Discontinued from May, 2022","permalink":"/rabbitmq-website/blog/2022/04/26/centos-7-support-discontinued"}},"content":"RabbitMQ 3.10 has recently been released and has some major new features\\r\\nwhich focus on optimizations, performance, and stability.\\r\\n\\r\\n[Release notes page](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.10.0)\\r\\nincludes information about the specific changes in this version as well as various installation assets.\\r\\nSee our [upgrade guide](/docs/upgrade) for more information about upgrading to 3.10.0.\\r\\n\\r\\nLet\'s have a tour!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Quorum Queues\\r\\n\\r\\nQuorum queues now support dead lettering with at-least-one guarantees and a long awaited feature: message TTL.\\r\\nA [separate blog post](/blog/2022/03/29/at-least-once-dead-lettering) covers these 2 aspects.\\r\\n\\r\\nQuorum queues now move messages to disk as quickly as possible.\\r\\nThis significantly reduces their memory footprint for some workloads, as well as provides more predictable throughput and latency.\\r\\n\\r\\nWe published a [detailed blog post on performance improvements in RabbitMQ 3.10](/blog/2022/05/16/rabbitmq-3.10-performance-improvements), but we can\'t help sharing a small glimpse here.\\r\\nThe following graph shows that quorum queues in RabbitMQ 3.10 provide significantly higher throughput and lower publish confirm latency than in 3.9:\\r\\n\\r\\n![Quorum queues in RabbitMQ 3.10 provide higher throughput and lower publish confirm latency than in RabbitMQ 3.9](qq-3-9-vs-3-10.png)\\r\\n\\r\\nWe encourage all users to use quorum queues instead of classic mirrored queues. Quorum queues are a better replicated and persistent queue type,\\r\\neven though previously the lack of support for message TTL could have prevented their adoption for some use cases.\\r\\nNow that quorum queues support message TTL, the following graph should convince you to always favor them over classic mirrored queues:\\r\\n\\r\\n![Quorum queues provides significantly higher throughput and lower publish confirm latency than classic mirrored queues](qq-vs-cmq.png)\\r\\n\\r\\n## Classic Queues\\r\\n\\r\\nClassic queues get new index and message store implementations, known as _CQv2_.\\r\\nWith CQv2, memory footprint of classic queues is more predictable and for most workloads, lower than with the previous version.\\r\\nAnother benefit of CQv2: consumer delivery is more efficient, potentially increasing throughput for workloads where consumers do keep up with producers.\\r\\n\\r\\nEven though we heavily tested and benchmarked CQv2, the original index and store implementations are still the default for now.\\r\\nCQv2 must be enabled explicitly via configuration (globally) or with a policy (for a specific set of queues).\\r\\nWe want CQv2 to perform optimally for most workloads and to be battle-tested before making it the default.\\r\\n\\r\\nThe following graph shows a test run with a fixed publishing rate and 3 phases where the message size start at 10 bytes,\\r\\nthen changes to 1,000 bytes, to finish at 5,000 bytes.\\r\\nCQv2 provides a lower publish confirm latency for the first phase than CQv1, and the two implementations behave comparably in the final two phases.\\r\\n\\r\\n![The new classic queue storage engine (CQv2) performs better than the original one for some workloads](cqv1-cqv2.png)\\r\\n\\r\\n## Streams\\r\\n\\r\\nStreams benefit from bug fixes and optimizations.\\r\\nThey now also support replication over TLS based on the [inter-node TLS configuration](/docs/clustering-ssl).\\r\\n\\r\\n## Scope Aliases in OAuth 2\\r\\n\\r\\n[RabbitMQ OAuth 2 plugin](https://github.com/rabbitmq/rabbitmq-server/tree/v3.10.x/deps/rabbitmq_auth_backend_oauth2) uses a convention that translates\\r\\nclient-resented JWT token scopes into a set of RabbitMQ resource permissions. This works well for many environments, however,\\r\\nin some cases JWT tokens come from an identity provider that won\'t produce scopes in this format, for technical or organizational reasons\\r\\n\\r\\nStarting with RabbitMQ 3.10, the plugin now can be configured with a map of scopes to sets of RabbitMQ permissions.\\r\\nThis allows the plugin to integrate with identity providers that use scopes as role names assigned to client identity.\\r\\nThis is done in the advanced config file:\\r\\n\\r\\n``` erlang\\r\\n{rabbitmq_auth_backend_oauth2, [\\r\\n    {resource_server_id, <<\\"rabbitmq-122\\">>},\\r\\n    {extra_scopes_source, <<\\"claims\\">>},\\r\\n    {scope_aliases, #{\\r\\n      <<\\"megacorp.roles.122\\">>      => [\\r\\n        <<\\"rabbitmq.read:vhost-122/*\\">>,\\r\\n        <<\\"rabbitmq.write:vhost-122/*\\">>,\\r\\n        <<\\"rabbitmq.configure:vhost-122/*\\">>\\r\\n      ],\\r\\n      <<\\"megacorp.roles.188\\">>     => [\\r\\n        <<\\"rabbitmq.read:vhost-188/*\\">>,\\r\\n        <<\\"rabbitmq.configure:vhost-188/*\\">>\\r\\n       ],\\r\\n      <<\\"megacorp.roles.read-only\\">> => [<<\\"rabbitmq.read:*/*\\">>]\\r\\n    }}\\r\\n    %% ...\\r\\n```\\r\\n\\r\\nIn the above example, identity provider can assign roles such as `megacorp.roles.122` or `megacorp.roles.read-only` to an identity\\r\\nand include them into JWT token scopes. The plugin will look up those \\"scope aliases\\" and append more scopes\\r\\nto the decoded token. Then they are translated into RabbitMQ permissions.\\r\\n\\r\\n## Miscellaneous\\r\\n\\r\\nRabbitMQ 3.10 comes with bug fixes and improvements in its core, but also in several plugins, like the Prometheus, MQTT,\\r\\nShovel, and Consul Peer Discovery plugins.\\r\\n\\r\\nIt is also the first release to introduce support for Erlang 25 (at RC stage at the time of writing).\\r\\n\\r\\n## Last Words\\r\\n\\r\\nWe would like to thank all contributors to this release.\\r\\n\\r\\nA couple of last recommendations before you [install](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.10.0)\\r\\nor [upgrade](/docs/upgrade) to RabbitMQ 3.10:\\r\\n\\r\\n* Use Erlang 24 or more for [the best performance](/blog/2021/03/23/erlang-24-support-roadmap)\\r\\n* Be aware of the [removal of some deprecated capabilities](/blog/2021/08/21/4.0-deprecation-announcements) in RabbitMQ 4.0\\r\\n\\r\\nWe value our feedback: you can [discuss](https://github.com/rabbitmq/rabbitmq-server/discussions) on GitHub, ask questions\\r\\non the [mailing list](https://groups.google.com/g/rabbitmq-users) or [RabbitMQ Community Slack](https://rabbitmq-slack.herokuapp.com),\\r\\nand report actionable [issues](https://github.com/rabbitmq/rabbitmq-server/issues) you run into."},{"id":"/2022/04/26/centos-7-support-discontinued","metadata":{"permalink":"/rabbitmq-website/blog/2022/04/26/centos-7-support-discontinued","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-04-26-centos-7-support-discontinued/index.md","source":"@site/blog/2022-04-26-centos-7-support-discontinued/index.md","title":"CentOS 7 Support is Discontinued from May, 2022","description":"RabbitMQ RPM packages for CentOS 7 will be discontinued from May 2022 because","date":"2022-04-26T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.37,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"CentOS 7 Support is Discontinued from May, 2022","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Rabbitmq 3.10 Release Overview","permalink":"/rabbitmq-website/blog/2022/05/05/rabbitmq-3.10-release-overview"},"nextItem":{"title":"At-Least-Once Dead Lettering","permalink":"/rabbitmq-website/blog/2022/03/29/at-least-once-dead-lettering"}},"content":"RabbitMQ RPM packages for CentOS 7 will be discontinued from May 2022 because\\r\\nthat CentOS release series provides outdated versions of OpenSSL and Linux kernel.\\r\\n\\r\\nCentOS 7 users are recommended to migrate to a new cluster which uses a more recent distribution\\r\\nvia one of the options:\\r\\n\\r\\n * [In-place Upgrades](/docs/upgrade#rolling-upgrade)\\r\\n * [definition transfer](/docs/definitions)\\r\\n * [Blue-Green Deployment upgrade](/docs/upgrade#blue-green-deployment).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nFrom the 1st of May 2022, RabbitMQ will discontinue support for CentOS 7.\\r\\nGoing forward, RabbitMQ RPM packages will support modern RPM-based distributions only, distributions such as: [Fedora](https://getfedora.org/), [Rocky Linux](https://rockylinux.org/), [CentOS Stream 8](https://www.centos.org/centos-stream/),\\r\\nand [Centos Stream 9](https://centos.org/stream9/) (when it goes GA).\\r\\n\\r\\n## The Reasons Why CentOS 7 is Being Discontinued\\r\\n\\r\\n * CentOS 7 still runs version 1.0 of OpenSSL. RabbitMQ requires 23.x and 24.x Erlang/OTP versions which in turn\\r\\n   require OpenSSL 1.1 at a minimum for modern cryptography support in Erlang. With CentOS 7 still running on\\r\\n   OpenSSL 1.0, this is one  of the reasons RabbitMQ needs to discontinue its use.\\r\\n * CentOS 7 still runs version 3.x of the Linux kernel (a later version of the Linux kernel is needed).\\r\\n * There are many advances in OpenSSL version 1.1 compared to OpenSSL version 1.0 (which CentOS 7 still runs on).\\r\\n   As a result, many projects including Erlang/OTP now require OpenSSL version 1.1.\\r\\n\\r\\n\\r\\n## What is Changing?\\r\\n\\r\\n * The upcoming [RabbitMQ 3.10](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.10.0-rc.4) release will not include packages for CentOS 7.\\r\\n * Any new patch releases of RabbitMQ 3.9 starting with 3.9.17 and of RabbitMQ 3.8 starting with 3.8.31 will not include packages for CentOS 7.\\r\\n   Learn more about [RabbitMQ release series](/release-information) in RabbitMQ documentation.\\r\\n * [Erlang RPM packages](https://github.com/rabbitmq/erlang-rpm) of Erlang 24.3 produced by our team\\r\\n    now provide packages compatible with [Fedora](https://getfedora.org/), [Rocky Linux](https://rockylinux.org/), [CentOS Stream 8](https://www.centos.org/centos-stream/),\\r\\n    and [Centos Stream 9](https://centos.org/stream9/).\\r\\n\\r\\n## What is not Changing?\\r\\n\\r\\n * Previously published RabbitMQ releases that currently include RPM packages for CentOS 7 can still be used.\\r\\n * [Erlang RPM packages](https://github.com/rabbitmq/erlang-rpm) of Erlang 23.3 releases can still be used.\\r\\n\\r\\n\\r\\n## The Actions You Must Complete\\r\\n\\r\\nTo use RabbitMQ 3.10 version onwards with a Red Hat family operating system, you must migrate your RabbitMQ deployments\\r\\nto one of: Fedora, Rocky Linux, Red Hat Linux 8.5, CentOS Stream 8, or CentOS Stream 9. The [ELevate project](https://almalinux.org/elevate)\\r\\nis an emerging tool that makes it easier to migrate from CentOS 7 to a more modern Red Hat Linux family distribution.\\r\\n\\r\\nOperating system migrations can be completed in several ways:\\r\\n\\r\\n * [In-place Upgrades](/docs/upgrade#rolling-upgrade)\\r\\n * Creation of a new cluster and [schema transfer](/docs/definitions) from the original one\\r\\n * [Blue-Green Deployment Upgrades](/docs/upgrade#blue-green-deployment)\\r\\n\\r\\nNote: If you want to or it is a requirement that you need to upgrade the OS, the kernel, Erlang/OTP, and RabbitMQ at the same time,\\r\\nthen it is highly recommended that you upgrade by either creating a new cluster and [transferring the schema](/docs/definitions)\\r\\nto it or by completing the [Blue/Green deployment upgrade](/docs/blue-green-upgrade) process."},{"id":"/2022/03/29/at-least-once-dead-lettering","metadata":{"permalink":"/rabbitmq-website/blog/2022/03/29/at-least-once-dead-lettering","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-03-29-at-least-once-dead-lettering/index.md","source":"@site/blog/2022-03-29-at-least-once-dead-lettering/index.md","title":"At-Least-Once Dead Lettering","description":"Quorum queues in RabbitMQ 3.10 provide a safer form of dead lettering that uses at-least-once guarantees for the message transfer between queues.","date":"2022-03-29T00:00:00.000Z","tags":[{"inline":true,"label":"Resiliency","permalink":"/rabbitmq-website/blog/tags/resiliency"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":19.925,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null},{"name":"Karl Nilsson","url":"https://github.com/kjnilsson","socials":{"github":"https://github.com/kjnilsson","linkedin":"https://www.linkedin.com/in/kjnils/","bluesky":"https://bsky.app/profile/kjnilsson.bsky.social"},"imageURL":"https://github.com/kjnilsson.png","key":"nkarl","page":null}],"frontMatter":{"title":"At-Least-Once Dead Lettering","tags":["Resiliency","New Features"],"authors":["dansari","nkarl"]},"unlisted":false,"prevItem":{"title":"CentOS 7 Support is Discontinued from May, 2022","permalink":"/rabbitmq-website/blog/2022/04/26/centos-7-support-discontinued"},"nextItem":{"title":"RabbitMQ 3.10.0 release calendar","permalink":"/rabbitmq-website/blog/2022/03/24/rabbitmq-3.10.0-release-calendar"}},"content":"Quorum queues in [RabbitMQ 3.10](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.10.0) provide a safer form of dead lettering that uses at-least-once guarantees for the message transfer between queues.\\r\\nThis blog post explains everything you need to know to start using at-least-once dead lettering.\\r\\n\\r\\nThis post also introduces two other [RabbitMQ 3.10](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.10.0) features: message Time-To-Live (TTL) for quorum queues and Prometheus metrics for dead lettered messages.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Overview\\r\\n\\r\\nSome messages stored in RabbitMQ queues will expire or be negatively acknowledged by consumers.\\r\\nInstead of silently dropping them, RabbitMQ can be configured to [\\"dead letter\\"](/docs/dlx#overview) them instead,\\r\\nthat is to republish those messages to a special-purpose exchange.\\r\\n\\r\\nPrior to RabbitMQ 3.10 dead lettering has not been [safe](/docs/dlx#safety).\\r\\nMessages that get dead lettered from a queue (the \\"source queue\\") are not guaranteed to be delivered to the queues routed to by the\\r\\nexchange configured in the `dead-letter-exchange` policy (henceforth the \\"target queues\\").\\r\\n\\r\\nThis is because messages are dead lettered without publisher confirms turned on internally.\\r\\nWe call it the \\"at-most-once\\" dead letter strategy.\\r\\nDead lettered messages may arrive at the target queues.\\r\\nThey may also get lost for a variety of reasons:\\r\\n\\r\\n* The target queue is unavailable. For example, a classic queue\'s host node is down or being upgraded or a quorum queue loses a majority of its nodes temporarily.\\r\\n* The target queue\'s [length limit](/docs/maxlength) is reached while its [overflow behaviour](/docs/maxlength#overflow-behaviour)\\r\\nis set to `reject-publish` rejecting any incoming messages.\\r\\n* A network partition prevents communication between source queue and target queue.\\r\\n* The dead letter routing topology is not configured correctly. For example, the configured `dead-letter-exchange` does not exist or no target queue is bound\\r\\nto the `dead-letter-exchange`.\\r\\n\\r\\nRabbitMQ 3.10 introduces a new feature called [\\"at-least-once\\" dead lettering](/docs/quorum-queues#dead-lettering).\\r\\nIt is an opt-in feature available for source queues being quorum queues.\\r\\nThis new feature ensures that all messages dead lettered in the source quorum queue will arrive at the target queues (classic queue, quorum queue, or stream) eventually\\r\\neven in the scenarios described above where messages would have been lost with the \\"at-most-once\\" strategy.\\r\\n\\r\\nThis blog post covers instructions how to enable at-least-once dead lettering, provides a detailed example, and describes caveats and best practices of this new feature.\\r\\n\\r\\n## Usage\\r\\n\\r\\nTo enable `at-least-once` dead-lettering for a source quorum queue, we need to apply the following policies\\r\\n(or their equivalent queue arguments starting with `x-`):\\r\\n\\r\\n* `dead-letter-strategy` is set to `at-least-once`. The default is `at-most-once`.\\r\\n* `overflow` is set to `reject-publish`. The default is `drop-head`.\\r\\n* `dead-letter-exchange` is configured.\\r\\n\\r\\nFurthermore, the [feature flag](/docs/feature-flags) `stream_queue` must be enabled. By default that feature flag is enabled for RabbitMQ clusters created since 3.9.\\r\\nEven though streams are not used in at-least-once dead lettering (unless a target queue happens to be a stream) the `stream_queue` feature flag is required because\\r\\nat-least-once dead lettering relies on some implementation details that come with that feature flag.\\r\\n\\r\\n## Example\\r\\n\\r\\nFollowing this example requires [kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl) client to be installed and pointing against any running Kubernetes cluster v1.19 or newer.\\r\\n\\r\\nIf you do not have a Kubernetes cluster available, the quickest way is to install [kind](https://kubernetes.io/docs/tasks/tools/#kind) to start a local Kubernetes cluster in Docker:\\r\\n```zsh\\r\\n> kind create cluster\\r\\n```\\r\\n\\r\\nInstall the [rabbitmq/cluster-operator](https://github.com/rabbitmq/cluster-operator):\\r\\n```zsh\\r\\n> kubectl apply -f https://github.com/rabbitmq/cluster-operator/releases/latest/download/cluster-operator.yml\\r\\n```\\r\\n\\r\\nDeploy a 3-node RabbitMQ cluster:\\r\\n```zsh\\r\\n> cat <<EOF | kubectl apply -f -\\r\\n---\\r\\napiVersion: rabbitmq.com/v1beta1\\r\\nkind: RabbitmqCluster\\r\\nmetadata:\\r\\n  name: my-rabbit\\r\\nspec:\\r\\n  replicas: 3\\r\\n  image: rabbitmq:3.10.0-management\\r\\nEOF\\r\\n```\\r\\n\\r\\nOnce all 3 pods are ready (which takes less than 1 minute), we create a source queue and a target queue:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqadmin declare queue name=my-source-queue \\\\\\r\\n    durable=true queue_type=quorum arguments=\'{\\"x-dead-letter-exchange\\" : \\"\\",\\r\\n    \\"x-dead-letter-routing-key\\" : \\"my-target-queue\\" , \\"x-overflow\\" : \\"reject-publish\\"}\'\\r\\n\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqadmin declare queue name=my-target-queue \\\\\\r\\n    durable=true queue_type=classic\\r\\n```\\r\\n\\r\\nThe last two commands declare a queue by executing the `rabbitmqadmin` command in the RabbitMQ container of pod `my-rabbit-server-0`.\\r\\n\\r\\nThe `rabbitmqadmin` command is a Python script that talks against the RabbitMQ Management API.\\r\\nThe `rabbitmqadmin` command is not the recommended way to declare queues and to send messages.\\r\\nWe use it in this blog post since it is the simplest way for you to follow the examples.\\r\\n\\r\\nThe rabbitmq/cluster-operator creates pod names in the format `<rabbitmq-cluster-name>-server-<index>`.\\r\\nIn the YAML above, we defined `<rabbitmq-cluster-name>` to be `my-rabbit`.\\r\\n\\r\\nThe first command creates the source queue. For at-least-once dead lettering to work it must be of `queue_type=quorum`.\\r\\nFor the source queue, we define further queue arguments (starting with `x-`) encoded in JSON format:\\r\\n\\r\\n* `x-dead-letter-exchange` set to the empty string (`\\"\\"`) means that messages dead lettered by the source queue are published to the default exchange.\\r\\n(While we could have created a new dead letter exchange, dead-lettering to the default exchange keeps this example simpler.)\\r\\n* `x-dead-letter-routing-key` set to `my-target-queue` means that dead lettered messages will be published with routing\\r\\nkey `my-target-queue`. Since this routing key matches the queue name of the target queue (created by the 2nd command), dead letter messages\\r\\nwill be routed by the default exchange to the target queue without the need to create any further bindings.\\r\\n* As stated above `x-overflow` must be set to `reject-publish` as a prerequisite for at-least-once dead lettering.\\r\\n\\r\\nThe second command creates the target queue. It can be of any queue type. In this example we choose a classic queue.\\r\\nNote that compared to the source quorum queue having 3 replicas on all 3 nodes, the target classic queue is not highly available\\r\\nand resides on a single node.\\r\\n\\r\\nLet us publish our first message `msg1`:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqadmin publish exchange=amq.default routing_key=my-source-queue \\\\\\r\\n    payload=msg1 properties=\'{\\"expiration\\" : \\"1000\\", \\"delivery_mode\\" : 2}\'\\r\\n```\\r\\n\\r\\nThis command demonstrates another new feature of RabbitMQ 3.10: [Message TTL](/docs/ttl) is supported for quorum queues.\\r\\nThe following figure illustrates how the message flows:\\r\\n\\r\\n1. We publish one message to the default exchange.\\r\\n1. It gets routed to the source quorum queue where it expires after 1 second (1000 milliseconds).\\r\\n1. The expiration causes the message to be dead lettered to the default exchange.\\r\\n1. It gets routed to the target classic queue.\\r\\n\\r\\n<!--diagrams: https://drive.google.com/drive/folders/1V-VuvO6jeL3dqHBiGZq3uCErc-vOeH49?usp=sharing -->\\r\\n![Figure 1: Dead letter routing topology (at-most-once)](at-least-once-dead-lettering.svg)\\r\\n\\r\\nNote that we set the `delivery_mode` to the integer `2` which denotes that the message is persisted.\\r\\nThat flag does not matter when publishing the message to the source quorum queue initially because all messages in quorum queues\\r\\nare written to disk anyway. However, that persistence flag becomes important once the message will be dead lettered\\r\\nto a target queue (which may not be a quorum queue).\\r\\n\\r\\nWe can validate that the message arrived in the target queue:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqctl list_queues --formatter=pretty_table --quiet \\\\\\r\\n    name type messages messages_ready messages_unacknowledged\\r\\n\\r\\n┌─────────────────┬─────────┬──────────┬────────────────┬─────────────────────────┐\\r\\n│ name            │ type    │ messages │ messages_ready │ messages_unacknowledged │\\r\\n├─────────────────┼─────────┼──────────┼────────────────┼─────────────────────────┤\\r\\n│ my-target-queue │ classic │ 1        │ 1              │ 0                       │\\r\\n├─────────────────┼─────────┼──────────┼────────────────┼─────────────────────────┤\\r\\n│ my-source-queue │ quorum  │ 0        │ 0              │ 0                       │\\r\\n└─────────────────┴─────────┴──────────┴────────────────┴─────────────────────────┘\\r\\n```\\r\\n\\r\\nNext, let us try out what happens when the target queue becomes unavailable.\\r\\nOne way to determine the host node of the target classic queue is listing the queue\'s process identifier (PID):\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqctl list_queues --quiet name pid\\r\\n\\r\\nname\\tpid\\r\\nmy-target-queue\\t<rabbit@my-rabbit-server-0.my-rabbit-nodes.default.1646297039.856.0>\\r\\nmy-source-queue\\t<rabbit@my-rabbit-server-0.my-rabbit-nodes.default.1646297039.821.0>\\r\\n```\\r\\n\\r\\nThe PID shows that both the target classic queue process and the source quorum queue leader process\\r\\nreside in pod `my-rabbit-server-0`.\\r\\nLet us stop that RabbitMQ server:\\r\\n\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqctl stop_app\\r\\n\\r\\nStopping rabbit application on node rabbit@my-rabbit-server-0.my-rabbit-nodes.default ...\\r\\n```\\r\\n\\r\\nThe source quorum queue will still be available because a majority of nodes (2 out of 3) are available and another node becomes the new leader.\\r\\n\\r\\nAs before we again send a message to the source queue and let it expire after 1 second.\\r\\nSince the RabbitMQ node in pod `my-rabbit-server-0` is down, we execute the following commands\\r\\nin `my-rabbit-server-1`:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-1 -c rabbitmq -- rabbitmqadmin publish exchange=amq.default routing_key=my-source-queue \\\\\\r\\n    payload=msg2 properties=\'{\\"expiration\\" : \\"1000\\", \\"delivery_mode\\" : 2}\'\\r\\n```\\r\\n\\r\\nSince the target queue is down, it will not report its statistics:\\r\\n```zsh\\r\\n>  kubectl exec my-rabbit-server-1 -c rabbitmq -- rabbitmqctl list_queues --formatter=pretty_table --quiet \\\\\\r\\n    name type messages messages_ready messages_unacknowledged state\\r\\n\\r\\n┌─────────────────┬──────────────────────┬──────────┬────────────────┬─────────────────────────┬─────────┐\\r\\n│ name            │ type                 │ messages │ messages_ready │ messages_unacknowledged │ state   │\\r\\n├─────────────────┼──────────────────────┼──────────┼────────────────┼─────────────────────────┼─────────┤\\r\\n│ my-target-queue │ rabbit_classic_queue │          │                │                         │ down    │\\r\\n├─────────────────┼──────────────────────┼──────────┼────────────────┼─────────────────────────┼─────────┤\\r\\n│ my-source-queue │ quorum               │ 0        │ 0              │ 0                       │ running │\\r\\n└─────────────────┴──────────────────────┴──────────┴────────────────┴─────────────────────────┴─────────┘\\r\\n```\\r\\nHowever, because the target queue is down and because the source queue does not contain any messages we know that the second message\\r\\ngot lost while it was dead lettered!\\r\\n\\r\\nSince we did not yet define `dead-letter-strategy` to be `at-least-once` when declaring the source queue above,\\r\\nthe source queue uses the default strategy `at-most-once`.\\r\\nWe can do better. In this example, we switch the dead letter strategy dynamically to `at-least-once` by applying a policy:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-1 -c rabbitmq -- rabbitmqctl set_policy --apply-to queues \\\\\\r\\n    my-policy my-source-queue \'{\\"dead-letter-strategy\\" : \\"at-least-once\\"}\'\\r\\n\\r\\nSetting policy \\"my-policy\\" for pattern \\"my-source-queue\\" to \\"{\\"dead-letter-strategy\\" : \\"at-least-once\\"}\\"\\r\\nwith priority \\"0\\" for vhost \\"/\\" ...\\r\\n```\\r\\n\\r\\nLet us send a third message:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-1 -c rabbitmq -- rabbitmqadmin publish exchange=amq.default routing_key=my-source-queue \\\\\\r\\n    payload=msg3 properties=\'{\\"expiration\\" : \\"1000\\", \\"delivery_mode\\" : 2}\'\\r\\n```\\r\\n\\r\\nWith the new `at-least-once` strategy when the 3rd message expires and gets dead lettered, it will be stored\\r\\nby the source queue since the target queue is not available:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-1 -c rabbitmq -- rabbitmqctl list_queues --formatter=pretty_table --quiet \\\\\\r\\n    name type messages messages_ready messages_unacknowledged state\\r\\n\\r\\n┌─────────────────┬──────────────────────┬──────────┬────────────────┬─────────────────────────┬─────────┐\\r\\n│ name            │ type                 │ messages │ messages_ready │ messages_unacknowledged │ state   │\\r\\n├─────────────────┼──────────────────────┼──────────┼────────────────┼─────────────────────────┼─────────┤\\r\\n│ my-target-queue │ rabbit_classic_queue │          │                │                         │ down    │\\r\\n├─────────────────┼──────────────────────┼──────────┼────────────────┼─────────────────────────┼─────────┤\\r\\n│ my-source-queue │ quorum               │ 1        │ 0              │ 0                       │ running │\\r\\n└─────────────────┴──────────────────────┴──────────┴────────────────┴─────────────────────────┴─────────┘\\r\\n```\\r\\n\\r\\nThe message is neither \\"ready\\" (i.e. available for normal queue consumers) nor \\"unacknowledged\\" (i.e. consumed by normal queue consumers but not yet acknowledged).\\r\\nHowever, the message is kept safely in the source quorum queue in a separate data structure that is only available for consumption\\r\\nby a special RabbitMQ internal dead letter consumer process.\\r\\n\\r\\nLet us output the logs of that dead letter consumer process.\\r\\nThe dead letter consumer process is co-located on the quorum queue leader node.\\r\\nWe first need figure out which node became the new leader:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-1 -c rabbitmq -- rabbitmqctl list_queues --formatter=pretty_table --quiet name leader\\r\\n┌─────────────────┬───────────────────────────────────────────────────┐\\r\\n│ name            │ leader                                            │\\r\\n├─────────────────┼───────────────────────────────────────────────────┤\\r\\n│ my-target-queue │                                                   │\\r\\n├─────────────────┼───────────────────────────────────────────────────┤\\r\\n│ my-source-queue │ rabbit@my-rabbit-server-1.my-rabbit-nodes.default │\\r\\n└─────────────────┴───────────────────────────────────────────────────┘\\r\\n```\\r\\nIn our example the new leader happens to be on pod `my-rabbit-server-1`.\\r\\nWhen you run this example, it could also be `my-rabbit-server-2` in which case you will need replace `1` with `2` in below commands.\\r\\n\\r\\nThe log displays a descriptive warning message:\\r\\n```\\r\\n> kubectl logs my-rabbit-server-1 -c rabbitmq | grep dead-letter\\r\\n\\r\\n[warn] <0.4156.0> Cannot forward any dead-letter messages from source quorum queue \'my-source-queue\'\\r\\nin vhost \'/\' with configured dead-letter-exchange exchange \'\' in vhost \'/\' and configured\\r\\ndead-letter-routing-key \'my-target-queue\'. This can happen either if the dead-letter routing topology is misconfigured\\r\\n(for example no queue bound to dead-letter-exchange or wrong dead-letter-routing-key configured)\\r\\nor if non-mirrored classic queues are bound whose host node is down.\\r\\nFix this issue to prevent dead-lettered messages from piling up in the source quorum queue.\\r\\nThis message will not be logged again.\\r\\n```\\r\\n\\r\\nWe fix this issue by restarting the target classic queue\'s host node:\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqctl start_app\\r\\n\\r\\nStarting node rabbit@my-rabbit-server-0.my-rabbit-nodes.default ...\\r\\n```\\r\\n\\r\\nThe internal dead letter consumer process retries to send the message periodically.\\r\\nThe current default retry interval is 3 minutes.\\r\\nAfter no later than 3 minutes the 3rd message should have made it to the target queue:\\r\\n\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqctl list_queues --formatter=pretty_table --quiet \\\\\\r\\n    name type messages messages_ready messages_unacknowledged state\\r\\n\\r\\n┌─────────────────┬─────────┬──────────┬────────────────┬─────────────────────────┬─────────┐\\r\\n│ name            │ type    │ messages │ messages_ready │ messages_unacknowledged │ state   │\\r\\n├─────────────────┼─────────┼──────────┼────────────────┼─────────────────────────┼─────────┤\\r\\n│ my-source-queue │ quorum  │ 0        │ 0              │ 0                       │ running │\\r\\n├─────────────────┼─────────┼──────────┼────────────────┼─────────────────────────┼─────────┤\\r\\n│ my-target-queue │ classic │ 2        │ 2              │ 0                       │ running │\\r\\n└─────────────────┴─────────┴──────────┴────────────────┴─────────────────────────┴─────────┘\\r\\n```\\r\\n\\r\\nOur understanding is that the 1st and 3rd message are in the target queue but that the 2nd message got lost\\r\\nbecause it used `at-most-once` dead lettering while the target queue was down:\\r\\n\\r\\n```zsh\\r\\n> kubectl exec my-rabbit-server-0 -c rabbitmq -- rabbitmqadmin get queue=my-target-queue count=2\\r\\n+-----------------+----------+---------------+---------+---------------+------------------+-------------+\\r\\n|   routing_key   | exchange | message_count | payload | payload_bytes | payload_encoding | redelivered |\\r\\n+-----------------+----------+---------------+---------+---------------+------------------+-------------+\\r\\n| my-target-queue |          | 1             | msg1    | 4             | string           | False       |\\r\\n| my-target-queue |          | 0             | msg3    | 4             | string           | False       |\\r\\n+-----------------+----------+---------------+---------+---------------+------------------+-------------+\\r\\n```\\r\\n\\r\\nThe `payload` column validates that our understanding is correct and that `at-least-once` dead lettering works as expected.\\r\\nEven though the target queue was unavailable, the dead letter message made it to the target queue once it became available again.\\r\\nThe 1st message is still stored in the target queue because we published to the source quorum queue setting the persistence flag.\\r\\nIf we did not set the persistence flag, the 1st message would have been lost as well.\\r\\n\\r\\nThe following figure summarises the flow of the 3rd message.\\r\\n\\r\\n![Figure 2: Dead letter routing topology (at-least-once)](at-least-once-dead-lettering-worker.svg)\\r\\n\\r\\n1. The message is published to the default exchange.\\r\\n1. The message is routed to the source quorum queue. A quorum queue is a replicated state machine in the Raft consensus algorithm.\\r\\nA quorum queue\'s state consists of more than a queue data structure where messages from publishers are enqueued:\\r\\nThe state also includes data about publishers, consumers as well as messages sent to (but not yet acknowledged by) consumers, and some other statistics.\\r\\n`At-least-once` dead lettering adds yet another queue data structure to the quorum queue\'s state: a queue that contains only dead lettered messages.\\r\\nSo when the message expires after 1 second it is moved from the \\"normal\\" message queue to the dead letter message queue.\\r\\nThe message remains safely stored there until it gets acknowledged by step 7.\\r\\n1. There is one (RabbitMQ internal) dead letter consumer process co-located on the node of the quorum queue leader.\\r\\nIts job is to consume messages from a single source quorum queue\'s dead letter message queue, forward them to all target queues,\\r\\nwaiting until **all** publisher confirmations are received (step 6) and finally acknowledge the dead lettered message\\r\\nback to the source quorum queue (step 7).\\r\\n1. The dead letter consumer routes dead lettered messages via the configured `dead-letter-exchange`. In our example, we configured the default exchange\\r\\nto be the dead letter exchange. If a route does not exist, the dead letter consumer will try to route again after some time.\\r\\n1. If a route exists the message is sent to the target queue.\\r\\n1. The target queue sends a publisher confirmation back to the dead letter consumer.\\r\\n1. The dead letter consumer sends a consumer acknowledgement back to the source quorum queue where the dead lettered message will be deleted.\\r\\n\\r\\n### Prometheus metrics\\r\\n\\r\\nRabbitMQ 3.10 comes with another new feature: Prometheus metrics for dead lettered messages.\\r\\nNode-global counters will return the number of messages that get dead lettered broken down by the following dimensions:\\r\\n\\r\\n1. dead letter reason:\\r\\n    * `expired`: Message TTL exceeded (as in our example).\\r\\n    * `rejected`: Consumer sent `basic.reject` or `basic.nack` without requeue option.\\r\\n    * `maxlen`: Queue length exceeded with `overflow` set to `drop-head` or `reject-publish-dlx`. (The latter setting applies only to classic queues.)\\r\\n    * `delivery_limit`: Delivery limit exceeded. (Applies only to quorum queues). Message got requeued too often,\\r\\nfor example because consumer sent `basic.reject` or `basic.nack` with requeue option or consumer got disconnected from the quorum queue leader.\\r\\n\\r\\n2. source queue type. i.e. queue type where messages were dead lettered **from**:\\r\\n    * `rabbit_classic_queue`\\r\\n    * `rabbit_quorum_queue`\\r\\n    * (Streams do not dead letter messages because they are append-only logs where messages get truncated according to retention policies.)\\r\\n\\r\\n3. dead letter strategy:\\r\\n    * `disabled`: Queue has no `dead-letter-exchange` configured or configured `dead-letter-exchange` does not exist implying messages get dropped.\\r\\n    * `at_most_once`: Queue\'s configured dead-lettered-exchange exists.\\r\\n    * `at_least_once`: Queue type is `rabbit_quorum_queue`, `dead-letter-exchange` is configured, `dead-letter-strategy` is set to `at-least-once`, `overflow` is set to `reject-publish`.\\r\\n\\r\\nFollowing our example let us output these metrics.\\r\\nIn a shell window port-forward RabbitMQ\'s Prometheus port `15692`:\\r\\n```zsh\\r\\n> kubectl port-forward pod/my-rabbit-server-1 15692\\r\\n```\\r\\nIn another shell window scrape the Prometheus endpoint:\\r\\n```zsh\\r\\n> curl --silent localhost:15692/metrics/ | grep rabbitmq_global_messages_dead_lettered\\r\\n\\r\\n# TYPE rabbitmq_global_messages_dead_lettered_confirmed_total counter\\r\\n# HELP rabbitmq_global_messages_dead_lettered_confirmed_total Total number of messages dead-lettered and confirmed by target queues\\r\\nrabbitmq_global_messages_dead_lettered_confirmed_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_least_once\\"} 1\\r\\n\\r\\n# TYPE rabbitmq_global_messages_dead_lettered_delivery_limit_total counter\\r\\n# HELP rabbitmq_global_messages_dead_lettered_delivery_limit_total Total number of messages dead-lettered due to\\r\\n# delivery-limit exceeded\\r\\nrabbitmq_global_messages_dead_lettered_delivery_limit_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_least_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_delivery_limit_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_delivery_limit_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\n\\r\\n# TYPE rabbitmq_global_messages_dead_lettered_expired_total counter\\r\\n# HELP rabbitmq_global_messages_dead_lettered_expired_total Total number of messages dead-lettered due to message TTL exceeded\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_least_once\\"} 1\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_most_once\\"} 1\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\n\\r\\n# TYPE rabbitmq_global_messages_dead_lettered_maxlen_total counter\\r\\n# HELP rabbitmq_global_messages_dead_lettered_maxlen_total Total number of messages dead-lettered due to overflow drop-head\\r\\n# or reject-publish-dlx\\r\\nrabbitmq_global_messages_dead_lettered_maxlen_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_maxlen_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_maxlen_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_maxlen_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\n\\r\\n# TYPE rabbitmq_global_messages_dead_lettered_rejected_total counter\\r\\n# HELP rabbitmq_global_messages_dead_lettered_rejected_total Total number of messages dead-lettered due to basic.reject or basic.nack\\r\\nrabbitmq_global_messages_dead_lettered_rejected_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_rejected_total{queue_type=\\"rabbit_classic_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_rejected_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_least_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_rejected_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_most_once\\"} 0\\r\\nrabbitmq_global_messages_dead_lettered_rejected_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"disabled\\"} 0\\r\\n```\\r\\n\\r\\nWe scraped only the Prometheus metrics of pod `my-rabbit-server-1`.\\r\\nSince these counters are \\"node-global\\", it means above list shows only the metrics as observed by node `my-rabbit-server-1` (but global\\r\\nacross all queues on that node).\\r\\n\\r\\nThe very 1st message we sent went to pod `my-rabbit-server-0` before we stopped that node.\\r\\nThereafter the quorum queue leader changed in our example from `my-rabbit-server-0` to `my-rabbit-server-1`.\\r\\nWe then sent the 2nd message using the `at-most-once` dead letter strategy and the 3rd message using the `at-least-once` dead letter strategy.\\r\\nThe 3rd message that got dead lettered was eventually acknowledged by the dead letter consumer (or in other words, confirmed by the target queues).\\r\\nThis is why the following counters have the value `1`:\\r\\n```zsh\\r\\nrabbitmq_global_messages_dead_lettered_confirmed_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_least_once\\"} 1\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_least_once\\"} 1\\r\\nrabbitmq_global_messages_dead_lettered_expired_total{queue_type=\\"rabbit_quorum_queue\\",dead_letter_strategy=\\"at_most_once\\"} 1\\r\\n```\\r\\n\\r\\nIf you are curious you can scrape the Prometheus metrics for pod `my-rabbit-server-0`.\\r\\nWhat would you expect to see? Does the output match your expectations?\\r\\nHint: \\"A Prometheus counter is a cumulative metric that represents a single monotonically increasing counter whose value can only increase or be reset to zero on restart.\\"\\r\\n\\r\\n## Caveats\\r\\n\\r\\nWe saw how messages being dead lettered make it from the dead letter source queue to the dead letter target queue eventually even when the target queue is temporarily unavailable.\\r\\nSo why is at-least-once dead lettering not the new default dead letter strategy?\\r\\n\\r\\nThere are some caveats to be aware of when enabling at-least-once dead lettering:\\r\\n\\r\\n### Caveat 1 - Message buildup in the source quorum queue\\r\\n\\r\\nAt-least-once dead lettering does a great job ensuring messages are not lost when target queues are temporarily unavailable or when the routing topology is not configured correctly.\\r\\nHowever, if the dead letter consumer process does not obtain publisher confirmations from **all** target queues for a long time while more and more messages keep getting dead lettered\\r\\nin the source queue, it can cause excessive message buildup in the source queue.\\r\\nIn the worst case, the source quorum queue will contain only of dead lettered messages.\\r\\nTo prevent excessive message buildup, set a [queue length limit](/docs/maxlength) for the source queue (`max-length` or `max-length-bytes`).\\r\\n\\r\\n### Caveat 2 - Dead letter throughput\\r\\n\\r\\nThe dead letter consumer has a configurable setting called `dead_letter_worker_consumer_prefetch` whose current default value is set to `32`.\\r\\nThis means that the dead letter consumer process will prefetch and buffer at most 32 messages while waiting for publisher confirmations from target queues.\\r\\n\\r\\nSince RabbitMQ 3.10 quorum queues store all message bodies / payloads always on disk.\\r\\nThere is still a very small per message memory overhead for each message in the quorum queue because the quorum queue holds some metadata for each message in memory (for example the Raft index and\\r\\nthe message payload size).\\r\\n\\r\\nThe dead letter consumer process on the other hand keeps message bodies in memory.\\r\\nTo protect against the worst case where hundreds of quorum queues have at-least-once dead lettering enabled and publisher confirmations are not received, this prefetch value is set\\r\\nto a moderate default value of `32` to not cause high memory usage by the dead letter consumers.\\r\\n\\r\\nA low prefetch value however will cause lower throughput.\\r\\nIf you have a scenario where sustained dead lettering throughput of thousands of messages per second is required (for example thousands of messages expire or are getting rejected every second)\\r\\nyou can increase the prefetch setting in the advanced config file.\\r\\n\\r\\nHere is an example how to increase the prefetch in Kubernetes:\\r\\n```yaml\\r\\n---\\r\\napiVersion: rabbitmq.com/v1beta1\\r\\nkind: RabbitmqCluster\\r\\nmetadata:\\r\\n  name: my-rabbit\\r\\nspec:\\r\\n  replicas: 3\\r\\n  rabbitmq:\\r\\n    advancedConfig: |\\r\\n      [\\r\\n          {rabbit, [\\r\\n              {dead_letter_worker_consumer_prefetch, 512}\\r\\n          ]}\\r\\n      ].\\r\\n```\\r\\n\\r\\n### Caveat 3 - Increased resource usage\\r\\n\\r\\nEnabling at-least-once dead lettering for every quorum queue will increase resource usage.\\r\\nMore memory and more CPU will be consumed.\\r\\nComparing figure 1 (at-most-once dead lettering) with figure 2 (at-least-once dead lettering), we observe that at-least-once dead lettering will require\\r\\nsending more messages (including acknowledgements).\\r\\n\\r\\n### Caveat 4 - Overflow drop-head\\r\\n\\r\\nAs explained in the [Usage](#usage) section, enabling `at-least-once` dead lettering requires setting `overflow` to `reject-publish`.\\r\\nSetting `overflow` to `drop-head` will make dead letter strategy fall back to `at-most-once`.\\r\\n`drop-head` is not supported because dropping dead lettered messages from the source quorum queue would violate `at-least-once` semantics.\\r\\n\\r\\n### Caveat 5 - Switching dead letter strategy\\r\\n\\r\\nFor a quorum queue, it is possible to switch the dead-letter strategy via a policy from `at-most-once`\\r\\nto `at-least-once` and vice versa. If the dead-letter strategy is changed either directly\\r\\nfrom `at-least-once` to `at-most-once` or indirectly, for example by changing overflow from `reject-publish`\\r\\nto `drop-head` or by unsetting `dead-letter-exchange`, any dead-lettered messages that have not yet been confirmed by all target queues will be permanently deleted\\r\\nin the source quorum queue.\\r\\n\\r\\n## Best Practices\\r\\n\\r\\nBased on what we have learnt above, at-least-once dead lettering best practices include:\\r\\n\\r\\n### Best Practice 1\\r\\n\\r\\nSet `max-length` or `max-length-bytes` in the source quorum queue to guard against excessive message buildup.\\r\\n\\r\\n### Best Practice 2\\r\\n\\r\\nBind a target quorum queue or stream to the dead letter exchange.\\r\\nThis provides higher availability than a target classic queue.\\r\\nRedelivery of dead letter messages will also be faster for target quorum queues or target streams than for target classic queues.\\r\\nThis is because quorum queues and streams have their own clients, delivery protocols and retry mechanisms.\\r\\nRemember that classic mirrored queues are deprecated.\\r\\n\\r\\n### Best Practice 3\\r\\n\\r\\nSet the persistence flag on all messages published to the source quorum queue.\\r\\nIf the persistence flag is not set, dead lettered messages will not have it set either.\\r\\nThis becomes relevant when dead lettered messages are routed to a target classic queue.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nPrior to RabbitMQ 3.10 dead lettering in RabbitMQ has not been safe.\\r\\nMessages being dead lettered could get lost for a variety of reasons - especially in multi-node RabbitMQ clusters.\\r\\n\\r\\nAt-least-once dead lettering ensures dead lettered messages arrive at the target queue eventually even in the presence of rolling upgrades and\\r\\ntemporary failures such as network partitions or routing topology misconfigurations.\\r\\n\\r\\nBesides at-least-once dead lettering for quorum queues, we also learnt about two other new features in RabbitMQ 3.10:\\r\\nMessage TTL in quorum queues and Prometheus metrics for dead letter messages.\\r\\n\\r\\nSince at-least-once dead lettering comes with increased resource usage, it should only be enabled if dead lettered messages are not \\"dead\\" in the\\r\\noriginal sense but rather \\"alive\\" and crucial for your business logic.\\r\\nIf in your use case dead lettered messages are only of informational nature, at-most-once dead lettering should be used.\\r\\n\\r\\nThe at-least-once dead lettering feature for quorum queues paves the way for new use cases where you know that you\\r\\nhave messages that might be negatively acknowledged but still needs to be processed or where you cannot lose messages with an expiring TTL.\\r\\nSuch scenarios were previously unsafe or hard to achieve with RabbitMQ."},{"id":"/2022/03/24/rabbitmq-3.10.0-release-calendar","metadata":{"permalink":"/rabbitmq-website/blog/2022/03/24/rabbitmq-3.10.0-release-calendar","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-03-24-rabbitmq-3.10.0-release-calendar/index.md","source":"@site/blog/2022-03-24-rabbitmq-3.10.0-release-calendar/index.md","title":"RabbitMQ 3.10.0 release calendar","description":"We intend to release RabbitMQ 3.10.0 on 11 April 2022. While we have been testing","date":"2022-03-24T00:00:00.000Z","tags":[],"readingTime":2.455,"hasTruncateMarker":true,"authors":[{"name":"Mirah Gary","url":"https://github.com/MirahImage","imageURL":"https://github.com/MirahImage.png","key":"mgary","page":null},{"name":"Ed Byford","url":"https://github.com/edbyford","imageURL":"https://github.com/edbyford.png","key":"ebyford","page":null}],"frontMatter":{"title":"RabbitMQ 3.10.0 release calendar","tags":[],"authors":["mgary","ebyford"]},"unlisted":false,"prevItem":{"title":"At-Least-Once Dead Lettering","permalink":"/rabbitmq-website/blog/2022/03/29/at-least-once-dead-lettering"},"nextItem":{"title":"Using OPA/Gatekeeper with RabbitMQ Messaging Topology Resources","permalink":"/rabbitmq-website/blog/2022/02/21/gatekeeper-validation"}},"content":"We intend to release RabbitMQ 3.10.0 on 11 April 2022. While we have been testing\\r\\nit internally for some time, with production-like workloads, we need your help to\\r\\ncheck that it is as stable and reliable as we believe it is.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThis is the timeline that we have to work together on making 3.10.0 the best release for\\r\\nyou:\\r\\n\\r\\n| Milestone             | Anticipated Date | Notes                                                                         |\\r\\n| ---                   | ---              | ---                                                                           |\\r\\n| Code freeze           | 24 March 2022    | No new features or refactorings before the final release                      |\\r\\n| 3.10.0-rc.1 produced  | 24 March 2022    | All artefacts built & published                                               |\\r\\n| 3.10.0-rc.1 announced | 25 March 2022    | First release candidate (RC) is announced & made public for testing           |\\r\\n| 3.10.0-rc.3 produced  | 7 April 2022     | All artefacts built & published                                               |\\r\\n| 3.10.0-rc.3 announced | 8 April 2022     | Second release candidate (RC) is announced & made public for testing          |\\r\\n| 3.10.0-rc.4 produced  | 24 April 2022    | If new issues are reported, a new RC with fixes is made available for testing |\\r\\n| 3.10.0-rc.5 produced  | 28 April 2022    | If new issues are reported, a new RC with fixes is made available for testing |\\r\\n| 3.10.0-rc.6 produced  | 30 April 2022    | If new issues are reported, a new RC with fixes is made available for testing |\\r\\n| 3.10.0 produced       | 3 May 2022       | Final release is built & published                                            |\\r\\n| 3.10.0 announced      | 9 May 2022       | Final release is announced & made public                                      |\\r\\n\\r\\nThe above release calendar is a point-in-time snapshot. For latest updates\\r\\nplease refer to the [Release Series](/release-information)\\r\\npage.\\r\\n\\r\\nRabbitMQ 3.10.0 introduces some highly requested functionality for quorum queues:\\r\\n* [Quorum Queue Message TTL](/docs/quorum-queues#feature-matrix)\\r\\n* [Quorum Queue At-Least-Once Dead Lettering](/docs/quorum-queues#dead-lettering)\\r\\n\\r\\nAdditionally, there are performance improvements to both classic queues and quorum queues.\\r\\n\\r\\nThis release calendar is meant to communicate what to expect, and when.\\r\\nBased on your feedback during the pre-release timeline, we may add additional\\r\\nrelease candidates, and extend the release timeline.\\r\\n\\r\\nOur intention is to give you the opportunity to find issues with this release\\r\\nbefore we publish the final version. We all want important new releases, such\\r\\nas 3.10.0, to be as stable and reliable as possible. While we have gone to great\\r\\nlengths to ensure that this is the case, more eyes and experiments will always\\r\\nhelp, especially with a community as experienced and battle-hardened as ours.\\r\\n\\r\\n**Help us make RabbitMQ 3.10.0 the best release for you!**\\r\\n\\r\\n\\r\\n## Intent to remove capabilities in RabbitMQ 4.0\\r\\n\\r\\nWe are intending to remove some aged and suboptimal capabilities of RabbitMQ (see [blog post here](/blog/2021/08/21/4.0-deprecation-announcements)).\\r\\n\\r\\nRabbitMQ 3.10 works towards this removal by improving feature parity between Classic Mirrored Queues and Quorum Queues.\\r\\n\\r\\nWe have not yet set a release date for 4.0.\\r\\n\\r\\nIf you have further comments, please complete the survey linked in the [blog post](/blog/2021/08/21/4.0-deprecation-announcements)."},{"id":"/2022/02/21/gatekeeper-validation","metadata":{"permalink":"/rabbitmq-website/blog/2022/02/21/gatekeeper-validation","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2022-02-21-gatekeeper-validation/index.md","source":"@site/blog/2022-02-21-gatekeeper-validation/index.md","title":"Using OPA/Gatekeeper with RabbitMQ Messaging Topology Resources","description":"Many organizations have policies around RabbitMQ usage wich they would like to enforce. This blog post explains via example how the Open Policy Agent Gatekeeper project can be used in combination with the RabbitMQ Messaging Topology Operator to manage RabbitMQ resources on Kubernetes and enforce policies on those resources by extending the Kubernetes API.","date":"2022-02-21T00:00:00.000Z","tags":[{"inline":true,"label":"Kubernetes","permalink":"/rabbitmq-website/blog/tags/kubernetes"}],"readingTime":3.695,"hasTruncateMarker":true,"authors":[{"name":"Mirah Gary","url":"https://github.com/MirahImage","imageURL":"https://github.com/MirahImage.png","key":"mgary","page":null}],"frontMatter":{"title":"Using OPA/Gatekeeper with RabbitMQ Messaging Topology Resources","tags":["Kubernetes"],"authors":["mgary"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.10.0 release calendar","permalink":"/rabbitmq-website/blog/2022/03/24/rabbitmq-3.10.0-release-calendar"},"nextItem":{"title":"RabbitMQ is not affected by the Log4j vulnerability","permalink":"/rabbitmq-website/blog/2021/12/16/rabbitmq-not-affected-by-log4j-vulnerability"}},"content":"Many organizations have policies around RabbitMQ usage wich they would like to enforce. This blog post explains via example how the [Open Policy Agent Gatekeeper project](https://open-policy-agent.github.io/gatekeeper/website/docs/) can be used in combination with the [RabbitMQ Messaging Topology Operator](https://github.com/rabbitmq/messaging-topology-operator) to manage RabbitMQ resources on Kubernetes and enforce policies on those resources by extending the Kubernetes API.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## The RabbitMQ Messaging Topology Operator\\r\\n\\r\\nThe Messaging Topology Operator allows messaging topology state within a RabbitMQ cluster to be declaratively managed by extending the Kubernetes API with [Custom Resource Definitions (CRD)](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/). Such messaging topology state includes vhosts, queues, exchanges, bindings, policies, federations, shovels, users, and permissions. Each of these types of objects is represented by a Kubernetes CRD, and examples of each of these Custom Resources (CRs) can be found in the [documentation](https://github.com/rabbitmq/messaging-topology-operator/tree/main/docs/examples).\\r\\n\\r\\nFor concreteness, let us consider a queue:\\r\\n```yaml\\r\\n---\\r\\napiVersion: rabbitmq.com/v1beta1\\r\\nkind: Queue\\r\\nmetadata:\\r\\n  name: my-queue\\r\\nspec:\\r\\n  name: my-queue\\r\\n  vhost: my-vhost\\r\\n  type: quorum\\r\\n  rabbitmqClusterReference:\\r\\n    name: my-rabbit-cluster\\r\\n```\\r\\nThis quourum queue is named `my-queue`, on the vhost `my-vhost` and the RabbitMQ cluster `my-rabbit-cluster`.\\r\\n\\r\\nIf developers are assigned roles that allow them to create Queue resources, then they are free to create any queues with any configurations they want.\\r\\n\\r\\nSuppose we have policies regarding queues that we would like to enforce, for example, the following list of policies:\\r\\n\\r\\n1. The RabbitMQ Cluster must be named `my-rabbit-cluster`.\\r\\n1. Queues must be declared on the vhost `my-vhost`.\\r\\n\\r\\nOne option would be to limit developers\' Kubernetes roles to prevent them from creating queues and instead institute a manual ticketing system, where a Kubernetes admin creates Queue objects for them. However, this method of policy enforcement is manual, time consuming, and prevents developers from meeting their own needs.\\r\\n\\r\\n## Enforcing Policy with Gatekeeper\\r\\n\\r\\nGatekeeper extends the Kubernetes API in a different way, allowing us to create webhooks to ensure Kubernetes API objects conform with policy defined via the [OPA Rego language](https://www.openpolicyagent.org/docs/latest/policy-language/). Once we have [deployed Gatekeeper](https://open-policy-agent.github.io/gatekeeper/website/docs/install) in our Kuberentes cluster, we can enforce any policies we choose. In particular, we can create a constraint which allows us to enforce the above policies.\\r\\n\\r\\nDeploying a constraint consists of three components:\\r\\n1. Gatekeeper config, informing gatekeeper what types of resources we would like to monitor.\\r\\n1. A constraint template, which lets gatekeeper know what type of constraint we would like to enforce and includes the rego policy configuration.\\r\\n1. A specific instance of the constraint.\\r\\n\\r\\nTurning to our example, the Gatekeeper config necessary to enforce policy on RabbitMQ Queues is\\r\\n```yaml\\r\\n---\\r\\napiVersion: config.gatekeeper.sh/v1alpha1\\r\\nkind: Config\\r\\nmetadata:\\r\\n  name: config\\r\\n  namespace: gatekeeper-system\\r\\nspec:\\r\\n  sync:\\r\\n    syncOnly:\\r\\n    - group: rabbitmq.com\\r\\n      version: v1beta1\\r\\n      kind: Queue\\r\\n```\\r\\n\\r\\nTo enforce the policies listed above, we create the following `ConstraintTemplate`\\r\\n```yaml\\r\\n---\\r\\napiVersion: templates.gatekeeper.sh/v1beta1\\r\\nkind: ConstraintTemplate\\r\\nmetadata:\\r\\n  name: queuevalidator\\r\\nspec:\\r\\n  crd:\\r\\n    spec:\\r\\n      names:\\r\\n        kind: QueueValidator\\r\\n      validation:\\r\\n        openAPIV3Schema:\\r\\n          properties:\\r\\n            rabbit:\\r\\n              type: string\\r\\n            vhost:\\r\\n              type: string\\r\\n  targets:\\r\\n  - target: admission.k8s.gatekeeper.sh\\r\\n    rego: |\\r\\n      package queuevalidator\\r\\n      violation[{\\"msg\\":msg}] {\\r\\n        allowedRabbit := input.parameters.rabbit\\r\\n        givenRabbit := input.review.object.spec.rabbitmqClusterReference.name\\r\\n        givenRabbit != allowedRabbit\\r\\n        allowedVhost := input.parameters.vhost\\r\\n        givenVhost := input.review.object.spec.vhost\\r\\n        givenVhost != allowedVhost\\r\\n        msg := sprintf(\\"Rabbit Cluster must be %v, queues must be declared on vhost %v\\", [allowedRabbit, allowedVhost])\\r\\n      }\\r\\n```\\r\\nFrom this `ConstraintTemplate`, Gatekeeper will create a custom resource kind `QueueValidator` which takes two properties, a `rabbit` and a `vhost`, both strings. This allows us to configure the allowed RabbitMQ cluster name and vhost as parameters when deploying an instance of the constraint. The rego code ensures that the `rabbitmqClusterReference` and `vhost` match the specified allowed values. More generally, the `rego` block must include a violation function which evaluates to true when a policy violation occurs, along with a message explaining the policy violation.\\r\\n\\r\\nWe must first deploy the `ConstraintTemplate` and allow Gatekeeper to create the CRD for the kind `QueueValidator` before we can deploy a `QueueValidator` instance.\\r\\n```yaml\\r\\n---\\r\\napiVersion: constraints.gatekeeper.sh/v1beta1\\r\\nkind: QueueValidator\\r\\nmetadata:\\r\\n  name: queue-validator\\r\\nspec:\\r\\n  match:\\r\\n    kinds:\\r\\n    - apiGroups: [\\"rabbitmq.com\\"]\\r\\n      kinds: [\\"Queue\\"]\\r\\n  parameters:\\r\\n  - rabbit: my-rabbit-cluster\\r\\n  - vhost: my-vhost\\r\\n```\\r\\n\\r\\nWith all of this configuration in place, if we attempt to create a Queue that does not conform to policy, it will be rejected by the webhook with an error.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nGatekeeper is an operator that extends the Kubernetes API to enforce policy. Together with the RabbitMQ Messaging Topology Operator, it is possible to declaratively manage RabbitMQ objects and ensure compliance via the Kubernetes API. We have shown a simple example, but the OPA language used to configure policies is highly extensible, allowing Gatekeeper to perform advanced policy management."},{"id":"/2021/12/16/rabbitmq-not-affected-by-log4j-vulnerability","metadata":{"permalink":"/rabbitmq-website/blog/2021/12/16/rabbitmq-not-affected-by-log4j-vulnerability","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-12-16-rabbitmq-not-affected-by-log4j-vulnerability/index.md","source":"@site/blog/2021-12-16-rabbitmq-not-affected-by-log4j-vulnerability/index.md","title":"RabbitMQ is not affected by the Log4j vulnerability","description":"RabbitMQ is not affected by the Log4j vulnerability, read below for more details.","date":"2021-12-16T00:00:00.000Z","tags":[{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"}],"readingTime":0.665,"hasTruncateMarker":true,"authors":[{"name":"Ed Byford","url":"https://github.com/edbyford","imageURL":"https://github.com/edbyford.png","key":"ebyford","page":null},{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"RabbitMQ is not affected by the Log4j vulnerability","tags":["Announcements"],"authors":["ebyford","acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Using OPA/Gatekeeper with RabbitMQ Messaging Topology Resources","permalink":"/rabbitmq-website/blog/2022/02/21/gatekeeper-validation"},"nextItem":{"title":"Interoperability in RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/10/07/rabbitmq-streams-interoperability"}},"content":"RabbitMQ is not affected by the Log4j vulnerability, read below for more details.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nRabbitMQ is an Erlang application and as such runs on the BEAM virtual machine, which is not the Java virtual machine.\\r\\n\\r\\nWe **do not** ship Log4j in the RabbitMQ broker.\\r\\n\\r\\nOur Java libraries (Java client, JMS client, etc) depend on a log façade (SLF4J), and application developers choose a \\"binding\\" - an implementation of a logging library - to use in their applications. Log4j is one of those possible bindings application developers might choose.\\r\\n\\r\\nWe do ship with a log binding for our utility programs, e.g. PerfTest, and the binding we use is Logback, which is not affected.\\r\\n\\r\\n_Please check in your application code (if Java) and take remedial action there if your developers are using Log4J._"},{"id":"/2021/10/07/rabbitmq-streams-interoperability","metadata":{"permalink":"/rabbitmq-website/blog/2021/10/07/rabbitmq-streams-interoperability","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-10-07-rabbitmq-streams-interoperability/index.md","source":"@site/blog/2021-10-07-rabbitmq-streams-interoperability/index.md","title":"Interoperability in RabbitMQ Streams","description":"RabbitMQ streams allow applications to convey detailled information thanks to the powerful message format they use.","date":"2021-10-07T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":7.37,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"Interoperability in RabbitMQ Streams","tags":["Streams","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"RabbitMQ is not affected by the Log4j vulnerability","permalink":"/rabbitmq-website/blog/2021/12/16/rabbitmq-not-affected-by-log4j-vulnerability"},"nextItem":{"title":"Offset Tracking with RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/09/13/rabbitmq-streams-offset-tracking"}},"content":"<!--diagrams: https://drive.google.com/drive/folders/1V-VuvO6jeL3dqHBiGZq3uCErc-vOeH49?usp=sharing -->\\r\\nRabbitMQ streams allow applications to convey detailled information thanks to the powerful message format they use.\\r\\nStreams are a feature of their own, but they also fully integrate with the existing resources and protocols that RabbitMQ supports.\\r\\nThis blog post covers the interoperability of streams in RabbitMQ and explores the scenarios it unlocks.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Messages in RabbitMQ Streams\\r\\n\\r\\nWe saw in the [RabbitMQ Streams First Application](/blog/2021/07/19/rabbitmq-streams-first-application) blog post that stream messages have a binary body, properties, with different types supported.\\r\\nFor example:\\r\\n\\r\\n```java\\r\\nMessage message = producer.messageBuilder()\\r\\n  .properties()\\r\\n    .creationTime(System.currentTimeMillis()) // Unix time, with a precision of milliseconds\\r\\n    .messageId(i) // long, string, binary, or UUID\\r\\n  .messageBuilder()\\r\\n    .addData(\\"hello world\\".getBytes(StandardCharsets.UTF_8))\\r\\n  .build();\\r\\n```\\r\\n\\r\\nRabbitMQ Stream uses the [AMQP 1.0 message format](https://www.amqp.org/resources/specifications) to encode messages.\\r\\nIt is a flexible, powerful, and efficient format, with a sophisticated type system.\\r\\nIt is also supported by a variety of platforms, like Java, Go, .NET, and many others.\\r\\nOur examples use Java, but messages could be published and consumed by [different](https://github.com/rabbitmq/rabbitmq-stream-go-client) [platforms](https://github.com/rabbitmq/rabbitmq-stream-dotnet-client) as well. \\r\\n\\r\\n\\r\\nNote RabbitMQ Streams does not use the AMQP 1.0 *protocol* as it has its own [binary protocol](https://github.com/rabbitmq/rabbitmq-server/blob/v3.9.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc), which happens to convey messages encoded in the AMQP 1.0 *format* in some of its frames.\\r\\nThe stream Java client documentation contains [more details on AMQP 1.0 messages](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#working-with-complex-messages).\\r\\n\\r\\n## What About Other Protocols?\\r\\n\\r\\nSo stream applications can publish and consume complex messages, so far so good. \\r\\nBut streams are not an island in RabbitMQ: they are interoperable with the other protocols supported by RabbitMQ, that is AMQP 0.9.1, AMQP 1.0, STOMP, and MQTT.\\r\\n\\r\\nSo if an application using a given protocol can publish messages that end up in a queue, a stream application can consume these messages as long as *the queue is a stream*.\\r\\nAnd the opposite is true: if a stream application publishes messages to a stream, applications using other protocols see the stream as a queue and can consume messages from it.\\r\\n\\r\\nThis interoperability combined with the routing capabilities of RabbitMQ bring a lot of flexibility and is helpful in many scenarios that may involve a variety of plaforms and programming languages.\\r\\nThis also means that even though streams are a new feature in RabbitMQ 3.9, you don\'t have to start using them only for new applications with stream publishers and stream consumers, but you can *include* them in your existing RabbitMQ architecture.\\r\\n\\r\\n## Streams in an Existing System\\r\\n\\r\\nImagine an existing system with publishers sending messages to a topic exchange.\\r\\nDepending on their routing keys, messages are routed to a given queue, matching a given region of the world.\\r\\nEach queue has its own processing, that depends on the region.\\r\\nNote the publishers don\'t have to use AMQP 0.9.1, they can use any protocol supported by RabbitMQ, as long as they publish to the exchange with the appropriate routing key.\\r\\n\\r\\n![A classic RabbitMQ architecture where messages from an exchange are routed to different queues for a specific processing.](existing-system-without-stream.svg)\\r\\n\\r\\nImagine now we want to keep the existing processing as is, but do some extra processing like analytics on all messages.\\r\\nWe just have to create a stream and bind it to the topic exchange with a wildcard:\\r\\n\\r\\n![The same system with an additional stream that receives all the messages thanks to the wildcard binding.](existing-system-with-stream.svg)\\r\\n\\r\\nA stream is appropriate for analytics thanks to its non-destructive consumer semantics and, as the stream protocol is very fast, results can be recomputed from scratch every day.\\r\\nThis can also benefit any other application that needs the entire or partial history of messages, as any number of consumers can read and re-read the stream from any point in time.\\r\\n\\r\\nThe region processing done from the queues can stay exactly the same, as long as the queue semantics fit the needs (destructive consuming, competing consumers, etc.)\\r\\n\\r\\nThis is an excellent example of how streams can be introduced easily and without risks in existing RabbitMQ architectures, to provide added value immediately.\\r\\n\\r\\n## Publishing With AMQP 0.9.1, Consuming With the Stream Protocol\\r\\n\\r\\nLet\'s see a bit of code that illustrates this example.\\r\\n\\r\\nThe next snippet shows a publisher using the RabbitMQ 0.9.1 AMQP Java client:\\r\\n\\r\\n```java\\r\\nchannel.basicPublish(\\r\\n  \\"events\\",  // exchange\\r\\n  REGIONS[i % REGIONS.length], // routing key, round robin across regions\\r\\n  new AMQP.BasicProperties.Builder()\\r\\n    .messageId(String.valueOf(i)) // message ID\\r\\n    .timestamp(new Date()) // creation time\\r\\n    .contentType(\\"text/plain\\") // content type\\r\\n    .build(),\\r\\n  (\\"message \\" + i).getBytes(StandardCharsets.UTF_8) // body\\r\\n);\\r\\n```\\r\\n\\r\\nThe publisher sets a few properties to illustrate the interoperability betweem AMQP 0.9.1 and stream messages.\\r\\n\\r\\nAnd here is a consumer that uses the stream Java client to process the messages from the world-wide stream:\\r\\n\\r\\n```java\\r\\nenvironment.consumerBuilder()\\r\\n  .stream(\\"world\\")\\r\\n  .offset(OffsetSpecification.first())\\r\\n  .messageHandler((context, message) -> {\\r\\n    String body = new String(message.getBodyAsBinary());\\r\\n    log(\\r\\n      \\"Message #%s, creation time %tF %tT, content type \'%s\', from exchange %s with routing key %s\\",\\r\\n      message.getProperties().getMessageId(),\\r\\n      message.getProperties().getCreationTime(),\\r\\n      message.getProperties().getCreationTime(),\\r\\n      message.getProperties().getContentType(),\\r\\n      message.getMessageAnnotations().get(\\"x-exchange\\"),\\r\\n      message.getMessageAnnotations().get(\\"x-routing-key\\"));\\r\\n  })\\r\\n  .build();\\r\\n```\\r\\n\\r\\nThe consumer can retrieve properties from the original AMQP 0.9.1 message even though stream are using the AMQP 1.0 message format.\\r\\nIt is also possible to retrieve the exchange and the routing key of the message in the message annotations (an AMQP 1.0 concept.)\\r\\n\\r\\n## Interoperability in Action\\r\\n\\r\\nLet\'s run the previous code in a project with the topology described above.\\r\\n\\r\\n### Setting Up The Sample Project\\r\\n\\r\\nRunning the samples requires Docker, Git, and Java 8 or higher installed.\\r\\nYou can start the broker with the following command:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --name rabbitmq -p 5552:5552 -p 5672:5672 -p 15672:15672 \\\\\\r\\n    -e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\'-rabbitmq_stream advertised_host localhost\' \\\\\\r\\n    rabbitmq:3.9-management\\r\\n```\\r\\n\\r\\nYou need then to enable the stream plugin:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_stream\\r\\n```\\r\\n\\r\\nThe [code is hosted on GitHub](https://github.com/acogoluegnes/rabbitmq-streams-blog-posts).\\r\\nHere is how to clone the repository:\\r\\n\\r\\n```shell\\r\\ngit clone https://github.com/acogoluegnes/rabbitmq-streams-blog-posts.git\\r\\ncd rabbitmq-streams-blog-posts\\r\\n```\\r\\n\\r\\nIn the sample project we will:\\r\\n* create the topology illustrated in the diagram above\\r\\n* publish messages with an AMQP 0.9.1 publisher\\r\\n* consume the messages from the stream using the stream protocol\\r\\n\\r\\n### Creating the Topology\\r\\n\\r\\nThe following command creates the exchange, the queues, the stream, and their respective bindings:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Interoperability$CreateTopology\'\\r\\n```\\r\\n\\r\\nYou should see the following on the console:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nCreating \'events\' topic exchange...\\r\\nCreating \'amer\' queue and binding it to \'events\' exchange...\\r\\nCreating \'emea\' queue and binding it to \'events\' exchange...\\r\\nCreating \'apac\' queue and binding it to \'events\' exchange...\\r\\nCreating \'world\' stream and binding it to \'events\' exchange...\\r\\nClosing connection\\r\\n```\\r\\n\\r\\nIt is possible to check the resources have been created in the [management UI](http://localhost:15672/#/queues) (user `guest`, password `guest`.)\\r\\n\\r\\n### Publishing the Messages\\r\\n\\r\\nThe following runs a publisher that sends 100 messages:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Interoperability$Publish\'\\r\\n```\\r\\n\\r\\nYou should get the following console output:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nSending 100 messages\\r\\nMessages sent, waiting for confirmation...\\r\\nMessages confirmed\\r\\nClosing connection\\r\\n```\\r\\n\\r\\nAs shown in the snippet above, the publisher sets some message properties and changes the routing key in a round robin fashion to publish to every region.\\r\\nYou can go back to the [management UI](http://localhost:15672/#/queues) to check the content of the queues and of the stream.\\r\\nNote the stream contains an extra message: it is a poison message to stop the consumer we\'ll run next.\\r\\n\\r\\n### Consuming the Message from the Stream\\r\\n\\r\\nIt\'s time to consume all the messages that ended up in the stream:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Interoperability$Consume\'\\r\\n```\\r\\n\\r\\nYou should get something like the following:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nStart consumer...\\r\\nMessage #0, creation time 2021-10-06 14:19:55, content type \'text/plain\', from exchange events with routing key amer\\r\\nMessage #1, creation time 2021-10-06 14:19:55, content type \'text/plain\', from exchange events with routing key emea\\r\\nMessage #2, creation time 2021-10-06 14:19:55, content type \'text/plain\', from exchange events with routing key apac\\r\\nMessage #3, creation time 2021-10-06 14:19:55, content type \'text/plain\', from exchange events with routing key amer\\r\\n...\\r\\nMessage #97, creation time 2021-10-06 14:19:55, content type \'text/plain\', from exchange events with routing key emea\\r\\nMessage #98, creation time 2021-10-06 14:19:55, content type \'text/plain\', from exchange events with routing key apac\\r\\nMessage #99, creation time 2021-10-06 14:19:55, content type \'text/plain\', from exchange events with routing key amer\\r\\nReceived poison message, stopping...\\r\\nClosing environment...\\r\\nEnvironment closed\\r\\n```\\r\\n\\r\\nThe stream consumer gets all the messages, without losing information between the AMQP 0.9.1 to AMQP 1.0 message format conversion.\\r\\nNote the exchange and routing key information is available as well as part of the message annotations.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nWe saw in this blog post that streams in RabbitMQ can convey messages with a sophisticated format (binary body, but also properties, with complex types.)\\r\\nApplications can access streams with the stream protocol, which is fast and efficient, but also with the other protocols RabbitMQ supports.\\r\\nThis makes streams first-class citizens in systems that require interoperability, one of the strong points of RabbitMQ.\\r\\nYou can use streams for brand new applications, but don\'t hesitate to integrate them smoothly in your existing systems as suggested in the scenario above."},{"id":"/2021/09/13/rabbitmq-streams-offset-tracking","metadata":{"permalink":"/rabbitmq-website/blog/2021/09/13/rabbitmq-streams-offset-tracking","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-09-13-rabbitmq-streams-offset-tracking/index.md","source":"@site/blog/2021-09-13-rabbitmq-streams-offset-tracking/index.md","title":"Offset Tracking with RabbitMQ Streams","description":"RabbitMQ Streams provides server-side offset tracking for consumers.","date":"2021-09-13T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":7.99,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"Offset Tracking with RabbitMQ Streams","tags":["Streams","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Interoperability in RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/10/07/rabbitmq-streams-interoperability"},"nextItem":{"title":"RabbitMQ Deprecation Announcements for 4.0","permalink":"/rabbitmq-website/blog/2021/08/21/4.0-deprecation-announcements"}},"content":"<!-- diagrams: https://drive.google.com/drive/folders/1CsoMiLkJBsShk4aBuUhRKyjBrGsIBEgb?usp=sharing -->\\r\\nRabbitMQ Streams provides server-side offset tracking for consumers.\\r\\nThis features allows a consuming application to restart consuming where it left off in a previous run.\\r\\nThis post covers the semantics of offset tracking and how it is implemented in the stream Java client.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## What is Offset Tracking?\\r\\n\\r\\nOffset tracking is the process for a consuming application to store its position in a stream.\\r\\nIf a consuming application position in a stream is 1,000, it means it has processed all the messages up to this position.\\r\\nIf the application were to stop and restart, it would re-attach to the stream right after its last stored position, that is 1,001 in our example, and restart consuming from there.\\r\\n\\r\\nWe use the concept of _offset_ to specify the exact position in a stream.\\r\\n\\r\\n## What is an Offset in the First Place?\\r\\n\\r\\nIf we model a stream like an array where each element is a message, then the offset is just the index of a given message in this array.\\r\\n\\r\\n![A stream can be represented as an array. The offset is the index of an element in the array.](offset-in-a-stream.svg)\\r\\n\\r\\nThis mental representation is accurate enough to understand offset tracking in our case, but it is not completely exact.\\r\\nLet\'s just say that an element in this large array is not always a message, it can be some piece of information needed for the stream housekeeping.\\r\\nA consequence is that 2 contiguous messages may not always have 2 contiguous offset values, but it does matter in the context of this post.\\r\\n\\r\\n## The Different Offset Specifications in a Stream\\r\\n\\r\\nThe absolute offset does not have any meaning, it is just technical.\\r\\nSo when an application wants to attach to a stream for the first time, it is unlikely it will use an offset, it will prefer to use a higher-level concept like the _beginning_ or the _end_ of the stream, or even some _point in time_ in the stream.\\r\\n\\r\\nLuckily, RabbitMQ Streams supports different _offset specifications_ in addition to the absolute offset: `first`, `last`, `next`, and `timestamp`.\\r\\n\\r\\nThere are 2 offset specifications for the \\"end\\" of the stream: `next` means the next offset to be written.\\r\\nIf a consumer attaches to a stream at `next` and no-one is publishing, the consumer won\'t receive anything.\\r\\nIt will start receiving when new messages come in.\\r\\n\\r\\n`last` means \\"from the last chunk of messages\\".\\r\\nA chunk is a RabbitMQ Streams term for \\"batch of messages\\", as messages are handled in batches for performance reasons.\\r\\n\\r\\nThe following figure shows offset specifications in a stream.\\r\\n\\r\\n![Different offset specifications in a stream with 2 chunks.](offset-specification.svg)\\r\\n\\r\\n## The Different Steps in Offset Tracking\\r\\n\\r\\nSo an application will usually specify an offset like `first` or `next` when it starts for the first time, process messages, and store an offset value periodically (e.g. every 10,000 messages) on the server.\\r\\n\\r\\nThe application may stop for some reason (e.g. upgrade).\\r\\nWhen it restarts, it will retrieve its last stored offset and restart consuming just after this position.\\r\\n\\r\\nThe RabbitMQ Stream protocol provides commands to store and look up an offset for a given application on a given stream, so offset tracking is mainly a client concern.\\r\\n\\r\\n## Offset Tracking Application Requirements\\r\\n\\r\\nThere is a simple requirement for an application that wants to use offset tracking in a stream: it must use a _tracking reference_ that stays the same between the application restarts.\\r\\n\\r\\nThe way to specify this reference depends on the client library and more generally, client libraries can have different features or approaches to deal with offset tracking.\\r\\nRead more about offset tracking in the stream Java client [here](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#consumer-offset-tracking).\\r\\n\\r\\n## The Dark Side of Server-Side Offset Tracking\\r\\n\\r\\nServer-side offset tracking in RabbitMQ Streams is pretty neat but it should be used cautiously though.\\r\\nOffset tracking information is stored in the stream log.\\r\\nRemember the array representation of a stream?\\r\\nImagine that most of the array elements are messages, but some contain offset tracking information, that is for example \\"offset 1000 for application \'my-application\'\\".\\r\\n\\r\\nSo every time a client asks to store an offset for a given consumer, this creates a small entry in the log.\\r\\nYou don\'t want to create too many of these entries, that\'s why we advise to store offsets every few thousands messages and avoid consumers that store offsets for every single message.\\r\\nAgain, just be cautious and reasonable with server-side offset tracking.\\r\\n\\r\\nRemember also that server-side offset tracking is just a commodity and by no means the only solution to allow consumers to restart where they left off.\\r\\nImagine message processing is a database operation inside a transaction.\\r\\nStoring the offset in the database as part of the same transaction is a good idea as it ensures the data changes and the offset storage happens atomically.\\r\\n\\r\\n## Server-Side Offset Tracking in Action\\r\\n\\r\\nLet\'s see now how to set up offset tracking with the stream Java client.\\r\\n\\r\\n### The Tracking Consumer\\r\\n\\r\\nHere is some code to start a consumer with offset tracking:\\r\\n\\r\\n```java\\r\\nAtomicInteger messageConsumed = new AtomicInteger(0);\\r\\nConsumer consumer = environment.consumerBuilder()\\r\\n    .stream(\\"offset-tracking-stream\\") // the stream to consume from\\r\\n    .offset(OffsetSpecification.first()) // start consuming at the beginning\\r\\n    .name(\\"my-application\\") // the name (reference) of the consumer\\r\\n    .manualTrackingStrategy() // tracking is done in application code\\r\\n    .builder()\\r\\n    .messageHandler((context, message) -> {\\r\\n        // ... message processing ...\\r\\n\\r\\n        // condition to store the offset: every 10,000 messages\\r\\n        if (messageConsumed.incrementAndGet() % 10_000 == 0) {\\r\\n           context.storeOffset(); // store the message offset\\r\\n        }\\r\\n        // ... \\r\\n    })\\r\\n    .build();\\r\\n```\\r\\n\\r\\nIn case you want a reminder on the stream Java client API, you can read [RabbitMQ Streams First Application](/blog/2021/07/19/rabbitmq-streams-first-application).\\r\\n\\r\\nHere are the key points in this snippet:\\r\\n* the consumer **must** have a name to enable offset tracking.\\r\\nIt uses its name as the tracking reference when storing an offset value.\\r\\n* the consumer starts consuming at the beginning of the stream with `OffsetSpecification.first()`.\\r\\nThis specification is ignored when the consumer restarts and there is a stored offset value for it.\\r\\n* the application code handles the tracking explicitly with `Context#storeOffset()`. The `Consumer#store(long)` method is another possibility to store an offset.\\r\\n\\r\\nYou see how offset tracking can depend on the client library.\\r\\nThe stream Java client provides also an [automatic offset tracking strategy](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#consumer-automatic-offset-tracking) if you don\'t want to deal with offset tracking in your code.\\r\\n\\r\\nAs you can see, offset tracking is pretty easy when the requirements and semantics are understood. Let\'s run the example now.\\r\\n\\r\\n### Setting Up The Sample Project\\r\\n\\r\\nRunning the samples requires Docker, Git, and Java 8 or higher installed.\\r\\nYou can start the broker with the following command:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --name rabbitmq -p 5552:5552 \\\\\\r\\n    -e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\'-rabbitmq_stream advertised_host localhost\' \\\\\\r\\n    rabbitmq:3.9\\r\\n```\\r\\n\\r\\nYou need then to enable the stream plugin:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_stream\\r\\n```\\r\\n\\r\\nThe [code is hosted on GitHub](https://github.com/acogoluegnes/rabbitmq-streams-blog-posts).\\r\\nHere is how to clone the repository:\\r\\n\\r\\n```shell\\r\\ngit clone https://github.com/acogoluegnes/rabbitmq-streams-blog-posts.git\\r\\ncd rabbitmq-streams-blog-posts\\r\\n```\\r\\n\\r\\nIn the sample project we will:\\r\\n* publish a first wave of messages\\r\\n* start the consumer, it will consume the messages, store offset periodically, and stop at the end of the first wave (thanks to a poison message)\\r\\n* publish a second wave of messages\\r\\n* start the consumer again and make sure it restart where it left off (at the end of the first wave) and consume only the messages from the second wave\\r\\n\\r\\n### Publishing the First Wave of Messages\\r\\n\\r\\nPublish the first messages with the following command:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.OffsetTracking$PublishFirstWave\'\\r\\n```\\r\\n\\r\\nYou should get the following on the console:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nCreating stream...\\r\\nStream created\\r\\nCreating producer...\\r\\nProducer created\\r\\nSending 500,000 messages\\r\\nMessages sent, waiting for confirmation...\\r\\nAll messages confirmed? yes (928 ms)\\r\\nClosing environment...\\r\\nEnvironment closed\\r\\n```\\r\\n\\r\\nThe program publishes 500,000 messages with the same `first wave` body, except for the last message which is a poison message to stop the consuming.\\r\\n\\r\\n### Consuming the First Wave of Messages\\r\\n\\r\\nStart the consumer:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.OffsetTracking$Consume\'\\r\\n```\\r\\n\\r\\nYou get:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nStart consumer...\\r\\nConsumed 500,000 messages in 364 ms (bodies: poison, first wave)\\r\\nClosing environment...\\r\\nEnvironment closed\\r\\n```\\r\\n\\r\\nThe consumer behaved as expected: it started from the beginning because it consumed the 500,000 messages.\\r\\nThe consumer also records all the bodies it get in a set, it got `first wave` messages and the `poison` message, good.\\r\\n\\r\\n### Publishing the Second Wave of Messages\\r\\n\\r\\nLet\'s publish another wave of messages:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.OffsetTracking$PublishSecondWave\'\\r\\n```\\r\\n\\r\\nThis time we get:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nCreating producer...\\r\\nProducer created\\r\\nSending 100,000 messages\\r\\nMessages sent, waiting for confirmation...\\r\\nAll messages confirmed? yes (312 ms)\\r\\nClosing environment...\\r\\nEnvironment closed\\r\\n```\\r\\n\\r\\nOK, 100,000 more messages in the stream.\\r\\n\\r\\n### Consuming the Second Wave of Messages\\r\\n\\r\\nLet\'s restart the consumer:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.OffsetTracking$Consume\'          \\r\\n```\\r\\n\\r\\nWe get:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nStart consumer...\\r\\nConsumed 100,000 messages in 215 ms (bodies: poison, second wave)\\r\\nClosing environment...\\r\\nEnvironment closed\\r\\n```\\r\\n\\r\\nNice! Even if the consumer was supposed to start at the beginning of the stream, it detected there was a stored offset, so it used it to restart properly.\\r\\nIt consumed only the second wave of messages.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nRabbitMQ Streams provide server-side offset tracking for consumers.\\r\\nA consumer instance must have a name (or tracking reference) that stays the same between restarts.\\r\\nThe client application stores the offsets periodically, the way it\'s done depends on the client library.\\r\\n\\r\\nOffset tracking is essential for applications that need to restart where they left off.\\r\\n\\r\\nThe stream Java client has excellent support for offset tracking and its [documentation](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#consumer-offset-tracking) covers it in-depth."},{"id":"/2021/08/21/4.0-deprecation-announcements","metadata":{"permalink":"/rabbitmq-website/blog/2021/08/21/4.0-deprecation-announcements","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-08-21-4.0-deprecation-announcements/index.md","source":"@site/blog/2021-08-21-4.0-deprecation-announcements/index.md","title":"RabbitMQ Deprecation Announcements for 4.0","description":"In RabbitMQ 4.0, we intend to remove some RabbitMQ features to:","date":"2021-08-21T00:00:00.000Z","tags":[{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements"}],"readingTime":3.83,"hasTruncateMarker":true,"authors":[{"name":"Ed Byford","url":"https://github.com/edbyford","imageURL":"https://github.com/edbyford.png","key":"ebyford","page":null}],"frontMatter":{"title":"RabbitMQ Deprecation Announcements for 4.0","tags":["Announcements"],"authors":["ebyford"]},"unlisted":false,"prevItem":{"title":"Offset Tracking with RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/09/13/rabbitmq-streams-offset-tracking"},"nextItem":{"title":"Message Deduplication with RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/07/28/rabbitmq-streams-message-deduplication"}},"content":"In RabbitMQ 4.0, we intend to remove some RabbitMQ features to:\\r\\n\\r\\n* Increase the resiliency of the core broker\\r\\n* Decrease the number of suboptimal configurations available\\r\\n* Remove technical surface area (maintaining old code) from the team\\r\\n* Reduce the support burden\\r\\n\\r\\nWe continually innovate to meet and exceed our users’ expectations. Removal of older functionality that no longer meets these expectations, or serves our users, means we can focus on our mission to provide a stable, performant, and flexible messaging system.\\r\\n\\r\\n<!-- truncate -->\\r\\n \\r\\nThe features we are announcing the deprecation of have been chosen because (either):\\r\\n\\r\\n* In certain conditions, they behave sub-optimally\\r\\n* They are infrequently used\\r\\n\\r\\nGiven for each feature there is a newer, safer alternative to achieve the same outcome, we do not believe anyone should be using these functions.\\r\\n\\r\\nThis document is designed to explain the changes and allow a chance to provide feedback.\\r\\n\\r\\n## When will these changes be made?\\r\\n\\r\\nWe intend to make these changes with the release of RabbitMQ 4.0. There is currently no timeline set for this release.\\r\\n\\r\\nBefore making the changes, we will review the feedback supplied via a survey.\\r\\n\\r\\n## How can I provide feedback?\\r\\n\\r\\nIf you’d like to provide feedback on this announcement, please complete this [survey](https://docs.google.com/forms/d/e/1FAIpQLSfDjOigPhdd8z4l9DzSbHie0AfgAgsJESsQlvVOEAoDIYjzDA/viewform?usp=sf_link).\\r\\n\\r\\n \\r\\n## The Announcements\\r\\n\\r\\n### Disable metrics delivery via the management API / UI\\r\\n\\r\\n#### Why are we making this decision?\\r\\n\\r\\nThe management API has been serving two functions: control plane and metrics delivery system. This dual purpose meant that in rare circumstances (i.e. extreme load) the metrics would be delayed.\\r\\n\\r\\n#### What alternatives exist?\\r\\n\\r\\nThe Prometheus plugin, available since 3.8 was released in October 2019, provides metrics even under load. It also has the added benefit of offering a wider array of metrics than those available from management API. The documentation on the Prometheus and Grafana dashboards is [here](/docs/prometheus).\\r\\n\\r\\n \\r\\n\\r\\n### Removal of global QoS\\r\\n\\r\\n#### Why are we making this decision?\\r\\n\\r\\nGlobal QoS, where a single shared prefetch is used for an entire channel, is not recommended practice.\\r\\n\\r\\n#### What alternatives exist?\\r\\n\\r\\nPer-consumer QoS (non-global) should be set instead.\\r\\n\\r\\n \\r\\n\\r\\n### Removal of RAM nodes\\r\\n\\r\\n#### Why are we making this decision?\\r\\n\\r\\nRAM nodes hold all of their internal metadata in memory, including users, policies, queues, and RabbitMQ cluster membership. When a broker node is restarted, all of this will be lost, meaning that using RAM nodes in a highly available cluster is not recommended as it can result in data loss.\\r\\n\\r\\n#### What alternatives exist?\\r\\n\\r\\nDisk nodes should be used with fast storage.\\r\\n\\r\\n \\r\\n\\r\\n### Removal of Classic Queue mirroring\\r\\n\\r\\n#### Why are we making this decision?\\r\\n\\r\\nQuorum Queues provide greater data safety as compared to classic mirrored queues.\\r\\n\\r\\n#### What alternatives exist?\\r\\n\\r\\nCustomers should make use of Quorum Queues for replication and data safety. TTLs for classic mirrored queues can be replaced by streams.\\r\\n\\r\\n \\r\\n\\r\\n### Removal of transient, non-exclusive queues\\r\\n\\r\\n#### Why are we making this decision?\\r\\n\\r\\nTransient queues are queues whose lifetime is linked to the uptime of the node they are declared on. In a single node cluster they are removed when the node is restarted. In a clustered environment they are removed when the node they are hosted on is restarted.\\r\\n \\r\\n\\r\\nCorrect use of transient queues requires that an application developer knows something about node uptime. Further, a node restart isn\'t a good way to remove unused queues.\\r\\n \\r\\nThere is one kind of transient queue that is not included in this deprecation; the exclusive queue. Exclusive queues are linked to the lifetime of the declaring connection which is something that an application developer can take into account and leverage.\\r\\n \\r\\nBy deprecating transient queues we are removing a potentially confusing queue option. We also reduce pressure on the boot procedure, as transient queues are currently removed on boot.\\r\\n\\r\\n#### What alternatives exist?\\r\\n\\r\\nQueue TTL should be used for auto-deleting unused, idle queues after some time of inactivity.\\r\\n\\r\\nExclusive queues: these are deleted once all connections to the queue are removed.\\r\\n\\r\\n \\r\\n### No longer use fsync for publisher confirms with Classic Queues\\r\\n\\r\\n#### Why are we making this decision?\\r\\n\\r\\nQuorum Queues provide greater data safety as compared to using non-mirrored classic queues, regardless of the use of fsync. Calling fsync manually results in loss of performance compared to letting the kernel decide when to flush to disk.\\r\\n\\r\\n#### What alternatives exist?\\r\\n\\r\\nCustomers should make use of Quorum Queues for replication and data safety.\\r\\n\\r\\n## Thank you\\r\\n\\r\\nThank you for reading. If you have any thoughts on the above, please fill in our [survey](https://docs.google.com/forms/d/e/1FAIpQLSfDjOigPhdd8z4l9DzSbHie0AfgAgsJESsQlvVOEAoDIYjzDA/viewform?usp=sf_link) and let us know how you feel about the proposed changes!"},{"id":"/2021/07/28/rabbitmq-streams-message-deduplication","metadata":{"permalink":"/rabbitmq-website/blog/2021/07/28/rabbitmq-streams-message-deduplication","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-07-28-rabbitmq-streams-message-deduplication/index.md","source":"@site/blog/2021-07-28-rabbitmq-streams-message-deduplication/index.md","title":"Message Deduplication with RabbitMQ Streams","description":"RabbitMQ Streams Overview introduced streams, a new feature in RabbitMQ 3.9 and RabbitMQ Streams First Application provided an overview of the programming model with the stream Java client. This post covers how to deduplicate published messages in RabbitMQ Streams.","date":"2021-07-28T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":8.835,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"Message Deduplication with RabbitMQ Streams","tags":["Streams","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Deprecation Announcements for 4.0","permalink":"/rabbitmq-website/blog/2021/08/21/4.0-deprecation-announcements"},"nextItem":{"title":"Connecting to Streams","permalink":"/rabbitmq-website/blog/2021/07/23/connecting-to-streams"}},"content":"[RabbitMQ Streams Overview](/blog/2021/07/13/rabbitmq-streams-overview) introduced streams, a new feature in RabbitMQ 3.9 and [RabbitMQ Streams First Application](/blog/2021/07/19/rabbitmq-streams-first-application) provided an overview of the programming model with the stream Java client. This post covers how to deduplicate published messages in RabbitMQ Streams.\\r\\n\\r\\nAs deduplication is a critical and intricate concept, the post will walk you through this mechanism step by step, from a naive and somewhat broken publishing application to an optimized and reliable implementation.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## The Problem With Duplicate Messages\\r\\n\\r\\nIt is quite easy for an application to publish the same message several times: the application is restarted in the wrong way and re-publishes all the data from the beginning, a network glitch makes the application reconnect and re-send a couple of messages, etc.\\r\\n\\r\\nEven though consuming applications should make their processing idempotent, duplicated published messages should be avoided as much as possible, as they can slow down processing and use extra space.\\r\\n\\r\\nThis post will start from a simple application that generates lots of duplicate messages (to help grasp the problem) and will improve it little by little to get a robust solution at the end.\\r\\n\\r\\n## Publishing Without Deduplication\\r\\n\\r\\nThe publishing program mimics an application that reads records from a data source and publish a message for each a of these records:\\r\\n\\r\\n```java\\r\\nProducer producer = environment.producerBuilder()\\r\\n  .stream(\\"deduplication-stream\\")\\r\\n  .build();\\r\\nint messageCount = 10;\\r\\nrecords(0, messageCount).forEach(record -> {\\r\\n  Message message = producer.messageBuilder()\\r\\n    .addData(record.content().getBytes(StandardCharsets.UTF_8))\\r\\n    .build();\\r\\n  producer.send(message, confirmationStatus -> latch.countDown());\\r\\n});\\r\\n```\\r\\n\\r\\nWe suppose the application reads _all_ the records available, and that number is 10 for the first run.\\r\\nIn case you want a reminder on the stream Java client API, you can read [RabbitMQ Streams First Application](/blog/2021/07/19/rabbitmq-streams-first-application). \\r\\n\\r\\nIf you want to run the code as you are reading, you can move on to the next section.\\r\\nNote you can follow the remaining of the post without running anything, so you can skip the next section if you don\'t want to try out the code.\\r\\n\\r\\n### Setting Up The Sample Project\\r\\n\\r\\nRunning the samples requires Docker, Git, and Java 8 or higher installed.\\r\\nYou can start the broker with the following command:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --name rabbitmq -p 5552:5552 \\\\\\r\\n    -e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\'-rabbitmq_stream advertised_host localhost\' \\\\\\r\\n    rabbitmq:3.9\\r\\n```\\r\\n\\r\\nYou need then to enable the stream plugin:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_stream\\r\\n```\\r\\n\\r\\nThe [code is hosted on GitHub](https://github.com/acogoluegnes/rabbitmq-streams-blog-posts).\\r\\nHere is how to clone the repository and create the stream used in the samples:\\r\\n\\r\\n```shell\\r\\ngit clone https://github.com/acogoluegnes/rabbitmq-streams-blog-posts.git\\r\\ncd rabbitmq-streams-blog-posts\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$CreateEmptyStream\'\\r\\n```\\r\\n\\r\\nOK, you are all set, let\'s run the publishing application.\\r\\n\\r\\n### Running The Publisher On The First Day\\r\\n\\r\\nRun the publishing application with the following command:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$PublishFirstDay\'\\r\\nConnecting...\\r\\nConnected.\\r\\nPublishing 10 messages.\\r\\nMessages confirmed? yes\\r\\n```\\r\\n\\r\\nWith this first run, the application read all the records from the data source (that is 10 records overall for this run) and send a message for each of them.\\r\\nWe can check the content of the stream with the following command:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$Consume\'        \\r\\nConnecting...\\r\\nConnected.\\r\\nStarting consuming, press Enter to exit...\\r\\nmessage 0\\r\\nmessage 1\\r\\nmessage 2\\r\\nmessage 3\\r\\nmessage 4\\r\\nmessage 5\\r\\nmessage 6\\r\\nmessage 7\\r\\nmessage 8\\r\\nmessage 9\\r\\n```\\r\\n\\r\\nSo far, so good, we published 10 messages and we can see 10 messages in the stream.\\r\\nLet\'s now if our application is viable and keeps working correctly for a second run.\\r\\n\\r\\n### Running the Publisher On The Second Day\\r\\n\\r\\nWe can imagine now that we run the application on the next day and the data source contains 10 additional records, so 20 records overall.\\r\\nOur publishing application is dumb: it will read everything from the data source and publishing messages.\\r\\nLet\'s try:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$PublishSecondDay\'\\r\\nConnecting...\\r\\nConnected.\\r\\nPublishing 20 messages.\\r\\nMessages confirmed? yes\\r\\n```\\r\\n\\r\\nAnd the content of the stream now:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$Consume\'\\r\\nConnecting...\\r\\nConnected.\\r\\nStarting consuming, press Enter to exit...\\r\\nmessage 0\\r\\nmessage 1\\r\\nmessage 2\\r\\n...\\r\\nmessage 9\\r\\nmessage 0\\r\\nmessage 1\\r\\nmessage 2\\r\\n...\\r\\nmessage 9\\r\\nmessage 10\\r\\nmessage 11\\r\\n...\\r\\nmessage 19\\r\\n```\\r\\n\\r\\nWe see 30 messages: the 10 from the first run and the 20 from the second run.\\r\\nThe first 10 appears twice, so our stream contains duplicate.\\r\\nWith the way we implemented the application this is expected, but we have to fix this, because we just want to the new records to be published on the second run.\\r\\n\\r\\nThis is when _deduplication_ in RabbitMQ Streams comes in.\\r\\n\\r\\n## Publishing With Deduplication\\r\\n\\r\\nWe need 2 things to enable deduplication on publishing:\\r\\n\\r\\n* a _name_ for the producer\\r\\n* a strictly increasing sequence value for each record, the _publishing ID_\\r\\n\\r\\nThe [stream Java client documentation](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#outbound-message-de-deduplication) provides more details about the producer name and the publishing ID.\\r\\nNote message deduplication is not specific to the stream Java client, it can be implemented by any client as long as it complies to the semantics.\\r\\n\\r\\nWe just have to pick a name for our publishing application and keep this name along the different runs.\\r\\nFor the publishing ID, we can use the ID of a record: it happens to be unique and the records are returned sorted by ID (e.g. just like records from a database with a numeric primary key and the appropriate query).\\r\\n\\r\\nHere is now our publishing application with the producer name and publishing ID changes:\\r\\n\\r\\n```java\\r\\nProducer producer = environment.producerBuilder()\\r\\n  .stream(\\"deduplication-stream\\")\\r\\n  .name(\\"app-1\\") // provide a name for the producer\\r\\n  .confirmTimeout(Duration.ZERO) // to never stop retrying\\r\\n  .build();\\r\\nint messageCount = 10;\\r\\nrecords(0, messageCount).forEach(record -> {\\r\\n  Message message = producer.messageBuilder()\\r\\n    .publishingId(record.id()) // set the publishing ID\\r\\n    .addData(record.content().getBytes(StandardCharsets.UTF_8))\\r\\n    .build();\\r\\n  producer.send(message, confirmationStatus -> latch.countDown());\\r\\n});\\r\\n```\\r\\n\\r\\nThe broker will keep track of the last publishing ID for this producer.\\r\\nWe\'ll see how this allows to deduplicate messages.\\r\\n\\r\\n### Running The Publisher On The First Day\\r\\n\\r\\nLet\'s re-create our stream first:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$CreateEmptyStream\'\\r\\nConnection...\\r\\nConnected. Trying to delete stream if it exists.\\r\\nStream deleted.\\r\\nCreating \'deduplication-stream\' stream.\\r\\nStream created.\\r\\n```\\r\\n\\r\\nThen we can run our improved publishing application a first time:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$PublishDedupFirstDay\'\\r\\nConnecting...\\r\\nConnected.\\r\\nPublishing 10 messages with deduplication enabled.\\r\\nMessages confirmed? yes\\r\\n```\\r\\n\\r\\nOK, 10 messages in the data source on the first day.\\r\\n\\r\\n### Running The Publisher On The Second Day\\r\\n\\r\\nWe run now our application on the second day, with the extra 10 records.\\r\\nOur application is less dumb that the first time: it uses the producer name and the publishing ID for deduplication. But it still reads _all_ the records from the data source:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$PublishDedupSecondDay\'\\r\\nConnecting...\\r\\nConnected.\\r\\nPublishing 20 messages with deduplication enabled.\\r\\nMessages confirmed? yes\\r\\n```\\r\\n\\r\\nAnd the content of the stream:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$Consume\'\\r\\nConnecting...\\r\\nConnected.\\r\\nStarting consuming, press Enter to exit...\\r\\nmessage 0\\r\\nmessage 1\\r\\nmessage 2\\r\\n...\\r\\nmessage 9\\r\\nmessage 10\\r\\nmessage 11\\r\\nmessage 12\\r\\n...\\r\\nmessage 19\\r\\n```\\r\\n\\r\\nNo duplicates this time, nice!\\r\\nEven though we re-published the first 10 messages, the broker managed to filter them out.\\r\\nIt knew that it should ignore all the messages with a publishing ID lesser than 9 (the last value in the first run).\\r\\nNote even though it filtered out these duplicates, it nevertheless confirmed them to the client.\\r\\n\\r\\nThis is much better that our first application where we ended up with duplicates, but there\'s still a problem: the application re-sends _all_ the messages every time.\\r\\nIf the data keeps growing, the application will take more and more time for each run.\\r\\nFortunately it is possible to find out where the application left off in the last run.\\r\\n\\r\\n## Know Where You Left Off: Making The Publisher Smarter\\r\\n\\r\\nWe\'ll see in this section how to make the publishing application even smarter by using not only deduplication but also querying the broker to for the last publishing ID it sent. \\r\\n\\r\\n### Running The Publisher On The First Day\\r\\n\\r\\nWe have to re-create our empty stream:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$CreateEmptyStream\'\\r\\nConnection...\\r\\nConnected. Trying to delete stream if it exists.\\r\\nStream deleted.\\r\\nCreating \'deduplication-stream\' stream.\\r\\nStream created.\\r\\n```\\r\\n\\r\\nAnd we can re-use our publishing application to send the first 10 messages:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$PublishDedupFirstDay\'\\r\\nConnecting...\\r\\nConnected.\\r\\nPublishing 10 messages with deduplication enabled.\\r\\nMessages confirmed? yes\\r\\n```\\r\\n\\r\\nThis version of the application is not the smartest, but it is enough for \\"the first day\\".\\r\\n\\r\\n### Running The (Smart) Publisher On The First Day\\r\\n\\r\\nThe publishing application needs to do better for the second day, where the data source contains now 20 messages.\\r\\nIt can use the `Producer#getLastPublishingId` method which queries the broker for the last publishing ID of this producer for this stream.\\r\\nThe application can add 1 to this value and it will get its starting point.\\r\\nThen it just has to select the records from this point until the last record available.\\r\\nThis way it does not re-publish from the beginning.\\r\\nThe following code shows how to do this:\\r\\n\\r\\n```java\\r\\nProducer producer = environment.producerBuilder()\\r\\n  .stream(\\"deduplication-stream\\")\\r\\n  .name(\\"app-1\\") // provide a name for the producer\\r\\n  .confirmTimeout(Duration.ZERO) // to never stop retrying\\r\\n  .build();\\r\\nlong start = producer.getLastPublishingId() + 1; // get last publishing ID and add 1\\r\\nint messageCount = 20;\\r\\nrecords(start, messageCount).forEach(record -> {\\r\\n  Message message = producer.messageBuilder()\\r\\n    .publishingId(record.id()) // set the publishing ID\\r\\n    .addData(record.content().getBytes(StandardCharsets.UTF_8))\\r\\n    .build();\\r\\n  producer.send(message, confirmationStatus -> latch.countDown());\\r\\n});\\r\\n```\\r\\n\\r\\nLet\'s run now this smart publisher:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$PublishSmartDedupSecondDay\'\\r\\nConnecting...\\r\\nConnected.\\r\\nStarting publishing at 10\\r\\nPublishing 10 message with deduplication enabled.\\r\\nMessages confirmed? yes\\r\\n```\\r\\n\\r\\nSo the publisher starts at 10 (9, the last publishing ID of the first run, + 1) and publishes the 10 (20, total, - 10 already published) new messages.\\r\\nWe can check the content of the stream:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.Deduplication$Consume\'\\r\\nConnecting...\\r\\nConnected.\\r\\nStarting consuming, press Enter to exit...\\r\\nmessage 0\\r\\nmessage 1\\r\\nmessage 2\\r\\n...\\r\\nmessage 9\\r\\nmessage 10\\r\\nmessage 11\\r\\nmessage 12\\r\\n...\\r\\nmessage 19\\r\\n```\\r\\n\\r\\nWe get the expected number of messages in the stream, but this time with an optimized publishing application.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nThis blog covered the deduplication feature of RabbitMQ Streams.\\r\\n\\r\\n* the broker can detect and filter out duplicate messages\\r\\n* a name for the producing application and a publishing ID are required to enable deduplication\\r\\n* the producer name must be unique and re-used between the application restarts\\r\\n* the publishing ID is a strictly increasing sequence, it is usually the identifier of a given message (e.g. primary key for a database record, line in a file)\\r\\n* applications should query the broker for the last publishing ID they used to restart where they left off"},{"id":"/2021/07/23/connecting-to-streams","metadata":{"permalink":"/rabbitmq-website/blog/2021/07/23/connecting-to-streams","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-07-23-connecting-to-streams/index.md","source":"@site/blog/2021-07-23-connecting-to-streams/index.md","title":"Connecting to Streams","description":"RabbitMQ Streams Overview introduced streams, a new feature in RabbitMQ 3.9.","date":"2021-07-23T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":12.465,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"Connecting to Streams","tags":["Streams","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Message Deduplication with RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/07/28/rabbitmq-streams-message-deduplication"},"nextItem":{"title":"First Application With RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/07/19/rabbitmq-streams-first-application"}},"content":"<!-- diagrams: https://drive.google.com/drive/folders/1ZLgazMBjma_wal2bcKZvFl4q9zB-cuQG?usp=sharing -->\\r\\n[RabbitMQ Streams Overview](/blog/2021/07/13/rabbitmq-streams-overview) introduced streams, a new feature in RabbitMQ 3.9.\\r\\nThis post covers how client applications should connect to RabbitMQ nodes to get the most benefit from streams when the [stream protocol](https://github.com/rabbitmq/rabbitmq-server/blob/v3.9.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc) is in use.\\r\\n\\r\\nStreams are optimized for high throughput scenarios, that\'s why technical details like data locality are critical to get the best out of your RabbitMQ cluster.\\r\\nClient libraries can handle most of the details, but a basic understanding of how things work under the hood is essential when a setup involves extra layers like containers and load balancers. Keep reading if you want to learn more about streams and avoid some headaches when deploying your first stream applications!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Topology of a Stream\\r\\n\\r\\nA stream is replicated and persistent, it is composed of a _leader_ Erlang process and _replica_ Erlang processes. These processes are spread across the nodes of a RabbitMQ cluster, as shown in the following diagram:\\r\\n\\r\\n![A stream is a replicated and persistent data structure. It has a leader process which accepts write operations and replicas which can dispatch messages to applications.](stream-topology.svg)\\r\\n\\r\\nOnly the leader process handles write operations like inbound messages. Any _member_ of the stream – leader and replicas – can dispatch messages to client applications.\\r\\n\\r\\nAn application that publishes to a stream using the [stream protocol](https://github.com/rabbitmq/rabbitmq-server/blob/v3.9.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc) can connect to any node in the cluster: messages will automatically go from the connection node to the node that hosts the leader process.\\r\\nIt does not require a PhD to understand that the operation is not optimal if the connection and the stream leader are not on the same node.\\r\\n_An application that publishes to a stream should connect to the node that hosts the leader of the stream, to avoid an extra network hop_.\\r\\n\\r\\nThe story is a bit different for consuming applications.\\r\\nWith the stream protocol, messages are dispatched to applications using [`sendfile`](https://man7.org/linux/man-pages/man2/sendfile.2.html): file chunks that contain messages are sent directly from the node file system to the network socket, without going through user space.\\r\\nThis optimization requires that _the node the consuming application is connected to hosts a member of the stream_.\\r\\nWhether this member is the leader or a replica does not matter, as long the data is on the file system, ready to go through the network socket with `sendfile`.\\r\\n\\r\\nThis constraint for consuming applications does not seem too harsh: in the diagram above, each node has a member of the stream, so an application can connect to any node to consume.\\r\\nBut imagine a 5-node cluster with streams using a replication factor of 2: each stream will have members only on 3 nodes out of the 5 nodes.\\r\\nIn this case, consuming applications have to pick their node appropriately.\\r\\n\\r\\nWith this knowledge in mind, let\'s try now to come up with some best practices. \\r\\n\\r\\n## Well-behaved Clients\\r\\n\\r\\nSo a publishing application can connect to any node of a cluster, it will always reach the leader process.\\r\\nA consuming application must connect to a node that hosts a member of the target stream, and this member can be the leader or a replica.\\r\\nClient applications can stick to these rules, but the following best practices should be enforced whenever possible:\\r\\n\\r\\n* **a publishing application should always connect to the node that hosts the leader process of the target stream**.\\r\\n* **a consuming application should always connect to a node that hosts a replica of the target stream**.\\r\\n\\r\\nThe following diagram illustrates these best practices:\\r\\n\\r\\n![Client applications that publish to a stream should connect to the node that hosts the stream leader, clients applications that consume from a stream should connect to a node that hosts a replica of this stream.](well-behaved-clients.svg)\\r\\n\\r\\nAs stated previously, connecting directly to the node of the stream leader avoids a network hop, as messages have to go the leader process anyway.\\r\\nWhat about always using a replica for consuming? Well, it just offloads the leader process, which is already busy dealing with all the write operations.\\r\\n\\r\\nThese best practices should be enforced ideally by client libraries, all these technical details should not leak into the application code.\\r\\nWe\'ll see next how the stream protocol allows client applications to find out about the topology of a given stream.\\r\\n\\r\\n## Streams Across a Cluster\\r\\n\\r\\nBefore moving on to the `metadata` command of the stream protocol, let\'s clarify how streams (plural) spread across the nodes of a RabbitMQ cluster.\\r\\nWe mentioned that a stream has a leader Erlang process located on a node and replica Erlang processes located on other nodes.\\r\\nWith several streams, all these Erlang processes (think \\"very lightweight thread\\" for an Erlang process) spread across the cluster nodes, and at no point a given RabbitMQ node is supposed to host all the stream leaders.\\r\\n\\r\\nThink of a stream as a small cluster in the RabbitMQ cluster, as illustrated with several streams in the next diagram:\\r\\n\\r\\n![Stream leaders spread across the nodes of a cluster. This means that a given node does not have to contain all the leaders at some point.](stream-spread.svg)\\r\\n\\r\\nThe way leaders are spread across the cluster depends on the \\"leader locator strategy\\" when a stream is created.\\r\\nThe default strategy is \\"least leaders\\", which means picking the node with least number of stream leaders for the leader of the new stream.\\r\\nThere are other strategies, but covering them is out of the scope of this post.\\r\\n\\r\\nWith this clarification in mind, let\'s move on to the way to find out about the topology of streams.\\r\\n\\r\\n## The `metadata` command\\r\\n\\r\\nThe stream protocol provides a [`metadata` command](https://github.com/rabbitmq/rabbitmq-server/blob/v3.9.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc#metadata) to query the topology of one or several streams.\\r\\nFor each queried stream, the response contains the hostname and port of the nodes that host the leader and replicas.\\r\\n\\r\\nThe following diagram illustrates how a client application already connected to one of the nodes can find out about the topology of a given stream:\\r\\n\\r\\n![A client can find out about the topology of a stream by using the `metadata` command.](metadata-command.svg)\\r\\n\\r\\n_So a common pattern is to provide one or several entry points to a client library, use the `metadata` command once connected to learn the topology of a target stream, and then connect to the appropriate nodes depending on the operations (publishing or consuming)_:\\r\\n\\r\\n![Once a client application knows about the topology of a stream, it can connect to the appropriate nodes to work with it: the node that hosts the stream leader to publish and nodes that host the stream replicas to consume.](use-connection-hints.svg)\\r\\n\\r\\nThe `metadata` command is key for client libraries to enforce the best practices mentioned above.\\r\\n\\r\\nUnfortunately, the metadata returned by default are not always accurate, or at least accurate enough for the client application to connect. Let\'s see an example.\\r\\n\\r\\n## Limitations of Default Metadata\\r\\n\\r\\nThe stream plugin returns the hostname of each node for the host metadata (this is the host part of the Erlang node name to be more accurate, but this does not matter much here).\\r\\nThis is fine... as long as the client can resolve the hostname to connect to the node!\\r\\n\\r\\nIn these times of containers, the hostname can be a blurry concept, which does not make much sense as soon as you are out of the container.\\r\\nThe following diagram illustrates a 3-node RabbitMQ cluster where the nodes are containers running on different VMs.\\r\\nA client application can connect to the nodes if the ports are mapped correctly, but there\'s no way it can do it by using the hostname of the containers.\\r\\n\\r\\n![Using the hostname in metadata will not work when the nodes run in containers, as it is very unlikely the client and the nodes can see each other directly.](use-connection-hints-with-docker.svg)\\r\\n\\r\\nThe stream plugin does its best, but it cannot do miracles here.\\r\\nFortunately, it is possible to configure what a node returns when it is asked its \\"coordinates\\" for the `metadata` command.\\r\\n\\r\\n## Advertised Host and Port\\r\\n\\r\\nThe [`advertised_host` and `advertised_port` configuration entries](/docs/stream#advertised-host-port) of the stream plugin can be set to tell a node what to return when asked how to be contacted.\\r\\nThere is no trick here: the plugin will just trust the operator that did the configuration and will blindly return these values.\\r\\nThis means a client application must be able to connect to the node using this information.\\r\\n\\r\\n![It is possible to configure advertised host and port if the default values are not appropriate.](metadata-hints.svg)\\r\\n\\r\\nThe `advertised_host` and `advertised_port` settings should help solve all the headaches with client applications not able to connect to nodes because of incorrect stream metadata.\\r\\nAlways keep them in mind if you deploy a RabbitMQ cluster with containerized nodes and if you use streams.\\r\\n\\r\\nThere is still one common use case where this discovery mechanism can be problematic: when a load balancer sits between client applications and the cluster nodes.\\r\\n\\r\\n## With a Load Balancer\\r\\n\\r\\nHaving a load balancer in front of a RabbitMQ cluster is a common scenario.\\r\\nThis may cause some problems because of the way streams work, but there are always solutions.\\r\\nIf we come back to the metadata command but with a load balancer, things will go wrong: the client will receive the nodes information and will use it to connect _directly_ to the nodes, bypassing the load balancer.\\r\\nThe following diagram illustrates this unfortunate situation:\\r\\n\\r\\n![Metadata hints are less useful when a load balancer sits between the client and the nodes. The client application will skip the load balancer and try to connect directly to the nodes. This can be impossible or a security concern.](load-balancer.svg)\\r\\n\\r\\nThis is probably not what you want.\\r\\n\\r\\nWhat about setting the `advertised_host` and `advertised_port` configuration entries to use the load balancer information?\\r\\nThis way client applications will always connect to the load balancer!\\r\\nThis is not such a great idea, because we won\'t be able to enforce the best practices (publishing to leader, consuming from replica) and in a deployment where streams are not on all nodes, consuming will fail if the application ends up being connected to a node without a stream member.\\r\\n\\r\\nOK, this is a bit depressing, but cheer up, as client libraries can implement a workaround to solve this problem.\\r\\n\\r\\n## Client Workaround With a Load Balancer\\r\\n\\r\\nA client application can still always connect to the load balancer and end up connected to the appropriate node.\\r\\nHow can it do it?\\r\\nTwo steps:\\r\\n\\r\\n* use the `metadata` command but _ignore_ the information and always connect to the load balancer\\r\\n* retry connecting until it gets connected to the appropriate node\\r\\n\\r\\nYou may wonder how to find out about the node once a connection is established?\\r\\nThe \\"coordinates\\" of the node (hostname and port, or `advertised_host` and `advertised_port` if configured) are available in a stream protocol connection.\\r\\nSo a client application can know to which node it is connected to.\\r\\n\\r\\n**This means `advertised_host` and `advertised_port` should not be configured when a load balancer is in use.**\\r\\nThe \\"coordinates\\" of a node that the `metadata` command returns are not used to connect in this case, as the client always connects to the load balancer.\\r\\nThey are used to _correlate_ the connection the load balancer provides with the node the client expects, and the hostname is perfect for this.\\r\\n\\r\\nLet\'s take an example:\\r\\n\\r\\n* a publishing application knows the leader of its targeted stream is on `node-1` thanks to the response of a `metadata` request\\r\\n* it creates a new connection using the load balancer address\\r\\n* the load balancer chooses to connect to `node-3`\\r\\n* the connection is properly established but the client application finds out it is connected to `node-3`, it immediately closes the connection, and retries\\r\\n* this time the load balancer chooses `node-1`\\r\\n* the application is happy about the node it\'s connected to, it moves on to publishing using this connection\\r\\n\\r\\nThe following diagram illustrates this process:\\r\\n\\r\\n![A client can choose to ignore the metadata hints and always use the load balancer. As stream connections convey the node hostname they originate from, the client can know whether it is connected to the right node or not, and keep the connection or close it and retry.](load-balancer-ignore-metadata.svg)\\r\\n\\r\\nAs stream connections are long-lived and a stream application is not supposed to have a lot of connection churn, retrying to connect is not a concern here.\\r\\n\\r\\nThis solution also assumes that the load balancer will not always connect to the same backend server. Round-robin is an appropriate balancing strategy for this case.\\r\\n\\r\\nIt should also be clear now that setting `advertised_host` and `advertised_port` is not necessary when using this technics and setting them to the load balancer coordinates for all nodes is a bad idea.\\r\\nLetting each node returns its hostname is fine here, as the hostname is supposed to be unique in a network.\\r\\n\\r\\nSo the onus is on the client library. Let\'s see now how this is implemented with the stream Java client.\\r\\n\\r\\n## Using the Stream Java Client With a Load Balancer\\r\\n\\r\\nThe [stream Java client](https://github.com/rabbitmq/rabbitmq-stream-java-client) provides [an `AddressResolver` extension point](https://github.com/rabbitmq/rabbitmq-stream-java-client/blob/main/src/main/java/com/rabbitmq/stream/AddressResolver.java).\\r\\nIt is used whenever a new connection is created: from the passed-in `Address` (the node to connect to based on the `metadata` query), the address resolver can provide some logic to compute the actual address to use.\\r\\nThe default implementation just returns the given address.\\r\\nIf you want to implement the workaround presented above when a load balancer is in use, always return the address of the load balancer, as shown in the following code snippet:\\r\\n\\r\\n```java\\r\\nAddress entryPoint = new Address(\\"my-load-balancer\\", 5552);\\r\\nEnvironment environment = Environment.builder()\\r\\n    .host(entryPoint.host())\\r\\n    .port(entryPoint.port())\\r\\n    .addressResolver(address -> entryPoint)\\r\\n    .build();\\r\\n```\\r\\n\\r\\nThe [stream PerfTest tool](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#the-performance-tool) also supports this mode when the `--load-balancer` option is enabled.\\r\\nHere is how to tell the tool to always use the same entry point for publishers and consumers connections:\\r\\n\\r\\n```shell\\r\\n# with the Java binary\\r\\njava -jar stream-perf-test.jar --uris rabbitmq-stream://my-load-balancer:5552 --load-balancer\\r\\n\\r\\n# with Docker\\r\\ndocker run -it --rm pivotalrabbitmq/stream-perf-test --uris rabbitmq-stream://my-load-balancer:5552 --load-balancer\\r\\n```\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nThis post covered how client applications should connect when using the stream protocol.\\r\\nHere is the gist:\\r\\n\\r\\n* publishing applications should connect to the node that hosts the leader of the target stream\\r\\n* consuming applications should connect to a node that hosts of replica of the target stream\\r\\n* client applications must use the [`metadata` stream protocol command](https://github.com/rabbitmq/rabbitmq-server/blob/v3.9.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc#metadata) to learn about the topology of the streams they want to interact with\\r\\n* the stream [Java](https://github.com/rabbitmq/rabbitmq-stream-java-client) and [Go](https://github.com/rabbitmq/rabbitmq-stream-go-client) clients enforce these best practices\\r\\n* the `metadata` command returns by default the nodes hostname and listener port, which can be problematic e.g. when containers are in use\\r\\n* the [`advertised_host` and `advertised_port` configuration entries](/docs/stream#advertised-host-port) allow to specify what values a node should return for the `metadata` command\\r\\n* a load balancer can confuse a client library that will try to bypass it to connect directly to the nodes\\r\\n* client libraries can provide a workaround to work properly with a load balancer\\r\\n* the stream [Java](https://github.com/rabbitmq/rabbitmq-stream-java-client) and [Go](https://github.com/rabbitmq/rabbitmq-stream-go-client) clients implement such a workaround"},{"id":"/2021/07/19/rabbitmq-streams-first-application","metadata":{"permalink":"/rabbitmq-website/blog/2021/07/19/rabbitmq-streams-first-application","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-07-19-rabbitmq-streams-first-application/index.md","source":"@site/blog/2021-07-19-rabbitmq-streams-first-application/index.md","title":"First Application With RabbitMQ Streams","description":"RabbitMQ Streams Overview introduced streams, a new feature in RabbitMQ 3.9.","date":"2021-07-19T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":6.29,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"First Application With RabbitMQ Streams","tags":["Streams","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Connecting to Streams","permalink":"/rabbitmq-website/blog/2021/07/23/connecting-to-streams"},"nextItem":{"title":"RabbitMQ Streams Overview","permalink":"/rabbitmq-website/blog/2021/07/13/rabbitmq-streams-overview"}},"content":"[RabbitMQ Streams Overview](/blog/2021/07/13/rabbitmq-streams-overview) introduced streams, a new feature in RabbitMQ 3.9.\\r\\nThis post continues by showing how to use streams with the Java client.\\r\\nWe will write our first application that publishes messages to a stream, and then consumes them.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Starting RabbitMQ with Streams Enabled\\r\\n\\r\\nLet\'s start a RabbitMQ Docker container:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --name rabbitmq -p 5552:5552 \\\\\\r\\n    -e RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=\'-rabbitmq_stream advertised_host localhost\' \\\\\\r\\n    rabbitmq:3.9\\r\\n```\\r\\n\\r\\nStreams ship as a core plugin in RabbitMQ 3.9, so we have to make sure this plugin is enabled.\\r\\nOpen a new terminal tab and execute the following command:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_stream\\r\\n```\\r\\n\\r\\nThe next step is to *connect* a client application to the stream plugin.\\r\\n\\r\\n## Connecting to RabbitMQ Streams\\r\\n\\r\\nWe will use the [stream Java client](https://github.com/rabbitmq/rabbitmq-stream-java-client) to interact with streams.\\r\\nThe client documentation covers how to declare the appropriate dependencies in a [Maven project](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#maven) and in a [Gradle project](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#gradle), so we can focus on the code in this post.\\r\\n\\r\\n\\r\\nThe entry point of the stream Java client is the `Environment`. It deals with stream management and the creation of publisher and consumer instances.\\r\\nHere is how to create an `Environment` instance:\\r\\n\\r\\n```java\\r\\ntry (Environment environment = Environment.builder()\\r\\n        .uri(\\"rabbitmq-stream://localhost:5552\\").build()) {\\r\\n\\r\\n // ...\\r\\n\\r\\n}\\r\\n```\\r\\n\\r\\nWe have the environment, let\'s create a stream.\\r\\n\\r\\n## Creating a Stream\\r\\n\\r\\nThe environment provides an API to create streams, we\'ll use it to create a `first-application-stream` stream with all the defaults:\\r\\n\\r\\n```java\\r\\nenvironment.streamCreator().stream(\\"first-application-stream\\").create();\\r\\n```\\r\\n\\r\\nThe stream is there, time to publish to it.\\r\\n\\r\\n## Publishing to a Stream\\r\\n\\r\\nWe need to create a `Producer` instance to publish to the stream. We use again the `Environment` to create this object:\\r\\n\\r\\n\\r\\n```java\\r\\nProducer producer = environment\\r\\n    .producerBuilder()\\r\\n    .stream(\\"first-application-stream\\") // stream to publish to\\r\\n    .build();\\r\\n```\\r\\n\\r\\nWe are going to publish some messages in a loop, let\'s proceed step by step and build the skeleton of the publishing loop:\\r\\n\\r\\n\\r\\n```java\\r\\nint messageCount = 1_000_000;\\r\\nCountDownLatch confirmLatch = new CountDownLatch(messageCount);\\r\\nIntStream.range(0, messageCount).forEach(i -> {\\r\\n    // send one message\\r\\n});\\r\\nboolean done = confirmLatch.await(1, TimeUnit.MINUTES);\\r\\n```\\r\\n\\r\\nNote the use of a `CountDownLatch` to make sure we move on only when we get all the publish confirmations, more on this later.\\r\\n\\r\\nWe will focus now on the creation of a message.\\r\\nRabbitMQ Streams uses the [AMQP 1.0 message format](https://www.amqp.org/resources/specifications), as it is a flexible and powerful format, with an advanced type system.\\r\\nUsing AMQP 1.0 message format allows for interoperability, making streams compatible with the other protocols RabbitMQ supports (AMQP 0.9.1 and 1.0, MQTT, STOMP.)\\r\\n\\r\\nThe stream Java client provides a message builder interface to create messages, we use it to create a message with a couple of properties and a binary payload:\\r\\n\\r\\n```java\\r\\nMessage message = producer.messageBuilder()\\r\\n        .properties()\\r\\n            .creationTime(System.currentTimeMillis())\\r\\n            .messageId(i)\\r\\n        .messageBuilder()\\r\\n        .addData(\\"hello world\\".getBytes(StandardCharsets.UTF_8))\\r\\n        .build();\\r\\n```\\r\\n\\r\\nOK, we have our message instance, the next step is to publish it.\\r\\nBut let\'s get back quickly to this AMQP 1.0 message format thing.\\r\\nWe want to insist on the fact that RabbitMQ Streams uses only the AMQP 1.0 *message format*, not the AMQP 1.0 *protocol*.\\r\\nRabbitMQ Streams has its own binary protocol, that happens to convey messages encoded in AMQP 1.0 format in some of its frames.\\r\\nThe message encoding is actually a client responsibility: RabbitMQ Streams is message format agnostic.\\r\\nMessages are just byte arrays, e.g. `[100, 76, 240, ...]`.\\r\\nThe AMQP 1.0 message format however makes streams highly operable with other protocols, such as AMQP 0.9.1, MQTT, etc. which streams support by default.\\r\\n\\r\\nTime now to send our message, we just have to pass it in to the producer:\\r\\n\\r\\n```java\\r\\nproducer.send(message, confirmationStatus -> confirmLatch.countDown());\\r\\n```\\r\\n\\r\\nNote the second argument of the `send` method: this is the callback when the publish confirmation for this message arrives asynchronously.\\r\\nThis is how you can make sure messages are not lost.\\r\\nHere we just decrement the count of the `CoundDownLatch`.\\r\\n\\r\\nThis is what all of the above looks like in code:\\r\\n\\r\\n```java\\r\\nint messageCount = 1_000_000;\\r\\nCountDownLatch confirmLatch = new CountDownLatch(messageCount);\\r\\nIntStream.range(0, messageCount).forEach(i -> {\\r\\n    Message message = producer.messageBuilder()\\r\\n        .properties()\\r\\n            .creationTime(System.currentTimeMillis())\\r\\n            .messageId(i)\\r\\n        .messageBuilder()\\r\\n        .addData(\\"hello world\\".getBytes(StandardCharsets.UTF_8))\\r\\n        .build();\\r\\n    producer.send(message, confirmationStatus -> confirmLatch.countDown());\\r\\n});\\r\\nboolean done = confirmLatch.await(1, TimeUnit.MINUTES);\\r\\n```\\r\\n\\r\\n## Running the Publisher\\r\\n\\r\\nYou can run the publisher sample locally, the [code is hosted on GitHub](https://github.com/acogoluegnes/rabbitmq-streams-blog-posts).\\r\\nYou just need JDK 8 or higher installed, and a running instance of RabbitMQ 3.9 with the rabbit_stream plugin enabled, as described above.\\r\\n\\r\\n```shell\\r\\ngit clone https://github.com/acogoluegnes/rabbitmq-streams-blog-posts.git\\r\\ncd rabbitmq-streams-blog-posts\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.FirstApplication$Publish\'\\r\\n```\\r\\n\\r\\nYou should get an output like the following, confirming the messages has been taken into account by the broker:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nCreating stream...\\r\\nStream created\\r\\nCreating producer...\\r\\nProducer created\\r\\nSending 1,000,000 messages\\r\\nMessages sent, waiting for confirmation...\\r\\nAll messages confirmed? yes (1440 ms)\\r\\nClosing environment...\\r\\nEnvironment closed\\r\\n```\\r\\n\\r\\nThe `rabbitmq-streams stream_status` CLI command confirms the messages landed on the broker:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmq-streams stream_status first-application-stream\\r\\n```\\r\\n\\r\\nYou should see the following output:\\r\\n\\r\\n```\\r\\nStatus of stream first-application-stream on node rabbit@ba9dbabe12b8 ...\\r\\n┌────────┬─────────────────────┬────────┬──────────────────┬──────────────┬─────────┬──────────┐\\r\\n│ role   │ node                │ offset │ committed_offset │ first_offset │ readers │ segments │\\r\\n├────────┼─────────────────────┼────────┼──────────────────┼──────────────┼─────────┼──────────┤\\r\\n│ writer │ rabbit@ba9dbabe12b8 │ 999999 │ 999938           │ 0            │ 0       │ 1        │\\r\\n└────────┴─────────────────────┴────────┴──────────────────┴──────────────┴─────────┴──────────┘\\r\\n```\\r\\n\\r\\nI want to highlight the `offset` column, which tells us the index of the last message in the stream, `999,999` in the example above.\\r\\nThis confirms the stream contains 1 million messages (offsets start from `0`).\\r\\n\\r\\n## Consuming the Messages\\r\\n\\r\\nThe consuming code is straightforward.\\r\\nWe need to create a `Consumer` instance from the `Environment`.\\r\\nThis requires to set a few parameters: the stream to consume from, the offset to start consuming from — `first` here —, and the behavior when receiving a message.\\r\\nHere is the code:\\r\\n\\r\\n\\r\\n```java\\r\\nAtomicInteger messageConsumed = new AtomicInteger(0); // just a counter\\r\\nConsumer consumer = environment.consumerBuilder()\\r\\n    .stream(\\"first-application-stream\\") // stream to consume from\\r\\n    .offset(OffsetSpecification.first()) // where to start consuming\\r\\n    .messageHandler((context, message) -> messageConsumed.incrementAndGet()) // behavior\\r\\n    .build();\\r\\n```\\r\\n\\r\\nThe code just increments a counter when a new message is received.\\r\\n\\r\\n## Running the Consumer\\r\\n\\r\\nYou can run the consumer code with the following command:\\r\\n\\r\\n```shell\\r\\n./mvnw -q compile exec:java -Dexec.mainClass=\'com.rabbitmq.stream.FirstApplication$Consume\'\\r\\n```\\r\\n\\r\\nYou should see something like the following in the console:\\r\\n\\r\\n```\\r\\nConnecting...\\r\\nConnected\\r\\nStart consumer...\\r\\nConsumed 1,000,000 messages in 732 ms\\r\\nClosing environment...\\r\\nEnvironment closed\\r\\n```\\r\\n\\r\\nCongratulations! The messages made it to the consumer.\\r\\n\\r\\nYou can make sure a consumer can read and re-read messages _without removing them from the stream_ by running the consumer program several times.\\r\\nYou will get the same number of consumed messages each time.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nThis concludes the writing of our first RabbitMQ Streams application. Here are the main elements to remember:\\r\\n\\r\\n* The [stream Java client](https://github.com/rabbitmq/rabbitmq-stream-java-client) provides comprehensive support for RabbitMQ Streams.\\r\\n* The main API are `Environment`, `Producer`, and `Consumer`.\\r\\n* Messages use the rich and interoperable AMQP 1.0 format.\\r\\n* The stream Java client provide a high-level API, it deals with boilerplate and lets developers focus on application code.\\r\\n\\r\\nAs a bonus, here is a video that covers RabbitMQ Streams and the [stream Go client](https://github.com/rabbitmq/rabbitmq-stream-go-client):\\r\\n\\r\\n<iframe width=\\"560\\" height=\\"315\\" src=\\"https://www.youtube.com/embed/m47E3XUzdAM?si=02yJM-rBGpMThrNa\\" title=\\"YouTube video player\\" frameBorder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" allowFullScreen></iframe>\\r\\n\\r\\nThe RabbitMQ team is looking forward to hearing your feedback on streams and on the stream client libraries ([Java](https://github.com/rabbitmq/rabbitmq-stream-java-client), [Go](https://github.com/rabbitmq/rabbitmq-stream-go-client)).\\r\\nWe are planning to write a [.NET client](https://github.com/rabbitmq/rabbitmq-stream-dotnet-client) for the [stream protocol](https://github.com/rabbitmq/rabbitmq-server/blob/v3.9.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc), so if you have .NET skills, you can come up with design suggestions or even a prototype.\\r\\n\\r\\nStay tuned for other blog posts on streams, where we\'ll cover features like publishing de-duplication, offset tracking, and interoperability between protocols supported in RabbitMQ."},{"id":"/2021/07/13/rabbitmq-streams-overview","metadata":{"permalink":"/rabbitmq-website/blog/2021/07/13/rabbitmq-streams-overview","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-07-13-rabbitmq-streams-overview/index.md","source":"@site/blog/2021-07-13-rabbitmq-streams-overview/index.md","title":"RabbitMQ Streams Overview","description":"RabbitMQ 3.9 introduces a new type of data structure: streams. Streams unlock a set of use cases that could have been tedious to implement with \\"traditional\\" queues. Let\'s discover in this post how streams expand the capabilities of RabbitMQ.","date":"2021-07-13T00:00:00.000Z","tags":[{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.255,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"RabbitMQ Streams Overview","tags":["Streams","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"First Application With RabbitMQ Streams","permalink":"/rabbitmq-website/blog/2021/07/19/rabbitmq-streams-first-application"},"nextItem":{"title":"RabbitMQ 3.9.0 release calendar","permalink":"/rabbitmq-website/blog/2021/07/09/rabbitmq-3.9.0-release-calendar"}},"content":"RabbitMQ 3.9 introduces a new type of data structure: *streams*. Streams unlock a set of use cases that could have been tedious to implement with \\"traditional\\" queues. Let\'s discover in this post how streams expand the capabilities of RabbitMQ.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## What are RabbitMQ Streams\\r\\n\\r\\nA RabbitMQ stream models an *append-only log* with *non-destructive consuming semantics*. This means that – contrary to traditional queues in RabbitMQ – consuming from a stream does not remove messages.\\r\\n\\r\\nStreams in RabbitMQ are *persisted and replicated*. This translates to data safety and availability (in case of the loss of a node),\\r\\nas well as scaling (reading the same stream from different nodes.)\\r\\n\\r\\nStreams can look a bit opinionated compared to the very versatile queues, but they come in handy for a set of use cases. They expand the capabilities of RabbitMQ in a very nice way.\\r\\n\\r\\n## What are streams good for\\r\\n\\r\\nRabbitMQ Streams shine for the following use cases:\\r\\n\\r\\n* **large fan-outs**: where many applications need to read the same messages _(with traditional queues, that would require declaring a queue per application and delivering a copy of the same message to each of them)_\\r\\n* **large backlogs**: streams store messages on disk, not in-memory, so the only limit is the disk capacity\\r\\n* **replay & time-traveling**: consumers can attach anywhere in a stream, using an absolute offset or a timestamp, and they can read and re-read the same data\\r\\n* **high throughput**: streams are super fast compared to traditional queues, several orders of magnitude faster\\r\\n\\r\\nAnd as streams ship as a [core plugin](/docs/stream) in RabbitMQ 3.9, you can use them along all the already existing RabbitMQ features.\\r\\n\\r\\n## RabbitMQ Streams in a nutshell\\r\\n\\r\\nLet\'s get more specific about streams:\\r\\n\\r\\n* streams provide at-least-once guarantees thanks to publisher confirms and message de-duplication on the publisher side.\\r\\n* streams support server-side offset tracking, to let consumers restart where they left off.\\r\\n* as streams have non-destructive semantics, they can grow a lot. RabbitMQ Streams can truncate streams automatically according to \\r\\nretention policies, based on size or age.\\r\\n* streams are accessible through a dedicated, blazing fast [binary protocol](https://github.com/rabbitmq/rabbitmq-server/blob/v3.9.x/deps/rabbitmq_stream/docs/PROTOCOL.adoc) and through AMQP 0.9.1 & 1.0 (less fast).\\r\\n* the stream protocol is accessible thanks to the [stream plugin](/docs/stream), which ships in the core distribution of RabbitMQ 3.9.\\r\\n* RabbitMQ Streams support client-server TLS.\\r\\n* a modern, highly-optimized [Java client](https://github.com/rabbitmq/rabbitmq-stream-java-client) is available. It uses the stream protocol for better performance. It is fully [documented](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/).\\r\\n* a [Go client](https://github.com/rabbitmq/rabbitmq-stream-go-client) is available as well.\\r\\n* there is also a [performance tool](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#the-performance-tool) based on the Java client. And yes, it comes as a [Docker image](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/#with-docker-2).\\r\\n\\r\\nYou can have a look at the streams overview presentation from RabbitMQ Summit 2021 below if you want to learn more.\\r\\nIf you are in a hurry, you can skip it and go directly to the quick start with Docker in the next section.\\r\\n\\r\\n<iframe className=\\"speakerdeck-iframe\\" style={{border: \'0px\', background: \'rgba(0, 0, 0, 0.1) padding-box\', margin: \'0px\', padding: \'0px\', borderRadius: \'6px\', boxShadow: \'rgba(0, 0, 0, 0.2) 0px 5px 40px\', width: \'100%\', height: \'auto\', aspectRatio: \'560 / 315\',}} frameBorder=\\"0\\" src=\\"https://speakerdeck.com/player/24ed5ae0d4544c19ac714f6f7dede00a\\" title=\\"RabbitMQ Streams Overview at RabbitMQ Summit 2021\\" allowFullScreen data-ratio=\\"1.7777777777777777\\"></iframe>\\r\\n\\r\\nWithout further ado, let\'s make this thing run.\\r\\n\\r\\n## Quick start with Docker\\r\\n\\r\\nExercising a stream is very easy with Docker. Let\'s make sure you don\'t already have the Docker images we are about to use locally:\\r\\n\\r\\n```shell\\r\\ndocker rmi rabbitmq:3.9 pivotalrabbitmq/stream-perf-test\\r\\n```\\r\\n\\r\\nYou\'ll get an error message if the images are not on the computer, but this is fine.\\r\\n\\r\\nLet\'s create now a network for our server and performance tool containers to communicate:\\r\\n\\r\\n```shell\\r\\ndocker network create rabbitmq-streams\\r\\n```\\r\\n\\r\\nIt is time to start the broker:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --network rabbitmq-streams --name rabbitmq rabbitmq:3.9\\r\\n```\\r\\n\\r\\nThe broker should start in a few seconds. When it\'s ready, enable the stream plugin:\\r\\n\\r\\n```shell\\r\\ndocker exec rabbitmq rabbitmq-plugins enable rabbitmq_stream\\r\\n```\\r\\n\\r\\n\\r\\nNow launch the performance tool. It will create a stream, and publish and consume as fast as possible:\\r\\n\\r\\n```shell\\r\\ndocker run -it --rm --network rabbitmq-streams pivotalrabbitmq/stream-perf-test \\\\\\r\\n    --uris rabbitmq-stream://rabbitmq:5552\\r\\n```\\r\\n\\r\\nYou can let the performance tool run for a while and then stop it with `Ctrl+C`:\\r\\n\\r\\n```\\r\\n19, published 1180489 msg/s, confirmed 1180145 msg/s, consumed 1180648 msg/s, \\\\\\r\\n    latency min/median/75th/95th/99th 1537/7819/9631/12136/14425 µs, chunk size 2639\\r\\n20, published 1181929 msg/s, confirmed 1181597 msg/s, consumed 1182074 msg/s, \\\\\\r\\n    latency min/median/75th/95th/99th 1537/7838/9562/11967/14355 µs, chunk size 2657\\r\\n^C\\r\\nSummary: published 1205835 msg/s, confirmed 1205435 msg/s, consumed 1205477 msg/s, latency 95th 12158 µs, chunk size 2654\\r\\n```\\r\\n\\r\\nThese are numbers on a regular Linux workstation, what you\'ll get depends on your own setup. Note numbers can be significantly lower on macOS and Windows, as Docker runs in a virtualized environment on those operating systems.\\r\\n\\r\\nYou can then stop the broker container with `Ctrl+C` and delete the network:\\r\\n\\r\\n```shell\\r\\ndocker network rm rabbitmq-streams\\r\\n```\\r\\n\\r\\nIf you want to go further and start building applications, the [stream Java client documentation](https://rabbitmq.github.io/rabbitmq-stream-java-client/stable/htmlsingle/) is a good starting point.\\r\\n\\r\\nThis concludes our overview of RabbitMQ Streams, a new append-only log data structure with awesome capabilities and tooling. Stay tuned to discover more about streams in subsequent posts!"},{"id":"/2021/07/09/rabbitmq-3.9.0-release-calendar","metadata":{"permalink":"/rabbitmq-website/blog/2021/07/09/rabbitmq-3.9.0-release-calendar","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-07-09-rabbitmq-3.9.0-release-calendar/index.md","source":"@site/blog/2021-07-09-rabbitmq-3.9.0-release-calendar/index.md","title":"RabbitMQ 3.9.0 release calendar","description":"We intend to release RabbitMQ 3.9.0 on 26 July 2021. While we have been testing","date":"2021-07-09T00:00:00.000Z","tags":[],"readingTime":1.73,"hasTruncateMarker":true,"authors":[{"name":"Jean-Sébastien Pédron","url":"https://github.com/dumbbell","imageURL":"https://github.com/dumbbell.png","key":"jpedron","page":null},{"name":"Gerhard Lazu","key":"glazu","page":null}],"frontMatter":{"title":"RabbitMQ 3.9.0 release calendar","tags":[],"authors":["jpedron","glazu"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Streams Overview","permalink":"/rabbitmq-website/blog/2021/07/13/rabbitmq-streams-overview"},"nextItem":{"title":"Notify me when RabbitMQ has a problem","permalink":"/rabbitmq-website/blog/2021/05/03/alerting"}},"content":"We intend to release RabbitMQ 3.9.0 on 26 July 2021. While we have been testing\\r\\nit internally for months, with production-like workloads, we need your help to\\r\\ncheck that it is as stable and reliable as we believe it is.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThis is the\\r\\ntimeline that we have to work together on making 3.9.0 the best release for\\r\\nyou:\\r\\n\\r\\n| Milestone            | Anticipated Date | Notes                                                                         |\\r\\n| ---                  | ---              | ---                                                                           |\\r\\n| Code freeze          | 5 July 2021      | No new features or refactorings before the final release                      |\\r\\n| 3.9.0-rc.1 produced  | 9 July 2021      | All artefacts built & published                                               |\\r\\n| 3.9.0-rc.1 announced | 12 July 2021     | First release candidate (RC) is announced & made public for testing           |\\r\\n| 3.9.0-rc.2           | TBD              | If new issues are reported, a new RC with fixes is made available for testing |\\r\\n| 3.9.0 produced       | 23 July 2021     | Final release is built & published                                            |\\r\\n| 3.9.0 announced      | 26 July 2021     | Final release is announced & made public                                      |\\r\\n\\r\\nThe above release calendar is a point-in-time snapshot. For latest updates\\r\\nplease refer to the [Release Series](/release-information)\\r\\npage.\\r\\n\\r\\nWe are trying something new for RabbitMQ 3.9.0 release, which introduces a\\r\\nhighly-anticipated feature: [Streams](/docs/streams).\\r\\nThis new release calendar is meant to communicate what to expect, and when.\\r\\nBased on your feedback during the pre-release timeline, we may add additional\\r\\nrelease candidates, and extend the release timeline.\\r\\n\\r\\nOur intention is to give you the opportunity to find issues with this release\\r\\nbefore we publish the final version. We all want important new releases, such\\r\\nas 3.9.0, to be as stable and reliable as possible. While we have gone to great\\r\\nlengths to ensure that this is the case, more eyes and experiments will always\\r\\nhelp, especially with a community as experienced and battle-hardened as ours.\\r\\n\\r\\nAt the time of publishing, we intend to ship RabbitMQ 3.9.0.rc-1 on Monday 12 July\\r\\n2021, just in time for [RabbitMQ Summit 2021](https://rabbitmqsummit.com/).\\r\\n\\r\\n**Help us make RabbitMQ 3.9.0 the best release for you!**"},{"id":"/2021/05/03/alerting","metadata":{"permalink":"/rabbitmq-website/blog/2021/05/03/alerting","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-05-03-alerting/index.md","source":"@site/blog/2021-05-03-alerting/index.md","title":"Notify me when RabbitMQ has a problem","description":"If you want to be notified when your RabbitMQ deployments have a problem, now you can set up the RabbitMQ monitoring and alerting that we have made available in the RabbitMQ Cluster Operator repository.","date":"2021-05-03T00:00:00.000Z","tags":[{"inline":true,"label":"Kubernetes","permalink":"/rabbitmq-website/blog/tags/kubernetes"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":5.345,"hasTruncateMarker":true,"authors":[{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null},{"name":"Gerhard Lazu","key":"glazu","page":null}],"frontMatter":{"title":"Notify me when RabbitMQ has a problem","tags":["Kubernetes","New Features"],"authors":["dansari","glazu"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.9.0 release calendar","permalink":"/rabbitmq-website/blog/2021/07/09/rabbitmq-3.9.0-release-calendar"},"nextItem":{"title":"Preparing for the Bintray Shutdown: How to Migrate","permalink":"/rabbitmq-website/blog/2021/03/31/migrate-off-of-bintray"}},"content":"If you want to be notified when your RabbitMQ deployments have a problem, now you can set up the RabbitMQ monitoring and alerting that we have made available in the [RabbitMQ Cluster Operator](https://github.com/rabbitmq/cluster-operator/tree/v1.7.0/observability) repository.\\r\\nRather than asking you to follow a series of steps for setting up RabbitMQ monitoring & alerting, we have combined this in [a single command](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/quickstart.sh).\\r\\nWhile this is a Kubernetes-specific quick-start, and you can use these Prometheus alerts outside of Kubernetes, the setup will require more consideration and effort on your part.\\r\\nWe share the quick & easy approach, open source and free for all.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nWhen everything is set up and there is a problem with RabbitMQ, this is an example of a notification that you can expect:\\r\\n\\r\\n![](slack-unroutable-messages.png)\\r\\n\\r\\nThe above is a good example of a problem that may not be obvious when it happens, and takes a few steps to troubleshoot.\\r\\nRather than losing messages due to a misconfiguration, this notification makes it clear when incoming messages are not routed within RabbitMQ.\\r\\n\\r\\n\\r\\n\\r\\n## What alerts are available today?\\r\\n\\r\\n* **[NoMajorityOfNodesReady](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/no-majority-of-nodes-ready.yml)**: Only a minority of RabbitMQ nodes can service clients. Some queues are likely to be unavailable, including replicated ones.\\r\\n* **[PersistentVolumeMissing](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/persistent-volume-missing.yml)**: A RabbitMQ node is missing a volume for persisting data and can\'t boot. This is either a misconfiguration or capacity issue.\\r\\n* **[InsufficientEstablishedErlangDistributionLinks](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/insufficient-established-erlang-distribution-links.yml)**: RabbitMQ nodes are not clustered due to networking issues or incorrect permissions.\\r\\n* **[UnroutableMessages](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/unroutable-messages.yml)**: Messages are not routed from channels to queues. Routing topology needs reviewing.\\r\\n* **[HighConnectionChurn](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/high-connection-churn.yml)**: Clients open and close connections too often, which is an anti-pattern. Clients should use long-lived connections.\\r\\n* **[LowDiskWatermarkPredicted](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/low-disk-watermark-predicted.yml)**: Available disk space is predicted to run out within 24h. Limit queue backlogs, consume faster or increase disk size.\\r\\n* **[FileDescriptorsNearLimit](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/file-descriptors-near-limit.yml)**: 80% of available file descriptors are in use. Fewer connections, fewer durable queues, or higher file descriptor limit will help.\\r\\n* **[TCPSocketsNearLimit](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/tcp-sockets-near-limit.yml)**: 80% of available TCP sockets are in use. More channels, fewer connections or a more even spread across the cluster will help.\\r\\n* **[ContainerRestarts](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq/container-restarts.yml)**: The Erlang VM system process within which RabbitMQ runs had an abnormal exit. The most common cause is misconfiguration.\\r\\n* **[RabbitMQClusterOperatorUnavailableReplicas](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/rules/rabbitmq-cluster-operator/unavailable-replicas.yml)**: The Operator managing RabbitMQ clusters is not available. Pod scheduling or misconfiguration issue.\\r\\n\\r\\n\\r\\n\\r\\n## How to get started quickly?\\r\\n\\r\\nYou will need the following:\\r\\n\\r\\n1. Any Kubernetes deployment version 1.18 or above\\r\\n1. [`kubectl`](//kubernetes.io/docs/tasks/tools/) pointing to your Kubernetes deployment and matching the Kubernetes server version\\r\\n1. [`helm`](//helm.sh/docs/intro/install/) version 3\\r\\n\\r\\nNow you are ready to run the following in your terminal:\\r\\n\\r\\n```bash\\r\\ngit clone https://github.com/rabbitmq/cluster-operator.git\\r\\n\\r\\n# Optionally, set the name of the Slack channel and the Slack Webhook URL\\r\\n# If you don\'t have a Slack Webhook URL, create one via https://api.slack.com/messaging/webhooks\\r\\n# export SLACK_CHANNEL=\'#my-channel\'\\r\\n# export SLACK_API_URL=\'https://hooks.slack.com/services/paste/your/token\'\\r\\n\\r\\n./cluster-operator/observability/quickstart.sh\\r\\n```\\r\\n\\r\\nThe last command takes about 5 minutes, and it sets up the entire RabbitMQ on Kubernetes stack:\\r\\n\\r\\n* [RabbitMQ Cluster Operator](https://github.com/rabbitmq/cluster-operator) declares `RabbitmqCluster` as a custom resource definition (CRD) and manages all RabbitMQ clusters in Kubernetes\\r\\n* [kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack) Helm chart which installs:\\r\\n  * [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator) manages Prometheus and Alertmanager, adds `PrometheusRule` and `ServiceMonitor` custom resource definitions\\r\\n  * [Prometheus](https://github.com/prometheus/prometheus) scrapes (i.e. reads) metrics from all RabbitMQ nodes, stores metrics in a time series database, evaluates alerting rules\\r\\n  * [Alertmanager](https://github.com/prometheus/alertmanager) receives alerts from Prometheus, groups them by RabbitMQ cluster, optionally sends notifications to Slack (or other services)\\r\\n  * [Grafana](https://github.com/grafana/grafana) visualises metrics from Prometheus\\r\\n  * [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics) provides Kubernetes metrics RabbitMQ alerting rules rely on\\r\\n* [ServiceMonitor](https://github.com/rabbitmq/cluster-operator/blob/v1.7.0/observability/prometheus/monitors/rabbitmq-servicemonitor.yml) configuration for Prometheus which helps discover [RabbitMQ metrics](https://github.com/rabbitmq/rabbitmq-server/blob/master/deps/rabbitmq_prometheus/metrics.md) from all RabbitMQ nodes\\r\\n* [PrometheusRule](https://github.com/rabbitmq/cluster-operator/tree/v1.7.0/observability/prometheus/rules) for each RabbitMQ Prometheus alert condition\\r\\n* [Secret](https://github.com/rabbitmq/cluster-operator/tree/v1.7.0/observability/prometheus/alertmanager) for the Alertmanager Slack configuration (optional)\\r\\n* [ConfigMap](https://github.com/rabbitmq/cluster-operator/tree/v1.7.0/observability/grafana/dashboards) for each RabbitMQ Grafana dashboard definition\\r\\n\\r\\n\\r\\n\\r\\n## Trigger your first RabbitMQ alert\\r\\n\\r\\nTo trigger an alert, we need a RabbitMQ cluster. This is the easiest way to create one:\\r\\n\\r\\n```bash\\r\\n# Add kubectl-rabbitmq plugin to PATH so that it can be used directly\\r\\nexport PATH=\\"$PWD/cluster-operator/bin:$PATH\\"\\r\\n\\r\\n# Use kubectl-rabbitmq plugin to create RabbitmqClusters via kubectl\\r\\nkubectl rabbitmq create myrabbit --replicas 3\\r\\n```\\r\\n\\r\\nTo trigger the `NoMajorityOfNodesReady` alert, we stop the `rabbit` application on two out of three nodes:\\r\\n```bash\\r\\nkubectl exec myrabbit-server-0 --container rabbitmq -- rabbitmqctl stop_app\\r\\nkubectl exec myrabbit-server-1 --container rabbitmq -- rabbitmqctl stop_app\\r\\n```\\r\\n\\r\\nWithin 2 minutes, two out of three RabbitMQ nodes will be shown as not `READY`:\\r\\n```diff\\r\\nkubectl rabbitmq get myrabbit\\r\\nNAME                    READY   STATUS    RESTARTS   AGE\\r\\n- pod/myrabbit-server-0   1/1     Running   0          70s\\r\\n+ pod/myrabbit-server-0   0/1     Running   0          3m\\r\\n- pod/myrabbit-server-1   1/1     Running   0          70s\\r\\n+ pod/myrabbit-server-1   0/1     Running   0          3m\\r\\n  pod/myrabbit-server-2   1/1     Running   0          3m\\r\\n```\\r\\n\\r\\nThe pods are still `Running` because the `rabbitmqctl stop_app` command leaves the Erlang VM system process running.\\r\\n\\r\\nTo see the `NoMajorityOfNodesReady` alert triggered in Prometheus, we open the Prometheus UI in our browser: [http://localhost:9090/alerts](http://localhost:9090/alerts).\\r\\nFor this to work, we forward local port 9090 to Prometheus port 9090 running inside Kubernetes:\\r\\n\\r\\n```bash\\r\\nkubectl -n kube-prometheus port-forward svc/prom-kube-prometheus-stack-prometheus 9090\\r\\n```\\r\\n![](prometheus-alerts.png)\\r\\n\\r\\n`NoMajorityOfNodesReady` alert is first orange which means it is in a `pending` state.\\r\\nAfter 5 minutes the colour changes to red and the state becomes `firing`.\\r\\nThis will send an alert to Alertmanager.\\r\\nAfter we port-forward - same as above - we open the Alertmanager UI: [http://localhost:9093](http://localhost:9093)\\r\\n\\r\\n```bash\\r\\nkubectl -n kube-prometheus port-forward svc/prom-kube-prometheus-stack-alertmanager 9093\\r\\n```\\r\\n![](alertmanager.png)\\r\\n\\r\\nAlertmanager groups alerts by `namespace` and `rabbitmq_cluster`.\\r\\nYou see a single alert which Alertmanager forwards to your configured Slack channel:\\r\\n\\r\\n![](slack-no-majority-of-nodes-ready.png)\\r\\n\\r\\nCongratulations, you triggered your first RabbitMQ alert! To resolve the alert, start the `rabbit` application on both nodes:\\r\\n\\r\\n```bash\\r\\nkubectl exec myrabbit-server-0 --container rabbitmq -- rabbitmqctl start_app\\r\\nkubectl exec myrabbit-server-1 --container rabbitmq -- rabbitmqctl start_app\\r\\n```\\r\\n\\r\\nThe alert will transition to green in Prometheus, it will be removed from Alertmanager, and a **RESOLVED** notification will be sent to your Slack channel.\\r\\n\\r\\n\\r\\n\\r\\n## Past and current RabbitMQ alerts\\r\\n\\r\\nTo see all past and current RabbitMQ alerts across all your RabbitMQ clusters, look at the RabbitMQ-Alerts Grafana dashboard: [http://localhost:3000/d/jjCq5SLMk](http://localhost:3000/d/jjCq5SLMk) (username: `admin` & password: `admin`)\\r\\n\\r\\n```bash\\r\\nkubectl -n kube-prometheus port-forward svc/prom-grafana 3000:80\\r\\n```\\r\\n![](rabbitmq-alerts-dashboard.png)\\r\\n\\r\\nIn the example above, we have triggered multiple alerts across multiple RabbitMQ clusters.\\r\\n\\r\\n\\r\\n\\r\\n## How can you help?\\r\\n\\r\\nWe have shared the simplest and most useful alerts that we could think of.\\r\\nSome of you already asked us about missing alerts such as memory threshold, Erlang processes & atoms, message redeliveries etc.\\r\\n[Commercial customers](https://tanzu.vmware.com/rabbitmq) asked us for runbooks and automated alert resolution.\\r\\n\\r\\nWhat are your thoughts on the current alerting rules? What alerts are you missing?\\r\\n[Let us know via a GitHub discussion.](https://github.com/rabbitmq/cluster-operator/discussions)"},{"id":"/2021/03/31/migrate-off-of-bintray","metadata":{"permalink":"/rabbitmq-website/blog/2021/03/31/migrate-off-of-bintray","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-03-31-migrate-off-of-bintray/index.md","source":"@site/blog/2021-03-31-migrate-off-of-bintray/index.md","title":"Preparing for the Bintray Shutdown: How to Migrate","description":"Bintray, one of the services our team currently uses to distribute packages,","date":"2021-03-31T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":4.165,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Preparing for the Bintray Shutdown: How to Migrate","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Notify me when RabbitMQ has a problem","permalink":"/rabbitmq-website/blog/2021/05/03/alerting"},"nextItem":{"title":"Erlang 24 Support Roadmap","permalink":"/rabbitmq-website/blog/2021/03/23/erlang-24-support-roadmap"}},"content":"Bintray, one of the services our team currently uses to distribute packages,\\r\\nis [shutting down on May 1st, 2021](https://jfrog.com/blog/into-the-sunset-bintray-jcenter-gocenter-and-chartcenter/).\\r\\n\\r\\nThis post explains what alternative services are available for the RabbitMQ community today or will be before\\r\\nthe shutdown date.\\r\\n\\r\\nNo new releases will be published to Bintray going forward. Those who do not switch from Bintray\\r\\nbefore May 1st will see their **deployments begin failing**. We highly recommend making\\r\\nmigration off of Bintray both an important and urgent task.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Big Shoes to Fill\\r\\n\\r\\nBintray has served our community well for years. The JFrog team were very generous with our customized open source\\r\\nproject limits and in general helpful with our requests.\\r\\n\\r\\nRabbitMQ distributes multiple package types, including modern Erlang\\r\\npackages for several distributions, and Bintray acommodated all of them.\\r\\n\\r\\nSome package hosting services specialize won\'t be able to replace Bintray alone.\\r\\nThis means that the migration options will differ depending on what package type you use.\\r\\n\\r\\nIn the next section we will cover the options available today and mention another one that\\r\\nis coming down the line.\\r\\n\\r\\n## The Post-Bintray Era Options\\r\\n\\r\\nWhat service you should migrate to depends on how you provision RabbitMQ.\\r\\n\\r\\nTeam RabbitMQ already publishes release artifacts to a few places:\\r\\n\\r\\n * GitHub [releases of RabbitMQ](https://github.com/rabbitmq/rabbitmq-server/releases): distributes every package type plus Debian package source files\\r\\n * [PackageCloud](https://packagecloud.io/rabbitmq): this repository provides Debian and RPM packages\\r\\n\\r\\nOur team plans to adopt [Cloudsmith.io](https://cloudsmith.io/~rabbitmq/repos/) in addition to the above options.\\r\\nCloudsmith supports multiple package types and we have had promising initial experience with it.\\r\\nPublishing RabbitMQ Debian packages via Launchpad is also under consideration.\\r\\n\\r\\nIn addition, our team produces and distributes packages of modern Erlang versions via\\r\\n\\r\\n * [Launchpad PPA](https://launchpad.net/~rabbitmq/+archive/ubuntu/rabbitmq-erlang) for Ubuntu and Debian\\r\\n * GitHub [releases of zero-dependency Erlang RPM](https://github.com/rabbitmq/erlang-rpm/releases)\\r\\n\\r\\n### Docker Community Image and Kubernetes Operator\\r\\n\\r\\nIf this is via the [Docker community image](https://github.com/docker-library/rabbitmq),\\r\\nthen **nothing changes** for you as the image does not depend on Bintray and is not distributed via Bintray.\\r\\n\\r\\nThis is equally true for the [RabbitMQ Kubernetes Operator](/kubernetes/operator/operator-overview) users.\\r\\n\\r\\n### Binary Builds\\r\\n\\r\\n[RabbitMQ binary builds](/docs/install-generic-unix) (a.k.a. generic UNIX builds) are best consumed from [GitHub releases](https://github.com/rabbitmq/rabbitmq-server/releases).\\r\\n\\r\\nIf you currently consume these packages from Bintray, updating the download location to use\\r\\nGitHub releases is all there is to do.\\r\\n\\r\\n### Windows Packages\\r\\n\\r\\nWindows users who use [Chocolatey](/docs/install-windows#chocolatey) are not affected by this transition.\\r\\n\\r\\n[RabbitMQ installer](/docs/install-windows#installer) and [Windows binary build](/docs/install-windows-manual) users\\r\\nshould now consume from [GitHub releases](https://github.com/rabbitmq/rabbitmq-server/releases).\\r\\n\\r\\n### Debian Packages of Modern Erlang\\r\\n\\r\\nTeam RabbitMQ\'s [Debian packages of modern Erlang](https://github.com/rabbitmq/erlang-debian-package) has found\\r\\na new home in a [Launchpad PPA](https://launchpad.net/~rabbitmq/+archive/ubuntu/rabbitmq-erlang).\\r\\n\\r\\nWhile Launchpad is an Ubuntu-oriented service, it can also be [used as a regular apt repository](/docs/install-debian#apt-launchpad-erlang)\\r\\nby Debian users.\\r\\n\\r\\nThese packages are also [available from Cloudsmith.io](/docs/install-debian#apt-cloudsmith).\\r\\n\\r\\nIn order to migrate, remove the existing `.list` file under `/etc/apt/sources.list.d` and install a new one\\r\\nas explained in the [Debian installation doc guide](/docs/install-debian).\\r\\n\\r\\nNext, import the [signing key](/docs/install-debian#erlang-apt-repo-signing-key) used by\\r\\nthe Launchpad repository.\\r\\n\\r\\nFinally, run\\r\\n\\r\\n``` shell\\r\\nsudo apt update -y\\r\\n```\\r\\n\\r\\nand re-install the packages.\\r\\n\\r\\n### Debian Packages of RabbitMQ\\r\\n\\r\\nThe options available for RabbitMQ Debian packages are as follows:\\r\\n\\r\\n * Using an [apt repository on PackageCloud](/docs/install-debian#apt-cloudsmith), including a [quick start example](/docs/install-debian#apt-quick-start-cloudsmith)\\r\\n * Using a [direct download](/docs/install-debian#manual-installation) from GitHub and installing its [dependencies](/docs/install-debian#manual-installation) the local package using `dpkg`\\r\\n\\r\\nOur team plans to also distribute this package via [Cloudsmith.io](https://cloudsmith.io/~rabbitmq/repos/) in the near future.\\r\\n\\r\\nIn order to migrate, remove the existing `.list` file under `/etc/apt/sources.list.d` and install a new one\\r\\nas explained in the [Debian installation doc guide](/docs/install-debian).\\r\\n\\r\\nNext, import the [signing key](/docs/install-debian#erlang-apt-repo-signing-key) used by\\r\\nthe PackageCloud repository.\\r\\n\\r\\nFinally, run\\r\\n\\r\\n``` shell\\r\\nsudo apt update -y\\r\\n```\\r\\n\\r\\nand re-install the packages.\\r\\n\\r\\n### RPM Packages of Modern Erlang\\r\\n\\r\\nTeam RabbitMQ\'s own [zero dependency Erlang RPM](https://github.com/rabbitmq/erlang-rpm/) can be consumed in a couple of ways:\\r\\n\\r\\n * Using a [Yum repository on PackageCloud](https://github.com/rabbitmq/erlang-rpm#latest-erlang-version-from-packagecloud)\\r\\n * Using a direct download from [GitHub releases](https://github.com/rabbitmq/erlang-rpm/releases) and installing the local package using `rpm install`\\r\\n\\r\\nOur team plans to also distribute this package via [Cloudsmith.io](https://cloudsmith.io/~rabbitmq/repos/) in the near future.\\r\\n\\r\\nIn order to migrate, remove the existing `.repo` file under `/etc/yum.repos.d/` and install a new one\\r\\nas explained in the [RPM installation doc guide](/docs/install-rpm).\\r\\n\\r\\nThen run\\r\\n\\r\\n``` shell\\r\\nsudo yum clean all\\r\\nsudo yum update -y\\r\\n```\\r\\n\\r\\nand re-install the packages.\\r\\n\\r\\n### RPM Packages of RabbitMQ\\r\\n\\r\\nThe options for RabbitMQ RPM packages match to those listed above for our zero-dependency Erlang RPM:\\r\\n\\r\\n * Using a [Yum repository on PackageCloud](/docs/install-rpm#cloudsmith). This would cover RHEL, CentOS, modern Fedora and openSUSE\\r\\n * Using a [direct download](/docs/install-rpm#downloads) from GitHub and installing its [dependencies](/docs/install-rpm#package-dependencies) the local package using `rpm install`\\r\\n\\r\\nOur team plans to also distribute this package via [Cloudsmith.io](https://cloudsmith.io/~rabbitmq/repos/) in the near future.\\r\\n\\r\\nIn order to migrate, remove the existing `.repo` file under `/etc/yum.repos.d/` and install a new one\\r\\nas explained in the [RPM installation doc guide](/docs/install-rpm).\\r\\n\\r\\nThen run\\r\\n\\r\\n``` shell\\r\\nsudo yum clean all\\r\\nsudo yum update -y\\r\\n```\\r\\n\\r\\nand re-install the packages.\\r\\n\\r\\n\\r\\n## Feedback\\r\\n\\r\\nIf you have any questions or feedback, please share it in the [RabbitMQ community Slack](https://rabbitmq-slack.herokuapp.com/)\\r\\nin the `#usage-questions` and `#core-and-plugin-dev` channels."},{"id":"/2021/03/23/erlang-24-support-roadmap","metadata":{"permalink":"/rabbitmq-website/blog/2021/03/23/erlang-24-support-roadmap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-03-23-erlang-24-support-roadmap/index.md","source":"@site/blog/2021-03-23-erlang-24-support-roadmap/index.md","title":"Erlang 24 Support Roadmap","description":"TL;DR","date":"2021-03-23T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Erlang","permalink":"/rabbitmq-website/blog/tags/erlang"},{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":4.27,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Erlang 24 Support Roadmap","tags":["Performance","Erlang","Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Preparing for the Bintray Shutdown: How to Migrate","permalink":"/rabbitmq-website/blog/2021/03/31/migrate-off-of-bintray"},"nextItem":{"title":"How to Monitor Authentication Attempts","permalink":"/rabbitmq-website/blog/2021/03/01/auth-attempts-metrics"}},"content":"## TL;DR\\r\\n\\r\\n * Erlang 24 will ship in May and it offers significant performance gains to RabbitMQ users\\r\\n * Supporting Erlang 24 and 22 at the same time is not feasible, so in early May 2021, Erlang 22 support will be dropped\\r\\n * If you run on Erlang 22, upgrade to 23.2 today: it should be a drop-in replacement\\r\\n * Users of the [RabbitMQ Kubernetes Operator](https://github.com/rabbitmq/cluster-operator), the [Docker community image](https://github.com/docker-library/rabbitmq) and modern releases of [VMware Tanzu RabbitMQ for VMs](https://docs.pivotal.io/rabbitmq-cf/1-21/index.html#:~:text=RabbitMQ%20for%20VMs.-,About%20VMware%20Tanzu%20RabbitMQ%20for%20VMs,and%20a%20pre%2Dprovisioned%20service.&text=Dedicated%20VM%20that%20serves%20a%20single%20service%20instance.) are not affected as those projects all use Erlang 23 today\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## New Erlang Release is on The Finish Line\\r\\n\\r\\nThe core team has recently made RabbitMQ compatible with Erlang 24 which we expect to be released in May. This is a significant release and RabbitMQ users will benefit from it. In the process we have concluded that supporting Erlang 22 and 24 at the same time is not feasible. We believe that most users would\\r\\nstrongly prefer to move to Erlang 24 given the benefits (see below) instead\\r\\nof sticking to Erlang 22 for longer.\\r\\n\\r\\nAs such, Erlang 22 support will be dropped about three months earlier than our\\r\\nstandard [Erlang release support policy](/docs/which-erlang) outlines: **on May 3rd 2021**.\\r\\nA GA release of Erlang 24 is expected to come out in early to mid-May.\\r\\n\\r\\n## What You Should Do Today\\r\\n\\r\\nTo avoid any inconvenience, you can move to Erlang 23 today. We expect that this version will be supported until at least April 2022.\\r\\nErlang 23 is no longer a new release hot off the presses, and it\'s already very widely used by RabbitMQ users.\\r\\nFor example, the Docker community image provides the most recent Erlang 23 release\\r\\navailable, and the image is automatically rebuilt when new RabbitMQ, Erlang or OpenSSL releases come out.\\r\\n\\r\\n## Erlang 24 Benefits\\r\\n\\r\\n[Erlang 24](https://www.erlang.org/news/144) brings a number of positive changes that directly or indirectly\\r\\naffect nearly every RabbitMQ user.\\r\\n\\r\\n### Improved Performance\\r\\n\\r\\n Erlang 24 introduces a JIT to the runtime and that results in significant throughput gains for real world systems, including RabbitMQ nodes.\\r\\n Both Erlang/OTP maintainers and our team have [observed improvements](https://www.erlang-solutions.com/blog/performance-testing-the-jit-compiler-for-the-beam-vm/) in the 35-55% range depending on the workload.\\r\\n Since this is potentially relevant to every single RabbitMQ user, we believe this outweighs a couple of minor potentially\\r\\n breaking changes described below.\\r\\n\\r\\n### Improved security\\r\\n\\r\\nErlang 24 continues improving (maturing) TLSv1.3 support, which is highly relevant as more and more tools move to support TLSv1.3\\r\\nor even use it exclusively.\\r\\n\\r\\n### Improved RabbitMQ Developement Process\\r\\n\\r\\nFor contributors and the RabbitMQ core team, Erlang 24 offers significant quality of life improvements:\\r\\n\\r\\n * Comparable sound double digit % reductions in compilation time\\r\\n * Significantly more informative reporting of errors and warnings (source code data and formatting similar to clang)\\r\\n * Standard library improvements (and deprecations)\\r\\n\\r\\n\\r\\n## What Changes with Erlang 24\\r\\n\\r\\nThe substantial benefits listed above come at a cost that\\r\\nmost RabbitMQ users won\'t have to pay but some will.\\r\\n\\r\\nStarting with 3.9, RabbitMQ will use a logging library from Erlang 24 instead of a 3rd party dependency.\\r\\nThat dependency — Lager — has served us well for many years but is no longer obviously superior to the standard library option.\\r\\nThis switch won\'t affect most users but two things change:\\r\\n\\r\\n* Log event timestamp changes slightly\\r\\n* Lager-specific extensions and advanced configuration won\'t be supported any more\\r\\n\\r\\nThe former can affect systems that attempt to parse RabbitMQ logs. The latter will require those who depend on those advanced\\r\\nLager sink configuration settings to build a small plugin that provides an equivalent.\\r\\nIf you only use the [standard logging settings](/docs/logging) or Syslog,\\r\\nyou won\'t lose anything.\\r\\n\\r\\n\\r\\n## So What Is the Plan?\\r\\n\\r\\nRabbitMQ 3.9 (master) already supports Erlang 24. On May 3rd, 2021 RabbitMQ 3.8 branch will have Erlang 24 support merged.\\r\\nThat will automatically retire Erlang 22 support and all future RabbitMQ 3.8 releases will require Erlang 23.\\r\\nUpgrade to Erlang 23 today to make the transition smoother!\\r\\n\\r\\nNote that we expect at least one more Erlang 22-compatible patch release to come out before May 3rd.\\r\\n\\r\\nIf you rely on RabbitMQ log parsing, the changes in timestamp formatting will be mentioned in 3.9 release notes when it comes out.\\r\\n\\r\\nIf you rely on [Lager-specific advanced configuration settings](/docs/logging),\\r\\nyou should be able to build a small plugin that e.g. implements a custom backend or adjusts the formatting using\\r\\nthe standard library logger API which provides most if not all features that Lager has.\\r\\n\\r\\n\\r\\n## Community Docker Image and Kubernetes Operator for RabbitMQ\\r\\n\\r\\nIf you use the [Docker community RabbitMQ image](https://github.com/docker-library/rabbitmq) and have updated it recently, you already run on a very recent\\r\\nrelease of Erlang 23. So do most [RabbitMQ Kubernetes Operator](/kubernetes/operator/operator-overview) users.\\r\\nThe image will be upgraded to Erlang 24 likely a few weeks after it comes out,\\r\\nunless any serious enough Erlang 24-specific issues are discovered.\\r\\n\\r\\nOther Docker images likely already use Erlang 23 but this is something that you should verify\\r\\nif you use one of those images.\\r\\n\\r\\n\\r\\n## Feedback\\r\\n\\r\\nIf you have any questions or feedback, please share it in the [RabbitMQ community Slack](https://rabbitmq-slack.herokuapp.com/)\\r\\nin the `#usage-questions` and `#core-and-plugin-dev` channels."},{"id":"/2021/03/01/auth-attempts-metrics","metadata":{"permalink":"/rabbitmq-website/blog/2021/03/01/auth-attempts-metrics","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2021-03-01-auth-attempts-metrics/index.md","source":"@site/blog/2021-03-01-auth-attempts-metrics/index.md","title":"How to Monitor Authentication Attempts","description":"We have been constantly improving the monitoring capabilities that are built into RabbitMQ since shipping native Prometheus support in 3.8.0. Monitoring the broker and its clients is critically important for detecting issues before they affect the rest of the environment and, eventually, the end users.","date":"2021-03-01T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":3.425,"hasTruncateMarker":true,"authors":[{"name":"Diana Parra Corbacho","url":"https://github.com/dcorbacho","imageURL":"https://github.com/dcorbacho.png","key":"dcorbacho","page":null}],"frontMatter":{"title":"How to Monitor Authentication Attempts","tags":["New Features","HowTo"],"authors":["dcorbacho"]},"unlisted":false,"prevItem":{"title":"Erlang 24 Support Roadmap","permalink":"/rabbitmq-website/blog/2021/03/23/erlang-24-support-roadmap"},"nextItem":{"title":"RabbitMQ Kubernetes Operator reaches 1.0","permalink":"/rabbitmq-website/blog/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0"}},"content":"We have been constantly improving the monitoring capabilities that are built into RabbitMQ since shipping native Prometheus support in 3.8.0. Monitoring the broker and its clients is critically important for detecting issues before they affect the rest of the environment and, eventually, the end users.\\r\\n\\r\\nRabbitMQ 3.8.10 exposes client authentication attempts metrics via both the Prometheus endpoint and the HTTP API.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThe default behaviour is to return the total, failed and successful auth attempts for the following supported protocols: AMQP 0-9-1, AMQP 1.0 and MQTT. The broker can be configured to also track the source of each individual authentication attempt, including the remote IP address, username and protocol. Since there is no address information for AMQP 1.0 authorization, an empty source IP is reported in non-aggregated mode.\\r\\n\\r\\n\\r\\n\\r\\n## Configuration\\r\\n\\r\\nRabbitMQ always tracks the total number of authentication attempts on each cluster node, aggregating them per protocol.\\r\\n\\r\\nAuth attempts per individual address/user/protocol combination can be added via [advanced config](/docs/configure#advanced-config-file):\\r\\n\\r\\n```erlang\\r\\n[\\r\\n  {rabbit, [{track_auth_attempt_source, true}]}\\r\\n]\\r\\n```\\r\\n\\r\\n**Care must be taken when this option is enabled.**\\r\\n\\r\\nTracking the source IP, username and protocol via metrics may result in high cardinality, which means increased memory usage on the RabbitMQ node. As there are no obvious criteria for expiring these metrics from RabbitMQ\'s in-memory ETS-based metrics storage, it is not recommended to regularly track the authentication sources on a production cluster. The only exception to this rule may be when the number of remote IP addresses and users are guaranteed to be bounded.\\r\\n\\r\\nThe CLI commands can be used to enable/disable tracking of the remote source. This makes ad-hoc troubleshooting easy, with no need to restart a node.\\r\\n\\r\\nThe CLI commands can be found under both `rabbitmqctl` and `rabbitmq-diagnostics`:\\r\\n\\r\\n| Command | Usage |\\r\\n| ------- | ----- |\\r\\n| `disable_auth_attempt_source_tracking` | Disables the tracking of peer IP address and username of authentication attempts |\\r\\n| `enable_auth_attempt_source_tracking` | Enables the tracking of peer IP address and username of authentication attempts |\\r\\n| `reset_node_auth_attempt_metrics` | Resets auth attempt metrics on the target node |\\r\\n| `list_node_auth_attempt_stats` | Lists authentication attempts on the target node |\\r\\n\\r\\nWe would like to point out the `reset_node_auth_attempt_metrics` command. This is useful for resetting all authentication attempts metrics stored in RabbitMQ\'s node memory after source tracking has been disabled.\\r\\n\\r\\n\\r\\n\\r\\n## HTTP API\\r\\n\\r\\nThere are two HTTP API endpoints on the [management plugin](/docs/management#http-api) to query the authentication attempts.\\r\\n\\r\\nThe first one is always enabled and returns the total number of authentication attempts per protocol:\\r\\n\\r\\n```plaintext\\r\\nGET /api/auth/attempts/{node}\\r\\n```\\r\\n\\r\\n```json\\r\\n[{\\r\\n   \\"protocol\\":\\"http\\",\\r\\n   \\"auth_attempts\\":553,\\r\\n   \\"auth_attempts_failed\\":0,\\r\\n   \\"auth_attempts_succeeded\\":553\\r\\n },\\r\\n {\\r\\n   \\"protocol\\":\\"amqp091\\",\\r\\n   \\"auth_attempts\\":12,\\r\\n   \\"auth_attempts_failed\\":10,\\r\\n   \\"auth_attempts_succeeded\\":2\\r\\n }]\\r\\n```\\r\\nThe second one requires to enable the tracking of the source of the authentication attempts. It provides a breakdown of the attempts per source:\\r\\n\\r\\n```plaintext\\r\\nGET /api/auth/attempts/{node}/source\\r\\n```\\r\\n\\r\\n```json\\r\\n[{\\r\\n   \\"remote_address\\":\\"127.0.0.1\\",\\r\\n   \\"username\\":\\"guest\\",\\r\\n   \\"protocol\\":\\"http\\",\\r\\n   \\"auth_attempts\\":533,\\r\\n   \\"auth_attempts_failed\\":0,\\r\\n   \\"auth_attempts_succeeded\\":533\\r\\n },\\r\\n {\\r\\n   \\"remote_address\\":\\"127.0.0.1\\",\\r\\n   \\"username\\":\\"roger\\",\\r\\n   \\"protocol\\":\\"amqp091\\",\\r\\n   \\"auth_attempts\\":10,\\r\\n   \\"auth_attempts_failed\\":10,\\r\\n   \\"auth_attempts_succeeded\\":0\\r\\n },\\r\\n {\\r\\n   \\"remote_address\\":\\"127.0.0.1\\",\\r\\n   \\"username\\":\\"bugs\\",\\r\\n   \\"protocol\\":\\"amqp091\\",\\r\\n   \\"auth_attempts\\":2,\\r\\n   \\"auth_attempts_failed\\":0,\\r\\n   \\"auth_attempts_succeeded\\":2\\r\\n }]\\r\\n```\\r\\n\\r\\nAuth attempt metrics can be reset using the A `DELETE` HTTP request, e.g. `DELETE /api/auth/attempts/{node}/source`\\r\\n\\r\\n\\r\\n\\r\\n## Prometheus HTTP\\r\\n\\r\\nThe [Prometheus HTTP endpoint](/docs/prometheus), by default [http://localhost:15692/metrics](http://localhost:15692/metrics), captures the same authentication metrics:\\r\\n\\r\\n```plaintext\\r\\n# TYPE rabbitmq_auth_attempts_total counter\\r\\n# HELP rabbitmq_auth_attempts_total Total number of authorization attempts\\r\\nrabbitmq_auth_attempts_total{protocol=\\"amqp091\\"} 2\\r\\n# TYPE rabbitmq_auth_attempts_succeeded_total counter\\r\\n# HELP rabbitmq_auth_attempts_succeeded_total Total number of successful authentication attempts\\r\\nrabbitmq_auth_attempts_succeeded_total{protocol=\\"amqp091\\"} 0\\r\\n# TYPE rabbitmq_auth_attempts_failed_total counter\\r\\n# HELP rabbitmq_auth_attempts_failed_total Total number of failed authentication attempts\\r\\nrabbitmq_auth_attempts_failed_total{protocol=\\"amqp091\\"} 2\\r\\n```\\r\\n\\r\\nTo obtain the source details, **rabbitmq_prometheus** plugin must also be configured to return [per-object metrics](/docs/prometheus#metric-aggregation):\\r\\n\\r\\n```plaintext\\r\\n# TYPE rabbitmq_auth_attempts_total counter\\r\\n# HELP rabbitmq_auth_attempts_total Total number of authorization attempts\\r\\nrabbitmq_auth_attempts_total{protocol=\\"amqp091\\"} 5\\r\\n# TYPE rabbitmq_auth_attempts_succeeded_total counter\\r\\n# HELP rabbitmq_auth_attempts_succeeded_total Total number of successful authentication attempts\\r\\nrabbitmq_auth_attempts_succeeded_total{protocol=\\"amqp091\\"} 0\\r\\n# TYPE rabbitmq_auth_attempts_failed_total counter\\r\\n# HELP rabbitmq_auth_attempts_failed_total Total number of failed authentication attempts\\r\\nrabbitmq_auth_attempts_failed_total{protocol=\\"amqp091\\"} 5\\r\\n# TYPE rabbitmq_auth_attempts_detailed_total counter\\r\\n# HELP rabbitmq_auth_attempts_detailed_total Total number of authorization attempts with source info\\r\\nrabbitmq_auth_attempts_detailed_total{remote_address=\\"::ffff:127.0.0.1\\",username=\\"guest\\",protocol=\\"amqp091\\"} 1\\r\\n# TYPE rabbitmq_auth_attempts_detailed_succeeded_total counter\\r\\n# HELP rabbitmq_auth_attempts_detailed_succeeded_total Total number of successful authorization attempts with source info\\r\\nrabbitmq_auth_attempts_detailed_succeeded_total{remote_address=\\"::ffff:127.0.0.1\\",username=\\"guest\\",protocol=\\"amqp091\\"} 0\\r\\n# TYPE rabbitmq_auth_attempts_detailed_failed_total counter\\r\\n# HELP rabbitmq_auth_attempts_detailed_failed_total Total number of failed authorization attempts with source info\\r\\nrabbitmq_auth_attempts_detailed_failed_total{remote_address=\\"::ffff:127.0.0.1\\",username=\\"guest\\",protocol=\\"amqp091\\"} 1\\r\\n```\\r\\n\\r\\n<!-- TODO @gerhard: Add Grafana dashboard -->"},{"id":"/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0","metadata":{"permalink":"/rabbitmq-website/blog/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-11-17-rabbitmq-kubernetes-operator-reaches-1-0/index.md","source":"@site/blog/2020-11-17-rabbitmq-kubernetes-operator-reaches-1-0/index.md","title":"RabbitMQ Kubernetes Operator reaches 1.0","description":"We are pleased to announce that the RabbitMQ Operator for Kubernetes is now generally available. The RabbitMQ Operator makes it easy to provision","date":"2020-11-17T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"Kubernetes","permalink":"/rabbitmq-website/blog/tags/kubernetes"}],"readingTime":7.325,"hasTruncateMarker":true,"authors":[{"name":"Yaron Parasol","key":"yparasol","page":null}],"frontMatter":{"title":"RabbitMQ Kubernetes Operator reaches 1.0","tags":["New Features","Kubernetes"],"authors":["yparasol"]},"unlisted":false,"prevItem":{"title":"How to Monitor Authentication Attempts","permalink":"/rabbitmq-website/blog/2021/03/01/auth-attempts-metrics"},"nextItem":{"title":"This Month in RabbitMQ, Aug/Sep 2020 Recap","permalink":"/rabbitmq-website/blog/2020/11/06/this-month-in-rabbitmq-augsep-2020-recap"}},"content":"We are pleased to announce that the RabbitMQ Operator for Kubernetes is now generally available. The RabbitMQ Operator makes it easy to provision\\r\\nand manage RabbitMQ clusters consistently on any certified Kubernetes distribution.  Operators inform the Kubernetes container orchestration\\r\\nsystem how to provision and control specific applications. The Kubernetes (hereafter K8s) Operator pattern is a way to extend the K8s API and\\r\\nstate management to include the provisioning and management of custom resources -- resources not provided in a default K8s deployment. In this\\r\\npost, we’ll discuss how the Operator enables the K8s system to control a RabbitMQ cluster.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Where do I start?\\r\\n\\r\\nIf you are new to K8s, start with learning the basics of K8s and kubectl before attempting to use the operator.  You can also visit the\\r\\n[Kube Academy](https://kube.academy/) for more in-depth primers. Watch [this episode of TGIR](https://www.youtube.com/watch?v=NWISW6AwpOE)\\r\\nto see how easy it is to deploy and monitor a RabbitMQ cluster with the operator. Next you can try the\\r\\n[quick start guide](https://github.com/rabbitmq/cluster-operator). In a minute or two you will have the operator and your first instance\\r\\nof operator created rabbitMQ cluster.\\r\\n\\r\\nWant to go further? Look at the [operator yaml examples](https://github.com/rabbitmq/cluster-operator/tree/main/docs/examples) for\\r\\nquick deployment of advanced clusters. For the entire set of supported features, [look at the documentation](/kubernetes/operator/operator-overview).\\r\\n\\r\\n## The Rabbit K8s Operator\\r\\n\\r\\nIt’s recommended that you first be familiar with the basics of K8s. If you need a refresher, VMware’s Kube Academy has a comprehensive set of resources.\\r\\n**The Rabbit MQ K8s operator is composed of 2 building blocks**:\\r\\n\\r\\n * Custom resources: An extension to the native K8s resources in order to manage custom state of a particular stateful platform or application.\\r\\n In our case the custom resource  is reflecting the configuration size and state of a RabbitMQ cluster\\r\\n * Custom controller: A k8s controller is a non-terminating loop that regulates the state of standard K8s resources, like ReplicaSet, StatefulSet, or Deployments.\\r\\n The custom controller is adding a non-terminating control loop with custom logic to regulate the state of the custom resource. In the case of RabbitMQ cluster,\\r\\n the controller can settle changes to cluster & node configurations.\\r\\n\\r\\n## What’s the value of a RabbitMQ Cluster Operator?\\r\\n\\r\\nThe RabbitMQ Cluster Operator (aka the operator) is a bridge between K8s managed states and RabbitMQ configuration and state.\\r\\n**The RabbitMQ Cluster Operator helps to simplify two types of tasks**:\\r\\n\\r\\n * Provisioning of new clusters\\r\\n * Post-installation tasks, managed by K8s\\r\\n\\r\\n ## Provisioning of a new RabbitMQ cluster\\r\\n\\r\\n[Creating a new RabbitMQ cluster on K8s manually is a multi step process](/blog/tags/diy),\\r\\nthat the operator is automating:\\r\\n\\r\\n 1. Creating the RabbitMQ configuration file as a ConfigMap, so that is can be mounted as a file by the RabbitMQ container\\r\\n 1. Setting the K8s secrets required by RabbitMQ (TLS certificates, default user password etc)\\r\\n 1. Creating a StatefulSet that will manage the cluster nodes (as pods)\\r\\n 1. Creating a headless service(a service without a cluster IP) to manage rabbitMQ node discovery\\r\\n 1. Creating a service for RabbitMQ clients to access the cluster\\r\\n\\r\\nThe operator is not the only way to automate this process, but it has the benefit of mapping all the RabbitMQ configurations into a k8s descriptor\\r\\nand a custom resource.  This means that there is a single source of truth regarding the cluster state, and users can manage their clusters\\r\\nconfigurations using [Gitops](https://www.weave.works/blog/what-is-gitops-really). \\r\\n\\r\\nBy using an operator to provision RabbitMQ clusters, the user enjoys several benefits:\\r\\n\\r\\n * A declarative API to create a RabbitMQ cluster with any setting with a single command. The operator is automating the provisioning of the\\r\\n complex set of K8s resources composing the cluster: such as services, pods, statefulset, persistent volumes etc\\r\\n * The operator comes with a set of YAML examples so in most cases you have almost no effort in order to have a development or even a production\\r\\n grade cluster.\\r\\n * Once the cluster is created it has a K8s state and description you can observe to know if your RMQ cluster is ready. RabbitMQ comes with\\r\\n in-built support for Prometheus. Node and cluster metrics can be visualised with Grafana.\\r\\n * The operator goes further and displays status conditions for the RabbitMQ cluster. The possible status conditions are:\\r\\n   * *ClusterAvailable* - RabbitMQ accessible by client apps\\r\\n   * *AllReplicasReady* - RabbitMQ cluster fully available\\r\\n   * *ReconcileSuccess* - Custom Resource reconciled successfully. This being false may denote that the user needs to intervene\\r\\n (for example if TLS is enabled but the secret does not exist).\\r\\n * K8s controllers can now regulate the set of resources that compose the cluster: The rabbitMQ nodes, the routing service, the node registry\\r\\n service and the volumes. If any of these resources is not available according to K8s liveness probe, K8s will auto heal it\\r\\n\\r\\nWhile the operator is useful for day 1 tasks, it confers even greater benefits when we talk about day 2 operations triggered by the user or by k8s.\\r\\n\\r\\n## Post Installation Tasks\\r\\n\\r\\nHaving a RabbitMQ cluster provisioned is just the beginning of the journey as any developer and operator knows. There are various lifecycle events\\r\\nto take care of:\\r\\n * Scaling the cluster when the application messaging volume increases as a result of additional functionality or demand growth\\r\\n * Self healing the cluster when a node is crashed or the network breaks\\r\\n * Rotating certificates\\r\\n * Upgrading the cluster with zero downtime when a new version of RabbitMQ is needed for security patching or new features\\r\\n\\r\\nMany of the above processes require graceful termination of a node, some RabbitMQ API call after node start, or more complex flows that have a\\r\\nsequence of K8s lifecycle events and RabbitMQ cluster events.This is exactly where the value of the operator stands out.\\r\\n\\r\\n * The Cluster Operator will allow RabbitMQ users to address all of these with a simple K8s CLI declarative command.\\r\\n * The operator will automate these complex flows using both K8s building block and custom controller logic that takes care of the RabbitMQ\\r\\n administrative tasks\\r\\n\\r\\n**The operator now supports the core of day 2 RabbitMQ operations such as**:\\r\\n\\r\\n * Reconfigurations\\r\\n * Enabling / disabling of plugins\\r\\n * Self healing \\r\\n * Scaling\\r\\n * In place upgrade\\r\\n * Certificate rotations - using rolling updates\\r\\n\\r\\nIn the future, the operator can be upgraded to provide new flows. For example, a new version of the operator may be released with a new major version of RabbitMQ. The use of the operator pattern means we can provide specific logic to, say, upgrade the existing RabbitMQ clusters to a new major version without losing messages and without downtime. The existence of a new operator version does not force users to upgrade existing clusters; K8s will still be able to manage these clusters going forward.\\r\\n\\r\\n**It is only a K8s operator that can automate such complex and delicate processes in such an elegant way and without a risk. Here’s an example of\\r\\nhow RabbitMQ will save users from pain and errors by automating the process of in-place upgrade. The diagram lists the manual steps a user need to\\r\\nperform in order to have a rolling upgrade of the cluster (without an operator).**\\r\\n\\r\\n![](In-place-upgrade-rmq-1.png)\\r\\n\\r\\nNow watch as Gerhard covers more advanced topics in running [RabbitMQ reliably on K8s](https://www.youtube.com/watch?v=I02oKJlOnR4).\\r\\n\\r\\n## But wait - there’s more\\r\\n\\r\\nThe operator comes with a kubectl plugin that provides many commands to make your life easier. As described\\r\\n[here](/kubernetes/operator/install-operator#kubectl-plugin), you can install the kubectl\\r\\nplugin using [krew](https://github.com/kubernetes-sigs/krew). Some handy commands are installing the cluster operator as well\\r\\nas creating, listing and deleting RabbitMQ clusters. Other commands targeting a specific RabbitMQ cluster include printing\\r\\nthe default user secret, opening the RabbitMQ management UI, enabling debug\\r\\nlogging on all RabbitMQ nodes, and running [perf-test](https://github.com/rabbitmq/rabbitmq-perf-test).\\r\\n\\r\\n## What’s next?\\r\\n\\r\\nThe Cluster Operator gives users a lot of power to create clusters and manage them. There is still a wider scope of functionality to support,\\r\\ndepending on your requests and feedback.\\r\\n\\r\\nSome examples are:\\r\\n\\r\\n * Examples of topologies using Istio for encryption /decryption of traffic between nodes as well as client with traffic\\r\\n * Scaling down gracefully\\r\\n * Monitoring the operator - the operator will report metrics in Prometheus format\\r\\n * Labelling cluster resources with RMQ and operator metadata\\r\\n * Testing on additional K8s providers (currently testing on Tanzu Kubernetes Grid and GKE)\\r\\n\\r\\nIn addition, we plan to add another operator that will wrap some of RabbitMQ\'s APIs with K8s declarative API, allowing for creation of users, queues and exchanges.\\r\\n\\r\\n**We welcome feedback, feature requests, bug reports and any questions you have regarding RabbitMQ**:\\r\\n\\r\\n * For feature requests and bugs use [Github issues](https://github.com/rabbitmq/cluster-operator/issues)\\r\\n * For questions and feedback use Github or the [rabbitmq-users group](https://groups.google.com/g/rabbitmq-users).\\r\\n You can also subscribe to the community [mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users)\\r\\n and the RabbitMQ [Slack channel](https://rabbitmq-slack.herokuapp.com/)\\r\\n * Read the RabbitMQ [community blog](https://blog.rabbitmq.com)\\r\\n * We’re always looking for [new contributors](/github) to the RabbitMQ project!"},{"id":"/2020/11/06/this-month-in-rabbitmq-augsep-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/11/06/this-month-in-rabbitmq-augsep-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-11-06-this-month-in-rabbitmq-augsep-2020-recap/index.md","source":"@site/blog/2020-11-06-this-month-in-rabbitmq-augsep-2020-recap/index.md","title":"This Month in RabbitMQ, Aug/Sep 2020 Recap","description":"This month in RabbitMQ features a blog from Michael Klishin on deploying RabbitMQ on Kubernetes.","date":"2020-11-06T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.34,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, Aug/Sep 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Kubernetes Operator reaches 1.0","permalink":"/rabbitmq-website/blog/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0"},"nextItem":{"title":"This Month in RabbitMQ, July 2020 Recap","permalink":"/rabbitmq-website/blog/2020/08/31/this-month-in-rabbitmq-july-2020-recap"}},"content":"This month in RabbitMQ features a blog from Michael Klishin on deploying RabbitMQ on Kubernetes.\\r\\nAlso this month: RabbitMQ consumers on AWS, a three-part series on developing microservices with Lumen and\\r\\nRabbitMQ, and several articles on RabbitMQ and ASP.NET Core.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Highlights and Updates\\r\\n\\r\\n * [RabbitMQ 3.8.9](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.9) is released\\r\\n\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n * 1 Aug: [.NET Core and RabbitMQ Part 2](https://medium.com/swlh/net-core-and-rabbitmq-part-2-communication-via-amqp-35c5518cb64) — Communication via AMQP, by George Dyrrachitis (@giorgosdyrra)\\r\\n * 2 Aug: [A robust RabbitMQ client in Go](https://www.ribice.ba/golang-rabbitmq-client/), by Emir Ribic (@ribicemir)\\r\\n * 3 Aug: [\\"What is a message broker?\\"](https://medium.com/@ademcatamak/what-is-message-broker-4f6698c73089) Illustrated with RabbitMQ by @ademcatamak\\r\\n * 9 Aug: [Connection pools and RabbitMQ](https://hostiledeveloper.com/2020/08/09/connection-pools-and-rabbitmq.html): how to use ex_rabbit_pool to manage connections and channels by @_StevenNunez\\r\\n * 10 Aug: [Deploying RabbitMQ to Kubernetes: What’s Involved?](/blog/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved), by Michael Klishin (@michaelklishin)\\r\\n * 18 Aug: [RabbitMQ Thread Model](https://medium.com/swlh/rabbitmq-thread-model-62d5505d68ce), by Ryan Zheng\\r\\n * 19 Aug: [FAQ: How to Optimize the RabbitMQ Prefetch Count](https://www.cloudamqp.com/blog/2020-08-19-how-to-optimize-the-rabbitmq-prefetch-count.html)\\r\\n * 23 Aug: [RabbitMQ with ASP.NET Core – Microservice Communication with MassTransit](https://www.codewithmukesh.com/blog/rabbitmq-with-aspnet-core-microservice/) by Mukesh Murugan\\r\\n * 25 Aug: [Create your Event-driven Application with Spring Cloud Stream](https://medium.com/@soyphea/create-your-event-driven-application-with-spring-cloud-stream-53cfb5fb546a) by Soy Phea (@soyphea), featuring RabbitMQ\\r\\n * 27 Aug: [AWS and RabbitMQ Consumers](https://medium.com/@acloudcoder1/aws-rabbitmq-consumers-lambda-vs-ec2-vs-ecs-8a016f1b4c9c): Lambda Vs EC2 Vs ECS by Akshay Malik\\r\\n * 30 Aug: [RabbitMQ on Kubernetes for Beginners](https://www.youtube.com/channel/UCFe9-V_rN9nLqVNiI8Yof3w) (video) by Marcel Dempers\\r\\n * 31 Aug: [RabbitMQ resource provider courtesy of Pulumi](https://github.com/pulumi/pulumi-rabbitmq): lets you manage RabbitMQ resources in your cloud programs\\r\\n * 4 Sep: [Dead Lettering in Nest.js and RabbitMQ](https://medium.com/javascript-in-plain-english/dead-lettering-in-nest-js-rabbitmq-is-it-even-possible-a6aa5732ef1d) — Is it even possible, by Niklas Portmann (@niklaspor)\\r\\n * 9 Sep: [Developing Microservices by using Lumen and RabbitMQ — Part 1](https://medium.com/@behzadbabaei/developing-microservices-by-using-lumen-rabbitmq-part-1-ad6a77f0e812), by @behzadbabaei\\r\\n * 9 Sep: [Developing Microservices by using Lumen & RabbitMQ — Part 2](https://medium.com/@behzadbabaei/developing-microservices-by-using-lumen-rabbitmq-part-2-d78a0f7083d3), by @behzadbabaei\\r\\n * 10 Sep: Java: [Process Messages From RabbitMQ and Upload Data to MinIO Cloud](https://medium.com/better-programming/java-process-messages-from-rabbitmq-and-upload-data-to-minio-cloud-b70ecd2e82be), by Kirshi Yin (@kirshiyin)\\r\\n * 12 Sep: Python: [Publishing and Consuming from RabbitMQ using Python](https://fabianlee.org/2020/09/12/python-publishing-and-consuming-from-rabbitmq-using-python/), by Fabian Lee (@flee999)\\r\\n * 20 Sep: [Developing Microservices by using Lumen & RabbitMQ — Part 3](https://medium.com/@behzadbabaei/developing-microservices-by-using-lumen-rabbitmq-part-3-4dc039d2b3c8), by @behzadbabaei\\r\\n * 26 Sep: [Building a bulk SMS gateway with RabbitMQ](https://www.linkedin.com/pulse/building-bulk-sms-gateway-rabbitmq-penrose-akoto), by Penrose Akoto\\r\\n * 27 Sep: [Scalable Microservice Architecture Using RabbitMQ Request-Reply Pattern](https://medium.com/swlh/scalable-microservice-architecture-using-rabbitmq-rpc-d07fa8faac32), by @OdedShimon\\r\\n * 27 Sep: How to enable [Liveness and Readiness Probes in a Spring Boot Application](https://medium.com/@salarai.de/how-to-enable-liveness-and-readiness-probes-in-a-spring-boot-application-a40cf3423db3) (Illustrated with RabbitMQ), by Salar Ahmadi (@salarai_de)\\r\\n * 29 Sep: [How One Company Used Message Broker Publisher Patterns to Help Inexperienced Developers](https://medium.com/batc/outbox-polling-reliable-message-broker-publisher-61f46ae65cdd), by Timotius Pamungkas\\r\\n * 29 Sep: [RabbitMQ Monitoring on Kubernetes](https://piotrminkowski.com/2020/09/29/rabbitmq-monitoring-on-kubernetes/), by Piotr Minkowski (@piotr_minkowski)\\r\\n\\r\\n\\r\\n## Learn More\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\n * Udemy:  [RabbitMQ and Messaging Concepts](https://www.udemy.com/course/rabbitmq-and-messaging-concepts/), now discounted to $19.99\\r\\n * Tanzu Tuesdays, Nov 3: [What Can Tanzu RabbitMQ Do Better for You](https://tanzu.vmware.com/developer/tv/tanzu-tuesdays/0029/), with Gerhard Lazu\\r\\n * [JFtuture 2020 Online Conference](https://jfuture.dev/), Oct 23-24: [Game of Streams: How to Tame & Get the Most from your Messaging Platforms](http://jfuture.dev), by Mark Heckler (@mkheck)"},{"id":"/2020/08/31/this-month-in-rabbitmq-july-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/08/31/this-month-in-rabbitmq-july-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-08-31-this-month-in-rabbitmq-july-2020-recap/index.md","source":"@site/blog/2020-08-31-this-month-in-rabbitmq-july-2020-recap/index.md","title":"This Month in RabbitMQ, July 2020 Recap","description":"It’s not the holidays yet, but the RabbitMQ community has presents for you anyway!","date":"2020-08-31T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":1.985,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, July 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, Aug/Sep 2020 Recap","permalink":"/rabbitmq-website/blog/2020/11/06/this-month-in-rabbitmq-augsep-2020-recap"},"nextItem":{"title":"Deploying RabbitMQ to Kubernetes: What\'s Involved?","permalink":"/rabbitmq-website/blog/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved"}},"content":"It’s not the holidays yet, but the RabbitMQ community has presents for you anyway!\\r\\nThe RabbitMQ Kubernetes cluster operator is now open-sourced and developed in the open in GitHub.\\r\\nAlso, Gavin Roy has a new Python app that migrates queues between types.\\r\\nFinally, a [webinar on RabbitMQ consumers](https://www2.erlang-solutions.com/webinar-registration-1#pardot-form) from Ayanda Dube, Head of RabbitMQ Engineering at Erlang Solutions.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Highlights and Updates\\r\\n\\r\\n * A Windows-specific binary planting vulnerability was patched. See [CVE-2020-5419](https://tanzu.vmware.com/security/cve-2020-5419) for details.\\r\\n   [CVSS score](https://www.first.org/cvss/calculator/3.0#CVSS:3.0/AV:L/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H) is 6.7 out of 10.\\r\\n   We\'d like to thank Ofir Hamam and Tomer Hadad at Ernst & Young\'s Hacktics Advanced Security Center for researching and responsibly disclosing\\r\\n   this vulnerability.\\r\\n * [RabbitMQ 3.8.7](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.7) and [RabbitMQ 3.7.28](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.28)\\r\\n   are two patch releases that patch the vulnerability.\\r\\n * The above releases are the first ones [released under the Mozilla Public License 2.0](https://github.com/rabbitmq/rabbitmq-server/issues/2372)\\r\\n\\r\\n## Project updates\\r\\n\\r\\n * [Kubernetes Cluster Operator](/kubernetes/operator/operator-overview) development is [picking up the pace](https://github.com/rabbitmq/cluster-operator/pulls?q=is%3Apr+is%3Aclosed)\\r\\n * RabbitMQ 3.7 goes out of extended support [in a few weeks](/release-information) on September 30th, 2020\\r\\n * RabbitMQ .NET client community continues with [project simplification and efficiency gains](https://github.com/rabbitmq/rabbitmq-dotnet-client/pulls?q=is%3Apr+is%3Aclosed) for the next major version\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n * Gavin Roy (@Crad) created a Python app that uses dynamic Shovels to [migrate between queue types](https://gist.github.com/gmr/535c68a72b0338b3c4dd1832403422b1)\\r\\n * 5 Jul: [Spinning up a RabbitMQ instance](https://www.youtube.com/watch?v=eWiqa5SgxeA) and consuming it with Node.js (video) by Hussein Nasser\\r\\n * 6 Jul: Deploying a [Geo-Redundant Serverless RabbitMQ Cluster on Azure Using Pulumi](https://www.pulumi.com/blog/rabbitmq-azure/) for .NET by @itaypodhajcer\\r\\n * 8 Jul: [Schedule Messages in RabbitMQ](https://medium.com/swlh/delay-schedule-messages-in-rabbitmq-208b594cdc00) by Balwant Shekhawat (@balwantshekhawat)\\r\\n * 9 Jul:  Nuno Brites (@nbrites_) writes about experiments with [async messaging with Kotlin and RabbitMQ](https://medium.com/swlh/async-messaging-with-kotlin-and-rabbitmq-d69df1937b25)\\r\\n * 11 Jul: A [practical summary of RabbitMQ](http://www.ezlippi.com/blog/2020/07/rabbitmq-practice.html) by EZLippi\\r\\n * 16 Jul: [Using Spring Boot with RabbitMQ](https://www.ershicimi.com/p/de6004823c72e3e4805c5eee802c87a3) by Liao Xuefeng (in Chinese)\\r\\n * 20 Jul: [RabbitMQ Tutorial for Beginners](https://examples.javacodegeeks.com/rabbitmq-tutorial-for-beginners/) by Yatin\\r\\n * 20 Jul: [Error Handling with Spring AMQP](https://www.baeldung.com/spring-amqp-error-handling) by Eugene Baeldung (@baeldung), featuring RabbitMQ\\r\\n * 22 Jul: [RabbitMQ Work Queues Using Python](https://medium.com/@nipunsampath/rabbitmq-work-queues-using-python-d7663e3a2635) by Nipun Sampath (@nipunsampath)\\r\\n\\r\\n## Learn More\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\nUdemy is running a [special training on RabbitMQ](https://www.udemy.com/courses/search/?q=rabbitmq): 12 courses at $12.99 each. Highlights:\\r\\n\\r\\n * Learn RabbitMQ: Asynchronous Messaging with Java and Spring\\r\\n * Getting Started .NET Core Microservices RabbitMQ\\r\\n * RabbitMQ & Java (Spring Boot) for System Integration\\r\\n\\r\\nIn upcoming webinars: [RabbitMQ consumers under-the-hood](https://www2.erlang-solutions.com/webinar-registration-1#pardot-form).\\r\\nPresented by Ayanda Dube, Head of RabbitMQ Engineering at Erlang Solutions."},{"id":"/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved","metadata":{"permalink":"/rabbitmq-website/blog/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-08-10-deploying-rabbitmq-to-kubernetes-whats-involved/index.md","source":"@site/blog/2020-08-10-deploying-rabbitmq-to-kubernetes-whats-involved/index.md","title":"Deploying RabbitMQ to Kubernetes: What\'s Involved?","description":"Over time, we have seen the number of Kubernetes-related queries on our community","date":"2020-08-10T00:00:00.000Z","tags":[{"inline":true,"label":"Introductory","permalink":"/rabbitmq-website/blog/tags/introductory"},{"inline":true,"label":"Kubernetes","permalink":"/rabbitmq-website/blog/tags/kubernetes"},{"inline":true,"label":"Cloud","permalink":"/rabbitmq-website/blog/tags/cloud"},{"inline":true,"label":"DIY","permalink":"/rabbitmq-website/blog/tags/diy"}],"readingTime":21.295,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Deploying RabbitMQ to Kubernetes: What\'s Involved?","tags":["Introductory","Kubernetes","Cloud","DIY"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, July 2020 Recap","permalink":"/rabbitmq-website/blog/2020/08/31/this-month-in-rabbitmq-july-2020-recap"},"nextItem":{"title":"This Month in Rabbitmq June 2020 Recap","permalink":"/rabbitmq-website/blog/2020/07/30/this-month-in-rabbitmq-june-2020-recap"}},"content":"Over time, we have seen the number of Kubernetes-related queries on our community\\r\\n[mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users)\\r\\nand [Slack](https://rabbitmq-slack.herokuapp.com/) channels soar.\\r\\n\\r\\nIn 2024, the answer to most Kubernetes-related question is: [use the Kubernetes Operator](/kubernetes/operator/operator-overview) built by the RabbitMQ Core Team.\\r\\n It incorporates all the best practices and is the strongly recommended option.\\r\\n\\r\\nThis post explains the basics\\r\\nof a DIY deployment of RabbitMQ on Kubernetes: what Kubernetes resources will be necessary, how to make sure\\r\\nRabbitMQ nodes use durable storage, how to approach configuration of sensitive values, and so on.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## An Update from 2024\\r\\n\\r\\n:::tip\\r\\nInstead of rolling your own deployment of RabbitMQ to Kubernetes, consider [using the Kubernetes Operator](/kubernetes/operator/operator-overview)\\r\\nbuilt by the RabbitMQ Core Team. It incorporates all the best practices and is the strongly recommended option.\\r\\n:::\\r\\n\\r\\n\\r\\n## Introduction\\r\\n\\r\\nDeploying a stateful data service such as RabbitMQ to Kubernetes without [using the Kubernetes Operator](/kubernetes/operator/operator-overview)\\r\\nis a bit like assembling a jigsaw puzzle.\\r\\n\\r\\nThere are multiple pieces involved:\\r\\n\\r\\n * A [Kubernetes namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/)\\r\\n * A [stateful set](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) for RabbitMQ cluter nodes\\r\\n * Ensuring durable storage is used by [node data directories](/docs/relocate)\\r\\n * A Kubernetes Secret for [initial RabbitMQ user credentials](/docs/access-control#default-state)\\r\\n * A Kubernetes Secret for [inter-node and CLI tool authentication](/docs/clustering#erlang-cookie)\\r\\n * A [headless service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) for inter-node communication\\r\\n * Permissions for RabbitMQ node data directory and configuration file(s)\\r\\n * Node [configuration files](/docs/configure#configuration-files)\\r\\n * [Pre-enabled plugin file](/docs/plugins#enabled-plugins-file)\\r\\n * [Peer discovery](/docs/cluster-formation) settings\\r\\n * Kubernetes [access control (RBAC)](https://kubernetes.io/docs/reference/access-authn-authz/rbac/) rules\\r\\n * [Liveness and readiness](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes) probes\\r\\n * A [load balancer service](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer) for external client connections\\r\\n * Resource limits (CPU, memory, disk, network bandwidth)\\r\\n\\r\\nIn this post, we will try to cover the key parts as well as mention a couple\\r\\nmore steps that are not technically required to run RabbitMQ on Kubernetes, but every\\r\\nproduction system operator will have to worry about sooner rather than later:\\r\\n\\r\\n * How to set up cluster monitoring with Prometheus and Grafana\\r\\n * How to deploy a PerfTest instance to do basic functional and load testing of the cluster\\r\\n\\r\\nThis post by no means covers every aspect that may be relevant when deploying\\r\\nRabbitMQ to Kubernetes; our goal is to highlight the most important parts.\\r\\nDeployment- and workload-specific decisions such as what [resource limits](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/) to apply\\r\\nto RabbitMQ node pod (containers), [what kind of durable storage](/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1) to use,\\r\\nhow to approach TLS certificate/key pair rotation, log aggregation, and upgrades are great topics\\r\\nfor separate blog posts. Let us know what you\'d like to see in a follow-up!\\r\\n\\r\\n\\r\\n## Executable Examples\\r\\n\\r\\nThe files that accompany this post can be found in the [DIY RabbitMQ on Kubernetes example repository](https://github.com/rabbitmq/diy-kubernetes-examples).\\r\\nThis post uses a Google Kubernetes Engine (GKE) cluster but Kubernetes concepts are universal.\\r\\n\\r\\nTo follow along the examples,\\r\\n\\r\\n * Access to a Kubernetes Cluster\\r\\n * The [`kubectl` CLI tool](https://kubernetes.io/docs/tasks/tools/install-kubectl/)\\r\\n\\r\\nThis post assumes that the reader is familiar with [`kubectl` usage basics](https://kubernetes.io/docs/reference/kubectl/overview/)\\r\\nand the tool is [set up to work with a GKE cluster](https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-access-for-kubectl).\\r\\n\\r\\n\\r\\n## RabbitMQ Docker Image\\r\\n\\r\\nWe recommend using the [community RabbitMQ Docker image](https://hub.docker.com/_/rabbitmq).\\r\\nThe image is maintained by the [Docker Community](https://github.com/docker-library/rabbitmq) and is built with the latest versions of RabbitMQ,\\r\\nErlang and OpenSSL. The image has a variant built with RabbitMQ release candidates for early testing and adoption.\\r\\n\\r\\nNow let\'s begin with the first building block of a RabbitMQ cluster running on Kubernetes:\\r\\npicking a namespace to deploy to.\\r\\n\\r\\n\\r\\n## Kubernetes Namespace and Permissions (RBAC)\\r\\n\\r\\nEvery set of Kubernetes objects belongs to a [Kubernetes Namespace](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/).\\r\\nRabbitMQ cluster resources are no exception.\\r\\n\\r\\nWe recommend using a dedicated Namespace to keep the RabbitMQ cluster separate from other services that may be deployed\\r\\nin the Kubernetes cluster.\\r\\nHaving a dedicated namespace makes logical sense and makes it easy to [grant just enough permissions](https://kubernetes.io/docs/reference/access-authn-authz/rbac/) to the cluster nodes. This is a good\\r\\nsecurity practice.\\r\\n\\r\\nRabbitMQ\'s Kubernetes peer discovery plugin relies on the Kubernetes API as a data source.\\r\\nOn first boot, every node\\r\\nwill try to discover their peers using the Kubernetes API and attempt to join them.\\r\\nNodes that finish booting emit a [Kubernetes event](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application-introspection/) to make it easier to discover such events in cluster activity (event) logs.\\r\\n\\r\\nThe plugin requires the following access to Kubernetes resources:\\r\\n\\r\\n * `get` access to the `endpoints` resource\\r\\n * `create` access to the `events` resource\\r\\n\\r\\nSpecify a [Role, Role Binding and a Service Account](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)\\r\\nto configure this access.\\r\\n\\r\\nAn example namespace, along with RBAC rules can be seen in the [rbac.yaml example file](https://github.com/rabbitmq/diy-kubernetes-examples/blob/master/gke/rbac.yaml).\\r\\n\\r\\nIf following from the example, use the following command to create a namespace and the required RBAC rules.\\r\\nNote that this creates a namespace called `test-rabbitmq`.\\r\\n\\r\\n```bash\\r\\nkubectl apply -f namespace.yaml\\r\\nkubectl apply -f rbac.yaml\\r\\n```\\r\\n\\r\\nThe `kubectl`  examples below will use the `test-rabbitmq` namespace. This namespace can be set to be the default\\r\\none for convenience:\\r\\n\\r\\n```bash\\r\\n# set the namespace to be the current (default) one\\r\\nkubectl config set-context --current --namespace=test-rabbitmq\\r\\n# verify\\r\\nkubectl config view --minify | grep namespace:\\r\\n```\\r\\n\\r\\nAlternatively, `--namespace=\\"test-rabbitmq\\"` can be appended to all `kubectl` commands\\r\\ndemonstrated below.\\r\\n\\r\\n\\r\\n## Use a Stateful Set\\r\\n\\r\\nRabbitMQ **requires** using a [Stateful Set](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) to deploy a RabbitMQ cluster to Kubernetes.\\r\\nThe Stateful Set ensures that the RabbitMQ nodes are deployed in order, one at a time. This avoids running\\r\\ninto a potential [peer discovery race condition](/docs/cluster-formation#initial-formation-race-condition) when deploying a multi-node RabbitMQ cluster.\\r\\n\\r\\nThere are other, equally important reasons for using a Stateful Set instead of a Deployment:\\r\\nsticky identity, simple network identifiers, stable persistent storage and the ability to perform\\r\\nordered rolling upgrades.\\r\\n\\r\\nThe Stateful Set definition file is packed with detail such as mounting configuration, mounting credentials, opening ports, etc,\\r\\nwhich is explained topic-wise in the following sections.\\r\\n\\r\\nThe final Stateful Set file can be found in the [under `gke` directory](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yaml).\\r\\n\\r\\n\\r\\n## Create a Service For Clustering and CLI Tools\\r\\n\\r\\nThe Stateful Set definition can reference a Service which gives the Pods of the Stateful Set their network identity.\\r\\nHere, we are referring to the [`v1.StatefulSet.Spec.serviceName` property](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#statefulsetspec-v1-apps).\\r\\n\\r\\nThis is required by RabbitMQ for clustering, and as mentioned in the Kubernetes documentation, has to be created before the Stateful Set.\\r\\n\\r\\nRabbitMQ uses port 4369 for port 4369 for node discovery and port 25672 for inter-node communication.\\r\\nSince this Service is used internally and does not need to be exposed,\\r\\nwe create a [Headless Service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services).\\r\\nIt can be found in the [example headless-service.yaml file](https://github.com/rabbitmq/diy-kubernetes-examples/blob/master/gke/headless-service.yaml).\\r\\n\\r\\nIf following from the example, run the following to create a Headless Service for inter-node\\r\\nand CLI tool traffic:\\r\\n\\r\\n```bash\\r\\nkubectl apply -f rabbitmq-headless.yaml\\r\\n```\\r\\n\\r\\nThe service now can be observed in the `test-rabbitmq` namespace:\\r\\n\\r\\n```bash\\r\\nkubectl get all\\r\\n# => NAME                        TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\\r\\n# => service/rabbitmq-headless   ClusterIP   None         <none>        4369/TCP   7s\\r\\n```\\r\\n\\r\\n## Use a Persistent Volume for Node Data\\r\\n\\r\\nIn order for RabbitMQ nodes to retain data between Pod restarts, node\'s data directory must use durable storage.\\r\\nA [Persistent Volume](https://kubernetes.io/docs/concepts/storage/persistent-volumes/) must be attached to each RabbitMQ Pod.\\r\\n\\r\\nIf a transient volume is used to back a RabbitMQ node, the node will lose its identity and all of its\\r\\nlocal data in case of a restart.\\r\\nThis includes both [schema](/docs/clustering#cluster-membership) and [durable queue data](/docs/queues#durability).\\r\\nSyncing all of this data on every node restart would be highly inefficient. In case\\r\\nof a loss of [quorum](/docs/quorum-queues#what-is-quorum) during\\r\\na rolling restart, this will also lead to data loss.\\r\\n\\r\\nIn our [statefulset.yaml example](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yaml#L12-L22),\\r\\nwe create a Persistent Volume Claim to provision a Persistent Volume.\\r\\n\\r\\nThe Persistent Volume is mounted at `/var/lib/rabbitmq/mnesia`. This path is used for a [`RABBITMQ_MNESIA_BASE` location](/docs/relocate): the base directory\\r\\nfor all persistent data of a node.\\r\\n\\r\\nA description of [default file paths for RabbitMQ](/docs/relocate) can be found in the RabbitMQ documentation.\\r\\n\\r\\nNode\'s data directory base can be changed using the `RABBITMQ_MNESIA_BASE` variable if needed. Make sure\\r\\nto mount a Persistent Volume at the updated path.\\r\\n\\r\\n\\r\\n## Node Authentication Secret: the Erlang Cookie\\r\\n\\r\\nRabbitMQ nodes and CLI tools use a shared secret known as [the Erlang Cookie](/docs/clustering#erlang-cookie), to authenticate to each other.\\r\\nThe cookie value is a string of alphanumeric characters up to 255 characters in size. The value must be generated before creating\\r\\na RabbitMQ cluster since it is needed by the nodes to [form a cluster](https://github.com/rabbitmq/diy-kubernetes-examples/blob/gke-examples/examples/gke/statefulset.yaml#L72-L75).\\r\\n\\r\\nWith the community Docker image, RabbitMQ nodes will expect the cookie to be at `/var/lib/rabbitmq/.erlang.cookie`.\\r\\nWe recommend creating a Secret and mounting it as a Volume on the Pods at this path.\\r\\n\\r\\nThis is demonstrated in the [statefulset.yaml example](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yaml#L101-L105) file.\\r\\n\\r\\nThe secret is expected to have the following key/value pair:\\r\\n\\r\\n```yaml\\r\\ncookie: {value}\\r\\n```\\r\\n\\r\\nTo create a cookie Secret, run\\r\\n\\r\\n```bash\\r\\necho -n \\"this secret value is JUST AN EXAMPLE. Replace it!\\" > cookie\\r\\nkubectl create secret generic erlang-cookie --from-file=./cookie\\r\\n```\\r\\n\\r\\nThis will create a Secret with a single key, `cookie`, taken from the file name,\\r\\nand the file contents as its value.\\r\\n\\r\\n\\r\\n## Administrator Credentials\\r\\n\\r\\nRabbitMQ will seed a [default user](/docs/access-control#default-state) with well-known credentials on first boot.\\r\\nThe username and password of this user are both `guest`.\\r\\n\\r\\nThis default user can [only connect from localhost](/docs/access-control#loopback-users) by default.\\r\\nIt is possible to lift this restriction by opting in. This may be useful for testing but **very insecure**.\\r\\nInstead, an administrative user must be created using generated credentials.\\r\\n\\r\\nThe administrative user credentials should be stored in a [Kubernetes Secret](https://kubernetes.io/docs/concepts/configuration/secret/),\\r\\nand mounting them onto the RabbitMQ Pods.\\r\\nThe `RABBITMQ_DEFAULT_USER` and `RABBITMQ_DEFAULT_PASS` environment variables then can be set to the Secret values.\\r\\nThe community Docker image will use them to [override default user credentials](/docs/access-control#seeding).\\r\\n\\r\\n[Example for reference](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yaml#L91-L100).\\r\\n\\r\\nThe secret is expected to have the following key/value pair:\\r\\n\\r\\n```yaml\\r\\nuser: {username}\\r\\npass: {password}\\r\\n```\\r\\n\\r\\nTo create an administrative user Secret, use\\r\\n\\r\\n```bash\\r\\n# this is merely an example, you are welcome to use a different username\\r\\necho -n \\"administrator\\" > user\\r\\n# this is merely an example, you MUST use a different, generated password value!\\r\\necho -n \\"g3N3rAtED-Pa$$w0rd\\" > pass\\r\\nkubectl create secret generic rabbitmq-admin --from-file=./user --from-file=./pass\\r\\n```\\r\\n\\r\\nThis will create a Secret with two keys, `user` and `pass`, taken from the file names,\\r\\nand file contents as their respective values.\\r\\n\\r\\nUsers can be create explicitly using CLI tools as well.\\r\\nSee [RabbitMQ doc section on user management](/docs/access-control#seeding) to learn more.\\r\\n\\r\\n## Node Configuration\\r\\n\\r\\nThere are [several ways](/docs/configure) to configure a RabbitMQ node. The recommended way is to use configuration files.\\r\\n\\r\\nConfiguration files can be expressed as [Config Maps](https://kubernetes.io/docs/concepts/configuration/configmap/),\\r\\nand mounted as a Volume onto the RabbitMQ pods.\\r\\n\\r\\nTo create a Config Map with RabbitMQ configuration, apply our [minimal configmap.yaml example](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/configmap.yaml):\\r\\n\\r\\n```bash\\r\\nkubectl apply -f configmap.yaml\\r\\n```\\r\\n\\r\\n### Use an Init Container\\r\\n\\r\\nSince Kubernetes 1.9.4, Config Maps are mounted as read-only volumes onto Pods. This is problematic for the RabbitMQ community Docker image:\\r\\nthe image can try to update the config file at the time of container startup.\\r\\n\\r\\nThus, the path at which the RabbitMQ config is mounted must be read-write. If a read-only file is detected by the Docker image,\\r\\nyou\'ll see the following warning:\\r\\n\\r\\n```\\r\\ntouch: cannot touch \'/etc/rabbitmq/rabbitmq.conf\': Permission denied\\r\\n\\r\\nWARNING: \'/etc/rabbitmq/rabbitmq.conf\' is not writable, but environment variables have been provided which request that we write to it\\r\\n  We have copied it to \'/tmp/rabbitmq.conf\' so it can be amended to work around the problem, but it is recommended that the read-only\\r\\n  source file should be modified and the environment variables removed instead.\\r\\n```\\r\\n\\r\\nWhile the Docker image does work around the issue, it is not ideal to store the configuration file in `/tmp` and we recommend instead\\r\\nmaking the mount path read-write.\\r\\n\\r\\nAs a few other projects in the Kubernetes community, we use an [init container](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/) to overcome this.\\r\\n\\r\\nExamples:\\r\\n\\r\\n* [The Config Map](https://github.com/rabbitmq/diy-kubernetes-examples/blob/master/examples/minikube/configmap.yaml)\\r\\n* [Using an Init Container to mount the Config Map](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yml#L30-L64)\\r\\n\\r\\n### Run The Pod As the `rabbitmq` User\\r\\n\\r\\nThe Docker image [runs as the `rabbitmq` user with uid 999](https://github.com/docker-library/rabbitmq/blob/38bc089c287d05d22b03a4d619f7ad9d9a4501bc/3.8/ubuntu/Dockerfile#L186-L187](https://github.com/docker-library/rabbitmq/blob/38bc089c287d05d22b03a4d619f7ad9d9a4501bc/3.8/ubuntu/Dockerfile#L186-L187)) and writes to the `rabbitmq.conf` file.\\r\\nThus, the file permissions on `rabbitmq.conf` must allow this. A [Pod Security Context](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/) can be\\r\\nadded to the Stateful Set definition to achieve this.\\r\\nSet the [`runAsUser`, `runAsGroup` and the `fsGroup`](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yaml#L66-L75) to 999 in the Security Context.\\r\\n\\r\\nSee [Security Context](https://github.com/rabbitmq/diy-kubernetes-examples/blob/gke-examples/examples/gke/statefulset.yaml#L72-L75)\\r\\nin the Stateful Set definition file.\\r\\n\\r\\n### Importing Definitions\\r\\n\\r\\nRabbitMQ nodes can [importi definitions](/docs/definitions) exported from another RabbitMQ cluster.\\r\\nThis may also be done at [node boot time](/docs/definitions#import-on-boot).\\r\\n\\r\\nFollowing from the RabbitMQ documentation, this can be done using the following steps:\\r\\n\\r\\n1. Export definitions from the RabbitMQ cluster you wish to replicate and save the file\\r\\n1. Create a Config Map with the key being the file name, and the value being the contents of the file (See the `rabbitmq.conf` Config Map example)\\r\\n1. Mount the Config Map as a Volume on the RabbitMQ Pod in the Stateful Set definition\\r\\n1. Update the `rabbitmq.conf` Config Map with `load_definitions = /path/to/definitions/file`\\r\\n\\r\\n\\r\\n## Readiness Probe\\r\\n\\r\\nKubernetes uses a check known as the [readiness probe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/) to determine if a pod is ready to serve client traffic.\\r\\nThis is effectively a specialized [health check](/docs/monitoring#health-checks) defined\\r\\nby the system operator.\\r\\n\\r\\nWhen an [ordered pod deployment policy](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies) is used — and this is the commended option for RabbitMQ clusters —\\r\\nthe probe controls when the Kubernetes controller will consider the currently deployed pod to be ready\\r\\nand proceed to deploy the next one. This check, if not chosen appropriately, can deadlock a rolling\\r\\ncluster node restart.\\r\\n\\r\\nRabbitMQ nodes that belong to a clsuter will [attempt to sync schema from their peers on startup](/docs/clustering#restarting-schema-sync). If no peer comes online within a configurable time window (five minutes by default),\\r\\nthe node will give up and voluntarily stop. Before the sync is complete, the node won\'t mark itself as fully booted.\\r\\n\\r\\nTherefore, if a readiness probe assumes that a node is fully booted and running,\\r\\n**a rolling restart of RabbitMQ node pods using such probe will deadlock**: the probe will never succeed,\\r\\nand will never proceed to deploy the next pod, which must come online for the original pod to be considered\\r\\nready by the deployment.\\r\\n\\r\\nIt is therefore recommended to use a very basic RabbitMQ health check for readiness probe:\\r\\n\\r\\n```bash\\r\\nrabbitmq-diagnostics ping\\r\\n```\\r\\n\\r\\nWhile this check is not thorough, it allows all pods to be started and re-join the cluster within a certain time period,\\r\\neven when pods are restarted one by one, in order.\\r\\n\\r\\nThis is covered in a dedicated section of the RabbitMQ clustering guide: [Restarts and Health Checks (Readiness Probes)](/docs/clustering#restarting-readiness-probes).\\r\\n\\r\\nThe [readiness probe section](https://github.com/rabbitmq/diy-kubernetes-examples/blob/master/examples/gke/statefulset.yaml#L132-L143)\\r\\nin the Stateful Set definition file demonstrates how to configure a readiness probe.\\r\\n\\r\\n\\r\\n## Liveness Probe\\r\\n\\r\\nSimilarly to the readiness probe described above, Kubernetes allows for pod health checks using a different health check\\r\\ncalled the [liveness probe](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/).\\r\\nThe check determines if a pod must be restarted.\\r\\n\\r\\nAs with all [health checks](/docs/monitoring#health-checks), there is no single solution that can be\\r\\nrecommended for all deployments. Health checks can produce false positives, which means reasonably healthy, operational nodes\\r\\nwill be restarted or even destroyed and re-created for no reason, reducing system availability.\\r\\n\\r\\nMoreover, a RabbitMQ node restart won\'t necessarily address the issue. For example, restarting a node\\r\\nthat is in an [alarmed state](/docs/alarms) because it is low on available disk space won\'t help.\\r\\n\\r\\nAll this is to say that **liveness probes must be chosen wisely** and with false positives and \\"recoverability by a restart\\"\\r\\ntaken into account. Liveness probes also must [use node-local health checks instead of cluster-wide ones](/docs/monitoring#health-checks).\\r\\n\\r\\nRabbitMQ CLI tools provide a number of [pre-defined health checks](/docs/monitoring#health-checks) that\\r\\nvary in how thorough they are, how intrusive they are and how likely they are to produce false positives in different\\r\\nscenarios, e.g. when the system is under load. The checks are composable and can be combined.\\r\\nThe right liveness probe choice is a system-specific decision. When in doubt, start with a simpler, less intrusive\\r\\nand less thorough option such as\\r\\n\\r\\n```bash\\r\\nrabbitmq-diagnostics -q ping\\r\\n```\\r\\n\\r\\nThe following checks can be reasonable liveness probe candidates:\\r\\n\\r\\n```bash\\r\\nrabbitmq-diagnostics -q check_port_connectivity\\r\\n```\\r\\n\\r\\n```bash\\r\\nrabbitmq-diagnostics -q check_local_alarms\\r\\n```\\r\\n\\r\\nNote, however, that they will fail for the nodes [paused by the \\"pause minority\\" partition handliner strategy](/docs/partitions).\\r\\n\\r\\nThe [liveness probe section](https://github.com/rabbitmq/diy-kubernetes-examples/blob/master/examples/gke/statefulset.yaml#L119-L131)\\r\\nin the Stateful Set definition file demonstrates how to configure a liveness probe.\\r\\n\\r\\n\\r\\n## Plugins\\r\\n\\r\\nRabbitMQ [supports plugins](/docs/plugins). Some plugins are essential when running RabbitMQ on Kubernetes,\\r\\ne.g. the Kubernetes-specific peer discovery implementation.\\r\\n\\r\\nThe [`rabbitmq_peer_discovery_k8s` plugin](https://github.com/rabbitmq/diy-kubernetes-examples) is required\\r\\nto deploy RabbitMQ on Kubernetes.\\r\\nIt is quite common to also enable [`rabbitmq_management` plugin](/docs/management) in order to get a browser-based management UI\\r\\nand an HTTP API, and [`rabbitmq_prometheus`](/docs/prometheus) for monitoring.\\r\\n\\r\\nPlugins can be enabled in [different ways](/docs/plugins#ways-to-enable-plugins).\\r\\nWe recommend mounting the plugins file, `enabled_plugins`, to the node configuration directory, `/etc/rabbitmq`.\\r\\nA Config Map can be used to express the value of the `enabled_plugins` file. It can then be mounted\\r\\nas a Volume onto each RabbitMQ container in the Stateful Set definition.\\r\\n\\r\\nIn our [configmap.yaml example](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/configmap.yaml) file,\\r\\nwe demonstrate how to popular the the `enabled_plugins` file and mount it under the `/etc/rabbitmq` directory.\\r\\n\\r\\n\\r\\n## Ports\\r\\n\\r\\nThe final consideration for the Stateful Set is the ports to open on the RabbitMQ Pods.\\r\\nProtocols supported by RabbitMQ are all TCP-based and require the [protocol ports](/docs/networking#ports) to be opened on the RabbitMQ nodes.\\r\\nDepending on the plugins that are enabled on a node, the list of required ports can vary.\\r\\n\\r\\nThe example `enabled_plugins` file mentioned above enables a few plugins: `rabbitmq_peer_discovery_k8s` (mandatory), `rabbitmq_management`\\r\\nand `rabbitmq_prometheus`.\\r\\nTherefore, the service must [open several ports](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yaml#L106-L118) relevant for the core server and the enabled plugins:\\r\\n\\r\\n * `5672`: used by AMQP 0-9-1 and AMQP 1.0 clients\\r\\n * `15672`: management UI and  HTTP API)\\r\\n * `15692`: Prometheus scraping endpoint)\\r\\n\\r\\n\\r\\n## Deploy the Stateful Set\\r\\n\\r\\nThese are the key components in the Stateful Set file. Please have a look [at the file](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/statefulset.yaml),\\r\\nand if following from the example, deploy the Stateful Set:\\r\\n\\r\\n```bash\\r\\nkubectl apply -f statefulset.yaml\\r\\n```\\r\\n\\r\\nThis will start spinning up a RabbitMQ cluster. To watch the progress:\\r\\n\\r\\n```bash\\r\\nwatch kubectl get all\\r\\n# => NAME             READY   STATUS    RESTARTS   AGE\\r\\n# => pod/rabbitmq-0   0/1     Pending   0          8s\\r\\n# =>\\r\\n# => NAME                        TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\\r\\n# => service/rabbitmq-headless   ClusterIP   None         <none>        4369/TCP   61m\\r\\n# =>\\r\\n# => NAME                        READY   AGE\\r\\n# => statefulset.apps/rabbitmq   0/1     8s\\r\\n```\\r\\n\\r\\n## Create a Service for Client Connections\\r\\n\\r\\nIf all the steps above succeeded, you should have functioning RabbitMQ cluster deployed on Kubernetes! ?\\r\\nHowever, having a RabbitMQ cluster on Kubernetes is only useful clients can [connect](/docs/connections) to it.\\r\\n\\r\\nTime to create a Service to make the cluster accessible to [client connections](/docs/connections).\\r\\n\\r\\nThe type of the Service depends on your use case. The [Kubernetes API reference](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#servicespec-v1-core)\\r\\ngives a good overview of the types of Services available.\\r\\n\\r\\nIn the [client-service.yaml example file](https://github.com/rabbitmq/diy-kubernetes-examples/tree/master/gke/client-service.yaml),\\r\\nwe have gone with a `LoadBalancer` Service.\\r\\nThis gives us an external IP that can be used to access the RabbitMQ cluter.\\r\\n\\r\\nFor example, this should make it possible to visit the RabbitMQ management UI by visiting `{external-ip}:15672`, and signing in.\\r\\nClient applications can connect to endpoints such as `{external-ip}:5672` (AMQP 0-9-1, AMQP 1.0) or `{external-ip}:1883` (MQTT).\\r\\nPlease refer to the [get started guide](/tutorials) to learn how to use RabbitMQ.\\r\\n\\r\\nIf following from the example, run\\r\\n\\r\\n```bash\\r\\nkubectl apply -f client-service.yaml\\r\\n```\\r\\n\\r\\nto create a Service of type LoadBalancer with an external IP address. To find out what the external IP address is,\\r\\nuse `kubectl get svc`:\\r\\n\\r\\n```bash\\r\\nkubectl get svc\\r\\n# => NAME                        TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                                          AGE\\r\\n# => service/rabbitmq-client     LoadBalancer   10.59.244.70   34.105.135.216   15672:30902/TCP,15692:30605/TCP,5672:31210/TCP   2m19s\\r\\n```\\r\\n\\r\\n\\r\\n## Resource Usage and Limits\\r\\n\\r\\n[Container resource management](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/) is a topic that deserves\\r\\nits own post. [Capacity planning](/blog/tags/capacity-planning) recommendations are entirely workload-,\\r\\nenvironment- and system-specific. Optimal values are usually found via extensive [monitoring](/docs/monitoring) of the system, trial, and error.\\r\\nHowever, when picking the limits and resource allocation settings, consider a few RabbitMQ-specific things.\\r\\n\\r\\n### Use the Latest Major Erlang Release\\r\\n\\r\\nRabbitMQ runs on the Erlang runtime. Recent Erlang/OTP releases have introduced a number of improvements highly relevant to\\r\\nthe users who run RabbitMQ on Kubernetes:\\r\\n\\r\\n * In Erlang 22, inter-node communication [latency and head-of-line blocking(http://blog.erlang.org/OTP-22-Highlights/) have been\\r\\n   significantly reduced. In earlier versions, link congestion was known to make [cluster node heartbeat](/docs/nettick) false\\r\\n   positives likely.\\r\\n * In Erlang 23, the runtime will [respect the container CPU quotas](http://blog.erlang.org/OTP-23-Highlights/) when computing the default number of schedulers to start. This means that nodes will respect the Kubernetes-managed CPU resource limits.\\r\\n\\r\\nDocker community image for RabbitMQ ships with Erlang 23 at the time of writing. Users of custom Docker images are highly recommended\\r\\nto provision Erlang 23 as well.\\r\\n\\r\\n### CPU Resource Usage\\r\\n\\r\\nRabbitMQ was designed for workloads that involve [multiple queues](/docs/queues#runtime-characteristics) and where\\r\\na node serves multiple clients at the same time. Nodes will generally use all the [CPU cores allowed](/docs/runtime)\\r\\nwithout any explicit configuration. As the number of cores grows, some tuning may be necessary to reduce [CPU context switching](/docs/runtime#scheduling).\\r\\n\\r\\nHow CPU time is spent can be monitored via the [runtime thread activity metrics](/docs/runtime#thread-stats) which\\r\\nare also exposed via the [RabbitMQ Prometheus plugin](/docs/prometheus).\\r\\n\\r\\nIf RabbitMQ pods hover around their CPU resource allowance and experience throttling in environments with a large number of\\r\\nrelatively idle clients, the load likely can be [reduced with a modest amount of configuration](/docs/runtime#cpu-reduce-idle-usage).\\r\\n\\r\\n### Memory Limits\\r\\n\\r\\nRabbitMQ uses the concept of a [runtime memory high watermark](/docs/memory). By default a node will use 40% of detected\\r\\n(available) memory as the watermark. When the watermark is crossed, publishers across the entire cluster will be blocked\\r\\nand more aggressive paging out to disk initiated. The watermark value may seem like a memory quota on Kubernetes at first\\r\\nbut there is an important difference: RabbitMQ resource alarms assume a node can typically recover from this state. For example,\\r\\na large backlog of messages will eventually be consumed.\\r\\n\\r\\nKubernetes memory limits are [enforced by the OOM killer](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#requests-and-limits):\\r\\nno recovery is expected. This means that a RabbitMQ node\'s high memory watermark **must be lower** than the memory limit\\r\\nimposed on the node container. Kubernetes deployments should use the relative watermark values in the [recommended range](/docs/production-checklist#resource-limits-ram).\\r\\n\\r\\n[Memory usage breakdown data](/docs/memory-use) should be used to determine what consumes most memory on the node.\\r\\n\\r\\n### Disk Usage\\r\\n\\r\\nWe highly recommend overprovisioning the [disk space available to RabbitMQ containers](/docs/production-checklist#resource-limits-disk-space).\\r\\nA node that has run out of disk space won\'t always be able to recover from such an event. Such nodes must be\\r\\ndecomissioned and replaced.\\r\\n\\r\\n### Consider Available Network Link Bandwidth\\r\\n\\r\\nFinally, consider what kind of links and Kubernetes networking options are used for inter-node communication. Network link congestion\\r\\ncan be a significant limiting factor to system throughput and affect its availability.\\r\\n\\r\\nBelow is a very simplistic formula to calculate the amount of bandwidth needed by a workload, in bits:\\r\\n\\r\\n```\\r\\n# peak message rate * bits per message * 110% to account for metadata and protocol framing\\r\\nPeakMessageRate * AverageMessagePayloadSizeInBytes * 8 * 1.1\\r\\n```\\r\\n\\r\\nTherefore a workload with average message size of 3 kiB and expected peak message rate\\r\\nof 20K messages a second can consume up to\\r\\n\\r\\n```\\r\\n3 kiB * 20000/second * 8 * 1.1 = 528 megabits/second\\r\\n```\\r\\n\\r\\nof bandwidth.\\r\\n\\r\\nTeam RabbitMQ maintains a [Grafana dashboard](/docs/prometheus#other-dashboards) for inter-node communication\\r\\nlink metrics.\\r\\n\\r\\n\\r\\n## Using `rabbitmq-perf-test` to Run a Functional and Load Test of the Cluster\\r\\n\\r\\nRabbitMQ comes with a load simulation tool, [PerfTest](https://rabbitmq.github.io/rabbitmq-perf-test/stable/htmlsingle/),\\r\\nwhich can be executed from outside of a cluster or deployed to Kubernetes using the `perf-test` public [docker image](https://hub.docker.com/r/pivotalrabbitmq/perf-test/).\\r\\nHere\'s an example of how the image can be deployed to a Kubernetes cluster\\r\\n\\r\\n```bash\\r\\nkubectl run perf-test --image=pivotalrabbitmq/perf-test -- --uri amqp://{username}:{password}@{service}\\r\\n```\\r\\n\\r\\nHere the `{username}` and `{password}` are the user credentials, e.g. those set up in the `rabbitmq-admin` Secret.\\r\\nThe `{serivce}` is the hostname to connect to. We use the name of the client service that will resolve as a hostname when deployed.\\r\\n\\r\\nThe above `kubectl run` command will start a PerfTest pod which can be observed in\\r\\n\\r\\n```bash\\r\\nkubectl get pods\\r\\n```\\r\\n\\r\\nFor a functioning RabbitMQ cluster, running `kubectl logs -f {perf-test-pod-name}` where `{perf-test-pod-name}`\\r\\nis the name of the pod as reported by `kubectl get pods`,  will produce output similar to this:\\r\\n\\r\\n```\\r\\nid: test-110102-976, time: 263.100s, sent: 21098 msg/s, received: 21425 msg/s, min/median/75th/95th/99th consumer latency: 1481452/1600817/1636996/1674410/1682972 ?s\\r\\nid: test-110102-976, time: 264.100s, sent: 17314 msg/s, received: 17856 msg/s, min/median/75th/95th/99th consumer latency: 1509657/1600942/1636253/1695525/1718537 ?s\\r\\nid: test-110102-976, time: 265.100s, sent: 18597 msg/s, received: 17707 msg/s, min/median/75th/95th/99th consumer latency: 1573151/1716519/1756060/1813985/1846490 ?s\\r\\n```\\r\\n\\r\\nTo learn more about PerfTest, its settings, capabilities and output, see the [PerfTest doc guide](https://rabbitmq.github.io/rabbitmq-perf-test/stable/htmlsingle/).\\r\\n\\r\\nPerfTest is not meant to be running permanently. To tear down the `perf-test` pod, use\\r\\n\\r\\n```bash\\r\\nkubectl delete pod perf-test\\r\\n```\\r\\n\\r\\n\\r\\n## Monitoring the Cluster\\r\\n\\r\\n[Monitoring](/docs/monitoring) is a critically important part of any production deployment.\\r\\n\\r\\nRabbitMQ comes with [in-built support for Prometheus](/docs/prometheus). To enable it, enable the `rabbitmq_prometheus` plugin.\\r\\nThis in turn can be done by adding `rabbitmq_promethus` to the `enabled_plugins` Config Map as explained above.\\r\\n\\r\\nThe Prometheus scraping port, 15972, must be open on both the Pod and the client Service.\\r\\n\\r\\nNode and cluster metrics can be [visualised with Grafana](/docs/prometheus).\\r\\n\\r\\n\\r\\n## Alternative Option: the Kubernetes Cluster Operator for RabbitMQ\\r\\n\\r\\nAs this post demonstrates, there are quite a few parts involved in hosting a stateful data services\\r\\nsuch as RabbitMQ on Kubernetes. It may seem like a daunting task.\\r\\nThere are several alternatives to this kind of DIY deployment demonstrated in this post.\\r\\n\\r\\nTeam RabbitMQ at VMware has open sourced a [Kubernetes Operator pattern](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/)\\r\\nimplementation for RabbitMQ. As of August 2020, this is a young project under active development.\\r\\nWhile it currently has limitations, it is our recommended option over the manual DIY setup\\r\\ndemonstrated in this post.\\r\\n\\r\\nSee [RabbitMQ Cluster Operator for Kubernetes ](/kubernetes/operator/operator-overview) to learn more.\\r\\nThe project is developed in the open at [rabbitmq/cluster-operator on GitHub](https://github.com/rabbitmq/cluster-operator). Give it a try and let us know how it goes.\\r\\nBesides GitHub, two great venues for providing feedback to the team behind the Operator are the [RabbitMQ mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users)\\r\\nand the [`#kubernetes channel in RabbitMQ community Slack`](https://rabbitmq-slack.herokuapp.com/)."},{"id":"/2020/07/30/this-month-in-rabbitmq-june-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/07/30/this-month-in-rabbitmq-june-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-07-30-this-month-in-rabbitmq-june-2020-recap/index.md","source":"@site/blog/2020-07-30-this-month-in-rabbitmq-june-2020-recap/index.md","title":"This Month in Rabbitmq June 2020 Recap","description":"This month in RabbitMQ features the release of the RabbitMQ Cluster Kubernetes Operator, benchmarks and cluster sizing case studies by Jack Vanlightly (@vanlightly), and a write up of RabbitMQ cluster migration by Tobias Schoknecht (@tobischo), plus lots of other tutorials by our vibrant community!","date":"2020-07-30T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.425,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in Rabbitmq June 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Deploying RabbitMQ to Kubernetes: What\'s Involved?","permalink":"/rabbitmq-website/blog/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved"},"nextItem":{"title":"Disaster Recovery and High Availability 101","permalink":"/rabbitmq-website/blog/2020/07/07/disaster-recovery-and-high-availability-101"}},"content":"This month in RabbitMQ features the release of the RabbitMQ Cluster Kubernetes Operator, benchmarks and cluster sizing case studies by Jack Vanlightly (@vanlightly), and a write up of RabbitMQ cluster migration by Tobias Schoknecht (@tobischo), plus lots of other tutorials by our vibrant community!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n * The [RabbitMQ Cluster Kubernetes Operator](/kubernetes/operator/operator-overview) has been released in beta!\\r\\n    The Operators strives to offer best-in-class automation of RabbitMQ clusters running on Kubernetes, from initial deployments to Day 2 operations. Please try it and give us feedback via Github!\\r\\n * RabbitMQ will be [migrating to the Mozilla Public License 2.0](https://github.com/rabbitmq/rabbitmq-server/issues/2372) starting with the 3.8.6 release\\r\\n * [RabbitMQ 3.8.6-rc.1](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.6-rc.1) is released is\\r\\n   available for testing.\\r\\n * [RabbitMQ .NET client development](https://github.com/rabbitmq/rabbitmq-dotnet-client/pulls?q=is%3Apr+is%3Aclosed) has maintained its pace. Major thanks to our awesome community of users and contributors!\\r\\n\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n * June 1: [Recovering RabbitMQ connections in Go applications](https://medium.com/@dhanushgopinath/automatically-recovering-rabbitmq-connections-in-go-applications-7795a605ca59) by @dhanushgopinath\\r\\n * June 1: [Fanout Async Messaging Design](https://www.c-sharpcorner.com/article/fanout-design-with-rabbitmq-exchange/) In Microservices Using RabbitMQ, by Nilanjan Dutta (@nilanjan_i_am)\\r\\n * June 2: [Get Started with RabbitMQ 2: Consume Messages](https://codeburst.io/get-started-with-rabbitmq-2-consume-messages-using-hosted-service-e7e6a20b15a6) Using a Hosted Service by Changhui Xu (@changhuixu)\\r\\n * June 4: [How to Benchmark RabbitMQ](/blog/2020/06/04/how-to-run-benchmarks) by @vanlightly\\r\\n * June 6: Influx DB via RabbitMQ: [Gathering Metrics over RabbitMQ](https://raymondc.net/2020/06/06/influx-via-telegraf-and-rmq-index.html) by Raymond Coetzee\\r\\n * June 6: [Go RabbitMQ tutorial walkthrough](https://www.linkedin.com/pulse/go-rabbitmq-tutorial-walkthrough-sergei-stadnik) by Sergei Stadnik\\r\\n * June 12: [Implementing Resilience Between Microservices with RabbitMQ and Dead-Letter Exchanges](https://www.linkedin.com/pulse/implementando-resili%25C3%25AAncia-entre-microservi%25C3%25A7os-com-e-rabbitmq-alonso), by Rodrigo Alonso (in Portuguese)\\r\\n * June 13: [Tips for deploying and managing a high availability RabbitMQ cluster](https://medium.com/%E6%BC%B8%E5%BC%B7%E5%AF%A6%E9%A9%97%E5%AE%A4-crescendo-lab-engineering-blog/tips-for-deploy-and-manage-high-availability-rabbitmq-cluster-a0d8002ab97e) by Chris Kuan (@kst920106), in Chinese\\r\\n * June 17: [Microservices communication: Rabbitmq and ASP.NET core](https://doumer.me/micro-services-communication-rabbitmq-and-asp-net-core/) by @Damien_Doumer\\r\\n * June 18: [Cluster sizing and other considerations](/blog/2020/06/18/cluster-sizing-and-other-considerations) by @vanlightly\\r\\n * June 18: [Cluster Sizing Case Study: Mirrored Queues Part 1](/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1) by @vanlightly\\r\\n * June 18: [Cluster Sizing Case Study: Mirrored Queues Part 2](/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2) by @vanlightly\\r\\n * June 18: [Cluster Sizing Case Study: Quorum Queues Part 1](/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1) by @vanlightly\\r\\n * June 18: [Cluster Sizing Case Study: Quorum Queues Part 2](/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2) by @vanlightly\\r\\n * June 22: [How to bridge RabbitMQ with Azure Service Bus](https://dev.to/azure/how-to-bridge-rabbitmq-with-azure-service-bus-98l) by Álvaro Videla (@old_sound)\\r\\n * June 23: [Setting up a Flask app with a Celery beat scheduler and RabbitMQ](https://medium.com/@delivey/celery-beat-scheduler-flask-rabbitmq-e84cdba63ab7) as the message broker, by @delivey\\r\\n * June 23: [How Quorum Queues Deliver Locally](/blog/2020/06/23/quorum-queues-local-delivery) while still offering ordering guarantees, by @vanlightly\\r\\n * June 24: [How to do a RabbitMQ cluster migration](https://www.sysorchestra.com/rabbitmq-cluster-migration/) by Tobias Schoknecht (@tobischo)\\r\\n * June 24: [Installing RabbitMQ on Windows with a .NET Core Publisher and Consumer](https://medium.com/@a.burakbasaran/rabbitmq-nedir-windows-ortam%C4%B1na-kurulumu-ve-net-core-publisher-consumer-fd55adcf35e7) by Ali Burak Ba?aran (@a.burakbasaran), in Turkish\\r\\n * June 25: [Learning RabbitMQ](https://medium.com/ryans-dev-notes/learning-rabbitmq-3f59d11f66b4) by Ryan Ermita, with code examples (@ryanermita)\\r\\n * June 27: [Connecting Services using MassTransit and RabbitMQ on .NET Core 3.1](https://medium.com/@ffimnsr/connecting-services-using-masstransit-rabbitmq-on-net-core-3-1-343b510c9202) by Edward Fitz Abucay (@ffimnsr)\\r\\n\\r\\n\\r\\n## Learn More\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n * Udemy is offering “[Learn RabbitMQ: In-Depth Concepts](https://www.udemy.com/course/rabbitmq-message-broker-learn-in-depth-concepts-in-rabbitmq/) from Scratch with Demos” for $13.99, an 85% discount. You can’t afford not to learn RabbitMQ at this price!"},{"id":"/2020/07/07/disaster-recovery-and-high-availability-101","metadata":{"permalink":"/rabbitmq-website/blog/2020/07/07/disaster-recovery-and-high-availability-101","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-07-07-disaster-recovery-and-high-availability-101/index.md","source":"@site/blog/2020-07-07-disaster-recovery-and-high-availability-101/index.md","title":"Disaster Recovery and High Availability 101","description":"| Be aware this post has out of date information |","date":"2020-07-07T00:00:00.000Z","tags":[{"inline":true,"label":"Resiliency","permalink":"/rabbitmq-website/blog/tags/resiliency"}],"readingTime":19.315,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Disaster Recovery and High Availability 101","tags":["Resiliency"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"This Month in Rabbitmq June 2020 Recap","permalink":"/rabbitmq-website/blog/2020/07/30/this-month-in-rabbitmq-june-2020-recap"},"nextItem":{"title":"This Month in RabbitMQ, May 2020 Recap","permalink":"/rabbitmq-website/blog/2020/06/30/this-month-in-rabbitmq-may-2020-recap"}},"content":"| Be aware this post has out of date information |\\r\\n| :--- |\\r\\n| RabbitMQ now has Disaster Recovery capabilities in the commercial editions via the [Warm Standby Replication feature](https://docs.vmware.com/en/VMware-RabbitMQ-for-Kubernetes/1/rmq/standby-replication.html) |\\r\\n\\r\\n___ \\r\\n\\r\\n\\r\\nIn this post I am going to cover perhaps the most commonly asked question I have received regarding RabbitMQ in the enterprise.\\r\\n\\r\\n> How can I make RabbitMQ highly available and what architectures/practices are recommended for disaster recovery?\\r\\n\\r\\nRabbitMQ offers features to support high availability and disaster recovery but before we dive straight in I’d like to prepare the ground a little.\\r\\nFirst I want to go over Business Continuity Planning and frame our requirements in those terms. From there we need to set some expectations about what is possible. There are fundamental laws such as the speed of light and the CAP theorem which both have serious impacts on what kind of DR/HA solution we decide to go with.\\r\\n\\r\\nFinally we’ll look at the RabbitMQ features available to us and their pros/cons.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## What is the difference between High Availability and Disaster Recovery?\\r\\n\\r\\n*High Availability* typically refers to some kind of automated fail-over from one instance of deployed software to another in the event of a localised failure, such as a server or disk failing, or a limited network outage. The impact of failure on availability should either not be seen or be extremely low.\\r\\n\\r\\n*Disaster Recovery* typically refers to a response to a more major incident (a disaster) such as the loss of an entire data center, massive data corruption or any other kind of failure that could cause a total loss of service and/or data. Disaster Recovery attempts to avoid permanent partial or total failure or loss of a system and usually involves building a redundant system that is geographically separated from the main site.\\r\\n\\r\\nBoth fall within the realm of Business Continuity.\\r\\n\\r\\n## Business Continuity Planning 101\\r\\n\\r\\nUltimately, we want to be able to recover fast from major incidents (disaster recovery) and deliver continued availability during more minor incidents (high availability).\\r\\n\\r\\nA major incident may involve losing a whole data center, due to fire, a power outage or extreme weather. A more minor incident might involve the partial loss of a data center, or simply the loss of a disk drive or server.\\r\\n\\r\\nImplementing a system that can recover from failure and disaster can be expensive both monetarily and also with regard to performance. Ultimately the implementation will be a balance of cost of implementation vs the cost of data loss and service interruption.\\r\\n\\r\\nIn order to make that balance, we need to take into consideration:\\r\\n\\r\\n * The available tools for redundancy/availability and their limitations\\r\\n * The types of data and the associated costs to the business if lost\\r\\n\\r\\nFirst we’ll cover the measurable objectives that define our acceptable data loss and unavailability time windows in the event of an incident, then we’ll cover the considerations above.\\r\\n\\r\\n### Loss of Data and Availability Objectives\\r\\n\\r\\nAs part of a Business Continuity Plan, an enterprise must decide on two key objectives with regard to disaster recovery.\\r\\n\\r\\nThe **Recovery Point Objective** (RPO) determines the maximum time period of data loss a business can accept as the result of a major incident. The obvious answer is 0 seconds, meaning no data loss, but this can be hard to achieve and even when possible can have serious downsides like cost or performance. Other values might be 1 hour or 24 hours, with higher values typically being easier to achieve at a lower implementation cost. In the end it will be a balance of the downsides vs the business impact of data loss.\\r\\n\\r\\n![Fig 1. RPO defines the acceptable data loss window in the event of a disaster](rpo.png)\\r\\n\\r\\nThe **Recovery Time Objective** (RTO) determines the maximum time period of unavailability, aka the time it takes to recover and be operational again. The obvious answer might be 0 seconds, meaning a seamless failover with continued availability, but this might not be technically achievable and if it were then the costs might be far higher than your enterprise is willing to pay.\\r\\n\\r\\n![Fig 2. RTO defines the acceptable availability loss window in the event of a disaster](rto.png)\\r\\n\\r\\nThese windows of availability and data loss may or may not overlap.\\r\\n\\r\\n![Fig 3. Availability and data loss may or may not overlap](rpo-rto.png)\\r\\n\\r\\nUltimately both RPO and RTO are a trade-off between the benefits of having continued business operations and the various downsides, such as cost and performance impact. \\r\\n\\r\\n### Types of Data and Business Impact\\r\\n\\r\\n![Fig 4. Types of data and the impact of their loss on businesses](data-loss-impact.png)\\r\\n\\r\\nPersistent data sticks around week after week and even year after year. If an enterprise loses its most valuable persistent data it can kill the company. Transient data has a short life, it may be data in-flight between two systems or data that can be evicted at any time. While losing transient data can be impactful, it is unlikely to cause a company to go out of business. \\r\\n\\r\\nSource-of-truth data is either master data and/or data that doesn’t exist anywhere else. Secondary data is a copy (possibly filtered and transformed) of the source-of-truth that can be recovered from the source persistent store. Examples of secondary data are:\\r\\n\\r\\n * a cache stores secondary data that can be re-hydrated from a persistent store.\\r\\n * a microservice stores some small amount of data in a database that belongs to another service.\\r\\n * A distributed log streams database data modifications to other systems.\\r\\n\\r\\nThe loss of secondary data can cause:\\r\\n\\r\\n * loss of availability while it is recovered from the source-of-truth.\\r\\n * loss of performance capacity due losing \\"hot\\" data\\r\\n\\r\\nThe most damaging data loss would be loss of source-of-truth persistent data and the least would be transient secondary data.\\r\\n\\r\\nIn the persistent/transient continuum, at the persistent end we have databases, at the transient end we have message queues (like RabbitMQ) and in the middle are distributed logs (e.g. Apache Kafka). Databases, message queues and distributed logs can store both source-of-truth and secondary data. Caches and search engines typically store secondary data.\\r\\n\\r\\n![Fig 5. Data type continuum\'s and typical data store usage](data-types.png)\\r\\n\\r\\nRabbitMQ stores transient data. A message is simply data in-flight from a source to one or more destinations. Once read, the message is destroyed. If you want the data in that message to stick around then you’ll need to write that message data to some kind of persistent store like a database, file-system or object store. While a message is transient, it may still be source-of-truth data because it doesn’t exist anywhere else yet, and if lost can never be recovered.\\r\\n\\r\\nIt is important to take into account where your data sits in this continuum when defining your RPO and RTO values. Because these values are a balance of the cost of implementation vs cost of service interruption - make sure you get the appropriate balance for the type of data that is stored and served.\\r\\n\\r\\n### Data Redundancy Tools - Back-ups and Replication\\r\\n\\r\\nData systems such as databases, caches and message queues usually offer one or two ways of safeguarding data in the event of failure.\\r\\n\\r\\nAll database systems offer some kind of *back-up* feature. Full back-ups can be made on a schedule, such as nightly or weekly and additionally can offer incremental backups on a higher cadence, such as every 15 minutes.\\r\\n\\r\\nThe important thing to remember about backups is that recovering from them involves potential data loss as there was potentially new data that entered the system since the last backup was made. Recovery from back-up can also take time - time to move backup files to their destination and time for the data system to recover from those files.\\r\\n\\r\\nThe other common feature is *replication*. This is where data modifications are streamed from one node to another, meaning that the data now resides in at least two locations. Replication comes in two flavours: synchronous or asynchronous and there is a big difference between them.\\r\\n\\r\\nWith *synchronous replication*, the client only gets the confirmation that the operation has succeeded once it has been replicated to other nodes. This is the only form of replication that offers no data loss, but it comes at a price: \\r\\n\\r\\n * waiting for an operation to be replicated adds latency\\r\\n * If the network is down between the nodes then availability may be lost\\r\\n * If the secondary node(s) is down then availability may be lost\\r\\n\\r\\nSynchronous replication is typically the solution for high availability within a data center or cloud region. Fail-over is often automated and fast causing little or no impact on clients. Some data systems use asynchronous replication for high availability that provide eventual consistency (with potential data loss).\\r\\n\\r\\nWith *asynchronous replication*, the client gets the confirmation that the operation has succeeded when it has been committed locally. The operation is replicated in the background meaning that there is no additional latency for the client and no loss of availability if the network between the primary and secondary is down. The downside is that there will be lag between the primary and secondary node, meaning that data loss can occur in the event that the primary is lost.\\r\\n\\r\\nAsynchronous replication and backups are typically the solution for Disaster Recovery.\\r\\n\\r\\n### Fundamental Limits\\r\\n\\r\\nWhen designing both a High Availability and Disaster Recovery strategy, we need to take into account some fundamental limits such as the speed of light and the CAP theorem. These limits affect the costs and feasibility of the RPO and RTO values we choose.\\r\\n\\r\\nThe CAP theorem states that in the event of a network partition, either you can have  consistency or availability but not both. It uses the letters C for Consistency, A for Availability and P for Partition tolerance. We always have to choose P, but we only get A or C.\\r\\n\\r\\nCAP classifies systems as either:\\r\\n\\r\\n * AP - Availability in a partitioned network\\r\\n * CP - Consistency in a partitioned network\\r\\n\\r\\nCP systems lose availability if they cannot satisfy the necessary level of redundancy due to lack of connectivity to peer nodes. CP systems synchronously replicate operations and only confirm to clients when those operations are safely committed to multiple nodes. This avoids data loss at the cost of higher latency.\\r\\n\\r\\nYou choose a CP system when consistency is the most important consideration. \\r\\n\\r\\nAP systems continue to be available despite not reaching the desired redundancy level. AP systems asynchronously replicate operations but this can cause data loss if a node is lost, this loss being due to replication lag. The upside is lower latency as operations can be immediately confirmed to clients.\\r\\n\\r\\nYou choose an AP system when availability and/or latency is the most important consideration. \\r\\n\\r\\n#### Single Data Center\\r\\n\\r\\nWithin a single data center, you can choose either an AP or a CP system and many data systems are configurable allowing you to tune them towards availability or consistency. \\r\\n\\r\\nWithin a single data center, the network can offer a high degree of reliability and low latency. In this environment, the use of quorum (majority) based replication algorithms by CP systems can make unavailability a rare event. Quorum based CP systems can tolerate the failure or network isolation of a minority of nodes and delivery availability without data loss and are a good high availability solution.\\r\\n\\r\\n#### Multiple Data Centers\\r\\n\\r\\nThe reliability and latency of the network between data centers is inferior to that of a LAN and building a CP system that has acceptable availability and latency is at best challenging and most likely infeasible.\\r\\n\\r\\nAP systems can be built across multiple data centers but they increase the likelihood of data loss and also the size of the data loss window.\\r\\n\\r\\n### Rack Awareness\\r\\n\\r\\nThis is a feature of data systems that ensure that data is replicated across racks or availability zones or data centers, basically any type of failure domain in your infrastructure. The idea is that if data is replicated but still only exists on a single rack, then losing the entire rack means we lose the data. Rack awareness is an extra resiliency feature.\\r\\n\\r\\n![Fig 6. Service interruption and/or data loss because data was not spread across failure domains](rack-awareness-1.png)\\r\\n\\r\\nWhen spread out across AZs, the loss of one AZ cannot cause data loss or loss of availability.\\r\\n\\r\\n![Fig 7. Loss of a single failure domain does not impact availability or cause data loss](rack-awareness-2-2.png)\\r\\n\\r\\n## HA and DR Considerations Overview\\r\\n\\r\\n * High Availability is the ability to remain available in the face of failures\\r\\n * Disaster Recovery is the ability to recover from disaster with bounded data loss and unavailability\\r\\n * Recovery Point Objective (RPO) defines the time period of data loss that is acceptable in the event of a disaster.\\r\\n * Recovery Time Objective (RTO) defines the maximum time period to recovery (the unavailability period).\\r\\n * RPO and RTO are a tradeoff between cost of implementation and cost of data loss/service interruption.\\r\\n * Synchronous replication provides data safety at the cost of availability and extra latency. The only choice for an RPO of 0 seconds. Typically not multi-DC friendly.\\r\\n * Asynchronous replication provides higher availability, lower latency but at the cost of potential data loss in a fail-over - a good choice when RPO &gt; 0 minutes. Typically multi-DC compatible.\\r\\n * Back-ups can be slower to recover with, but have other benefits such as being able to travel back in time.\\r\\n * Rack awareness adds additional resiliency to replicated data stores.\\r\\n\\r\\nNow let’s look at RabbitMQ’s features, framed against what we have covered so far.\\r\\n\\r\\n## RabbitMQ \\r\\n\\r\\nRabbitMQ supports:\\r\\n\\r\\n * clustering of multiple nodes\\r\\n * synchronous replication - replicated queues\\r\\n * asynchronous cluster-to-cluster message routing - exchange federation and shovels\\r\\n * limited back-up support\\r\\n * limited rack awareness support\\r\\n\\r\\nWe’ll next see how these features can be used for high availability and disaster recovery.\\r\\n\\r\\n### High Availability\\r\\n\\r\\nFor high availability we recommend [*clustering*](/docs/clustering) multiple RabbitMQ brokers within a single data center or cloud region and the use of **replicated queues**. Clustering requires highly reliable, low latency links between brokers. Clustering over a WAN is highly discouraged.\\r\\n\\r\\n#### Clustering and Availability Zones\\r\\n\\r\\nMost regions in AWS, Azure and GCP offer multiple availability zones. Availability zones are essentially data centers that are connected by ultra reliable, low latency links but not geographically separated. Clustering across AZs in these clouds can offer higher availability than hosting a cluster in just one AZ. It can however increase costs if the cloud provider charges for cross AZ data transfer.\\r\\n\\r\\nA multi AZ cluster is a good option for high availability but due to lack of geographic separation may not meet your needs for disaster recovery. It is important to note that the concept of an AZ is not standardised and other cloud platforms may use this term more loosely.\\r\\n\\r\\nRabbitMQ offers two types of replicated queue: mirrored queues (HA queues) and quorum queues. These queue types use synchronous replication and provide data safety and high availability in the face of failures such as servers, disks and network.\\r\\n\\r\\n#### Clustering and Multiple Data Centers\\r\\n\\r\\nWe highly discourage clustering across a WAN due to the effect of network partitions. Links that are tunnels across the public internet are simply not viable. Leased links from providers are better but also a risky choice. If an enterprise has its own fibre linking its data centers which is highly reliable and consistently low latency (like on-prem availability zones), then it might be an option.\\r\\n\\r\\n#### Quorum Queues\\r\\n\\r\\n[Quorum queues](/docs/quorum-queues) are CP and tolerate the loss of brokers as long as a quorum (majority) remains functioning. Likewise, in the event of a network partition, as long as the queue has a majority that can still communicate, the queue continues to function. Quorum queues do not use RabbitMQ\'s traditional [partition handling strategies](/docs/partitions#automatic-handling) but use their own failure detector that is both faster to detect partitions and failures but also less prone to false positives, this allows them to deliver the fastest fail-over of the replicated queue types.\\r\\n\\r\\n#### Classic Mirrored Queues\\r\\n\\r\\nClassic queues can be [mirrored](/docs/3.13/ha) and configured for either availability (AP) or consistency (CP). Using the *auto-heal* or *ignore *partition handling strategies will allow all brokers in a cluster to continue serving publishers and consumers even if one or more brokers get cut off by a network partition. However, on recovering from the partition, data may be lost.\\r\\n\\r\\nUsing the *pause_minority* partition handling strategy makes mirrored queues favour consistency. In the event of a network partition, any brokers on the minority side will pause themselves, closing all network connections. No confirmed writes will be lost, but any brokers on the minority side lose availability and if there are multiple partitions where no majority exists then the entire cluster becomes unavailable. Likewise, if a majority of nodes are down, the remaining brokers will pause themselves. \\r\\n\\r\\nFail-overs are not as fast as quorum queues and there exist edge cases where the fail-over can take minutes or hours for extremely large queues.\\r\\n\\r\\nSee our recent [post on quorum queues and mirrored queues](/blog/2020/04/20/rabbitmq-gets-an-ha-upgrade) that explains this in more detail.\\r\\n\\r\\n#### Client Reconnections\\r\\n\\r\\nIn order to achieve high availability, clients also need to be able to reconnect automatically in the event of a connection failure or a broker going offline. Most RabbitMQ clients offer automatic reconnection features. When accessing the brokers of a cluster by their individual host names, ensure that all are provided to the client so that it can attempt to reconnect to all nodes in the cluster until it finds a broker that is up and running. When using a load balancer, ensure that there is no affinity/stickiness to the balancing to ensure that when clients reconnect they are not always routed back to the same broker (which may now be down).\\r\\n\\r\\n#### Rack Awareness\\r\\n\\r\\nWhile RabbitMQ does not currently have rack awareness, you can achieve the same results via manually specifying the nodes that a replicated queue should be spread across. With mirrored queues you can specify the [list of nodes](/docs/3.13/ha#mirroring-arguments) it should be spread across. With quorum queues you must currently create the queue with an initial group size of 1 and then [add members](/docs/man/rabbitmq-queues.8#Replication) on the nodes to achieve the desired spread.\\r\\n\\r\\n### Capacity Planning\\r\\n\\r\\nGood capacity planning goes hand-in-hand with Business Continuity Planning as both are required to achieve reliability and resiliency. Check out our [RabbitMQ sizing guidance](/blog/2020/06/18/cluster-sizing-and-other-considerations).\\r\\n\\r\\n### Disaster Recovery\\r\\n\\r\\nDisaster recovery typically requires asynchronous replication of data between data centers. RabbitMQ does not currently support this feature but other message routing features can be leveraged to offer a partial solution.\\r\\n\\r\\nRabbitMQ does have support for replication of schema (the exchanges, queues, bindings, users, permissions, policies etc) which allows for a secondary cluster in a different data center to be an empty mirror of the primary cluster. A fail-over using only schema synchronisation would provide availability but with a data loss window.\\r\\n\\r\\n#### Schema Replication\\r\\n\\r\\nRabbitMQ has two features for schema replication.\\r\\n\\r\\n[Definitions export/import](/docs/definitions) is a feature of the management plugin that allows the export and import of the schema via JSON files.\\r\\n\\r\\n[Tanzu RabbitMQ](https://tanzu.vmware.com/rabbitmq) offers the Schema Sync Plugin which actively replicates schema changes to a secondary cluster.\\r\\n\\r\\n#### Data\\r\\n\\r\\nRabbitMQ does not yet have an asynchronous data replication feature that is suitable for all multi-DC scenarios. However, you can leverage [exchange federation](/docs/federated-exchanges) or [shovels](/docs/shovel) which are an asynchronous message routing feature that work across clusters. These features were not built for an active-passive architecture and therefore do have some drawbacks. They were built for moving messages between clusters to be actively processed, not to mirror a cluster’s data for redundancy.\\r\\n\\r\\nThe difference between replication and cross-cluster message routing is that replication involves replicating both enqueue and acknowledgement operations, whereas message routing is only about replicating the messages. The fact that a message was consumed and removed from the queue is not included in federation or shovels (because that is not the purpose of those features).\\r\\n\\r\\nAs an example, exchange E1 has a single binding to a quorum queue in DC1. DC2 has a federation link to DC1 and a federated exchange E1 which also has a single binding to a quorum queue. When message m1 and m2 is published to E1 on DC1, those messages are routed to the queue on DC1 and also routed asynchronously to E1 in DC2 and enqueued on the queue there. Now messages m1 and m2 exist on the queue in both DCs.\\r\\n\\r\\n![Fig 8. Messages are replicated to the passive data center](replication-vs-message-routing1.png)\\r\\n\\r\\nBut now a consumer consumes and acknowledges messages m1 and m2 on DC1, and new messages m3 and m4 are published. The quorum queue leader synchronously replicates the new enqueues and the acknowledgements. Federation routes the m3 and m4 messages to DC2 but not the acks (federation does message routing only). Now m1 and m2 only exist on DC2, having been consumed on DC1. If DC1 went down and we failed over to DC2, m1 and m2 would be consumed again.\\r\\n\\r\\n![Fig 9. Passive DC2 accumulates messages, only removed by TTL or length limit policies](replication-vs-message-routing2.png)\\r\\n\\r\\nThis means that you will need to tolerate duplicates in the event of a fail-over from one RabbitMQ cluster to another. Also, queues will continue to grow as messages accumulate. \\r\\n\\r\\nIn order to mitigate the problems of duplication, you can apply either [message TTL policies](/docs/ttl#per-queue-message-ttl) on the passive cluster that remove messages after a time period or [queue length limits](/docs/maxlength) that remove messages when the queue length reaches the limit. These are admittedly, imperfect solutions given that they could actually cause message loss. Given a 24 hour TTL, a message might have been sitting in a queue in DC1 for 25 hours unconsumed when DC1 went down, and that same message will have been discarded from the same queue in DC2 an hour before.\\r\\n\\r\\nIn order to cope with duplication, your systems either need to tolerate duplication (by being idempotent) or have a deduplication solution in place (like message ids being stored in Redis). Any at-least-once message queue/bus will cause duplicates from time to time, so this may already be something that is taken care of.\\r\\n\\r\\n### A Note on Back-ups\\r\\n\\r\\nRabbitMQ does support [back-ups](/docs/backup) but the support is limited and therefore not commonly used. The limitation is that a cluster must be shut down entirely in order to make a back-up of its data directory. This makes back-ups an infeasible disaster recovery strategy for most enterprises.\\r\\n\\r\\n## Summary\\r\\n\\r\\nRabbitMQ provides excellent support for high availability within a single data center or across multiple availability zones via the use of clustering and replicated queues.\\r\\n\\r\\nFor business continuity plans that require multiple data centers, with geographical separation in an active-passive architecture there are challenges. An RPO of 0 minutes is only achievable with a single cluster and so is not realistic in a multi-DC (or multi-region) scenario. With an RPO above 0 minutes, we can leverage federation and shovel but this also presents challenges in the form of message duplication. This duplication can be accommodated with a deduplication strategy.\\r\\n\\r\\nRabbitMQ has many features on its road-map, including real asynchronous replication support for disaster recovery, data recovery tooling, rack awareness and more. So stay tuned because RabbitMQ is changing fast."},{"id":"/2020/06/30/this-month-in-rabbitmq-may-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/30/this-month-in-rabbitmq-may-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-30-this-month-in-rabbitmq-may-2020-recap/index.md","source":"@site/blog/2020-06-30-this-month-in-rabbitmq-may-2020-recap/index.md","title":"This Month in RabbitMQ, May 2020 Recap","description":"This month, Jack Vanlightly continues his blog series on Quorum Queues in RabbitMQ.","date":"2020-06-30T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":1.715,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, May 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Disaster Recovery and High Availability 101","permalink":"/rabbitmq-website/blog/2020/07/07/disaster-recovery-and-high-availability-101"},"nextItem":{"title":"How quorum queues deliver locally while still offering ordering guarantees","permalink":"/rabbitmq-website/blog/2020/06/23/quorum-queues-local-delivery"}},"content":"This month, Jack Vanlightly continues his blog series on [Quorum Queues in RabbitMQ](/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts).\\r\\nAlso, be sure to watch the replay of his [related webinar](https://tanzu.vmware.com/content/rabbitmq/jun-11-ha-and-data-safety-in-messaging-quorum-queues-in-rabbitmq).\\r\\n\\r\\nFinally, Episode 5 of TGI RabbitMQ is out -- Gerhard Lazu walks us through [how to run RabbitMQ on Kubernetes](https://www.youtube.com/watch?v=-yU95ocpBYs).\\r\\nDon’t miss!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n* [RabbitMQ 3.8.4](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.4) was released in late May,\\r\\nthe first release to feature Erlang 23 compatibility. Three weeks later [3.8.5](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.5) followed with complete Erlang 23 support.\\r\\n* Docker community-maintained RabbitMQ image [has adopted Erlang 23](https://github.com/docker-library/rabbitmq/pull/411) in less than two weeks since its release\\r\\n* rabbit-hole, the most popular Go RabbitMQ HTTP API client, has [reached version 2.2.0](https://github.com/michaelklishin/rabbit-hole/releases/tag/v2.2.0)\\r\\n* Merged an impressive pull request from GitHub user @joseliber that fixed the generation of\\r\\npassword-encrypted certificates in the [tls-gen](https://github.com/michaelklishin/tls-gen/pull/23) project.\\r\\nThis project is used by RabbitMQ, its client libraries, and other projects to easily generate self-signed certificates.\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* May 1: [Improvements in memory allocations in RabbitMQ .NET client](https://stebet.net/real-world-example-of-reducing-allocations-using-span-t-and-memory-t/) by Stefán Jökull Sigurðarson (@stebets)\\r\\n* May 1: [Connecting To RabbitMQ In Golang](https://dev.to/wagslane/connecting-to-rabbitmq-in-golang-en4) by Lane Wagner (@wagslane)\\r\\n* May 12: [RabbitMQ Use Cases](https://www.petermorlion.com/rabbitmq-use-cases/) by Peter Morlion (@petermorlion)\\r\\n* May 14: Jack Vanlightly on [flow control in RabbitMQ](/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks), with benchmarks (@vanlightly)\\r\\n* May 15: [Flow control in RabbitMQ: stress tests](/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests) (@vanlightly)\\r\\n* May 17: [Produce And Consume Messages To RabbitMQ Docker Container](https://www.c-sharpcorner.com/article/publisher-and-consumer-with-rabbitmq-docker-container/) Using .NET Client, by Nilanjan Dutta (@nilanjan_i_am)\\r\\n* May 25: [.NET Core and RabbitMQ, Part 1](http://codereform.com/blog/post/net-core-and-rabbitmq/), by George Dyrrachitis (@giorgosdyrra)\\r\\n* May 27: [.NET Core and RabbitMQ, Part 2](http://codereform.com/blog/post/net-core-and-rabbitmq-part-2-communication-via-amqp/), by George Dyrrachitis (@giorgosdyrra)\\r\\n* May 27: [Spring Cloud Stream with RabbitMQ](https://medium.com/@odysseymoon/spring-cloud-stream-with-rabbitmq-c273ed9a79b) by @odysseymoon\\r\\n* May 28: [RabbitMQ Exchange Types](https://medium.com/trendyol-tech/rabbitmq-exchange-types-d7e1f51ec825) by Fatiha Beqirovski (@fatihabeqirovski)\\r\\n* May 31: [RabbitMQ: Bindings](https://www.petermorlion.com/rabbitmq-bindings/) by Peter Morlion (@petermorlion)\\r\\n\\r\\n## Learn More\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* Udemy offers “[RabbitMQ from start to finish](https://www.udemy.com/course/rabbitmq-from-start-to-finish/)” for the low, low price of only $19.99!\\r\\n* New course: [Introduction to Spring Cloud Stream](https://www.baeldung.com/spring-cloud-stream) by baeldung, illustrated with RabbitMQ\\r\\n* [RabbitMQ Expert Training](https://www.eventbrite.co.uk/e/rabbitmq-expert-training-online-tickets-102979348002): online, by Erlang Solutions, Nov 9 2020"},{"id":"/2020/06/23/quorum-queues-local-delivery","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/23/quorum-queues-local-delivery","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-23-quorum-queues-local-delivery/index.md","source":"@site/blog/2020-06-23-quorum-queues-local-delivery/index.md","title":"How quorum queues deliver locally while still offering ordering guarantees","description":"The team was recently asked about whether and how quorum queues can offer the same message ordering guarantees as classic queues given that they will deliver messages from a local queue replica (leader or follower) when possible. Mirrored queues always deliver from the master (the leader), so delivering from any queue replica sounds like it could impact those guarantees.","date":"2020-06-23T00:00:00.000Z","tags":[{"inline":true,"label":"Technical Deep Dive","permalink":"/rabbitmq-website/blog/tags/technical-deep-dive"}],"readingTime":16.075,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"How quorum queues deliver locally while still offering ordering guarantees","tags":["Technical Deep Dive"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, May 2020 Recap","permalink":"/rabbitmq-website/blog/2020/06/30/this-month-in-rabbitmq-may-2020-recap"},"nextItem":{"title":"Cluster Sizing Case Study – Quorum Queues Part 2","permalink":"/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2"}},"content":"The team was recently asked about whether and how quorum queues can offer the same message ordering guarantees as classic queues given that they will deliver messages from a local queue replica (leader or follower) when possible. Mirrored queues always deliver from the master (the leader), so delivering from any queue replica sounds like it could impact those guarantees. \\r\\n\\r\\nThat is the subject of this post. Be warned, this post is a technical deep dive for the curious and the distributed systems enthusiast. We’ll take a look at how quorum queues can deliver messages from any queue replica, leader or follower, without additional coordination (extra to Raft) but maintaining message ordering guarantees.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## TLDR\\r\\n\\r\\nAll queues, including quorum queues, provide ordering guarantees per channel for messages that are not *redeliveries*. The simplest way to look at it is if a queue has only one consumer, then that consumer will get messages delivered in FIFO order. Once you have two consumers on a single queue, then those guarantees change to a monotonic ordering of *non-redelivered* messages - that is that there may be gaps (because consumers now compete) but a consumer will never be delivered a later message before an earlier message (that is *not a redelivery*).\\r\\n\\r\\nIf you need bullet proof FIFO ordering guarantees of ALL messages (including redelivered messages) then you need to use the Single Active Consumer feature with a prefetch of 1. Any redelivered messages get added back to the queue before the next delivery takes place - maintaining FIFO order.\\r\\n\\r\\nQuorum queues deliver the same ordering guarantees as classic queues. It just happens to also be able to deliver from any local replica, that is, local to the consumer channel. If you want to understand how quorum queues manage that, then read on! If not then stop here but be happy knowing that the usual ordering guarantees are still maintained.\\r\\n\\r\\n## The Cost of Proxying Traffic\\r\\n\\r\\nRabbitMQ tries to make things simple by allowing any client to connect to any node in a cluster. If a consumer connects to broker 1 but the queue exists on broker 2, then the traffic will be proxied from broker 2 to broker 1 and back. The consumer has no clue that the queue is hosted on a different node.\\r\\n\\r\\nThis flexibility and ease of use comes at a cost though. On a three node cluster, the worst case scenario is that the publisher connects to broker 1, its messages are routed to a classic unreplicated queue on broker 2 and the consumer of that queue is connected to broker 3. To process these messages, all three brokers have been roped into it which is of course less efficient.\\r\\n\\r\\nIf that queue were replicated then the messages would have to be transmitted between the brokers one time for the proxying and then additionally for the replication. On top of that we covered how inefficient the [mirrored queue algorithm](/blog/2020/04/20/rabbitmq-gets-an-ha-upgrade) is with multiple sends of each message.\\r\\n\\r\\n![Fig 1 shows the mirrored queue replication traffic in blue, with additional traffic for proxying publisher and consumer traffic.](mirrored-network-traffic.png)\\r\\n\\r\\nIt would be nice if consumers could get delivered the messages from where they are connected to, rather than from the leader that exists on a different broker - this would save on network utilisation and take some pressure off the queue leader.\\r\\n\\r\\n![Fig 2 shows a quorum queue with replication traffic in blue and only the publisher traffic being proxied as the consumer consumes directly from a follower.](qq-network-traffic.png)\\r\\n\\r\\n## The Cost of Coordination\\r\\n\\r\\nWith mirrored queues, all messages are delivered by the queue master (and potentially sent to the consumer via another broker). This is simple and requires no coordination between the master and its mirrors.\\r\\n\\r\\nIn quorum queues we could have added coordination between the leader and the followers to achieve local delivery. Communication between the leader and followers would coordinate who would deliver which message - because what we can’t have is a message being delivered twice or not at all. Unfortunate things can happen, consumers can fail, brokers can fail, network partitions etc and the coordination would need to handle all of that. \\r\\n\\r\\nBut coordination is bad for performance. The kind of coordination to make local delivery work could be extremely impactful on performance and also extremely complex. We needed another way and luckily everything we needed was already built into the protocol.\\r\\n\\r\\n## Coordination No, Determinism Yes\\r\\n\\r\\nA common method of avoiding coordination in distributed systems is by using determinism. If every node in a cluster gets the same data, in the same order and makes decisions based only on that data then each node will make the same decision at that point in the log. \\r\\n\\r\\nDeterministic decision making requires that each node is fed the same data in the same order. Quorum queues are built on Raft which is a replicated commit log - an ordered sequence of operations. So as long as all the information required to perform local delivery is written to this ordered log of operations, then each replica (leader or follower) will know who should deliver each message without needing to talk to each other about it.\\r\\n\\r\\nIt turns out that even for leader-only deliveries, we still need the coming and going of consumers to be added to the log. If a broker fails and another follower gets promoted to leader, it will need to know about the surviving consumer channels that exist across the cluster so it can deliver messages to them. This information also enables coordination free local delivery.\\r\\n\\r\\n## Effects and the Local flag\\r\\n\\r\\nQuorum queues are built on a Raft implementation called Ra (also developed by the RabbitMQ team). Ra is a programmable state machine that replicates a log of operations. It differentiates between operations that all replicas should perform (commands), for consistency, and external operations that only the leader should perform (effects). These commands, states and effects are programmed by the developer. Quorum queues have their own commands, states and effects.\\r\\n\\r\\nA good example of commands and effects are a key-value store. Adding, updating and deleting the data should be performed by all replicas. Each replica needs to have the same data, so when a leader fails, a follower can take over, with the same data. So data modifications are commands. But notifying a client application that a key changed should only happen once. If a client app asked to be notified when a key is updated, it doesn’t want to be notified by the leader and all the secondary replicas! So only the leader should execute the effects.\\r\\n\\r\\nRa has support for “local” effects. In the case of quorum queues, only the *send_msg* effect is local. The way it works is that all replicas know which consumer channels exist and on which nodes. When a consumer registers, that information is added to the log and likewise, when it fails or cancels that is also added to the log.\\r\\n\\r\\nEach replica “applies” each *committed* (majority replicated) command in the log in order. Applying an *enqueue* command adds the message to the queue, applying a *consumer down* command removes that consumer from the Service Queue (more on that next) and returns all messages it has pending back to the queue for redelivery.\\r\\n\\r\\nThe consumers are added to a Service Queue (SQ) which is deterministically maintained - meaning that all replicas have the same SQ at any given point in the log. Each consumer will assess any given message not yet delivered, with exactly the same SQ as all the other replicas and will dequeue a consumer from the SQ. If that consumer is local (meaning that its channel process is hosted on the same broker as the replica) then the replica will send the message to that local channel. That channel will then send it to the consumer. If the consumer channel is not local, then the replica will not deliver it, but will track its state (who it was delivered to, whether it has been acknowledged etc). One caveat is that if there isn’t a replica that is local to the consumer channel, then the leader sends it to that channel (the proxying approach).\\r\\n\\r\\nIf you still find this interesting, but find it hard to conceptualise then I don’t blame you. What we need are diagrams and a sequence of events to demonstrate this.\\r\\n\\r\\n## An example with diagrams\\r\\n\\r\\nI will group sets of events into each diagram, so as to keep the number of diagrams as low as possible.\\r\\n\\r\\nEach diagram consists of three queue replicas, one leader and two followers. We see the state of the log, the service queue, the queue representation and the “apply” actions. Each operation has the format “command term:offset data”. So for example ***E 1:1 m1*** is the enqueue command, which is added in the first term, has the first offset and is message m1. Terms and offsets are Raft algorithm terms and not super important in order to understand local delivery (but I recommend reading up on the Raft algorithm if you find this interesting).\\r\\n\\r\\n**Diagrams guide**\\r\\n\\r\\n![](diagram-guide.png)\\r\\n\\r\\n### Group 1 (event sequence 1)\\r\\n\\r\\n* A publisher channel adds an **enqueue m1* *command for message m1.\\r\\n\\r\\n![](group1-1.png)\\r\\n\\r\\n### Group 2 (event sequence 2-3)\\r\\n\\r\\n* The leader replicates the **enqueue m1** command to Follower A\\r\\n* The leader replicates the **enqueue m1** command to Follower C\\r\\n\\r\\n![](group2-2.png)\\r\\n\\r\\n### Group 3 (event sequence 4-5)\\r\\n\\r\\n* The channel for consumer 1, connected to the broker of Follower A, adds a **subscribe c1** command\\r\\n* Command **enqueue m1** is applied by leader B (because it is now committed). \\r\\n  1. The leader adds it to its queue\\r\\n  1. The leader notifies the publisher channel it is committed.\\r\\n\\r\\n![](group3-1.png)\\r\\n\\r\\n### Group 4 (event sequence 6-9)\\r\\n\\r\\n* The leader replicates the **subscribe c1** command to Follower A\\r\\n* The leader replicates the **subscribe c1** command to Follower C\\r\\n* Follower C applies the **enqueue m1** command:\\r\\n  1. Adds the message to its queue\\r\\n  1. Sees no consumers, so no delivery to be made\\r\\n* Follower A applies the **enqueue m1** command:\\r\\n  1. Adds the message to its queue\\r\\n  1. Sees no consumers, so no delivery to be made\\r\\n\\r\\nThe consumer does exist of course, but the replicas only learn of consumers when they apply the subscribe command in their logs. They do have those commands in their logs, but they have not yet applied them.\\r\\n\\r\\n![](group4-1.png)\\r\\n\\r\\n### Group 5 (event sequence 10-12)\\r\\n\\r\\n* Leader B applies the **subscribe c1** command:\\r\\n  1. C1 is added to its Service Queue (SQ)\\r\\n  1. Assesses message m1 which is not delivered yet. It dequeues C1 from the SQ but sees that it is not local so does not send the message to C1, instead it just tracks m1 as being handled by C1. Requeues C1 on the SQ.\\r\\n* C2 adds a **subscribe c2** command to the leader.\\r\\n* The publisher channel adds an **enqueue m2** command for message m2.\\r\\n\\r\\n![](group5-1.png)\\r\\n\\r\\n\\r\\n\\r\\n### Group 6 (event sequence 13-16)\\r\\n\\r\\n* The leader replicates the **subscribe c2** command to Follower A\\r\\n* The leader replicates the **subscribe c2** command to Follower C\\r\\n* Follower C applies the **subscribe c1** command:\\r\\n  1. C1 is added to its Service Queue (SQ)\\r\\n  1. Assesses message m1 against the first consumer in its SQ, but that channel is not local, requeues C1 on the SQ.\\r\\n* Follower A applies the **subscribe c1** command:\\r\\n  1. C1 is added to its Service Queue (SQ)\\r\\n  1. Assesses message m1 against the first consumer in its SQ, and sees that the channel is local and so sends the message to that local channel. Requeues C1 on the SQ.\\r\\n\\r\\n![](group6-1.png)\\r\\n\\r\\n### Group 7 (event sequence 17-20)\\r\\n\\r\\n* Leader B applies the **subscribe c2** command:\\r\\n  1. Enqueues C2 on its SQ.\\r\\n* The leader replicates the **enqueue m2** command to Follower A\\r\\n* The channel of consumer 1 adds an **acknowledge m1** command for m1.\\r\\n* Follower A applies the **subscribe c2** command:\\r\\n  1. Enqueues C2 on its SQ.\\r\\n\\r\\nNotice that Follower A and Leader B are at the same point in their logs, and have the same Service Queues.\\r\\n\\r\\n![](group7-1.png)\\r\\n\\r\\n### Group 8 (event sequence 21-23)\\r\\n\\r\\n* Leader B replicates the **enqueue m2** command to Follower C\\r\\n* Follower C applies the **subscribe c2** command\\r\\n  1. Enqueues C2 to its SQ\\r\\n* Leader B applies the **enqueue m2** command:\\r\\n  1. Adds message m2 to its queue\\r\\n  1. Dequeues C1 from its SQ. Sees that this channel is not local. Requeues C1 to the SQ. Tracks state message m1 (that C1 will handle it).\\r\\n  1. Notifies the publisher channel that this message has been committed.\\r\\n\\r\\nAt this point the SQ of Leader B is different from the followers, but that is only because it is one command ahead in its log.\\r\\n\\r\\n![](group8-1.png)\\r\\n\\r\\n### Group 9 (event sequence 24-26)\\r\\n\\r\\n* Leader B applies the **acknowledge m1** command:\\r\\n  1. Removes the message from its queue\\r\\n*Follower C applies the **enqueue m2** command:\\r\\n  1. Adds message m2 to its queue\\r\\n  1. Dequeues C1 from the SQ, but C1 is not local.\\r\\n* Follower A applies the **enqueue m2** command:\\r\\n  1. Adds message m2 to its queue\\r\\n  1. Dequeues C1 from the SQ, and sees that C1 is local so sends C1 the message m2. Requeues C1 on the SQ.\\r\\n\\r\\nSee that the service queues match each other - the followers are at the same offset and the leader is ahead by one, but acknowledgements don’t affect the service queues.\\r\\n\\r\\n![](group9-1.png)\\r\\n\\r\\n### Group 10 (event sequence 27)\\r\\n\\r\\n* The broker that hosts Leader B fails or is shutdown.\\r\\n\\r\\n![](group10-1.png)\\r\\n\\r\\n### Group 11 (event sequence 28)\\r\\n\\r\\n* A leader election occurs and Follower A wins as it has the highest epoch:offset operation in its log.\\r\\n\\r\\n![](group11-2.png)\\r\\n\\r\\n### Group 12 (event sequence 29-30)\\r\\n\\r\\n* A publisher channel adds an **enqueue m3** command.\\r\\n* Leader A replicates the **acknowledge m1** command to Follower C\\r\\n\\r\\n![](group12-1.png)\\r\\n\\r\\n### Group 13 (event sequence 31-33)\\r\\n\\r\\n* Leader A replicates the **enqueue m3** command to Follower C\\r\\n* Leader A applies the **acknowledge m1** command\\r\\n  1. Removes m1 from its queue\\r\\n* Follower C applies the **acknowledge m1** command\\r\\n  1. Removes m1 from its queue\\r\\n\\r\\n![](group13-1.png)\\r\\n\\r\\n### Group 14 (event sequence 34-35)\\r\\n\\r\\n* Leader A applies the **enqueue m3** command:\\r\\n  1. Adds m3 to its queue\\r\\n  1. Dequeues C2 from its SQ. C2 is not local, so requeues C2 and tracks message m3 state.\\r\\n* Follower C applies the **enqueue m3** command:\\r\\n  1. Adds m3 to its queue\\r\\n  1. Dequeues C2 from its SQ. C2 is local and so sends message m3 to that local channel. Requeues C2 on its SQ.\\r\\n\\r\\n![](group14-1.png)\\r\\n\\r\\nSo we see that without additional coordination between the replicas, we achieve local delivery, while maintaining FIFO order, even across leadership fail-overs.\\r\\n\\r\\nBut what about if a consumer fails after having been delivered a message by a follower? Will that be detected and the message redelivered to another consumer channel on a different broker?\\r\\n\\r\\n## Alternate scenario - Consumer Failure\\r\\n\\r\\nWe’ll continue where we left off from Group 6 - m1 was already delivered to C1 but not acknowledged.\\r\\n\\r\\n### Group 7 - Alternate (event sequence 17-20)\\r\\n\\r\\n* The channel for C1 goes away (for whatever reason)\\r\\n* Leader B applies the **subscribe c2** command:\\r\\n  1. Enqueues C2 to SQ\\r\\n* Follower A applies the **subscribe c2** command:\\r\\n  1. Enqueues C2 to SQ\\r\\n* Leader B’s monitor sees that C1 is gone. Adds a **down c1** command it’s log.\\r\\n\\r\\n![](group7-alternate-1.png)\\r\\n\\r\\n### Group 8 - Alternate (event sequence 21-25)\\r\\n\\r\\n* Leader A replicates the **down c1** command to Follower A\\r\\n* Leader A replicates the **enqueue m2** command to Follower C\\r\\n* Follower C applies the **subscribe c2** command:\\r\\n  1. Enqueues C2 to its SQ\\r\\n* Leader B applies the **enqueue m2** command:\\r\\n  1. Dequeues C1 from its SQ, but C1 is not local so requeues it. \\r\\n* Follower A applies **enqueue m2** command:\\r\\n  1. Dequeues C1 from its SQ. C1 is local. Tries to send it the message m2 (but can’t because it doesn\'t exist anymore). Requeues C1 on its SQ.\\r\\n\\r\\n![](group8-alternate.png)\\r\\n\\r\\n### Group 9 - Alternate (event sequence 26-28)\\r\\n\\r\\n* Leader B applies the **down c1** command:\\r\\n  1. Removes C1 from its SQ\\r\\n  1. Retuns to the queue the messages m1 and m2 that were previously delivered to C1 but not acknowledged\\r\\n  1. For redelivering message m1, dequeues C2 from the SQ but sees that it is not local. Requeues C2.\\r\\n* Follower C applies the **enqueue m2** command:\\r\\n  1. Dequeues C1 from its SQ, but C1 is not local so requeues it, tracks m2 as being handled by C1.\\r\\n* Follower A applies the **down c1** command:\\r\\n  1. Removes C1 from its SQ\\r\\n  1. Returns to the queue the messages m1 and m2 that were previously delivered to C1 but not acknowledged\\r\\n  1. For redelivering message m1, dequeues C2 from the SQ but sees that it is not local. Tracks as being handled by C2.\\r\\n\\r\\n![](group9-alternate-1.png)\\r\\n\\r\\n### Group 10 - Alternate (event sequence 29-31)\\r\\n\\r\\n* Follower A takes the next undelivered message, m2. Dequeues C2 from its SQ, but C2 is not local. Tracks m2 as being handled by C2, requeues C2 on the SQ.\\r\\n* Leader B takes the next undelivered message, m2. Dequeues C2 from its SQ, but C2 is not local. Tracks m2 as being handled by C2, requeues C2 on the SQ.\\r\\n* Follower C applies **down c1** command:\\r\\n  1. Removes C1 from its SQ\\r\\n  1. Follower C takes the next undelivered message, m1. Dequeues C2 from its SQ, and sees that C2 is local. Sends m1 to this local channel, requeues C2 on the SQ.\\r\\n\\r\\n![](group10-alternate-1.png)\\r\\n\\r\\n### Group 11 - Alternate (event sequence 32)\\r\\n\\r\\n* Follower C takes the next undelivered message, m2. Dequeues C2 from its SQ, and sees that C2 is local. Sends m2 to this local channel. Requeues C2 on the SQ.\\r\\n\\r\\n![](group11-alternate-2.png)\\r\\n\\r\\nThe quorum queue handled the consumer 1 failure without any problems, while still delivering from a local replica without additional coordination. The key is deterministic decision making which requires that each node uses only data in the log to inform it\'s decisions and that there is no divergence of committed entries in their logs (which is all handled by Raft).\\r\\n\\r\\n## Final Thoughts\\r\\n\\r\\nQuorum queues have the same ordering guarantees as any queue but are also able to deliver messages from a local replica. How they achieve this is interesting but not relevant to developers or administrators. What IS useful is understanding that this is another reason to choose quorum queues over mirrored queues. We [previously described](/blog/2020/04/20/rabbitmq-gets-an-ha-upgrade) the very network inefficient algorithm behind mirrored queues, and now you’ve seen that with quorum queues we have heavily optimised network utilisation.\\r\\n\\r\\nConsuming from a follower replica doesn’t just result in better network utilisation though, we also get better isolation between publisher and consumer load. Publishers can impact consumers and the other way around because they put contention on the same resource - a queue. By allowing consumers to consume from a different broker, we get better isolation. Just see the [recent sizing case study](/blog/2020/06/18/cluster-sizing-and-other-considerations) that showed that quorum queues can sustain a high publish rate even in the face of huge queue backlogs and extra pressure from consumers. Mirrored queues were more susceptible.\\r\\n\\r\\nSo... consider quorum queues!"},{"id":"/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-22-cluster-sizing-case-study-quorum-queues-part-2/index.md","source":"@site/blog/2020-06-22-cluster-sizing-case-study-quorum-queues-part-2/index.md","title":"Cluster Sizing Case Study – Quorum Queues Part 2","description":"In the last post we started a sizing analysis of our workload using quorum queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.","date":"2020-06-22T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Capacity Planning","permalink":"/rabbitmq-website/blog/tags/capacity-planning"}],"readingTime":11.29,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Cluster Sizing Case Study – Quorum Queues Part 2","tags":["Performance","Capacity Planning"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"How quorum queues deliver locally while still offering ordering guarantees","permalink":"/rabbitmq-website/blog/2020/06/23/quorum-queues-local-delivery"},"nextItem":{"title":"Cluster Sizing Case Study – Quorum Queues Part 1","permalink":"/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1"}},"content":"In the [last post](/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1) we started a sizing analysis of our [workload](/blog/2020/06/18/cluster-sizing-and-other-considerations) using quorum queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.\\r\\n\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $54\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $69\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge), st1 HDD. Cost: $93\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $98\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $107\\r\\n\\r\\nThere are more tests to run to ensure these clusters can handle things like brokers failing and large backlogs accumulating during things like outages or system slowdowns.\\r\\n\\r\\nAll quorum queues are declared with the following properties:\\r\\n\\r\\n* x-quorum-initial-group-size=3\\r\\n* x-max-in-memory-length=0\\r\\n\\r\\nThe *x-max-in-memory-length* property forces the quorum queue to remove message bodies from memory as soon as it is safe to do. You can set it to a longer limit, this is the most aggressive - designed to avoid large memory growth at the cost of more disk reads when consumers do not keep up. Without this property message bodies are kept in memory at all times which can place memory growth to the point of memory alarms setting off which severely impacts the publish rate - something we want to avoid in this workload case study.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Adverse Conditions - Coping with rolling restarts and lost brokers\\r\\n\\r\\nWe are using quorum queues because we care about our data and availability. If we lose a broker due to a disk failure, or because we had to reboot as part of an emergency OS patch, then we get continued availability and no data loss, but can we maintain our target peak rate of 30k msg/s? Resiliency isn\'t just about not losing data and remaining available, it\'s about handling the load adequately as well.\\r\\n\\r\\nTo that end, we run exactly the same test again, but hard kill a broker part way into each intensity level.\\r\\n\\r\\n![Fig 1. One broker killed during each test](qq-lost-broker.png)\\r\\n\\r\\nIn the same test with mirrored queues (with one master, one mirror) we saw a drop-off in throughput when a broker was killed off. With quorum queues we don’t see such a strong effect.\\r\\n\\r\\nLet’s look at our 30k msg/s target rate period.\\r\\n\\r\\n![Fig 2. 30k msg/s lost broker test](qq-lost-broker-30k.png)\\r\\n\\r\\nThe reason why we saw the large impact of losing a broker with mirrored queues is that mirrored queues try to maintain the redundancy level by creating a new mirror on another broker when a master or mirror is lost. This concentrates the same amount of message traffic on fewer servers. Quorum queues do not do this. If a broker is lost that hosts a queue replica, then the membership of that queue does not change. As long as the majority of queue replicas (leader, followers) are available the queue continues to function. As soon as the broker comes back online, its follower replica on that broker will start getting replicated to again.\\r\\n\\r\\nSo replication traffic does not get concentrated on fewer servers, only the client traffic does. Quorum queues also benefit from the fact that if a consumer happens to connect to a broker that hosts a follower replica of the queue they want to consume, then they read directly from that replica - no proxying of messages from the broker that hosts the leader to the broker that the consumer is connected to.\\r\\n\\r\\nThe fact that mirrored queues try to maintain the redundancy level by creating new mirrors is undermined by the fact that synchronisation is blocking. So many admins use manual synchronisation to avoid a huge traffic spike between the remaining brokers as new mirrors get replicated to.\\r\\n\\r\\nThe largest clusters (7x16, 7x8 and 9x8) saw no noticeable impact of losing the broker. The fail-overs to new leaders was fast and throughput carried on as before.\\r\\n\\r\\n## Adverse Conditions - Consumer Slowdown\\r\\n\\r\\nWhen processing messages, consumers normally need to interact with other systems like databases or third party APIs. These downstream systems can slowdown due heavy load, or some kind of outage and this has the knock-on effect of slowing down your consumers. This then causes the number of messages in your queues to grow which can then also impact publishers. RabbitMQ delivers best performance when queues are small or empty (empty because messages are immediately consumed).\\r\\n\\r\\nOur requirements dictated that if we suffer a consumer slowdown, the publishing should continue unaffected, even at the target peak load of 30k msg/s.\\r\\n\\r\\nIn this test the processing time per message varies:\\r\\n\\r\\n* 5 minutes at 10ms\\r\\n* Grows from 10ms to 30ms over a 20 minute period\\r\\n* 5 minutes at 30ms\\r\\n* Reduces from 30ms to 10ms over a 20 minute period\\r\\n* 50 minutes at 10ms\\r\\n\\r\\nThe message backlogs can grow into the tens of millions as this is a high traffic system where backlogs can form fast. We shall see an S shape to the consume rate as first the processing time increases, then decreases and consume rate then exceeds the publish rate as the consumers process the backlog.\\r\\n\\r\\nAs the consume rate recovers but the queue length is still very large, this is when we might see impact on the publishers. The publish rate can drop for a period until the backlog is cleared. The higher performing clusters should see no impact or an impact for a short duration.\\r\\n\\r\\nWe\'ll run the test at three different publish rates:\\r\\n\\r\\n* 10k msg/s with 200 consumers across the 100 queues. Top consume rate is 20k msg/s which then drops to 6.6k msg/s at the 30ms processing time.\\r\\n* 20k msg/s with 300 consumers across the 100 queues. Top consume rate is  30k msg/s which then drops to 10k msg/s at the 30ms processing time.\\r\\n* 30k msg/s with 400 consumers across the 100 queues. Top consume rate is  40k msg/s which then drops to 13.3k msg/s at the 30ms processing time.\\r\\n\\r\\n![Fig 3. Consumer slowdown test at publish rates 10k msg/s, 20k msg/s and 30k msg/s and quorum queues.](qq-consumer-slowdown-all.png)\\r\\n\\r\\nThe first thing to notice is how much better quorum queues fared than mirrored queues. With mirrored queues, no clusters managed to maintain the 30k msg/s publish rate in this test, but with quorum queues the 7x16 cluster just managed to handle it.\\r\\n\\r\\nSee some examples of how large the queue backlogs became.\\r\\n\\r\\n**3x16 Cluster**\\r\\n\\r\\n![Fig 4. Queue backlog size for the 3x36 cluster with quorum queues](qq-consumer-slowdown-3x36-backlog.png)\\r\\n\\r\\n**7x16 Cluster**\\r\\n\\r\\n![Fig 5. Queue backlog size for the 7x16 cluster with quorum queues](qq-consumer-slowdown-7x16-backlog.png)\\r\\n\\r\\n![Fig 6. Memory usage and memory high watermark for the 7x16 cluster with quorum queues.](qq-consumer-slowdown-7x16-memory.png)\\r\\n\\r\\n**9x8 Cluster**\\r\\n\\r\\n![Fig 7. Queue backlog size for the 9x8 cluster with quorum queues](qq-consumer-slowdown-9x8-backlog.png)\\r\\n\\r\\n![Fig 8. Memory usage and memory high watermark for the 9x8 cluster with quorum queues.](qq-consumer-slowdown-9x8-memory.png)\\r\\n\\r\\nDespite the queue backlogs across the 100 queues reaching as high as 25 million, memory usage stays well below the high watermark (which is when memory alarms would block the publishers).\\r\\n\\r\\nAll clusters handled this test at 10k msg/s. At 20k msg/s only two clusters handled it (7x16 and 9x8). The 7x16 cluster is the clear winner in this test as it managed to handle the very stressful 30k msg/s test which created backlogs of up to 25 million messages.\\r\\n\\r\\nYou can run a test like with PerfTest (from version 2.12 and up):\\r\\n\\r\\n```\\r\\nbin/runjava com.rabbitmq.perf.PerfTest \\\\\\r\\n-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \\\\\\r\\n-z 1800 \\\\\\r\\n-f persistent \\\\\\r\\n-q 1000 \\\\\\r\\n-c 1000 \\\\\\r\\n-ct -1 \\\\\\r\\n-ad false \\\\\\r\\n--rate 100 \\\\\\r\\n--size 1024 \\\\\\r\\n--queue-pattern \'perf-test-%d\' \\\\\\r\\n--queue-pattern-from 1 \\\\\\r\\n--queue-pattern-to 100 \\\\\\r\\n-qa auto-delete=false,durable=false,x-queue-type=quorum \\\\\\r\\n--producers 200 \\\\\\r\\n--consumers 200 \\\\\\r\\n--producer-random-start-delay 30 \\\\\\r\\n-vl 10000:300 \\\\\\r\\n-vl 11000:60 -vl 12000:60 -vl 13000:60 -vl 14000:60 -vl 15000:60 -vl 16000:60 -vl 17000:60 -vl 18000:60 -vl 19000:60 \\\\\\r\\n-vl 20000:60 -vl 21000:60 -vl 22000:60 -vl 23000:60 -vl 24000:60 -vl 25000:60 -vl 26000:60 -vl 27000:60 -vl 28000:60 -vl 29000:60 \\\\\\r\\n-vl 30000:300 \\\\\\r\\n-vl 29000:60 -vl 28000:60 -vl 27000:60 -vl 26000:60 -vl 25000:60 -vl 24000:60 -vl 23000:60 -vl 22000:60 -vl 21000:60 -vl 20000:60 \\\\\\r\\n-vl 19000:60 -vl 18000:60 -vl 17000:60 -vl 16000:60 -vl 15000:60 -vl 14000:60 -vl 13000:60 -vl 12000:60 -vl 11000:60 -vl 10000:60 \\\\\\r\\n-vl 10000:3000\\r\\n```\\r\\n\\r\\n## Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity\\r\\n\\r\\nLike the consumer slowdown, we end up with a situation where the publish rate exceeds the consume rate causing message backlogs. But this time caused by a large peak in the publish rate, one that our backend systems are unable to handle. Absorbing peaks in the publish rate is one of the reasons to choose a message queue. You don\'t need to scale-out your backend systems to handle peak load, which might be expensive, instead you allow the message queue to absorb the extra traffic instead. Then you process the backlog over a time period.\\r\\n\\r\\nIn this test we keep the processing time at 10ms but increase the publish rate then decrease it:\\r\\n\\r\\n* 5 minutes at base rate\\r\\n* Grows from base rate to peak over a 20 minute period\\r\\n* 5 minutes at peak.\\r\\n* Reduces from peak to base rate over a 20 minute period\\r\\n* 50 minutes at base\\r\\n\\r\\nWe\'ll run three tests:\\r\\n\\r\\n* 10 k msg/s base publish rate, 20k msg/s peak. 200 consumers with 13k msg/s top consume rate.\\r\\n* 20 k msg/s base publish rate, 30k msg/s peak. 300 consumers with 23k msg/s top consume rate.\\r\\n* 30 k msg/s base publish rate, 40k msg/s peak. 400 consumers with 33k msg/s top consume rate.\\r\\n\\r\\n![Fig 9. 10k msg/s base rate, 20k msg/s peak with up to 7k msg/s consumer rate deficit.](qq-publish-peak-all-10k.png)\\r\\n\\r\\nAll the clusters managed to reach the 20k msg/s publish rate peak except for the 3x16 and 5x8 clusters.\\r\\n\\r\\n![Fig 10. 20k msg/s base rate, 30k msg/s peak with up to 7k msg/s consumer rate deficit.](qq-publish-peak-all-20k.png)\\r\\n\\r\\nOnly the larger 5x16, 7x18 and 9x8 clusters manage to hit the 30k msg/s peak.\\r\\n\\r\\n![Fig 11. 30k msg/s base rate, 40k msg/s peak with up to 7k msg/s consumer rate deficit.](qq-publish-peak-all-30k-1.png)\\r\\n\\r\\nThe 7x16 cluster barely managed to hit the 40k msg/s peak and saw its message backlog reach close to 6 million messages but it still handled it.\\r\\n\\r\\n![](qq-publish-peak-30k-7x16-backlog.png)\\r\\n\\r\\nYou can run a test like with PerfTest:\\r\\n\\r\\n```\\r\\nbin/runjava com.rabbitmq.perf.PerfTest \\\\\\r\\n-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \\\\\\r\\n-z 1800 \\\\\\r\\n-f persistent \\\\\\r\\n-q 1000 \\\\\\r\\n-ct -1 \\\\\\r\\n-ad false \\\\\\r\\n-c 1000 \\\\\\r\\n--size 1024 \\\\\\r\\n--queue-pattern \'perf-test-%d\' \\\\\\r\\n--queue-pattern-from 1 \\\\\\r\\n--queue-pattern-to 100 \\\\\\r\\n-qa auto-delete=false,durable=false,x-queue-type=quorum \\\\\\r\\n--producers 200 \\\\\\r\\n--consumers 200 \\\\\\r\\n--producer-random-start-delay 30 \\\\\\r\\n--consumer-latency 10000 \\\\\\r\\n-vr 100:300 \\\\\\r\\n-vr 102:60 -vr 104:60 -vr 106:60 -vr 108:60 -vr 110:60 -vr 112:60 -vr 114:60 -vr 116:60 -vr 118:60 -vr 120:60 \\\\\\r\\n-vr 122:60 -vr 124:60 -vr 126:60 -vr 128:60 -vr 130:60 -vr 132:60 -vr 134:60 -vr 136:60 -vr 138:60 -vr 140:60 \\\\\\r\\n-vr 142:60 -vr 144:60 -vr 146:60 -vr 148:60 -vr 150:60 \\\\\\r\\n-vr 148:60 -vr 146:60 -vr 144:60 -vr 142:60 -vr 140:60 -vr 138:60 -vr 136:60 -vr 134:60 -vr 132:60 -vr 130:60 \\\\\\r\\n-vr 128:60 -vr 126:60 -vr 124:60 -vr 122:60 -vr 120:60 -vr 118:60 -vr 116:60 -vr 114:60 -vr 112:60 -vr 110:60 \\\\\\r\\n-vr 108:60 -vr 106:60 -vr 104:60 -vr 102:60 -vr 100:60 \\\\\\r\\n-vr 100:3000\\r\\n```\\r\\n\\r\\n## Adverse Conditions Tests - Conclusions\\r\\n\\r\\nAfter performing the ideal conditions tests, we had many clusters that could handle the peak load so we ended up a top 5 leaderboard of clusters in terms of cost per 1000 msgs/s per month. Now after running the adverse conditions tests we\'re down to two potentials from the original set. The 7x16 was the only cluster to handle all tests but if you are also sensitive to cost then the cheaper 9x8 was close to passing the backlog tests.\\r\\n\\r\\n* Cluster: 7 nodes, 16 vCPUs, gp2 SSD. Cost: $104 per 1000 msg/s\\r\\n* Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $81 per 1000 msg/s\\r\\n\\r\\nScaling out the smaller VMs gave us the best top throughput and cost effectiveness in the ideal conditions. But the 7x16 was the best all-rounder when taking into account the adverse conditions.\\r\\n\\r\\nFor this workload I would choose quorum queues (with gp2 volumes) over mirrored queues based on their superior ability to continue to handle the ingress rate in the event of message backlogs. Of course there are other reasons to choose quorum queues on top of that:\\r\\n\\r\\n* better data safety\\r\\n* higher availability when handling rolling restarts\\r\\n\\r\\n## Quorum Queue Case Study Takeaways\\r\\n\\r\\nThe takeaways are the same as the mirrored queue case study: don\'t just run tests under ideal conditions. Make sure you include adverse conditions tests into your methodology or you may find that your cluster cannot handle your workload when you need it most. Systems are more likely to suffer these kinds of issues when under heavy load, so test at your expected peak load levels and beyond.\\r\\n\\r\\nThe bottom line is that RabbitMQ can handle broker loss pretty well, what it struggles with more are queue backlogs. Our top clusters, the 7x16 and 9x8 configurations hit 65-70k msg/s in ideal conditions but only 20-30k msg/s in the most adverse conditions we threw at it. I say only 20-30k msg/s, but that is 1.7-2.5 billion daily messages which is higher than most use cases for RabbitMQ.\\r\\n\\r\\nFinally...this was a specific workload, check out the other recommendations in the [first post](/blog/2020/06/18/cluster-sizing-and-other-considerations) that can apply to other workloads and scenarios."},{"id":"/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-21-cluster-sizing-case-study-quorum-queues-part-1/index.md","source":"@site/blog/2020-06-21-cluster-sizing-case-study-quorum-queues-part-1/index.md","title":"Cluster Sizing Case Study – Quorum Queues Part 1","description":"In a first post in this sizing series we covered the workload, the tests, and the cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with quorum queues. We also ran a sizing analysis on mirrored queues.","date":"2020-06-21T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Capacity Planning","permalink":"/rabbitmq-website/blog/tags/capacity-planning"}],"readingTime":15.18,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Cluster Sizing Case Study – Quorum Queues Part 1","tags":["Performance","Capacity Planning"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Cluster Sizing Case Study – Quorum Queues Part 2","permalink":"/rabbitmq-website/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2"},"nextItem":{"title":"Cluster Sizing Case Study – Mirrored Queues Part 2","permalink":"/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2"}},"content":"In a [first post](/blog/2020/06/18/cluster-sizing-and-other-considerations) in this sizing series we covered the workload, the tests, and the cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with quorum queues. We also ran a [sizing analysis on mirrored queues](/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1).\\r\\n\\r\\nIn this post we\'ll run the increasing intensity tests that will measure our candidate cluster sizes at varying publish rates, under ideal conditions. In the next post we\'ll run resiliency tests that measure whether our clusters can handle our target peak load under adverse conditions.\\r\\n\\r\\nAll quorum queues are declared with the following properties:\\r\\n\\r\\n* x-quorum-initial-group-size=3 (replication factor)\\r\\n* x-max-in-memory-length=0\\r\\n\\r\\nThe *x-max-in-memory-length* property forces the quorum queue to remove message bodies from memory as soon as it is safe to do. You can set it to a longer limit, this is the most aggressive - designed to avoid large memory growth at the cost of more disk reads when consumers do not keep up. Without this property message bodies are kept in memory at all times which can place memory growth to the point of memory alarms setting off which severely impacts the publish rate - something we want to avoid in this workload case study.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Ideal Conditions - Growing Intensity Tests\\r\\n\\r\\nIn a previous [post ](/blog/2020/06/04/how-to-run-benchmarks)we discussed options for running benchmarks. You can run this workload, at these intensities with the following command:\\r\\n\\r\\n```\\r\\nbin/runjava com.rabbitmq.perf.PerfTest \\\\\\r\\n-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \\\\\\r\\n-z 1800 \\\\\\r\\n-f persistent \\\\\\r\\n-q 1000 \\\\\\r\\n-c 1000 \\\\\\r\\n-ct -1 \\\\\\r\\n-ad false \\\\\\r\\n--rate 50 \\\\\\r\\n--size 1024 \\\\\\r\\n--queue-pattern \'perf-test-%d\' \\\\\\r\\n--queue-pattern-from 1 \\\\\\r\\n--queue-pattern-to 100 \\\\\\r\\n-qa auto-delete=false,durable=false,x-queue-type=quorum \\\\\\r\\n--producers 200 \\\\\\r\\n--consumers 200 \\\\\\r\\n--consumer-latency 10000 \\\\\\r\\n--producer-random-start-delay 30\\r\\n```\\r\\n\\r\\nJust change the --rate argument to the rate you need for each test and remember that it is the rate per publisher rather than the total combined rate. Because the consumer processing time (consumer latency) is set to 10ms, we also need to increase the number of consumers for the higher publish rates.\\r\\n\\r\\nNote that we set durable=false because this property is not relevant to quorum queues.\\r\\n\\r\\n### io1 - High Performance SSD\\r\\n\\r\\n![Fig 1. Increasing intensity tests and the io1 volume](qq-io1-phase1-1.png)\\r\\n\\r\\nIn the intensities where the quorum queues reached their limit, they tended to accumulate message backlogs, causing 95th percentile and above end-to-end latencies to go up. Below are the 50th and 75th latencies.\\r\\n\\r\\n![Fig 2. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.](qq-io1-phase1-50-75-latencies-1-4.png)\\r\\n\\r\\n![Fig 3. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.](qq-io1-phase1-50-75-latencies-5-7-1.png)\\r\\n\\r\\nWe see that in some cases latencies shot much higher when the quorum queues reached throughput capacity.\\r\\n\\r\\n![Fig 4. 95th, 99th and 99.9th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.](qq-io1-phase1-95-99-999-latencies-1-4.png)\\r\\n\\r\\n![Fig 5. 95th, 99th and 99.9th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.](qq-io1-phase1-95-99-999-latencies-5-7-1.png)\\r\\n\\r\\nAll except for the 3x16 and 5x8 clusters managed the target peak of 30k msg/s and all at below the 1 second end-to-end latency requirement. As expected, the larger clusters achieved the highest throughput.\\r\\n\\r\\n**Bottom throughput cluster (3x16) server metrics**\\r\\n\\r\\n![Fig 6. CPU and network for the worst performing cluster (3x16)](qq-io1-phase1-cpu-network-bottom.png)\\r\\n\\r\\nWe see that for this small cluster, CPU seemed to be the resource bottleneck.\\r\\n\\r\\n![Fig 7. Disk stats for the worst performing cluster (3x16)](qq-io1-phase1-disk-bottom.png)\\r\\n\\r\\nFirst of all we see a much lower number of IOPs compared to mirrored queues. As we progressed through the increasing intensities, the IOPs actually dropped, with each write operation getting larger and larger.\\r\\n\\r\\n**Top throughput cluster server metrics**\\r\\n\\r\\n![Fig 8. CPU and network of the top performing cluster (7x16)](qq-io1-phase1-cpu-network-top.png)\\r\\n\\r\\nCPU did not reached saturation for this large cluster. Network bandwidth hit 500 Mbps which was lower than the same tests with mirrored queues which reached 750 Mbps (even though the mirrored queues had a lower replication factor). The inefficient usage of network by mirrored queues was discussed in a previous blog post.\\r\\n\\r\\n![Fig 9. Disk stats for the top performing cluster (7x16)](qq-io1-phase1-disk-top.png)\\r\\n\\r\\nJust like with the mirrored queues tests, the worst performing cluster not only managed a lower throughput, but saw higher disk IO. This is because of how quorum queues write to disk. Every message is always written to the Write-Ahead Log (WAL). In order to keep the size of the WAL under control, WAL files are truncated which involves writing their messages to segment files. There is an optimisation where if a message is consumed and acknowledged before being written to a segment file, this second disk write is not performed - as far as RabbitMQ is concerned that message no longer exists. This means that if consumers keep up, messages are only written to disk once, but if consumers fall behind then messages can end up being written to disk twice.\\r\\n\\r\\nThe top throughput cluster saw no resource bottleneck, indicating that the limitation was the cost of coordination (Raft based replication).\\r\\n\\r\\nThe bottom throughput cluster did reach above 90% CPU utilisation early on which corresponded with the moment it stopped reaching the target throughput. It reached &gt; 90% on the 4th test and from the 5th test and onward it failed to match the target reliably.\\r\\n\\r\\nSo quorum queues will use more disk bandwidth than mirrored queues which write to disk once at most.\\r\\n\\r\\nThis was how each cluster coped with the target rate of 30k msg/s.\\r\\n\\r\\n![Fig 10. The 30k msg/s peak load.](qq-io1-phase1-30k.png)\\r\\n\\r\\n**Leaderboard in matched target throughput**\\r\\n\\r\\nFrom 35k msg/s, many of the sizes continued to show increases in throughput as the target throughput increased, but always fell a little short of the target.\\r\\n\\r\\nThe one size that was able to hit its target far beyond 30k msg/s was:\\r\\n\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge) - 60k msg/s\\r\\n\\r\\nThe rest fell short of their targets in each test from 35k msg/s and up, but still showed higher throughput as the tests progressed. This is the leaderboard in terms of top throughput:\\r\\n\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 65k msg/s\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 63k msg/s\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 54k msg/s\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 53k msg/s\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 50k msg/s\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 40k msg/s\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 37k msg/s\\r\\n\\r\\nScaling out and the middle ground of up/out showed the best results. \\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month, at top throughput.**\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $97 (50k)\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge. Cost: $98 (37k)\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge. Cost: $115 (53k)\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge. Cost: $126 (54k)\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge. Cost: $137 (40k)\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge. Cost: $139 (63k)\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge. Cost: $142 (65k)\\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.**\\r\\n\\r\\nWe see that two clusters didn\'t quite manage the 30k msg/s target. The leaderboard for the ones that did:\\r\\n\\r\\n1. Cluster: 5 nodes, 16 vCPU (c5.4xlarge). Cost: $135\\r\\n1. Cluster: 7 nodes, 8 vCPU (c5.2xlarge). Cost: $151\\r\\n1. Cluster: 3 nodes, 36 vCPU (c5.9xlarge). Cost: $183\\r\\n1. Cluster: 9 nodes, 8 vCPU (c5.2xlarge). Cost: $194\\r\\n1. Cluster: 7 nodes, 16 vCPU (c5.4xlarge). Cost: $204\\r\\n\\r\\nCost effectiveness and performance were at odds with each other with this test. Scaling out is expensive when the storage volumes are the most costly item. The best value came from the middle ground of scaling out and up.\\r\\n\\r\\nDo we really need those costly io1 SSDs? The IOPs in this test were relatively low and we didn’t go above 250MiB/s so the cheap gp2 volumes should be a good option. Let’s see.\\r\\n\\r\\n## gp2 - General Purpose SSD\\r\\n\\r\\n![Fig 11. Increasing intensity tests with the gp2 volume.](qq-gp2-phase1.png)\\r\\n\\r\\nAs before, the 50th and 75th percentiles remain pretty low.\\r\\n\\r\\n![Fig 12. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.](qq-gp2-phase1-50-75-latencies-1-4.png)\\r\\n\\r\\n![Fig 13. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.](qq-gp2-phase1-50-75-latencies-5-7.png)\\r\\n\\r\\nBut the 95th, 99th and 99.9th percentiles shot up in some cases when the clusters reached their throughput capacity. This latency basically means that queues started accumulating messages. These backlogs only occurred on the larger 16 vCPU clusters.\\r\\n\\r\\n![Fig 14. 95th, 99th and 99.9th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16.](qq-gp2-phase1-all-latencies-1-4.png)\\r\\n\\r\\n![Fig 15. 95th, 99th and 99.9th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8.](qq-gp2-phase1-all-latencies-5-7.png)\\r\\n\\r\\nThe results for the gp2 volumes are no worse than the more expensive io1 volumes.\\r\\n\\r\\n**Bottom throughput cluster (3x16) disk metrics**\\r\\n\\r\\n![Fig 16. Worst performing cluster (3x16) disk stats.](qq-gp2-phase1-disk-bottom-1024x640.png)\\r\\n\\r\\n**Top throughput cluster (7x16) disk metrics.**\\r\\n\\r\\n![Fig 17. Top performing cluster (7x16) disk stats.](qq-gp2-phase1-disk-top-1024x617.png)\\r\\n\\r\\nIn both cases IOPs started high being relatively close to the 3000 IOPs limit (reached 2.3k) but as load increased, IO sizes grew larger and the number of operations reduced.\\r\\n\\r\\nWith a target of 30k msg/s with 1kb messages, even if we wrote every message twice, we’d still not hit the 250MiB/s limit of gp2. As before, the smaller cluster saw more disk IO because it performed more double writes than the larger, higher performing cluster.\\r\\n\\r\\nThis is how the target of 30k msg/s turned out.\\r\\n\\r\\n![Fig 18. Throughput for all clusters for the 30k msg/s target test.](qq-gp2-phase1-30k.png)\\r\\n\\r\\n**Leaderboard in matched target throughput**\\r\\n\\r\\nFrom 35k msg/s and up, many of the sizes continued to show increases in throughput as the target throughput increased, but always fell a little short of the target.\\r\\n\\r\\nThe size that was able to hit its target far beyond that was:\\r\\n\\r\\n1. Cluster: 7 nodes, c5.4xlarge - 60k msg/s\\r\\n\\r\\nIn the tests beyond 35k msg/s the rest fell short of their targets either by just a little or by some margin, but still showed higher throughput as the tests progressed. This is the leaderboard in terms of top throughput:\\r\\n\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 67k msg/s\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 66k msg/s\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 54k msg/s\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 54k msg/s\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 42k msg/s\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 37k msg/s\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 36k msg/s\\r\\n\\r\\nScaling out and the middle ground of up/out showed the best results. \\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month, at top throughput.**\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $41 (42k)\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $45 (54k)\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $47 (66k)\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Cost: $49 (36k)\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $55 (54k)\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $72 (67k)\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $97 (37k)\\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.**\\r\\n\\r\\nThe clusters that managed the 30k msg/s target:\\r\\n\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $54\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $69\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $98\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $107\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $120\\r\\n\\r\\nCost effectiveness and performance were more aligned with this test. Small scaled out VMs showed great ROI due to their cheap storage volumes. For this workload, io1 is simply not worth it.\\r\\n\\r\\nIn a previous post we recommended the use of SSDs with quorum queues. We showed that quorum queues did fine on HDDs with a pure quorum queue workload. But when you run mixed workloads of classic queues and quorum queues we saw that HDDs couldn’t deliver the performance that quorum queues need. Seeing as this is a purely quorum workload, let’s see how they do on a HDD.\\r\\n\\r\\n## st1 - HDD\\r\\n\\r\\n![Fig 19. Increasing intensity tests with quorum queues and the st1 HDD.](qq-st1-phase1.png)\\r\\n\\r\\nQuorum queues did fine on a HDD although the throughput was more choppy once a cluster had reached its throughput capacity. Throughput was also a little lower for all clusters except for the 7x16 cluster which reliably comes in at the top in these tests. We generally [recommend the usage of SSDs](/blog/2020/04/21/quorum-queues-and-why-disks-matter) because performance can suffer significantly with mixed classic/quorum queue workloads due to the random IO characteristics of classic queues. But this test shows that for a pure quorum queue workload, that HDD can perform well.\\r\\n\\r\\nThe 50th and 75th percentile latencies are higher than the SSDs though all sub-second except for the 5x8 cluster that saw message backlogs at the higher intensities.\\r\\n\\r\\n![Fig 20. 50th and 75th percentile end-to-end latency for clusters 3x36, 3x16, 5x16 and 7x16 and the st1 volume.](qq-st1-phase1-50-75-latencies-1-4.png)\\r\\n\\r\\n![Fig 21. 50th and 75th percentile end-to-end latency for clusters 5x8, 7x8 and 9x8 and the st1 volume.](qq-st1-phase1-50-75-latencies-5-7.png)\\r\\n\\r\\nAs with the SSDs, in some cases latency shot up when clusters reached their throughput capacity (meaning that small message backlogs occurred).\\r\\n\\r\\n![Fig 22. All latencies for clusters 3x36, 3x16, 5x16 and 7x16, with the st1 volume.](qq-st1-phase1-all-latencies-1-4.png)\\r\\n\\r\\n![Fig 23. All latencies for clusters 5x8, 7x8 and 9x8, with the st1 volume.](qq-st1-phase1-all-latencies-5-7.png)\\r\\n\\r\\nImportantly, all latencies were sub-second at the 30k msg/s target.\\r\\n\\r\\nLooking at the disk metrics, as expected for a HDD, the IOPs were generally lower again with the correspondingly large write sizes.\\r\\n\\r\\n![Fig 24. Top performing cluster (7x16) disk metrics.](qq-st1-phase1-disk-top-1024x647.png)\\r\\n\\r\\nThis is how the target of 30k msg/s turned out.\\r\\n\\r\\n![Fig 25. All clusters at 30k msg/s throughput with the st1 volume.](qq-st1-phase1-30k.png)\\r\\n\\r\\nThis time we could argue that the 5x8 cluster has achieved the 30k msg/s target, which it didn\'t manage when on SSDs.\\r\\n\\r\\nFrom 35k msg/s and onward, many of the sizes continued to show increases in throughput as the target throughput increased, but fell a little short of the target.\\r\\n\\r\\nThe sizes that were able to hit their target beyond that were:\\r\\n\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 60k msg/s\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 40k msg/s\\r\\n\\r\\nThe rest fell short of their targets in each test beyond 35k msg/s, but still showed higher throughput as the tests progressed. This is the leaderboard in terms of top throughput:\\r\\n\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 67k msg/s\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 62k msg/s\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 54k msg/s\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 50k msg/s\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 37k msg/s\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 32k msg/s\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 27k msg/s\\r\\n\\r\\nScaling out and the middle ground of up/out showed the best results. \\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month, at top throughput.**\\r\\n\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $74 (54k)\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $76 (37k)\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $78 (50k)\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $81 (62k)\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Cost: $89 (27k)\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $94 (67k)\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $132 (32k)\\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.**\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Cost: $93\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Cost: $131\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Cost: $134\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Cost: $142\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Cost: $168\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Cost: $211\\r\\n\\r\\nCost effectiveness and performance were not against each other in this case (like the io1) but they were not aligned either (like the gp2). Scaling out was best for performance but the more expensive volumes meant that scaling out was also now not the most cost effective. The middle ground and scaling out and up was best.\\r\\n\\r\\n## End-to-end Latency and the Three Volume Types\\r\\n\\r\\nIn these tests we treat end-to-end latency as the time between a message being published and consumed. If we look at the 30k msg/s target rate and the 7x16 cluster type we see:\\r\\n\\r\\n**io1 SSD**\\r\\n\\r\\n![Fig 26. 50 and 75th percentile end-to-end latency with the io1 SSD.](qq-latency-50-75-io1-7x16-30k.png)\\r\\n\\r\\n![Fig 27. All percentiles end-to-end latency with the io1 SSD.](qq-latency-all-io1-7x16-30k.png)\\r\\n\\r\\n**gp2 SSD**\\r\\n\\r\\n![Fig 28. 50 and 75th percentile end-to-end latency with the gp2 SSD.](qq-latency-50-75-gp2-7x16-30k.png)\\r\\n\\r\\n![Fig 29. All percentiles end-to-end latency with the gp2 SSD.](qq-latency-all-gp2-7x16-30k.png)\\r\\n\\r\\n**st1 HDD**\\r\\n\\r\\n![Fig 30. 50 and 75th percentile end-to-end latency with the st1 HDD.](qq-latency-50-75-st1-7x16-30k.png)\\r\\n\\r\\n![Fig 31. All percentiles end-to-end latency with the st1 HDD.](qq-latency-all-st1-7x16-30k.png)\\r\\n\\r\\nUnlike mirrored queues, we saw no benefit to latency when using the expensive io1 volumes compared to the gp2. The HDD showed higher end-to-end latencies than the SSDs as expected.\\r\\n\\r\\n## Increasing Intensity Benchmarks - Conclusion\\r\\n\\r\\nSo far the conclusions are:\\r\\n\\r\\n* The expensive io1 volume just wasn’t worth it. It performed no better than the gp2. However, if we’d had a larger workload or larger messages we might have needed a volume capable of more than 250MiB/s, and in those cases we might choose the io1, but not with the high IOPS. With io1, you pay for the volume per GB, but also for the IOPs. So paying for 3000 (or less) instead of 10000 would make sense.\\r\\n* The inexpensive gp2 volume offers the best combination of performance and cost and is the best option for most workloads. Just remember that we used a 1TB size that does not have burst IOPs and there is a 250 MiBs limit (which we never hit).\\r\\n* With cheap storage volumes, scaling out the smaller 8 vCPU VMs was the most cost effective and best in terms of performance.\\r\\n* With expensive volumes, going with the middle ground of scaling out and up was most cost effective.\\r\\n* Scaling up with 3 large VMs was never optimal.\\r\\n\\r\\nTop 5 Configurations for cost per 1000 msg/s per month for the 30k msg/s throughput:\\r\\n\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $54\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge), gp2 SDD. Cost: $69\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge), st1 HDD. Cost: $93\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $98\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge), gp2 SDD. Cost: $107\\r\\n\\r\\n## We\'ve only tested under ideal conditions...\\r\\n\\r\\nWe\'ve gathered a lot of data from 21 different cluster configurations at 15 different workload intensities. We think that so far we should go with a medium to large cluster of small VMs on the inexpensive gp2 volumes. But this was testing the happy scenario where queues are empty or close to empty where RabbitMQ operates at its peak performance. Next we\'ll run more tests that ensure that despite brokers being lost and queue backlogs occurring that our chosen cluster size continues to deliver the performance that we need. [Next](/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2) we test resiliency."},{"id":"/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-20-cluster-sizing-case-study-mirrored-queues-part-2/index.md","source":"@site/blog/2020-06-20-cluster-sizing-case-study-mirrored-queues-part-2/index.md","title":"Cluster Sizing Case Study – Mirrored Queues Part 2","description":"In the last post we started a sizing analysis of our workload using mirrored queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.","date":"2020-06-20T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Capacity Planning","permalink":"/rabbitmq-website/blog/tags/capacity-planning"}],"readingTime":11.325,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Cluster Sizing Case Study – Mirrored Queues Part 2","tags":["Performance","Capacity Planning"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Cluster Sizing Case Study – Quorum Queues Part 1","permalink":"/rabbitmq-website/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1"},"nextItem":{"title":"Cluster Sizing Case Study - Mirrored Queues Part 1","permalink":"/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1"}},"content":"In the [last post](/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1) we started a sizing analysis of our [workload](/blog/2020/06/18/cluster-sizing-and-other-considerations) using mirrored queues. We focused on the happy scenario that consumers are keeping up meaning that there are no queue backlogs and all brokers in the cluster are operating normally. By running a series of benchmarks modelling our workload at different intensities we identified the top 5 cluster size and storage volume combinations in terms of cost per 1000 msg/s per month.\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs, gp2 SDD. Cost: $58\\r\\n1. Cluster: 7 nodes, 8 vCPUs, gp2 SDD. Cost: $81\\r\\n1. Cluster: 5 nodes, 8 vCPUs, st1 HDD. Cost: $93\\r\\n1. Cluster: 5 nodes, 16 vCPUs, gp2 SDD. Cost: $98\\r\\n1. Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $104\\r\\n\\r\\nThere are more tests to run to ensure these clusters can handle things like brokers failing and large backlogs accumulating during things like outages or system slowdowns.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Adverse Conditions - Coping with rolling restarts and lost brokers\\r\\n\\r\\nWill our gp2 SSD based clusters handle the same load if a broker goes down? Perhaps a VM or a disk fails, or you need to perform an emergency OS patch? We really need to make sure that on our Black Friday sales peak, that we’re going to be able to serve traffic even in the face of failures.\\r\\n\\r\\nTo that end, we run exactly the same test again, but hard kill a broker part way into each intensity level.\\r\\n\\r\\n![Fig 1. One broker killed during each test](mirrored-gp2-lost-broker.png)\\r\\n\\r\\nSome clusters did better than others but no cluster gets to the end of the test without seeing a drop in throughput when a broker is killed. The smaller 3 and 5 broker clusters see that drop in the lower intensity tests whereas the 7 and 9 broker clusters only start seeing that drop in the higher intensities.\\r\\n\\r\\nLet’s look at our 30k msg/s target rate period.\\r\\n\\r\\n![Fig 2. Different clusters handle a lost broker better than others](mirrored-gp2-lost-broker-30k.png)\\r\\n\\r\\nYou’ll notice that the 5x16, 7x16, 7x8 and 9x8 clusters fully recover, while at the other end of the spectrum the 3 node clusters see the biggest dip. For the ones that fully recover, the dip is small but this is with *ha-sync-mode* as *manual*. If you choose *automatic*, the recovery still happens but the dip is larger and longer duration.\\r\\n\\r\\nThe reason for this drop in throughput is that when a mirrored queue becomes under-replicated because of a broker loss it will create a new mirror on another broker if it can - maintaining the same redundancy level. This concentrates the same amount of traffic on fewer brokers. So if you use a replication factor of 2 (one master, one mirror) like in this test, have three brokers and lose one then you’ll be increasing load on the other two by a sizeable percentage. If you use* ha-mode=all*, then you won’t see such a dip as there will be no brokers to place new mirrors on.\\r\\n\\r\\nHowever if you have nine nodes and lose one, then the load increase is marginal.\\r\\n\\r\\nScaling out wins this round.\\r\\n\\r\\n## Adverse Conditions - Consumer Slowdown\\r\\n\\r\\nWhen processing messages, consumers normally need to interact with other systems like databases or third party APIs. These downstream systems can slowdown due heavy load, or some kind of outage and this has the knock-on effect of slowing down your consumers. This then causes the number of messages in your queues to grow which can then also impact publishers. RabbitMQ delivers best performance when queues are small or empty (empty because messages are immediately consumed).\\r\\n\\r\\nOur requirements dictated that if we suffer a consumer slowdown, the publishing should continue unaffected, even at the target peak load of 30k msg/s.\\r\\n\\r\\nIn this test the processing time per message varies:\\r\\n\\r\\n* 5 minutes at 10ms\\r\\n* Grows from 10ms to 30ms over a 20 minute period\\r\\n* 5 minutes at 30ms\\r\\n* Reduces from 30ms to 10ms over a 20 minute period\\r\\n* 50 minutes at 10ms\\r\\n\\r\\nThe message backlogs can grow into the tens of millions as this is a high traffic system where backlogs can form fast. We shall see an S shape to the consume rate as first the processing time increases, then decreases and consume rate then exceeds the publish rate as the consumers process the backlog.\\r\\n\\r\\nAs the consume rate recovers but the queue length is still very large, this is when we might see impact on the publishers. The publish rate can drop for a period until the backlog is cleared. The higher performing clusters should see no impact or an impact for a short duration.\\r\\n\\r\\nWe\'ll run the test at three different publish rates:\\r\\n\\r\\n* 10k msg/s with 200 consumers across the 100 queues. Top consume rate is 20k msg/s which then drops to 6.6k msg/s at the 30ms processing time.\\r\\n* 20k msg/s with 300 consumers across the 100 queues. Top consume rate is  30k msg/s which then drops to 10k msg/s at the 30ms processing time.\\r\\n* 30k msg/s with 400 consumers across the 100 queues. Top consume rate is  40k msg/s which then drops to 13.3k msg/s at the 30ms processing time.\\r\\n\\r\\n![Fig 3. Consumer slowdown test at publish rates 10k msg/s, 20k msg/s and 30k msg/s.](consumer-slowdown-all-mirrored.png)\\r\\n\\r\\nSee some examples of how large the queue backlogs became.\\r\\n\\r\\n**3x16 Cluster**\\r\\n\\r\\n![Fig 4. Queue backlog size for the 3x36 cluster](consumer-slowdown-3x36-backlog.png)\\r\\n\\r\\n**7x16 Cluster**\\r\\n\\r\\n![Fig 5. Queue backlog size for the 7x16 cluster](consumer-slowdown-7x16-backlog.png)\\r\\n\\r\\nThe queue backlogs grow quite large, but even so, we only reach up to 50% of our maximum memory limit of 11GB. We\'re using the default memory high watermark of 40% of server memory.\\r\\n\\r\\n![Fig 7. Memory usage and memory high watermark for the 7x16 cluster.](consumer-slowdown-7x16-memory-1.png)\\r\\n\\r\\n**9x8 Cluster**\\r\\n\\r\\n![Fig 6. Queue backlog size for the 9x8 cluster](consumer-slowdown-9x8-backlog.png)\\r\\n\\r\\n![Fig 8. Memory usage and memory high watermark for the 9x8 cluster.](consumer-slowdown-9x8-memory.png)\\r\\n\\r\\nThe smaller 8 vCPU instances have half the memory available with the high watermark at 6GB, but still these tests only use about half of that.\\r\\n\\r\\nAt 10k msg/s, all clusters handle the consumer slowdown and associated backlogs.\\r\\n\\r\\nAt 20k msg/s only the 7x16 and 9x8 clusters handle it without the publish rate dropping. The 7x8 is very close to handling it. The rest see a drop in publish rate as there is contention between consumers and publishers while the queue backlog is still high. Long queues are less efficient, both due to increase disk usage but also in-memory data structures. Note that this is our expected peak load, but we want to size for above that just in case (at 30k msg/s).\\r\\n\\r\\nBut at 30k msg/s none of our clusters were able to handle 30k msg/s sustained throughout the consumer slowdown. The best were the 7x16 and 9x8 clusters that had a reduced publish rate for around 20-25 minutes.\\r\\n\\r\\nSo either we decide that this is good enough or we need to go even bigger with either a 9x16 or an 11x8 cluster.\\r\\n\\r\\n![Fig 9. The 30k msg/s test with 9x16 and 11x8 clusters.](consumer-slowdown-vlarge-mirrored.png)\\r\\n\\r\\nThe 9x16 cluster handles the 30k msg/s load though with a slightly choppy publish rate. For the 8 vCPU instances, it looks like we would need to go up to 13 instances or more instances. These are large clusters, but this is also a very demanding workload.\\r\\n\\r\\nYou can run a test like with PerfTest (from version 2.12 and up):\\r\\n\\r\\n```\\r\\nbin/runjava com.rabbitmq.perf.PerfTest \\\\\\r\\n-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \\\\\\r\\n-z 1800 \\\\\\r\\n-f persistent \\\\\\r\\n-q 1000 \\\\\\r\\n-c 1000 \\\\\\r\\n-ct -1 \\\\\\r\\n--rate 100 \\\\\\r\\n--size 1024 \\\\\\r\\n--queue-pattern \'perf-test-%d\' \\\\\\r\\n--queue-pattern-from 1 \\\\\\r\\n--queue-pattern-to 100 \\\\\\r\\n--producers 200 \\\\\\r\\n--consumers 200 \\\\\\r\\n--producer-random-start-delay 30 \\\\\\r\\n-vl 10000:300 \\\\\\r\\n-vl 11000:60 -vl 12000:60 -vl 13000:60 -vl 14000:60 -vl 15000:60 -vl 16000:60 -vl 17000:60 -vl 18000:60 -vl 19000:60 \\\\\\r\\n-vl 20000:60 -vl 21000:60 -vl 22000:60 -vl 23000:60 -vl 24000:60 -vl 25000:60 -vl 26000:60 -vl 27000:60 -vl 28000:60 -vl 29000:60 \\\\\\r\\n-vl 30000:300 \\\\\\r\\n-vl 29000:60 -vl 28000:60 -vl 27000:60 -vl 26000:60 -vl 25000:60 -vl 24000:60 -vl 23000:60 -vl 22000:60 -vl 21000:60 -vl 20000:60 \\\\\\r\\n-vl 19000:60 -vl 18000:60 -vl 17000:60 -vl 16000:60 -vl 15000:60 -vl 14000:60 -vl 13000:60 -vl 12000:60 -vl 11000:60 -vl 10000:60 \\\\\\r\\n-vl 10000:3000\\r\\n```\\r\\n\\r\\n## Adverse Conditions - Publish Rate Peak Exceeds Consumer Capacity\\r\\n\\r\\nLike the consumer slowdown, we end up with a situation where the publish rate exceeds the consume rate causing message backlogs. But this time caused by a large peak in the publish rate, one that our backend systems are unable to handle. Absorbing peaks in the publish rate is one of the reasons to choose a message queue. You don\'t need to scale-out your backend systems to handle peak load, which might be expensive, instead you allow the message queue to absorb the extra traffic instead. Then you process the backlog over a time period.\\r\\n\\r\\nIn this test we keep the processing time at 10ms but increase the publish rate then decrease it:\\r\\n\\r\\n* 5 minutes at base rate\\r\\n* Grows from base rate to peak over a 20 minute period\\r\\n* 5 minutes at peak.\\r\\n* Reduces from peak to base rate over a 20 minute period\\r\\n* 50 minutes at base\\r\\n\\r\\nWe\'ll run three tests:\\r\\n\\r\\n* 10 k msg/s base publish rate, 20k msg/s peak. 200 consumers with 13k msg/s top consume rate.\\r\\n* 20 k msg/s base publish rate, 30k msg/s peak. 300 consumers with 23k msg/s top consume rate.\\r\\n* 30 k msg/s base publish rate, 40k msg/s peak. 400 consumers with 33k msg/s top consume rate.\\r\\n\\r\\n![Fig 10. 10k msg/s base rate, 20k msg/s peak with up to 7k msg/s consumer rate deficit.](publish-peak-all-10k.png)\\r\\n\\r\\nThe 7x16, 9x8, 7x8 clusters handle the peak, with the 5x8 mostly handling it with a couple of momentary drops in publish rate. The other clusters got close but were not able to handle the target rate.\\r\\n\\r\\n![Fig 11. 20k msg/s base rate, 30k msg/s peak with up to 7k msg/s consumer rate deficit.](publish-peak-all-20k.png)\\r\\n\\r\\nOnly the 7x16 and 9x8 clusters could handle it, but the 5 node clusters were close.\\r\\n\\r\\n![Fig 12. 30k msg/s base rate, 40k msg/s peak with up to 7k msg/s consumer rate deficit.](publish-peak-all-30k.png)\\r\\n\\r\\nOnly the 7x16 cluster reached the 40k msg/s publish rate but the 9x8 was close. The 7x16 saw its message backlog reach close to 7 million messages but it still handled it.\\r\\n\\r\\n![](publish-peak-7x16-30k-backlog.png)\\r\\n\\r\\nYou can run a test like with PerfTest:\\r\\n\\r\\n```\\r\\nbin/runjava com.rabbitmq.perf.PerfTest \\\\\\r\\n-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \\\\\\r\\n-z 1800 \\\\\\r\\n-f persistent \\\\\\r\\n-q 1000 \\\\\\r\\n-ct -1 \\\\\\r\\n-c 1000 \\\\\\r\\n--size 1024 \\\\\\r\\n--queue-pattern \'perf-test-%d\' \\\\\\r\\n--queue-pattern-from 1 \\\\\\r\\n--queue-pattern-to 100 \\\\\\r\\n--producers 200 \\\\\\r\\n--consumers 200 \\\\\\r\\n--producer-random-start-delay 30 \\\\\\r\\n--consumer-latency 10000 \\\\\\r\\n-vr 100:300 \\\\\\r\\n-vr 102:60 -vr 104:60 -vr 106:60 -vr 108:60 -vr 110:60 -vr 112:60 -vr 114:60 -vr 116:60 -vr 118:60 -vr 120:60 \\\\\\r\\n-vr 122:60 -vr 124:60 -vr 126:60 -vr 128:60 -vr 130:60 -vr 132:60 -vr 134:60 -vr 136:60 -vr 138:60 -vr 140:60 \\\\\\r\\n-vr 142:60 -vr 144:60 -vr 146:60 -vr 148:60 -vr 150:60 \\\\\\r\\n-vr 148:60 -vr 146:60 -vr 144:60 -vr 142:60 -vr 140:60 -vr 138:60 -vr 136:60 -vr 134:60 -vr 132:60 -vr 130:60 \\\\\\r\\n-vr 128:60 -vr 126:60 -vr 124:60 -vr 122:60 -vr 120:60 -vr 118:60 -vr 116:60 -vr 114:60 -vr 112:60 -vr 110:60 \\\\\\r\\n-vr 108:60 -vr 106:60 -vr 104:60 -vr 102:60 -vr 100:60 \\\\\\r\\n-vr 100:3000\\r\\n```\\r\\n\\r\\n## Adverse Conditions Test Conclusions\\r\\n\\r\\nAfter performing the happy scenario tests, we had many clusters that could handle the peak load so we ended up a top 5 leaderboard of clusters in terms of cost per 1000 msgs/s per month. Now after running the adverse conditions tests we\'re down to two potentials from the original set:\\r\\n\\r\\n* Cluster: 7 nodes, 16 vCPUs, gp2 SSD. Cost: $104 per 1000 msg/s\\r\\n* Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $81 per 1000 msg/s\\r\\n\\r\\nScaling out the smaller VMs gave us the best top throughput and cost effectiveness in the happy scenario. But the 7x16 was the best all-rounder when taking into account the resiliency tests.\\r\\n\\r\\nOf course even the 7x16 cluster struggled with the 30k msg/s consumer slowdown test. So we might still need to consider the clusters:\\r\\n\\r\\n* Cluster: 9 nodes, 16 vCPUs, gp2 SSD. Cost: $133 per 1000 msg/s\\r\\n* Cluster: 11 nodes, 8 vCPUs, gp2 SSD. Cost: $99 per 1000 msg/s\\r\\n\\r\\n## Mirrored queue case study takeaways\\r\\n\\r\\nBeware of only testing simple scenarios like our first happy scenario test where the publish rate is constant and the consume rate is fixed - you are only sizing RabbitMQ in ideal conditions. If you need RabbitMQ to deliver a certain throughput, even in the face of adversity then you need to include tests like the ones we\'ve run in this post. You are more likely to see adverse scenarios when under heavier loads. Queue backlogs caused by slow consumers are more likely to occur when the wider system is under heavy load. Likewise, it can be peaks in traffic that causes the publish rate to exceed the consume rate. So testing at and beyond peak conditions is important to ensure that a cluster is resilient to your expected load.\\r\\n\\r\\nThe bottom line is that RabbitMQ can handle broker loss pretty well, what it struggles with more are queue backlogs. Our top clusters, the 7x16 and 9x8 configurations hit 65-70k msg/s in ideal conditions but only 20k msg/s in the most adverse conditions we threw at it. I say only 20k msg/s, but that is 1.7 billion daily messages which is higher than most use cases for RabbitMQ.\\r\\n\\r\\nFinally...this was a specific workload, check out the other recommendations in the [first post](/blog/2020/06/18/cluster-sizing-and-other-considerations) that can apply to other workloads and scenarios."},{"id":"/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-19-cluster-sizing-case-study-mirrored-queues-part-1/index.md","source":"@site/blog/2020-06-19-cluster-sizing-case-study-mirrored-queues-part-1/index.md","title":"Cluster Sizing Case Study - Mirrored Queues Part 1","description":"In a first post in this sizing series we covered the workload, cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with mirrored queues.","date":"2020-06-19T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Capacity Planning","permalink":"/rabbitmq-website/blog/tags/capacity-planning"}],"readingTime":12.94,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Cluster Sizing Case Study - Mirrored Queues Part 1","tags":["Performance","Capacity Planning"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Cluster Sizing Case Study – Mirrored Queues Part 2","permalink":"/rabbitmq-website/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2"},"nextItem":{"title":"Cluster Sizing and Other Considerations","permalink":"/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations"}},"content":"In a [first post](/blog/2020/06/18/cluster-sizing-and-other-considerations) in this sizing series we covered the workload, cluster and storage volume configurations on AWS ec2. In this post we’ll run a sizing analysis with mirrored queues.\\r\\n\\r\\nThe first phase of our sizing analysis will be assessing what intensities each of our clusters and storage volumes can handle easily and which are too much.\\r\\n\\r\\nAll tests use the following policy:\\r\\n\\r\\n* ha-mode: exactly\\r\\n* ha-params: 2\\r\\n* ha-sync-mode: manual\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Ideal Conditions - Growing Intensity Tests\\r\\n\\r\\nIn a previous [post](/blog/2020/06/04/how-to-run-benchmarks) we discussed options for running benchmarks. You can run this workload, at these intensities with the following command:\\r\\n\\r\\n```\\r\\nbin/runjava com.rabbitmq.perf.PerfTest \\\\\\r\\n-H amqp://guest:guest@10.0.0.1:5672/%2f,amqp://guest:guest@10.0.0.2:5672/%2f,amqp://guest:guest@10.0.0.3:5672/%2f \\\\\\r\\n-z 1800 \\\\\\r\\n-f persistent \\\\\\r\\n-q 1000 \\\\\\r\\n-c 1000 \\\\\\r\\n-ct -1 \\\\\\r\\n--rate 50 \\\\\\r\\n--size 1024 \\\\\\r\\n--queue-pattern \'perf-test-%d\' \\\\\\r\\n--queue-pattern-from 1 \\\\\\r\\n--queue-pattern-to 100 \\\\\\r\\n--producers 200 \\\\\\r\\n--consumers 200 \\\\\\r\\n--consumer-latency 10000 \\\\\\r\\n--producer-random-start-delay 30\\r\\n```\\r\\n\\r\\nJust change the --rate argument to the rate you need for each test and remember that it is the rate per publisher rather than the total combined rate. Because the consumer processing time (consumer latency) is set to 10ms, we also need to increase the number of consumers for the higher publish rates.\\r\\n\\r\\nBefore running PerfTest you will need to create a policy to turn the created queues into mirrored queues with one master and the number of mirrors you wish to test with.\\r\\n\\r\\n### io1 - High Performance SSD\\r\\n\\r\\n![Fig 1. Increasing intensity tests and the io1 volume](mirrored-io1-phase1-throughput-1.png)\\r\\n\\r\\n![Fig 2. End-to-end latencies for clusters 3x36, 3x16, 5x16 and 7x16.](mirrored-io1-phase1-latency1.png)\\r\\n\\r\\n![Fig 3. End-to-end latencies for clusters 5x8, 7x8, and 9x8. Note that the 99th percentile for the 5x8 reached 30 seconds.](mirrored-io1-phase1-latency2.png)\\r\\n\\r\\nDifferent clusters managed to reach different intensities but all tests except for one remained under the 1 second for 99th percentile end-to-end latency requirement.\\r\\n\\r\\nThe limiting factor in most tests was CPU so no surprise that the configuration with most CPUs did best. What was interesting is that the 3 node, 36 vCPU cluster (3x36) that had the second highest total vCPU count was way down, below the 7x8 vCPU cluster. In fact, CPU didn’t go above 50% on the 3x36 cluster, it seems that Erlang was not able to efficiently make use of all those 36 vCPUs per broker (more on that later).\\r\\n\\r\\nDisk throughput did not get close to capacity, but IOPS did reach 8000-9000 in all configurations with roughly 5-7kb write sizes. Network bandwidth remained lower than 1gbit, which was within the limit of all VMs.\\r\\n\\r\\n### Bottom throughput cluster (3x16):\\r\\n\\r\\n![Fig 4. CPU and Network for the poorest performing cluster (3x16).](mirrored-io1-phase1-bottom-cpu-network.png)\\r\\n\\r\\n![Fig 5. Disk usage for the poorest performing cluster (3x16).](mirrored-io1-phase1-bottom-disk-1024x635.png)\\r\\n\\r\\n### Top throughput cluster (7x16)\\r\\n\\r\\n![Fig 6. CPU and network for the top performing cluster (7x16).](mirrored-io1-phase1-top-cpu-network.png)\\r\\n\\r\\n![Fig 7. Disk usage for the top performing cluster (7x16).](mirrored-io1-phase1-top-disk-1024x634.png)\\r\\n> Insight: The lower performing 3x16 cluster had a slightly higher disk write throughput than the top performing 7x16 cluster. This is because a message is not persisted to disk if it has already been consumed by the time an fsync is performed. So when consumers keep up, disk writes are lower. If we look at the 25k msg/s test which is the highest both can handle, we see that the 3x16 cluster has a 95th percentile latency of around 250ms and the 7x16 around 4ms. Fsyncs occur every 200ms roughly. So the higher performing cluster performs less writes.\\r\\n\\r\\n**Leaderboard in matched target throughput**\\r\\n\\r\\nThe highest throughput each cluster size managed, where it delivered exactly the target rate.\\r\\n\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 65k msg/s\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 45k msg/s\\r\\n1. Cluster: 9 nodes, 8 vCPUs ( c5.2xlarge). Rate: 45k msg/s\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 40k msg/s\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 30k msg/s\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 20k msg/s\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 20k msg/s\\r\\n\\r\\nWe see the middle ground of scaling up and out gave us the best throughput but scaling out did pretty well too. Scaling up was not so good.\\r\\n\\r\\n**Leaderboard in cost per 1000 mgs/s per month, at top throughput.**\\r\\n\\r\\n1. Cluster: 5 nodes, 16 vCPUs. Cost: $134 (45k msg/s)\\r\\n1. Cluster: 7 nodes, 16 vCPUs. Cost: $140 (65k msg/s)\\r\\n1. Cluster: 7 nodes, 8 vCPUs. Cost: $170 (40k msg/s)\\r\\n1. Cluster: 3 nodes, 16 vCPUs. Cost: $182 (20k msg/s)\\r\\n1. Cluster: 3 nodes, 36 vCPUs. Cost: $182 (30k msg/s)\\r\\n1. Cluster: 9 nodes, 8 vCPUs. Cost: $194 (45k msg/s)\\r\\n1. Cluster: 5 nodes, 8 vCPUs. Cost: $242 (20k msg/s)\\r\\n\\r\\n**Leaderboard in cost per 1000 msg/s per month at a target of 30k msg/s.**\\r\\n\\r\\n1. Cluster: 3 nodes, 36 vCPUs. Cost: $183\\r\\n1. Cluster: 5 nodes, 16 vCPUs. Cost: $202\\r\\n1. Cluster: 7 nodes, 8 vCPUs. Cost: $226\\r\\n1. Cluster: 9 nodes, 8 vCPUs. Cost: $291\\r\\n1. Cluster: 7 nodes, 16 vCPUs. Cost: $307\\r\\n\\r\\nWhile scaling out with smaller VMs had decent throughput, it was undermined by the fact that our disks were the most expensive item. Because the disks were expensive, the most cost effective cluster was the one with the least instances, however, this 3x36 cluster only just managed the peak in this ideal conditions test, it is unlikely to hold up under the more difficult tests. So if we ignore the 3x36 cluster, the most cost effective was the middle ground of scaling up and out.\\r\\n\\r\\nDo we really need those costly io1 SSDs? We’re not needing them for IO throughput, but those 10000 IOPS are almost fully utilised. Will the 3000 IOP gp2 handle the higher intensities?\\r\\n\\r\\n### gp2 - General Purpose SSD\\r\\n\\r\\n![Fig 8. Increasing intensity test with the gp2 volume.](mirrored-gp2-phase1-throughput.png)\\r\\n\\r\\n![Fig 9. End-to-end latencies for clusters 3x36, 3x16, 5x16 and 7x16.](mirrored-gp2-phase1-latency1.png)\\r\\n\\r\\n![Fig 10. End-to-end latencies for clusters 5x8, 7x8, and 9x8.](mirrored-gp2-phase1-latency2.png)\\r\\n\\r\\nAgain, different clusters managed different throughputs, but all came in within the end-to-end latency requirements.\\r\\n\\r\\nWe have a new winner with the gp2 volume: the 9x8 cluster followed by the 7x8 cluster. The 7x16 and 5x16 showed some choppy throughput once they had reached and then past their top capacity. The bottom two were the same: the 3x36 and 3x16 clusters.\\r\\n\\r\\nSo how did RabbitMQ handle the lower IOPs volumes?\\r\\n\\r\\n**Bottom Throughput Cluster (3x16)**\\r\\n\\r\\n![Fig 11. Disk usage for the poorest performing cluster (3x16).](mirrored-gp2-phase1-bottom-disk-1024x635.png)\\r\\n\\r\\nWe hit the 3000 IOPs limit from the 5000 msg/s rate and upward. As the tests go on, in order to cope with the larger disk throughput, the IO size increases. So it looks like we don’t need all those IOPs after all.\\r\\n\\r\\n### Top Throughput Cluster (9x8)\\r\\n\\r\\n![Fig 12. Disk usage for the top performing cluster (9x8).](mirrored-gp2-phase1-top-disk-1024x612.png)\\r\\n\\r\\nExactly the same story for the highest performing cluster - RabbitMQ adjusted to the lower available IOPs.\\r\\n\\r\\n**Leaderboard in matched target throughput**\\r\\n\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 65k msg/s\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 50k msg/s\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 50k msg/s\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 40k msg/s\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 35k msg/s\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 35k msg/s\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 25k msg/s\\r\\n\\r\\nThis time, scaling out was clearly the most effective. Scaling up was not so good.\\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month, at top throughput.**\\r\\n\\r\\n1. Cluster: 9 nodes, 8 vCPUs. Cost: $48 (65k msg/s)\\r\\n1. Cluster: 7 nodes, 8 vCPUs. Cost: $48 (50k msg/s)\\r\\n1. Cluster: 5 nodes, 8 vCPUs. Cost: $49 (35k msg/s)\\r\\n1. Cluster: 3 nodes, 16 vCPUs. Cost: $71 (25k msg/s)\\r\\n1. Cluster: 5 nodes, 16 vCPUs. Cost: $74 (40k msg/s)\\r\\n1. Cluster: 7 nodes, 16 vCPUs. Cost: $96 (50k msg/s)\\r\\n1. Cluster: 3 nodes, 36 vCPUs. Cost: $103 (35k msg/s)\\r\\n\\r\\nIn terms of cost per top throughput the order was: *core count desc, node count desc*.\\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.**\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs. Cost: $58\\r\\n1. Cluster: 7 nodes, 8 vCPUs. Cost: $81\\r\\n1. Cluster: 5 nodes, 16 vCPUs. Cost: $98\\r\\n1. Cluster: 9 nodes, 8 vCPUs. Cost: $104\\r\\n1. Cluster: 3 nodes, 36 vCPUs. Cost: $120\\r\\n1. Cluster: 7 nodes, 16 vCPUs. Cost: $161\\r\\n\\r\\nAt our target rate of 30k msg/s, the 5x8 was the best. The conclusion is that scaling out smaller VMs gave both better performance but also best cost effectiveness. The reason was that the gp2 volumes are relatively cheap and we don’t get penalised for scaling out like we did with the expensive io1 volumes.\\r\\n\\r\\n### st1 - HDD\\r\\n\\r\\nSo far we’ve seen RabbitMQ make use of the available IOPs it has available by adjusting to lower IOPs as needed. HDDs are built for large and sequential workloads with low IOPs so will RabbitMQ be able to adjust its disk operations yet again to make even fewer, but larger disk operations? Let’s see.\\r\\n\\r\\n![Fig 13. Increasing intensity test with the st1 volume.](mirrored-st1-phase1-throughput.png)\\r\\n\\r\\n![Fig 14. End-to-end latencies for clusters 3x36, 3x16, 5x16 and 7x16.](mirrored-st1-phase1-latency1.png)\\r\\n\\r\\n![Fig 15. End-to-end latencies for clusters 5x8, 7x8 and 9x8.](mirrored-st1-phase1-latency2.png)\\r\\n\\r\\nLooking at the throughput, HDDs did the best of all in terms of top throughput, actually achieving the 70k msg/s highest intensity. The end-to-end latency had a different pattern. With the SSDs the latencies started out very small and then grew as the intensity grew. But the HDDs started out with a much higher latency and it grew at a much lower rate.\\r\\n\\r\\nLet’s see how RabbitMQ used the available IOPs.\\r\\n\\r\\n**Bottom Throughput Cluster (3x16)**\\r\\n\\r\\n![Fig 16. Disk usage for the poorest performing cluster (3x16).](mirrored-st1-phase1-bottom-disk-1024x636.png)\\r\\n\\r\\nWe’re down now to 500-600 IOPS with an average write size approaching 50kb (ignoring the initial peaks). Far fewer, but much larger IO operations. IO latency is much higher. We’ve gone from 0.5ms (io1), 2ms (gp2) to 10ms (st1) which is likely a combination of the IO size and ability of the storage drive to do random IO fast. Further down, we’ll compare end-to-end latency for the three disk types.\\r\\n\\r\\n**Top Throughput Cluster (9x8)**\\r\\n\\r\\n![Fig 17. Disk usage for the top performing cluster (9x8).](mirrored-st1-phase1-top-disk-1024x686.png)\\r\\n\\r\\n**Leaderboard in throughput**\\r\\n\\r\\nOnly three sizes were able to meet their targets, the rest were always short, even as their throughput climbed in each test. We might have been able to increase throughput with different publisher confirm in-flight limits, a higher limit might have benefited the higher latency HDDs.\\r\\n\\r\\nThe winners that were able to hit their target were:\\r\\n\\r\\n1. Cluster: 9 nodes, 8 vCPUs (c5.2xlarge). Rate: 70k msg/s\\r\\n1. Cluster: 7 nodes, 16 vCPUs (c5.4xlarge). Rate: 65k msg/s\\r\\n1. Cluster: 7 nodes, 8 vCPUs (c5.2xlarge). Rate: 55k msg/s\\r\\n\\r\\nThe rest fell short of their targets in each test, but still showed higher throughput as the tests progressed:\\r\\n\\r\\n1. Cluster: 5 nodes, 16 vCPUs (c5.4xlarge). Rate: 55k msg/s\\r\\n1. Cluster: 5 nodes, 8 vCPUs (c5.2xlarge). Rate: 43k msg/s\\r\\n1. Cluster: 3 nodes, 36 vCPUs (c5.9xlarge). Rate: 35k msg/s\\r\\n1. Cluster: 3 nodes, 16 vCPUs (c5.4xlarge). Rate: 29k msg/s\\r\\n\\r\\nWith HDDs, it was all about scaling out, not up. \\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month, at their top rate.**\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs. Cost: $65 (43k msg/s)\\r\\n1. Cluster: 7 nodes, 8 vCPUs. Cost: $71 (55k msg/s)\\r\\n1. Cluster: 9 nodes, 8 vCPUs. Cost: $72 (70k msg/s)\\r\\n1. Cluster: 5 nodes, 16 vCPUs. Cost: $73 (55k msg/s)\\r\\n1. Cluster: 3 nodes, 16 vCPUs. Cost: $83 (29k msg/s)\\r\\n1. Cluster: 7 nodes, 16 vCPUs. Cost: $97 (65k msg/s)\\r\\n1. Cluster: 3 nodes, 36 vCPUs. Cost: $121 (35k msg/s)\\r\\n\\r\\n**Leaderboard in cost per 1000 messages per month at a target of 30k msg/s.**\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs. Cost: $93\\r\\n1. Cluster: 7 nodes, 8 vCPUs. Cost: $131\\r\\n1. Cluster: 5 nodes, 16 vCPUs. Cost: $134\\r\\n1. Cluster: 3 nodes, 36 vCPUs. Cost: $142\\r\\n1. Cluster: 9 nodes, 8 vCPUs. Cost: $168\\r\\n1. Cluster: 7 nodes, 16 vCPUs. Cost: $211\\r\\n\\r\\nIn terms of their top throughput, its clear that smaller VMs were most cost effective. But when considering the target of 30k msg/s, the middle ground of scaling out/up showed the best results. There is some conflict again between scaling out which is best for performance and cost (the st1 volumes are a little costly). So the middle ground wins.\\r\\n\\r\\n### End-to-end Latency and the Three Volume Types\\r\\n\\r\\nIn these tests we treat end-to-end latency as the time between a message being published and consumed. If we look at the 30k msg/s target rate and the 7x16 cluster type we see:\\r\\n\\r\\n### io1\\r\\n\\r\\n![Fig 18. 50th and 75th percentile latencies for io1 at 30k msg/s.](latency-50-75-io1-7x16-30k.png)\\r\\n\\r\\n![Fig 19. 50th, 75th, 95th, 99th and 99.9th percentile latencies for io1 at 30k msg/s.](latency-all-io1-7x16-30k.png)\\r\\n\\r\\n### gp2\\r\\n\\r\\n![Fig 20. 50th and 75th percentile latencies for gp2 at 30k msg/s.](latency-50-75-gp2-7x16-30k.png)\\r\\n\\r\\n![Fig 21. 50th, 75th, 95th, 99th and 99.9th percentile latencies for gp2 at 30k msg/s.](latency-all-gp2-7x16-30k.png)\\r\\n\\r\\n### st1\\r\\n\\r\\n![Fig 22. 50th and 75th percentile latencies for st1 at 30k msg/s.](latency-50-75-st1-7x16-30k.png)\\r\\n\\r\\n![Fig 23. 50th, 75th, 95th, 99th and 99.9th percentile latencies for st1 at 30k msg/s.](latency-all-st1-7x16-30k.png)\\r\\n\\r\\nWe see that io1 delivers the best latencies up to 95th percentile, after that it matched more or less gp2. The st1 HDD showed much higher in latencies but still within our target of 1 second.\\r\\n\\r\\n### CPU Utilisation and 36 vCPU VMs\\r\\n\\r\\nIn the 8 and 16 vCPU (CPU thread) instances, CPU seems to be the bottleneck. Once CPU reached above 90% we stopped seeing any more increases in throughput. However, the 36 vCPU instances tended to always look like this:\\r\\n\\r\\n![Fig 24. CPU utilisation on the 3x36 cluster.](cpu-3x36.png)\\r\\n\\r\\nCPU utilisation and Erlang is not always straightforward. Erlang schedulers will do busy-waiting when they deem that it is more effective to do so. This means that rather than sleep, a scheduler sits in a busy loop, utilising CPU while it waits for new work to do. This can make it appear that the Erlang application is doing lots of work, using the CPU, but actually it is just waiting for work.\\r\\n\\r\\n36 vCPUs is just a waste in this particular case. We’ve seen that they are more expensive and deliver inferior results compared to scaled out smaller VMs.\\r\\n\\r\\n## Increasing Intensity Benchmarks - Conclusion\\r\\n\\r\\nSo far the conclusions are:\\r\\n\\r\\n* The expensive io1 is only worth it if we really care about end-to-end latency.\\r\\n* The inexpensive gp2 offers the best combination of performance and cost and is the best option for most workloads. Just remember that we used a 1TB size that does not have burst IOPs and there is a 250 MiBs limit (which we never hit).\\r\\n* With cheap storage volumes, scaling out the smaller 8 vCPU VMs was the most cost effective and best in terms of performance.\\r\\n* With expensive volumes, going with the middle ground of scaling out and up was most cost effective.\\r\\n* CPU utilisation seemed to be the limiting factor on the 16 and 8 vCPUs. The large 36 vCPU instances didn’t go past 60% utilisation, but also didn’t hit disk or network limits. Erlang just couldn’t efficiently use that many cores.\\r\\n\\r\\nTop 5 Configurations for cost per 1000 msg/s per month for the 30k msg/s throughput:\\r\\n\\r\\n1. Cluster: 5 nodes, 8 vCPUs, gp2 SDD. Cost: $58\\r\\n1. Cluster: 7 nodes, 8 vCPUs, gp2 SDD. Cost: $81\\r\\n1. Cluster: 5 nodes, 8 vCPUs, st1 HDD. Cost: $93\\r\\n1. Cluster: 5 nodes, 16 vCPUs, gp2 SDD. Cost: $98\\r\\n1. Cluster: 9 nodes, 8 vCPUs, gp2 SDD. Cost: $104\\r\\n\\r\\n## We\'ve only tested under ideal conditions...\\r\\n\\r\\nWe\'ve gathered a lot of data from 21 different cluster configurations at 15 different workload intensities. We think that so far we should go with a medium to large cluster of small VMs on the inexpensive gp2 volumes. But this was testing the happy scenario where queues are empty or close to empty where RabbitMQ operates at its peak performance. Next we\'ll run more tests that ensure that despite brokers being lost and queue backlogs occurring that our chosen cluster size continues to deliver the performance that we need. [Next](/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2) we test resiliency."},{"id":"/2020/06/18/cluster-sizing-and-other-considerations","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-18-cluster-sizing-and-other-considerations/index.md","source":"@site/blog/2020-06-18-cluster-sizing-and-other-considerations/index.md","title":"Cluster Sizing and Other Considerations","description":"This is the start of a short series where we look at sizing your RabbitMQ clusters. The actual sizing wholly depends on your hardware and workload, so rather than tell you how many CPUs and how much RAM you should provision, we’ll create some general guidelines and use a case study to show what things you should consider.","date":"2020-06-18T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Capacity Planning","permalink":"/rabbitmq-website/blog/tags/capacity-planning"}],"readingTime":16.95,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Cluster Sizing and Other Considerations","tags":["Performance","Capacity Planning"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Cluster Sizing Case Study - Mirrored Queues Part 1","permalink":"/rabbitmq-website/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1"},"nextItem":{"title":"How to Run Benchmarks","permalink":"/rabbitmq-website/blog/2020/06/04/how-to-run-benchmarks"}},"content":"This is the start of a short series where we look at sizing your RabbitMQ clusters. The actual sizing wholly depends on your hardware and workload, so rather than tell you how many CPUs and how much RAM you should provision, we’ll create some general guidelines and use a case study to show what things you should consider.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Common Questions\\r\\n\\r\\nWhat is the best combination of VM size and VM count for your RabbitMQ cluster? Should you scale up and go for three nodes with 32 CPU threads? Or should you scale out and go for 9 nodes with 8 CPU threads? What type of disk offers the best value for money? How much memory do you need? Which hardware configuration is better for throughput, latency, cost of ownership?\\r\\n\\r\\nFirst of all, there is no single answer. If you run in the cloud then there are fewer options but if you run on-premise then the sheer number of virtualisation, storage and networking products and configurations out there makes this an impossible question.\\r\\n\\r\\nWhile there is no single sizing guide with hard numbers, we can go through a sizing analysis and hopefully that will help you with your own sizing.\\r\\n\\r\\n## Some common considerations\\r\\n\\r\\n### The number of queues and clients\\r\\n\\r\\nClient connections and queues require compute time and memory. If you have thousands of queues and clients, then that will affect your sizing. The more you have, the more CPU cores and memory you\'re likely to need. Having few queues and clients is more efficient for RabbitMQ to handle - there is less CPU context switching and less memory overhead. So if you have a workload with thousands of queues and clients, then you\'ll need larger VMs or more VMs for the same total throughput compared to if you only had a handful of each.\\r\\n\\r\\nVarious types of churn can impact a cluster:\\r\\n\\r\\n* Connection churn (the opening and closing of connections)\\r\\n* Queue and queue binding churn (the creation and deletion queues and bindings)\\r\\n\\r\\n### What is high throughput?\\r\\n\\r\\nA million messages a day might sound like a lot, but when you calculate that as a per-second rate, it\'s just down to just under 12 messages per second. When you have throughput anywhere under a 100 per second you\'ll likely be able to size your VMs very small. It is unlikely you\'ll see a resource bottleneck unless you have thousands of queues and clients. If you use a cluster, at this rate it will be purely for redundancy rather than performance.\\r\\n\\r\\nOnce you get past 1000 messages a second (86 million a day or 2.5 billion per month), that\'s when you need to spend more time on your sizing analysis. For 1000 messages a second you can still go pretty small, but there may be some resource bottlenecks.\\r\\n\\r\\nBeyond 10000 (860 million per day or 25 billion per month), I recommend you be even more thorough with your sizing analysis. We say *a happy Rabbit is an empty Rabbit*. RabbitMQ provides the best throughput and lowest latency when queues are empty. Messages are served from memory, often not written to disk at all. When you have a large backlog, messages are very likely read/written to disk, data structures are larger and less efficient and inevitably the maximum throughput a cluster can handle drops. When you have a high throughput cluster, backlogs can go from nothing to millions fast, and so you need to make sure you size for that. Don\'t just size for the happy case, but also the unhappy case. We\'ll look at this in more detail later on.\\r\\n\\r\\n### What workloads require more memory?\\r\\n\\r\\nClassic and classic mirrored queues will keep messages in memory but start evicting them when memory gets low. Its hard to predict because it is a dynamic behaviour. One good practice is to use lazy queues if you have very large queues because lazy queues evict from memory very early and typically use far less memory.\\r\\n\\r\\nQuorum queues store all messages in memory at all times by default, even under low memory conditions. This means unless you change the defaults, you are more likely to hit the memory alarms (which blocks all publishers) when queues grow longer. The good news is this can be configured using a couple of queue properties (such as x-max-in-memory-length) which will only keep this configured number of messages in memory at a time. This should probably be set on all your quorum queues. It does mean that more messages are read from disk so it doesn\'t come for free.\\r\\n\\r\\n### How does redundancy affect sizing?\\r\\n\\r\\nIf you use quorum queues or mirrored queues, then each message will be delivered to multiple brokers. If you have a cluster of three brokers and quorum queues with a replicator factor of 3, then every broker will receive every message. In that case, we\'ve created a cluster for redundancy only. But we can also create larger clusters for scalability. We could have a cluster of 9 brokers, with quorum queues with a rep factor of 3 and now we\'ve spread that load out and can handle a much larger total throughput.\\r\\n\\r\\nAdding more redundancy will reduce total throughput, so to counteract that you can add more brokers to your cluster to spread the load.\\r\\n\\r\\n### How does message size affect sizing?\\r\\n\\r\\nSmall messages, say under 1kb, are unlikely to saturate network or disk. If you hit a resource bottleneck it will likely be CPU. But we can easily saturate network and disk with larger message sizes. If you have 1Mb messages and a 5gbit network, then with a classic queue, you\'re going to saturate the network at just over 300 msg/s. If you use quorum or mirrored queues, it will be even lower as the messages must not only be received/sent to clients, but replicated between brokers.\\r\\n\\r\\n### Do you plan to use Federation?\\r\\n\\r\\nFederation involves running AMQP clients on the RabbitMQ brokers. That means they contend for the same resources as channels and queues. This may mean you need to increase the size/number of your VMs. Also take into account that:\\r\\n\\r\\n* if you use mirrored queues for the local queues (that act as an outbox), then you\'ll be replicating those outgoing messages across your cluster. Redundancy is expensive.\\r\\n* messages will be transmitted across the network to another broker, this adds to your network sizing.\\r\\n\\r\\nAlways include the federation setup in your sizing tests.\\r\\n\\r\\n## Sizing - An AWS Case Study\\r\\n\\r\\nWe\'ll go through a case study now which will involve identifying the workload, defining our requirements regarding end-to-end latency and resiliency and finally a suite of tests that will measure different VM sizes and numbers against those requirements.\\r\\n\\r\\nRemember, this is a case study, so your own requirements and workload may be very different to this. It is also a detailed analysis suitable for when RabbitMQ is a critical part of your infrastructure and is worth the time investment in doing a thorough sizing analysis.\\r\\n\\r\\n### The Case Study Workload\\r\\n\\r\\nFor the purposes of our case study, I have chosen a medium sized, high intensity workload. That means we have a moderate number of queues and clients, but pushing a large number of messages through them.\\r\\n\\r\\n* 200 publishers\\r\\n* 100 queues\\r\\n* 200 consumers\\r\\n* No fanout - using the default exchange to do point-to-point\\r\\n* 1kb message sizes\\r\\n* 10 millisecond processing time per message\\r\\n* Java client\\r\\n* Constant rate\\r\\n\\r\\nWe have relatively stable throughput of 5000 msg/s most of the time but peaks of up to 20,000 msg/s that can last anything up to an hour or two hours per day. We project that traffic is likely to increase by 10% over the next year.\\r\\n\\r\\n### Our Requirements\\r\\n\\r\\nWe want to size our cluster according to the peak throughput plus an additional 10,000 msg/s just in case of unexpectedly high traffic which will also cover the expected 10% growth. We don\'t need to size according to our expected growth beyond that as we can easily upgrade EC2 instances in the future.\\r\\n\\r\\nWe want to use a replicated queue as these messages have monetary value for the business. So we’ll run a sizing analysis for mirrored and the newer quorum queues.\\r\\n\\r\\nIn terms of latency, we’re happy as long as we’re below 1 second at 99th percentile end-to-end (time between publish and consumption of a message).\\r\\n\\r\\nFinally we want to make sure we can hit our throughput peak even under adverse conditions such as losing a broker or there is a downstream outage that affects consumer throughput. If a queue backlog grows because consumers are running slowly, we want to absorb the message ingress (maintaining the publish rate). Slowing down publishing has a monetary cost for us.\\r\\n\\r\\n### The Tests\\r\\n\\r\\n#### Ideal Conditions - Increasing Intensity Tests\\r\\n\\r\\nFor the publish rate, we’ll actually run a series of benchmarks with different publish rates that cover the 5k to 30k msg/s and more. The idea is to identify up to what rate does a chosen sizing deliver the necessary results and when does it start to struggle and not meet the requirements. This is the happy scenario where RabbitMQ will likely remain empty (and fastest) because the consumers are keeping up at all times (until the cluster reaches its capacity).\\r\\n\\r\\nWe’ll use the rates (total across all publishers):\\r\\n\\r\\n* 1000 msg/s (hourly=3.6 million, daily=86.4 million, monthly=2.5 billion)\\r\\n* 5000 msg/s (hourly=18 million, daily=432 million, monthly=12.9 billion)\\r\\n* 10000 msg/s (hourly=36 million, daily=864 million, monthly=25.8 billion)\\r\\n* 15000 msg/s (hourly=54 million, daily=1.3 billion, monthly=38.9 billion)\\r\\n* ...\\r\\n* 70000 msg/s (hourly=252 million, daily= 6 billion, monthly=181.4 billion)\\r\\n\\r\\n#### Adverse Conditions - Lose a Broker Test\\r\\n\\r\\nWe\'ll test that a chosen cluster size can handle the peak rate (30k msg/s) even when a broker is down. Brokers can go down because of multiple reasons: we reboot a machine as part of OS patch installations, a disk fails, a network partition etc. The worst case is this happens during peak load.\\r\\n\\r\\n#### Adverse Conditions - Consume rate drops, creating a backlog test\\r\\n\\r\\nA database server is being overloaded, or there is a network slowdown in downstream systems or a third party API is running slowly. Either way, the time to process each message goes from 10ms to 30 ms, dropping the consume rate. Can we continue to accept the publish rate unaffected and absorb the backlog?\\r\\n\\r\\n#### Adverse Conditions - Publish rate peaks very high, exceeding consumers capacity test\\r\\n\\r\\nA marketing campaign goes viral and we get way more traffic than expected, so much that our processing systems cannot handle the load. Can we absorb the traffic as large queue backlogs that can be processed later?\\r\\n\\r\\n### The Clusters\\r\\n\\r\\n#### The Cluster Sizes and Storage Volumes\\r\\n\\r\\nWe\'re running on AWS ec2, and what is the cloud but one giant API? We can easily automate the creation of any cluster size or any ec2 instance type we want.\\r\\n\\r\\nWe\'ll run all these tests on 7 different cluster configurations, with three different storage volume types (io1, gp2, st1).\\r\\n\\r\\nThe clusters:\\r\\n\\r\\n* 3 nodes, c5.9xlarge, 36 vCPUs, 72 GB RAM = 108 vCPUs\\r\\n* 3 nodes, c5.4xlarge, 16 vCPUs, 32GB RAM = 48 vCPUs\\r\\n* 5 nodes, c5.4xlarge, 16 vCPUs, 32GB RAM = 80 vCPUs\\r\\n* 7 nodes, c5.4xlarge, 16 vCPUs, 32GB RAM = 112 vCPUs\\r\\n* 5 nodes, c5.2xlarge, 8 vCPUs, 16 GB RAM = 40 vCPUs\\r\\n* 7 nodes, c5.2xlarge, 8 vCPUs, 16 GB RAM = 56 vCPUs\\r\\n* 9 nodes, c5.2xlarge, 8 vCPUs, 16 GB RAM = 72 vCPUs\\r\\n\\r\\nThe c5.9xlarge can be considered a very large VM, it is definitely the biggest VM you would ever you go for. The c5.4xlarge could be considered large and the c5.2xlarge a medium sized instance. This is quite an intensive workload which is why we include these large instance types in the analysis. Many less intensive workloads would be suitable on a smaller instance type, such as the c5.xlarge with 4 vCPUs or c5.large. Larger memory instance types (m5, r5) are also an option if memory ever becomes an issue on these compute optimised instances.\\r\\n\\r\\nThe volumes:\\r\\n\\r\\n* io1 (provisioned iops SSD), 200GB, 10000 IOPS, 500MiB/s max = $725 per month\\r\\n* gp2 (general purpose SSD), 1000GB, 3000 IOPS, 250 MiB/s max = $100 per month\\r\\n* st1 (high throughput HDD), 7000GB, 280 MB/s baseline, 500MiB/s max = $315 per month\\r\\n\\r\\nThe io1 has a large number of IOPs for its size which is expensive. This choice was in part a way of showing how more expensive disks factor into a sizing analysis. You\'ll see from the case studies that we could go with an io1 with less IOPs and it would be more cost effective.\\r\\n\\r\\nWe go for a large gp2 because smaller volumes get burst credits, which can surprise you. Likewise we went for 7TB HDD because of burst credits also. This size still has burst, but these workloads don’t dig into the burst much and are a balance of cost (this size will manage the 2 hour peaks). For the lower intensity workloads, we could go smaller and save ourselves some money.\\r\\n\\r\\nThis is a test with a 1TB HDD where the burst ran out.\\r\\n\\r\\n![Fig 1. EBS volume burst credits run out.](burst-credits-1.png)\\r\\n\\r\\n### Costs Per Month (On-Demand pricing)\\r\\n\\r\\n#### io1 SSD\\r\\n\\r\\nCosts are: VMs + Volumes = Total\\r\\n\\r\\n* 3 nodes, c5.9xlarge = 36 vCPUs, monthly cost of $3300 + $2175 = $5475\\r\\n* 3 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $1468 + $2175 = $3643 \\r\\n* 5 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $2445 + $3625 = $6070\\r\\n* 7 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $4123 + $5075 = $9198\\r\\n* 5 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1225 + $3625 = $4850\\r\\n* 7 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1715 + $5075 = $6790\\r\\n* 9 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $2205 + $6525 = $8730\\r\\n\\r\\n#### gp2 SSD\\r\\n\\r\\nCosts are: VMs + Volumes = Total\\r\\n\\r\\n* 3 nodes, c5.9xlarge = 36 vCPUs, monthly cost of $3300 + $300 = $3600\\r\\n* 3 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $1468 + $300 = $1768 \\r\\n* 5 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $2445 + $500 = $2945\\r\\n* 7 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $4123 + $700 = $4823\\r\\n* 5 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1225 + $500 = $1725\\r\\n* 7 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1715 + $700 = $2415\\r\\n* 9 nodes, c5.2xlarge = 8 vCPUs,, monthly cost of $2205 + $900 = $3105\\r\\n\\r\\n\\r\\n#### st1 HDD\\r\\n\\r\\nCosts are: VMs + Volumes = Total\\r\\n\\r\\n* 3 nodes, c5.9xlarge = 36 vCPUs, monthly cost of $3300 + $945 = $4245\\r\\n* 3 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $1468 + $945 = $2413 \\r\\n* 5 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $2445 + $1575 = $4020\\r\\n* 7 nodes, c5.4xlarge = 16 vCPUs, monthly cost of $4123 + $2205 = $6328\\r\\n* 5 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1225 + $1575 = $2800\\r\\n* 7 nodes, c5.2xlarge = 8 vCPUs, monthly cost of $1715 + $2205 = $3920\\r\\n* 9 nodes, c5.2xlarge = 8 vCPUs,, monthly cost of $2205 + $2835 = $5040\\r\\n\\r\\nWe are not including data transfer costs.\\r\\n\\r\\nWe see that choosing gp2 is actually the cheapest option for us. Of course the st1 HDD is half the cost per GB but if we go smaller we can’t achieve the higher intensity throughput. So it seems that for our needs, an SSD could be the most cost effective option. Of course, it can never handle more than 250 MiB/s, so if that is the limiting factor then you would be forced to choose either the expensive io1 or the st1.\\r\\n\\r\\n## The case studies\\r\\n\\r\\nIn the next posts we’ll perform this sizing analysis using both mirrored and quorum queues.\\r\\n\\r\\n* [Cluster Sizing Case Study - Mirrored Queues Part 1](/blog/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1)\\r\\n* [Cluster Sizing Case Study - Mirrored Queues Part 2](/blog/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2)\\r\\n* [Cluster Sizing Case Study - Quorum Queues Part 1](/blog/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1)\\r\\n* [Cluster Sizing Case Study - Quorum Queues Part 2](/blog/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2)\\r\\n\\r\\n## Other tests that might apply to your workload\\r\\n\\r\\nThere are some more tests that you may wish to run depending on your workload. For example:\\r\\n\\r\\n* You might want to run long-running tests at peak load. The tests in these two case studies were short - between 10 minutes to 1hr 40 minutes. If you identify a specific intensity and cluster configuration, you can try running it for 24 hours to make sure of your choice. Obviously if you have burst network/disk then that may affect things if you test at peak for that long.\\r\\n* You might periodically get very large messages from a batch job that you want to test. *By the way, we recommend using an object store like s3 for large messages (passing its URI as the message).*\\r\\n* You might want to test recovery time with a backlog by doing a full stop and start of your cluster. \\r\\n* You may have a variable number of clients connect to your cluster. Test your candidate cluster sizes with normal to worst case number of connected clients.\\r\\n* [Connection churn](/docs/connections#high-connection-churn) (the opening and closing of connections) can also stress a cluster. If you have a variable amount of connection churn then test with normal and worst case. Also see [/docs/networking.html#tuning-for-large-number-of-connections-tcp-buffer-size](/docs/networking#tuning-for-large-number-of-connections-tcp-buffer-size).\\r\\n* You may have a variable number of queues. Test your candidate cluster sizes with normal to worst case number of queues.\\r\\n\\r\\n## Final Thoughts\\r\\n\\r\\nThe amount of effort you put into sizing is probably going to relate to how much you rely on RabbitMQ in your system and what kind of costs are involved if it fails to deliver the necessary performance. If you have a small workload that is not critical then you may not wish to spend too much time on sizing. Try out a couple of small options and monitor.\\r\\n\\r\\nIf you have larger workloads or business critical workloads, then taking the time to do capacity planning and sizing right may save you more lost time and pain later.\\r\\n\\r\\nTake the time to review the quorum and mirrored queue case studies, but if you don\'t have time then here are some guidelines distilled into a single section.\\r\\n\\r\\nHigh availability (HA) is a common requirement and is the reason we use replicated queues (quorum, mirrored). We don\'t want to lose messages and we want to have continued availability even when failures occur. Don\'t forget that capacity planning is also critical to get right in order to achieve those goals.\\r\\n\\r\\nSizing is about running your workload or workload simulations under both ideal and adverse conditions. Peak load is often when a business is making most money and when adverse conditions are also most likely to occur. Sizing according to the adverse conditions is a key part of getting sizing right.\\r\\n\\r\\nAdverse conditions, where RabbitMQ can still operate effectively if appropriately sized are:\\r\\n\\r\\n* loss of brokers (disk failing, VM reboots, network partitions)\\r\\n* queue backlogs (caused by consumer slowdown or publishing peaks)\\r\\n* huge numbers of TCP connections\\r\\n* huge numbers of queues\\r\\n\\r\\nOf those things, broker loss is probably the least stressful for RabbitMQ. One of the hardest things for RabbitMQ to handle is very large queue backlogs. In our case studies we saw that with appropriate sizing, RabbitMQ could handle this high throughput workload despite huge backlogs, but only with the largest clusters. Smaller clusters did fine under ideal conditions but quickly deteriorated when queues started backing up.\\r\\n\\r\\nIf you already have your production and QA environment deployments automated, then testing different VM sizes and counts should be simple enough to do. If you can run these sizing tests with your actual applications then that is likely to give you the most accurate results. If using your own applications to generate the load is too much, then look at designing a synthetic workload that matches the real-world as close as possible.\\r\\n\\r\\nThe case studies include PerfTest commands and there is also [this post](/blog/2020/06/04/how-to-run-benchmarks) that provides guidance and options for running performance tests.\\r\\n\\r\\nI hope this sizing guidance has been helpful and helps RabbitMQ be a rock solid piece of your architecture."},{"id":"/2020/06/04/how-to-run-benchmarks","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/04/how-to-run-benchmarks","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-04-how-to-run-benchmarks/index.md","source":"@site/blog/2020-06-04-how-to-run-benchmarks/index.md","title":"How to Run Benchmarks","description":"There can be many reasons to do benchmarking:","date":"2020-06-04T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":8.085,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"How to Run Benchmarks","tags":["Performance"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Cluster Sizing and Other Considerations","permalink":"/rabbitmq-website/blog/2020/06/18/cluster-sizing-and-other-considerations"},"nextItem":{"title":"This Month in RabbitMQ, April 2020 Recap","permalink":"/rabbitmq-website/blog/2020/06/01/this-month-in-rabbitmq-april-2020-recap"}},"content":"There can be many reasons to do benchmarking:\\r\\n\\r\\n* Sizing and capacity planning\\r\\n* Product assessment (can RabbitMQ handle my load?)\\r\\n* Discover best configuration for your workload\\r\\n\\r\\nIn this post we’ll take a look at the various options for running RabbitMQ benchmarks. But before we do, you’ll need a way to see the results and look at system metrics.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## RabbitMQ Observability\\r\\n\\r\\nYou have routed X number of messages per second through your RabbitMQ cluster and concluded that you have reached peak throughput, but have you considered:\\r\\n\\r\\n* your CPU was maxed out at that point and wouldn’t have coped with any peak above that load\\r\\n* you were close to your network bandwidth, disk IOPs etc and wouldn’t have coped with any peak on top of that load\\r\\n* your end-to-end latency was in the minutes, not milliseconds\\r\\n* you lost thousands of messages because you didn’t use confirms or acks while putting huge strain on the brokers and the network.\\r\\n\\r\\n*You have to be able to see more than just a throughput number.* \\r\\n\\r\\nSince 3.8.0, we have made the rabbitmq_prometheus plugin available. [See how](/docs/prometheus) to get Grafana, Prometheus and RabbitMQ to work together and get amazing insight into your RabbitMQ instances.\\r\\n\\r\\nSee our [published Grafana dashboards](https://grafana.com/orgs/rabbitmq) for insight into not only the queue counts, connection counts, message rates etc, but also insight into what is going on under the hood from the Erlang perspective. There are also countless system metrics dashboards and agents you can install to see the system metrics such as CPU, RAM, network and disk IO. For example, check out the [node_exporter](https://github.com/prometheus/node_exporter) which gives insights into hardware and OS behaviour.\\r\\n\\r\\nAnother reason to use a solution like Prometheus is that when you push RabbitMQ to its limit, the management UI can become sluggish or unresponsive. The UI is trying to operate on a machine that might already be close to 100% CPU utilisation.\\r\\n\\r\\n## Some Benchmarking Do’s and Don’ts\\r\\n\\r\\n**Do:**\\r\\n\\r\\n* use our observability tooling!\\r\\n* try to model your benchmark workload to match your real workload as closely as you can, else you’ll be comparing apples to oranges.\\r\\n* take the time to understand the concepts that can affect performance: publisher confirms, consumer acknowledgements, message size, queue counts (see next heading).\\r\\n* make sure that the VM hosting your load generator is not the bottleneck. Either over-provision your load gen machine, or monitor it (CPU and network).\\r\\n* beware of IaaS with burstable resources such as CPU, network and disk. If you only look at the first 30 minutes of your test you may think that your chosen disk is up to the task. If you’d left the benchmark running you might have seen throughput hit the floor as soon as your burst ran out.\\r\\n* Beware that if you are running benchmarks in shared on-prem environments that might have complex networking setups (e.g. double NAT, VPC gateways, load balancers, firewall etc.) then you will not necessarily be benchmarking RabbitMQ, but your IT infrastructure. \\r\\n\\r\\nIf you run a benchmark both in an isolated environment and in your main IT infrastructure, it can help you isolate and optimise sub-optimal areas of your prod/qa environment.\\r\\n\\r\\n**Don’t:**\\r\\n\\r\\n* run an end-to-end latency test without rate limiting the publishers. Latency tests are only useful when the load is within the brokers capacity.\\r\\n* run a load generator (like [perf-test](https://github.com/rabbitmq/rabbitmq-perf-test/)) on the same machine as your RabbitMQ brokers.\\r\\n* run a benchmark in a shared on-prem environment without telling your IT ops people first. Using up all the network bandwidth on your benchmark tends to get the blood flowing of your IT operations people.\\r\\n* run a benchmark in cloud IaaS and then use those results to size an on-prem environment. There can be huge differences in performance depending on CPU generation, storage configuration, networking topology etc. There are even differences between clouds!\\r\\n\\r\\n## Some Common Impacts on Performance\\r\\n\\r\\nBelow are some things you can expect as you vary different aspects of a benchmark.\\r\\n\\r\\n* One queue has a throughput limit, so creating a few queues can increase total throughput. But creating hundreds of queues will then reduce total throughput. One or two queues per CPU thread tends to give highest throughput. More than that and the context switching will reduce efficiency.\\r\\n* Using publisher confirms and consumer acknowledgements has lower throughput than not using them. But when using hundreds of publishers and queues, publisher confirms can actually improve performance as they act as an effective back-pressure mechanism on publishers - avoiding large swings in throughput (learn more about [flow control](/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts)).\\r\\n* Sending one message, waiting for the publisher confirm, then sending the next and so on, is very very slow. Using a batch or a pipelining strategy with publisher confirms increases throughput significantly ([/tutorials/tutorial-seven-java.html](/tutorials/tutorial-seven-java) or [/tutorials/tutorial-seven-dotnet.html](/tutorials/tutorial-seven-dotnet))\\r\\n* Using no consumer prefetch will increase throughput (but it is not recommended as it can overwhelm a consumer - prefetch is how we exert back pressure on RabbitMQ). A prefetch of 1 will lower throughput significantly. Experiment with prefetch to find the right value for your workload.\\r\\n* Sending small messages will increase throughput (though MB/s will be low) and sending large messages will decrease throughput (but MB/s will be high).\\r\\n* Having a handful of publishers and consumers will result in the highest throughput. Creating thousands will result in lower total throughput.\\r\\n* Classic queues are faster than replicated queues (mirrored/quorum). The larger the replication factor, the slower the queue.\\r\\n\\r\\nOne common pattern is that once you get past a few tens of queues and/or clients, total throughput will drop. The more connections and connection there are, the more context switching there is and the less efficient things become. There are only a limited number of CPU cores. If you have thousands of queues and clients then that is not a bad thing, but realise that you may not get the same total throughput compared to when you have tens or hundreds of clients/queues.\\r\\n\\r\\n## Option #1 - Use Your Existing Applications\\r\\n\\r\\nIf you need to benchmark for capacity planning or to find the best configuration, then using your existing applications is most likely to yield the most useful results.\\r\\n\\r\\nThe trouble with synthetic benchmarks is that they tell you how your RabbitMQ installation will cope with loads generated by the chosen load generator, which may be quite different to your real usage.\\r\\n\\r\\nThe trouble with using your real applications is that generating load may take some work to set up. \\r\\n\\r\\nSecondly, unless you already have it instrumented, you won’t get end-to-end latency metrics. Of course you can add that. You could add a timestamp to a message header and extract that header in the consumer and publish the metric. Most languages have libraries for emitting metrics efficiently, without the need to hand-roll anything (for example [https://micrometer.io/](https://micrometer.io/)). Also take into account that without clock synchronisation like NTP, the end-to-end latency metrics will not be accurate, and even then, there may be jitter.\\r\\n\\r\\n## Option #2 - Perf Test\\r\\n\\r\\nPerfTest is our recommended tool for doing synthetic benchmarking of simple workloads with RabbitMQ. [PerfTest](https://github.com/rabbitmq/rabbitmq-perf-test) is on GitHub and has some nice [instructions](https://rabbitmq.github.io/rabbitmq-perf-test/stable/htmlsingle/). To run it yourself, please follow the [installation instructions](https://rabbitmq.github.io/rabbitmq-perf-test/stable/htmlsingle/#installation). \\r\\n\\r\\nIt even has its own Grafana [dashboard](https://grafana.com/grafana/dashboards/6566)! \\r\\n\\r\\n## Option #3 - Perf Test + CloudFoundry\\r\\n\\r\\nSee our [workloads](https://github.com/rabbitmq/workloads) project on GitHub. It will show you have to deploy and test for various workloads on CloudFoundry.\\r\\n\\r\\n## Option #4 - RabbitTestTool\\r\\n\\r\\nThis is an [*experimental* tool](https://github.com/Vanlightly/RabbitTestTool) that I use (and built) personally to do [automated exploratory testing](https://jack-vanlightly.com/blog/2020/5/26/with-great-observation-comes-great-insight). It is a powerful but complex tool and probably not your ideal choice for that reason. It’s more of a QA tool than for customers to benchmark their own setups.\\r\\n\\r\\nBut it has some features that might interest you.\\r\\n\\r\\nFirstly it has a [*model driven, property based test mode*](https://github.com/Vanlightly/RabbitTestTool/blob/master/benchmark/README.md#running-a-model-driven-property-based-test) that detects data loss, ordering violations (without redelivered flag), duplicate delivery (without redelivered flag) and availability. It is the data loss and availability detection that might interest you. Duplicates and ordering are only useful in our alpha and pre-alpha builds that might have bugs in new features.\\r\\n\\r\\nYou can use this tool to practice a blue/green deployment or a rolling upgrade, to ensure that you can perform the operation without data loss and availability.\\r\\n\\r\\nIt also has highly customisable EC2 deployment and benchmark orchestration. It is possible to set up many side-by-side benchmarks on different AWS hardware, RabbitMQ versions and configurations. But, again, this is so configurable that it is also complex.\\r\\n\\r\\n## Option #5 - RabbitMQ Benchmark X-Project\\r\\n\\r\\nOk so the name is a work-in-progress, but it represents a new project which we aim to benefit our own team but also the wider community, it will be the one benchmark project to rule them all.\\r\\n\\r\\nThe plan is to use a benchmark tool like PerfTest plus the Kubernetes API to combine both orchestration (the brokers, the disks etc) and the benchmark tool itself. Orchestration (deployment of RabbitMQ, load gen, observability) is often the most onerous part of benchmarking so we hope this project will solve that once and for all - not just for us but for *everyone*.\\r\\n\\r\\n## Wrap-Up\\r\\n\\r\\nBenchmarking can be hard to get right, but if done correctly it can provide valuable information. The key is to use as much of the observability tooling as possible and to try and model your actual workloads as closely as possible. It is hugely important to understand the usage of publisher confirms and consumer acknowledgements, [their role in flow control](/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks) and the impact they have on performance.\\r\\n\\r\\nIn subsequent blog posts that cover performance I’ll be including the PerfTest arguments that you’ll need to recreate the load generation side of things."},{"id":"/2020/06/01/this-month-in-rabbitmq-april-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/06/01/this-month-in-rabbitmq-april-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-06-01-this-month-in-rabbitmq-april-2020-recap/index.md","source":"@site/blog/2020-06-01-this-month-in-rabbitmq-april-2020-recap/index.md","title":"This Month in RabbitMQ, April 2020 Recap","description":"A Webinar on Quorum Queues","date":"2020-06-01T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.675,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, April 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"How to Run Benchmarks","permalink":"/rabbitmq-website/blog/2020/06/04/how-to-run-benchmarks"},"nextItem":{"title":"Quorum Queues and Flow Control - Stress Tests","permalink":"/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests"}},"content":"### A Webinar on Quorum Queues\\r\\n\\r\\nBefore we start with RabbitMQ project and community updates from April,\\r\\nwe have a webinar to announce! Jack Vanlightly, a RabbitMQ core team member,\\r\\nwill present on [High Availability and Data Safety in Messaging](https://www.brighttalk.com/webcast/14891/412069)\\r\\non June 11th, 2020.\\r\\n\\r\\nIn this webinar, Jack Vanlightly will explain [quorum queues](/docs/quorum-queues),\\r\\na new replicated queue type in RabbitMQ. Quorum queues were introduced in RabbitMQ 3.8 with a focus on data safety\\r\\nand efficient, predictable recovery from node failures.\\r\\nJack will cover and contrast the design of quorum and classic mirrored queues.\\r\\n\\r\\nAfter this webinar, you\'ll understand:\\r\\n\\r\\n * Why quorum queues offer better data safety than mirrored queues\\r\\n * How and why server resource usage changes when switching to quorum queues from mirrored queues\\r\\n * Some best practices when using quorum queues\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n * [JMS Client 2.1.0](https://groups.google.com/d/msg/rabbitmq-users/Vg81lYLLKLA/sqKLJUhnAgAJ) is released with a new feature and dependency upgrades.\\r\\n * [HOP 3.7.0](https://groups.google.com/d/msg/rabbitmq-users/ON4haXBaKOw/je08cqx1AwAJ) is released with a new feature, usability improvements, and dependency upgrades.\\r\\n * TGIR episode 5 is out and it covers [running RabbitMQ on Kubernetes](https://www.youtube.com/watch?v=-yU95ocpBYs)\\r\\n * [RabbitMQ 3.8.4](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.4) is released with support for Erlang 23\\r\\n * [Erlang 23](http://blog.erlang.org/OTP-23-Highlights/) includes an important improvement for container\\r\\n    users: the runtime now takes CPU quotas into account when computing how many [runtime schedulers](/docs/runtime) to start\\r\\n * Docker community\'s RabbitMQ image is [updated](https://github.com/docker-library/rabbitmq/issues/409) to RabbitMQ 3.8.4 and Erlang 23\\r\\n * Version 2.2.0 of [Go client for RabbitMQ HTTP API](https://github.com/michaelklishin/rabbit-hole/blob/master/ChangeLog.md) was released. We\'d like to thank [Raymond Fallon](https://github.com/niclic) for major contributions to this release.\\r\\n\\r\\n\\r\\n## Community Writings\\r\\n\\r\\n * April 3:  Gabor Olah presented [an introduction to RabbitMQ](https://www.erlang-solutions.com/blog/an-introduction-to-rabbitmq-what-is-rabbitmq.html)\\r\\n * April 4:  A new article about [RabbitMQ Headers Exchange with Docker in .NET](https://stefanescueduard.github.io/2020/04/04/rabbitmq-consumer-events-with-docker-in-dotnet/),  by Eduard Stefanescu (@EdStefanescu)\\r\\n * April 6:  Lovisa Johannson walks us through [asynchronous communication, illustrated by RabbitMQ](https://www.cloudamqp.com/blog/2016-09-13-asynchronous-communication-with-rabbitmq.html)\\r\\n * April 9:  [An introduction to RabbitMQ](https://slacker.ro/2020/04/09/an-introduction-to-rabbitmq-what-is-rabbitmq) by Erlang Solutions\\r\\n * April 9:  [Lessons for building a successful open source project](https://blogs.vmware.com/opensource/2020/04/09/open-source-contributions-rabbitmq/) from the RabbitMQ experience, by Dan Carwin\\r\\n * April 15:  [Using Celery with RabbitMQ\'s lazy classic queue mode](https://blog.whtsky.me/tech/2020/using-celery-with-rabbitmqs-lazy-queue/)\\r\\n * April 18: Via the blog, Programming with Wolfgang, Wolfgang Ofner finishes a three-part series on microservices with a how-to on [RabbitMQ in an ASP .Net Core 3.1 Microservice](https://www.programmingwithwolfgang.com/rabbitmq-in-an-asp-net-core-3-1-microservice/)\\r\\n * April 20:  Jack Vanlightly [introduces us to quorum queues](/blog/2020/04/20/rabbitmq-gets-an-ha-upgrade), the latest type of replicated queue that provide data safety guarantees for your messages.\\r\\n * April 21:  Jack Vanlightly continues his [blog series on quorum queues](/blog/2020/04/21/quorum-queues-and-why-disks-matter) with a closer look at their performance characteristics on different storage configurations.\\r\\n * April 22:  Over at Dev, Enrico Bison (@enricobix) compares [RabbitMQ exchange types](https://dev.to/enbis/amqp-exchange-type-comparison-using-go-rabbitmq-client-39p7)\\r\\n * April 27: Danny Simantov talks about [building a web-scraper for hourly news headlines](https://medium.com/swlh/backend-web-scraping-with-kubernetes-puppeteer-node-js-efe7513d834c) with RabbitMQ\\r\\n * April 27:  Composing a [pub/sub scenario with MassTransit 6.2 + RabbitMQ +.NET Core 3.1](https://medium.com/@alikzlda/a-simple-pub-sub-scenario-with-masstransit-6-2-rabbitmq-net-core-3-1-elasticsearch-mssql-5a65c993b2fd) + Elasticsearch + MSSQL from Ali Kizildag (@alikzlda)\\r\\n * April 27:  [Using RabbitMQ with the Symfony PHP framework](https://medium.com/@ibrahimgunduz34/using-rabbitmq-in-a-symfony-application-through-messenger-component-e61498b668b), by Ibharim Gunduz (@ibrahimgunduz34)\\r\\n * April 29:  An overview of [connecting to RabbitMQ in Golang](https://qvault.io/2020/04/29/connecting-to-rabbitmq-in-golang/) by Lane Wagoner (@wagslane)\\r\\n\\r\\n\\r\\n## Learn More\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n * New course: [Introduction to Spring Cloud Stream](https://www.baeldung.com/spring-cloud-stream) by baeldung, illustrated with RabbitMQ\\r\\n * [RabbitMQ Expert Training](https://www.eventbrite.co.uk/e/rabbitmq-expert-training-online-tickets-102979348002) — Online, by Erlang Solutions, Nov 9 2020"},{"id":"/2020/05/15/quorum-queues-and-flow-control-stress-tests","metadata":{"permalink":"/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-05-15-quorum-queues-and-flow-control-stress-tests/index.md","source":"@site/blog/2020-05-15-quorum-queues-and-flow-control-stress-tests/index.md","title":"Quorum Queues and Flow Control - Stress Tests","description":"In the last post we ran some simple benchmarks on a single queue to see what effect pipelining publisher confirms and consumer acknowledgements had on flow control.","date":"2020-05-15T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":22.245,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Quorum Queues and Flow Control - Stress Tests","tags":["Performance"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, April 2020 Recap","permalink":"/rabbitmq-website/blog/2020/06/01/this-month-in-rabbitmq-april-2020-recap"},"nextItem":{"title":"Quorum Queues and Flow Control - Single Queue Benchmarks","permalink":"/rabbitmq-website/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks"}},"content":"In the [last post](/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks) we ran some simple benchmarks on a single queue to see what effect pipelining publisher confirms and consumer acknowledgements had on flow control. \\r\\n\\r\\nSpecifically we looked at:\\r\\n\\r\\n* Publishers: Restricting the number of in-flight messages (messages sent but pending a confirm).\\r\\n* Consumers: Prefetch (the number in-flight messages the broker will allow on the channel)\\r\\n* Consumers: Ack Interval (multiple flag usage)\\r\\n\\r\\nUnsurprisingly, we saw when we restricted publishers and the brokers to a small number of in-flight messages at a time, that throughput was low. When we increased that limit, throughput increased, but only to a point, after which we saw no more throughput gains but instead just latency increases. We also saw that allowing consumers to use the multiple flag was beneficial to throughput.\\r\\n\\r\\nIn this post we’re going to look at those same three settings, but with many clients, many queues and different amounts of load, including stress tests. We’ll see that publisher confirms and consumer acknowledgements play a role in flow control to help prevent overload of a broker. \\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nWith data safety the clients play a role, they must use confirms and acks correctly to achieve at-least once processing. Likewise, thousands of clients shouldn’t expect to hammer a broker with load and accept no responsibility for how that goes. \\r\\n\\r\\nBe warned, there is a fair amount of detail in this post so make sure you are comfortable with a beverage nearby before you begin.\\r\\n\\r\\n## Mechanical Sympathy\\r\\n\\r\\nI really like the term mechanical sympathy. When you drive a racing car slowly, you can get away with pretty much anything. It’s when you push the car to its limits that you need to start listening to it, feeling the vibrations and adjust accordingly else it will break down before the end of the race. \\r\\n\\r\\nLikewise, with RabbitMQ, if you have a low load, then you can get away with a lot. You might not see much impact of changing these three settings, or using confirms at all (at least on performance). It’s when you stress a cluster to its limit that these settings really become important.\\r\\n\\r\\n## Degrading Gracefully\\r\\n\\r\\nWhat should a system do when you throw more data at it than it can handle? \\r\\n\\r\\n* Answer 1: accept all data only to burst into a flaming pile of bits.\\r\\n* Answer 2: deliver huge swings of high and low throughput, with hugely varying latencies.\\r\\n* Answer 3: rate limit data ingress and deliver steady throughput with low latencies.\\r\\n* Answer 4: favour ingress to egress, absorbing the data as if it were a peak in load causing high latencies but better keeping up with the ingress rate.\\r\\n\\r\\nAt RabbitMQ we would argue that answers 3 and 4 are reasonable expectations whereas nobody wants 1 and 2.\\r\\n\\r\\nWhen it comes to answer 4, when is a peak not a peak? At what point does a short peak become chronic? How should such a system favour publishers over consumers? This is a hard choice to make and a hard one to implement well. RabbitMQ goes more along with answer 3: rate limit publishers and try to balance the publish and consume rate as much as possible.\\r\\n\\r\\nIt comes down to flow control.\\r\\n\\r\\n## Choosing the right in-flight limit and prefetch\\r\\n\\r\\nThe decision is simple if you never expect heavy load. We saw in the last post with a single high throughput queue that you can set a high in-flight limit, high prefetch and optionally use the multiple flag with consumer acknowledgements and you’ll do ok. If you have low load then likely all settings look the same to the final throughput and latency numbers.\\r\\n\\r\\nBut if you expect periods of heavy load and have hundreds or even thousands of clients then is that still a good choice? The best way I know to answer these questions is to run tests, many, many tests with all kinds of parameters.\\r\\n\\r\\nSo we’ll run a series of benchmarks with different:\\r\\n\\r\\n* numbers of publishers\\r\\n* numbers of  queues\\r\\n* numbers of  consumers\\r\\n* publish rates\\r\\n* in-flight limits\\r\\n* prefetch and ack intervals\\r\\n\\r\\nWe’ll measure both throughput and latency. The in-flight limit will be a percentage of the target rate per publisher with the percentages anywhere between 1% to 200%. So for example with a per publisher target rate of 1000:\\r\\n\\r\\n* 1% in-flight limit = 10\\r\\n* 5% in-flight limit = 50\\r\\n* 10% in-flight limit = 100\\r\\n* 20% in-flight limit = 200\\r\\n* 100% in-flight limit = 1000\\r\\n* 200% in-flight limit = 2000\\r\\n\\r\\nLike in the last post we’ll test both mirrored and quorum queues. Mirrored with one master plus one mirror (rep factor 2) and quorum queues with one leader and two followers (rep factor 3).\\r\\n\\r\\nAll tests use an alpha build of RabbitMQ 3.8.4 with improved quorum queue internals for handling high load. Additionally we’ll be conservative with memory use and set the quorum queue *x-max-in-memory-length* property to a low value, this makes a quorum queue act a little bit like a lazy queue, it will remove message bodies from memory as soon as it is safe to do so and the queue length has reached this limit. Without this limit, quorum queues maintain all messages in memory. It can be less performant if consumers are not keeping up as there are more disk reads, but it is a safer more conservative configuration. It will become important as we stress the system as it avoids large memory spikes. In these tests it is set to 0 which is the most aggressive setting.\\r\\n\\r\\nAll tests were on 3 node clusters with 16 vCPU (Cascade Lake/Skylake Xeon) machines with SSDs.\\r\\n\\r\\nBenchmarks:\\r\\n\\r\\n1. 20 publishers, 1000 msg/s, 10 queues, 20 consumers, 1kb messages\\r\\n1. 20 publishers, 2000 msg/s, 10 queues, 20 consumers, 1kb messages\\r\\n1. 500 publishers, 30 msg/s, 100 queues, 500 consumers, 1kb messages\\r\\n1. 500 publishers, 60 msg/s, 100 queues, 500 consumers, 1kb messages\\r\\n1. 1000 publishers, 100 msg/s, 200 queues, 1000 consumers, 1kb messages\\r\\n\\r\\n## Benchmark #1: 20 publishers, 1000 msgs/s per publisher, 10 queues, 20 consumers\\r\\n\\r\\nWith a  total target rate of 20000 msg/s this is within the total throughput limit of the cluster on the chosen hardware for this number of clients and queues. This kind of load is sustainable for this cluster.\\r\\n\\r\\nWe have two tests:\\r\\n\\r\\n1. No publisher confirms\\r\\n1. Confirms with in-flight limit as a percentage of the target send rate: 1% (10), 2% (20), 5% (50), 10% (100), 20% (200), 100% (1000).\\r\\n\\r\\n**Mirrored queue without confirms**\\r\\n\\r\\n![Fig 1. 20 publishers (1000 msg/s), 10 mirrored queues, 20 consumers without publisher confirms](20-pub-queue-con-1000-sec-mirrored-no-confirms.png)\\r\\n\\r\\nThe cluster is not being driven harder by the publishers than it can handle. We get a smooth throughput that matches our target rate with sub-second latency.\\r\\n\\r\\n**Mirrored queue with confirms**\\r\\n\\r\\n![Fig 2. 20 publishers (1000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits](20-pub-queue-con-1000-sec-mirrored-confirms-1.png)\\r\\n\\r\\nWith this load level, all in-flight settings behave the same. We are not anywhere near the broker’s limit.\\r\\n\\r\\n**Quorum queue without confirms**\\r\\n\\r\\n![Fig 3. 20 publishers (1000 msg/s), 10 quorum queues, 20 consumers without publisher confirms](20-pub-queue-con-1000-sec-qq-no-confirms.png)\\r\\n\\r\\nTarget rate matched, latency sub-second.\\r\\n\\r\\n**Quorum queue with confirms**\\r\\n\\r\\n![Fig 4. 20 publishers (1000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits](20-pub-queue-con-1000-sec-qq-confirms-1.png)\\r\\n\\r\\nWith confirms, and a low in-flight limit, quorum queues are a tiny bit short of the target rate but are achieving &lt; 200ms at all percentiles. As we increase the in-flight limit, the target rate is reached, with a smooth line but latencies increase while still falling below 1 second.\\r\\n\\r\\n### Conclusion\\r\\n\\r\\nWhen the publish rate is within a clusters capacity to deliver it to consumers, confirms with a low in-flight limit delivered the best end-to-end latency while no confirms or confirms with a high in-flight limit delivered the target throughput but at a higher latency (though still sub-second).\\r\\n\\r\\n## Benchmark #2: 20 publishers, 2000 msgs/s per publisher, 10 queues, 20 consumers\\r\\n\\r\\nWith a total target rate of 40000 msg/s, this is around or above the throughput limit of the cluster on the chosen hardware. This kind of load is probably unsustainable for this cluster but could occur under peak load conditions. If it were sustained then bigger hardware would be advised.\\r\\n\\r\\nWe have three tests:\\r\\n\\r\\n1. No publisher confirms\\r\\n1. Confirms with in-flight limit as a percentage of the target send rate: 1% (20), 2% (40), 5% (100), 10% (200), 20% (400), 100% (2000). Prefetch of 2000, ack interval of 1.\\r\\n1. Same as 2, but with multiple flag usage by consumers, using an ack interval of 200 (10% of prefetch).\\r\\n\\r\\n**Mirrored queue without confirms**\\r\\n\\r\\n![Fig 5. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers without publisher confirms](20-pub-queue-con-2000-sec-mirrored-no-confirms.png)\\r\\n\\r\\nPublishers briefly touch close to the target rate but both publisher and consumer rates stabilise at a lower rate, with the publish rate exceeding the consumer rate. This causes the queues to fill up and latencies to skyrocket. If this were sustained then the queue would grow huge and place increasing pressure on resource usage.\\r\\n\\r\\n**Mirrored queue with confirms**\\r\\n\\r\\n![Fig 6. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits.](20-pub-queue-con-2000-sec-mirrored-confirms-1.png)\\r\\n\\r\\n**Mirrored queue with confirms and multiple flag usage**\\r\\n\\r\\n![Fig 7. 20 publishers (2000 msg/s), 10 mirrored queues, 20 consumers with publisher confirms and different in-flight limits. Multiple flag usage by consumers.](20-pub-queue-con-2000-sec-mirrored-confirms-multiple-flag.png)\\r\\n\\r\\nConfirms really make a difference now, applying effective back pressure on the publishers. We hit the peak throughput (still way-off the target) with the lowest in-flight limit of 20 (1% of target rate). End-to-end latency is low, at around 20ms. But as we increase the in-flight limit, a minority of the queues start filling up, causing the 95th percentile latency to shoot up. \\r\\n\\r\\nWe see that using the multiple flag reduces the publish-to-consume rate imbalance when at the high in-flight limit and thereby reduces the worst of the latencies a bit. But the effect is not super strong in this case.\\r\\n\\r\\n**Quorum queue without confirms**\\r\\n\\r\\n![Fig 8. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers without publisher confirms.](20-pub-queue-con-2000-sec-qq-no-confirms.png)\\r\\n\\r\\nQuorum queues tend to outperform mirrored queues when the queue count is low. Here we see that 40000 msg/s was achieved and so back pressure on publishers was not needed.\\r\\n\\r\\n**Quorum queue with confirms**\\r\\n\\r\\n![Fig 9. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits.](20-pub-queue-con-2000-sec-qq-confirms-1.png)\\r\\n\\r\\n**Quorum queue with confirms and multiple flag usage**\\r\\n\\r\\n![Fig 10. 20 publishers (2000 msg/s), 10 quorum queues, 20 consumers with publisher confirms and different in-flight limits, with consumers using the multiple flag.](20-pub-queue-con-2000-sec-qq-confirms-multiple-flag.png)\\r\\n\\r\\nQuorum queues yet again deliver higher throughput and we even reached the target rate of 40000 msg/s with an in-flight limit of 2000. There was a mild benefit to using the multiple flag.\\r\\n\\r\\n### Conclusion\\r\\n\\r\\nWithout the back pressure of using publisher confirms and an in-flight limit, mirrored queues fell apart. When publishers used confirms they effectively put back pressure on the publishers, achieving low latency until the in-flight limit reached 100% of the target rate, where again latency started spiking again. The important thing to note is that this target rate exceeded the mirrored queues capacity, and we saw how important back pressure was.\\r\\n\\r\\nQuorum queues can achieve higher throughput than mirrored queues when the number of queues and publishers is relatively low. They were capable of delivering 40000 msg/s and so using confirms or not using confirms was not critical to stable performance.\\r\\n\\r\\nMultiple flag usage was beneficial, but not game changing.\\r\\n\\r\\n## Benchmark #3: 500 publishers, 30 msgs/s per publisher, 100 queues, 500 consumers\\r\\n\\r\\nWith a total target rate of 15000 msg/s, this is within the total throughput limit of the cluster on the chosen hardware. \\r\\n\\r\\nWe have two tests:\\r\\n\\r\\n1. No publisher confirms\\r\\n1. Confirms with in-flight limit as a percentage of the target send rate: 6% (2), 10% (3), 20% (6), 50% 12, 100% (30), 200% (60) and no multiple flag usage.\\r\\n\\r\\n**Mirrored queue without confirms**\\r\\n\\r\\n![Fig 11. 500 publishers (30 msg/s), 100 mirrored queues, 500 consumers without publisher confirms.](500-pub-queue-con-30-sec-mirrored-no-confirms.png)\\r\\n\\r\\n**Mirrored queue with confirms**\\r\\n\\r\\n![Fig 12. 500 publishers (30 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits](500-pub-queue-con-30-sec-mirrored-confirms-1.png)\\r\\n\\r\\n**Quorum queue without confirms**\\r\\n\\r\\n![Fig 13. 500 publishers (30 msg/s), 100 quorum queues, 500 consumers without publisher confirms.](500-pub-queue-con-30-sec-qq-no-confirms.png)\\r\\n\\r\\n**Quorum queue with confirms**\\r\\n\\r\\n![Fig 14. 500 publishers (30 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits](500-pub-queue-con-30-sec-qq-confirms-1.png)\\r\\n\\r\\nIn all cases we matched the target rate. With confirms and a low in-flight limit the throughput had a small amount of jitter that resolved at higher limits.\\r\\n\\r\\nAs we increased the in-flight limit, latency crept up. Mirrored queues passed 1 second while quorum queues remained below 1 second.\\r\\n\\r\\nAgain, we see that when the cluster is within its capacity, we don’t need confirms as a back pressure mechanism (just for data safety).\\r\\n\\r\\n## Benchmark #4: 500 publishers, 60 msgs/s per publisher, 100 queues, 500 consumers\\r\\n\\r\\nWith a total target rate of 30000 msg/s, this is just above the total throughput limit of the cluster for this number of clients and queues (on the chosen hardware). This will stress the cluster and is not a sustainable load that this cluster should be exposed to.\\r\\n\\r\\nWe have three tests:\\r\\n\\r\\n1. No publisher confirms\\r\\n1. Confirms with in-flight limit as a percentage of the target send rate: 5% (3), 10% (6), 20% (12), 50% (24), 100% (60), 200% (120) and a prefetch of 60.\\r\\n1. Same as 2 but with multiple flag usage with an ack interval of 6 (10% of prefetch).\\r\\n\\r\\n**Mirrored queue without confirms**\\r\\n\\r\\n![Fig 15. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers without publisher confirms.](500-pub-queue-con-60-sec-mirrored-no-confirms.png)\\r\\n\\r\\nWithout confirms, publishers briefly manage the target rate but consumers can’t keep up. Throughput is pretty wild and latencies for half the queues get close to 1 minute and the rest reach over 2-3 minutes.\\r\\n\\r\\n**Mirrored queue with confirms**\\r\\n\\r\\n![Fig 16. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits.](500-pub-queue-con-60-sec-mirrored-confirms-2.png)\\r\\n\\r\\n**Mirrored queue with confirms and multiple flag usage**\\r\\n\\r\\n![Fig 17. 500 publishers (60 msg/s), 100 mirrored queues, 500 consumers with publisher confirms and different in-flight limits with multiple fag usage.](500-pub-queue-con-60-sec-mirrored-confirms-multiple-flag.png)\\r\\n\\r\\nWith confirms we get much more stable throughput where consumers keep up with the publish rate because the publishers are being rate limited by their in-flight limit. The multiple flag definitely helps this time, pushing us up to 5000 msg/s higher throughput. Notice that the in-flight limit of just 3% of the target rate delivers the best performance.\\r\\n\\r\\n**Quorum queue without confirms**\\r\\n\\r\\n![Fig 18. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers without publisher confirms.](500-pub-queue-con-60-sec-qq-no-confirms.png)\\r\\n\\r\\nThe publishers hit their target, but consumers are not keeping up and the queues are filling. This is not a sustainable position to be in.\\r\\n\\r\\n**Quorum queue with confirms**\\r\\n\\r\\n![Fig 19. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits.](500-pub-queue-con-60-sec-qq-confirms-1.png)\\r\\n\\r\\n**Quorum queue with confirms and multiple flag**\\r\\n\\r\\n![Fig 20. 500 publishers (60 msg/s), 100 quorum queues, 500 consumers with publisher confirms and different in-flight limits and multiple flag usage.](500-pub-queue-con-60-sec-qq-confirms-multiple-flag.png)\\r\\n\\r\\nWith publisher confirms we see more stable throughput but there is a definitely a saw-tooth pattern. We can go all the way up to an in-flight limit of 100% of the target rate without things falling apart, though latencies are steadily rising. At 200%, the publish rate exceeds the consume rate and the queues start filling up.\\r\\n\\r\\n### Conclusion\\r\\n\\r\\nWhen a cluster is past its limit, use of publisher confirms with an in-flight limit ensure a balanced publish and consume rate. Even though the publishers would go faster, they rate limit themselves and RabbitMQ can deliver sustainable performance for long periods.\\r\\n\\r\\nWith large numbers of publishers, consumers and queues, the maximum throughput of mirrored and quorum queues has converged to a similar number. Quorum queues no longer outperform mirrored queues. We saw a higher throughput with less clients and queues. Less means less context switching, less random IO which is all more efficient.\\r\\n\\r\\n## Benchmark #5: 1000 publishers, 100 msgs/s per publisher, 200 queues, 1000 consumers\\r\\n\\r\\nThis load is way past what this cluster can handle at a total target rate of 100000 msg/s second over 200 queues. Beyond the low 10s of queues, expect maximum throughput of a cluster to fall as the number of queues increases.\\r\\n\\r\\nIf this cluster ever gets hit like this then it should only be for short periods of time.\\r\\n\\r\\nWe have three tests:\\r\\n\\r\\n1. No confirms\\r\\n1. Confirms with in-flight limit as a percentage of the target send rate: 2% (2), 5% (5), 10% (10), 20% (20), 50% (50), 100% (100) and a prefetch of 100.\\r\\n1. Same as 2 but with multiple flag usage and an ack interval of 10 (10% of prefetch).\\r\\n\\r\\n**Mirrored queue without confirms**\\r\\n\\r\\n![Fig 21. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers without publisher confirms.](1000-pub-queue-con-100-sec-mirrored-no-confirms.png)\\r\\n\\r\\nPublishers almost reach the target rate, but then buffers inside the brokers start reaching capacity and throughput plummets like a stone. Relying on TCP back pressure, with default credit based flow control settings with 1000 publishers sending faster than the cluster could handle didn’t go very well. \\r\\n\\r\\nThe initial credit is 400 for each actor in the credit chain, so the reader process on each connection will accept at the least 400 messages before being blocked. With 1000 publishers, that’s 400,000 messages buffered just in the reader processes. Add to that the buffers of the channels and the queues, and all the outgoing port buffers etc and you can see how a broker can absorb and then get choked by a large number of messages from a large number of publishers, even before TCP back pressure kicks in.\\r\\n\\r\\n**Mirrored queue with confirms**\\r\\n\\r\\n![Fig 22. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers with publisher confirms and different in-flight limits.](1000-pub-queue-con-100-sec-mirrored-confirms-1.png)\\r\\n\\r\\n**Mirrored queue with confirms and multiple flag usage**\\r\\n\\r\\n![Fig 23. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers with publisher confirms and different in-flight limits.](1000-pub-queue-con-100-sec-mirrored-confirms-multiple-flag.png)\\r\\n\\r\\nThe publishers would love to reach the target rate but they are being rate limited effectively. As we increase the in-flight limit we see a slight increase in throughput and a larger increase in latency. In the end, when we reach an in-flight limit of 200% of the target rate, it’s too much, but publishers are still throttled. Queues back up a little and throughput drops, getting pretty choppy. Usage of the multiple flag helps, it lessens the drop and keeps latency below 25 seconds.\\r\\n\\r\\nIf we look at the [RabbitMQ Overview](https://grafana.com/grafana/dashboards/10991) Grafana dashboard (slightly modified for show here), we see that when the in-flight limit is low, there are a low number of pending confirms and pending consumer acks, but as we reach 100% in-flight limit those numbers reach 100,000. So RabbitMQ has a lot more messages buffered internally. Consumers have not reached their prefetch limit though peaking at 55,000 of their total possible 100,000.\\r\\n\\r\\n![Fig 24. RabbitMQ overview shows pending confirms and acks increasing inline with the in-flight limit.](1000-pub-queue-con-100-sec-mirrored-confirms-overview-1.png)\\r\\n\\r\\n**Quorum queue without confirms**\\r\\n\\r\\n![Fig 25. 1000 publishers (100 msg/s), 200 mirrored queues, 1000 consumers without publisher confirms.](1000-pub-queue-con-100-sec-qq-no-confirms.png)\\r\\n\\r\\nSame as mirrored queues. TCP back pressure was not enough to stop overload.\\r\\n\\r\\n**Quorum queue with confirms**\\r\\n\\r\\n![Fig 26. 1000 publishers (100 msg/s), 200 quorum queues, 1000 consumers with publisher confirms and different in-flight limits.](1000-pub-queue-con-100-sec-qq-confirms-1.png)\\r\\n\\r\\n**Quorum queue with confirms and multiple flag usage**\\r\\n\\r\\n![Fig 27. 1000 publishers (100 msg/s), 200 quorum queues, 1000 consumers with publisher confirms and different in-flight limits.](1000-pub-queue-con-100-sec-qq-confirms-multiple-flag.png)\\r\\n\\r\\nQuorum queues definitely benefited more than mirrored queues when switching from a low to a medium sized in-flight limit. With multiple flag usage we even hit close to 35000 msg/s. Things started to go wrong at the 100% of target rate limit and then really bad at 200%. The publishers pulled ahead causing the queues to fill up. This is when you really need that low value for the  *x-max-in-memory-length* quorum queue property. Without it, memory usage would spike very fast under these conditions causing huge swings in throughput as memory alarms turn on and off repeatedly.\\r\\n\\r\\nWe have made big improvements to quorum queue memory usage under stress in the upcoming 3.8.4 release. All these tests show the results of that work. Towards the end of this post we’ll show this same test with 3.8.3 and how it doesn’t deal so well with this stress test.\\r\\n\\r\\nIn the Overview dashboard we see how the queues are filling up. Consumers have reached their prefetch limit.\\r\\n\\r\\n![Fig 28. RabbitMQ overview shows quorum queue pending confirms and acks increasing inline with the in-flight limit.](1000-pub-queue-con-100-sec-qq-confirms-overview-1.png)\\r\\n\\r\\n### Conclusion\\r\\n\\r\\nNeither queue type could handle this load without publisher confirms. Each cluster got totally overwhelmed.\\r\\n\\r\\nWith confirms, mirrored and quorum queues achieved the same ballpark throughput and latency numbers until the 100% and 200% in-flight limits, where quorum queues fared worse.\\r\\n\\r\\nMirrored queues handled the overload pretty well, even with high in-flight limits. Quorum queues needed the additional help of a low in-flight limit to achieve stable throughput with low latency.\\r\\n\\r\\n## What about 3.8.3 and earlier?\\r\\n\\r\\nAll the quorum queue tests were run on an alpha of 3.8.4, in order to show performance of the upcoming 3.8.4 release. But the rest of you will be on version 3.8.3 and earlier. So what can you expect?\\r\\n\\r\\nThe improvements landing in 3.8.4 are:\\r\\n\\r\\n* High throughput capacity of segment writing. Messages are written first to the WAL and secondly to segment files. In 3.8.3 we saw that the segment writer was a bottleneck in high load, high queue count scenarios which would cause high memory usage. 3.8.4 comes with parallelised segment writing which completely solves this bottleneck.\\r\\n* Default configuration values for quorum queues were load tested and we found some changes resulted in more stable throughput under high load. Specifically we changed quorum\\\\_commands\\\\_soft\\\\_limit from 256 to 32 and raft.wal\\\\_max\\\\_batch\\\\_size from 32768 to 4096.\\r\\n\\r\\nIf you are on 3.8.3 the good news is that rolling upgrades these days are easily performed, but if you can’t upgrade then try the above configurations. You’ll still have the possible bottleneck of the segment writer though.\\r\\n\\r\\nBelow is benchmark #5, with a longer running time, with 3.8.3 (with the configuration changes applied).\\r\\n\\r\\n**3.8.3 benchmark #5**\\r\\n\\r\\n![Fig 29. 3.8.3 sees large peaks and troughs caused by memory alarms.](1000-pub-queue-con-100-sec-qq-383-confirms-long.png)\\r\\n\\r\\nThe main difference with 3.8.3 is that as we increase the in-flight limit, the segment writer falls behind and memory grows until memory alarms hit. Publishers get blocked and consumers are then unconstrained by competing with publishers to get their acks into the replicated log. The consume rate reaches short peaks of up to 90k msg/s until the queues are drained, memory falls and alarms deactivated, only to repeat again and again.\\r\\n\\r\\nWe can see that from the Overview dashboard. The 3.8.4 alpha has a slowly increasing memory growth as the in-flight limit rises.\\r\\n\\r\\n![Fig 30. The 3.8.4 alpha sees stable memory growth as the in-flight limit increases.](custom-build-memory.png)\\r\\n\\r\\n**3.8.3 hits the memory alarms repeatedly.**\\r\\n\\r\\n![Fig 31. 3.8.3 hits memory alarms repeatedly under heavy load from a 1000 publishers.](3.8.3-memory.png)\\r\\n\\r\\nEven with the low in-flight limit, this heavy workload with a 1000 publishers was too much for the segment writer and it reached close to the memory alarms early in the test.\\r\\n\\r\\nSo if you have large publisher and queue counts with regular peaks in load that exceed its limits, then consider upgrading to 3.8.4 when it is out.\\r\\n\\r\\n## Final Conclusions\\r\\n\\r\\nFirst of all, if you are using a replicated queue (mirrored or quorum) then not using publisher confirms, from a data safety point of view, is highly inadvisable. Message delivery is not guaranteed, so please use them.\\r\\n\\r\\nData safety aside, these tests show that confirms also play a role in flow control.\\r\\n\\r\\nSome key takeaways:\\r\\n\\r\\n* Quorum queues can deliver higher throughput than mirrored queues when the queue count is in the region of 1-2 per core.\\r\\n* At low publisher and queue counts, you can pretty much do anything. TCP back pressure is probably enough for both mirrored and quorum queues (not using confirms).\\r\\n* At high publisher and queue counts and higher load, TCP back pressure is not enough. We must employ publisher confirms so that publishers rate limit themselves.\\r\\n* At high publisher and queue counts, performance was more or less similar for both queue types. But quorum queues needed a little extra help via a lower in-flight limit during the stress test.\\r\\n* Multiple flag usage was beneficial but not critical.\\r\\n* Whatever you do, don\'t put your brokers under high load without publisher confirms!\\r\\n\\r\\nSo what is the best in-flight limit? I hope I’ve managed to persuade you that *it depends*, but as a rule of thumb, with low network latency between publishers and the broker, using a limit between 1% and 10% of the target rate is optimal. With fewer publishers that have a high send rate, then we veer towards 10% but with hundreds of clients then we veer towards the 1% mark. These numbers are likely to increase with higher latency links between publishers and brokers.\\r\\n\\r\\nRegarding consumer prefetch, all these tests used a prefetch of the target publish rate (per publisher, not total), but remember that in these tests, the number of publishers matched the number of consumers. When the multiple flag was used, the ack interval was 10% of the prefetch value. Multiple flag usage is beneficial but its not a big deal if you don\'t use it.\\r\\n\\r\\nIf you are currently on mirrored queues and your workload more closely resembles benchmark #5 rather than any of the others, then it is recommended to make the jump after 3.8.4 is released. Improving flow control and resiliency under load is likely to be an ongoing effort, but is also workload specific in many cases. Hopefully you have seen that you have the power to tune throughput and latency via the use confirms, and get the behaviour that you need.\\r\\n\\r\\nI would be amiss if I didn\'t mention capacity planning. Ensuring that RabbitMQ has enough hardware to handle peak loads is the best way to ensure that it can deliver performance that is acceptable. But there are always surprise loads, limits in budget and so on.\\r\\n\\r\\nRemember, as with all benchmarks like this, don\'t fixate on these specific numbers. Your situation will be different. Different hardware, different message sizes, degrees of fanout, different versions of RabbitMQ, different clients, frameworks... the list goes on. The main takeaway is that you shouldn’t expect RabbitMQ to exert flow control by itself when under heavy load. It’s all about *mechanical sympathy*.\\r\\n\\r\\nNext in the series is a look at migrating from mirrored to quorum queues."},{"id":"/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks","metadata":{"permalink":"/rabbitmq-website/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-05-14-quorum-queues-and-flow-control-single-queue-benchmarks/index.md","source":"@site/blog/2020-05-14-quorum-queues-and-flow-control-single-queue-benchmarks/index.md","title":"Quorum Queues and Flow Control - Single Queue Benchmarks","description":"In the last post we covered what flow control is, both as a general concept and the various flow control mechanisms available in RabbitMQ. We saw that publisher confirms and consumer acknowledgements are not just data safety measures, but also play a role in flow control.","date":"2020-05-14T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":12.03,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Quorum Queues and Flow Control - Single Queue Benchmarks","tags":["Performance"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Quorum Queues and Flow Control - Stress Tests","permalink":"/rabbitmq-website/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests"},"nextItem":{"title":"Quorum Queues and Flow Control - The Concepts","permalink":"/rabbitmq-website/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts"}},"content":"In the last post we covered what flow control is, both as a general concept and the various flow control mechanisms available in RabbitMQ. We saw that publisher confirms and consumer acknowledgements are not just data safety measures, but also play a role in flow control. \\r\\n\\r\\nIn this post we’re going to look at how application developers can use publisher confirms and consumer acknowledgements to get a balance of safety and high performance, in the context of a single queue. \\r\\n\\r\\nFlow control becomes especially important when a broker is being overloaded. A single queue is unlikely to overload your broker. If you send large messages then sure, you can saturate your network, or if you only have a single CPU core, then one queue could max it out. But most of us are on 8, 16 or 30+ core machines. But it’s interesting to break down the effects of confirms and acks on a single queue. From there we can take our learnings and see if they apply to larger deployments (the next post).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Pipelining and Publisher Confirms\\r\\n\\r\\nPublishers can rate limit themselves based on the number of unconfirmed messages in-flight. With a limit of 5, the publisher will send 5 messages and then block until confirms come in. If a single confirm comes in, the publisher can now send a message and block again. If three confirms come in, the publisher can send three more, and so on.\\r\\n\\r\\nConfirms can be batched together via the use of the *multiple* flag. This allows the broker to confirm multiple messages at a time. If 100 messages are pending confirmation, with sequence numbers 1-100, the broker can send a single confirm with the multiple flag set and the sequence number of 100. This allows for less communications between publisher and broker, which is more efficient.\\r\\n\\r\\nThis pipelining method will produce the highest and most stable throughput. You can find code samples for how to do this in tutorial 7, strategy #3. There is a [Java](/tutorials/tutorial-seven-java) version and a [C#](/tutorials/tutorial-seven-dotnet) version. The same approach can be applied to other languages.\\r\\n\\r\\n## Pipelining and Consumer Acks\\r\\n\\r\\nRabbitMQ employs the pipelining method, where its “in-flight limit” is the consumer prefetch (QoS) on a given channel. Without a prefetch, it will send messages as fast as it can until there are no more messages to send or TCP back-pressure is applied due to the client TCP buffer being full. This can overload the consumer so please use a prefetch!\\r\\n\\r\\nWhen your consumer sends an acknowledgement, that is like when the broker sends a confirm to a publisher. It allows more messages to be pushed down the channel.\\r\\n\\r\\nJust like confirms, consumer acks get to use the multiple flag as well. The consumer can choose to acknowledge every message individually or every N number of messages. We’ll call this the *ack interval*. With an ack interval of 10, a consumer will acknowledge every 10th message, using the multiple flag. \\r\\n\\r\\nThis can be more complex code as you also need to take into account:\\r\\n\\r\\n* If the last 10 messages includes a mix of acks, nacks and rejects then you can’t simply perform a single ack with multiple flag set.\\r\\n* You will probably wish to put a temporal limit on the length of time between acks, in case messages come in slowly, for example, every 10 messages or up to 50ms.\\r\\n\\r\\n## Measuring the Impact of In-Flight Limit, Prefetch and Ack Interval\\r\\n\\r\\nThe best way to see the impact is to run a series of benchmarks with a typical cluster and change the publisher confirm in-flight limit, the consumer prefetch and the ack interval.\\r\\n\\r\\nAll benchmarks are run in AWS with the following configuration:\\r\\n\\r\\n* c5.4xlarge EC2 instance: 16 vCPUs (Cascade Lake/Skylake Xeon), 32 GB RAM, 5gbit network, 200 GB SSD (io1 with 10000 IOPS)\\r\\n* 3 brokers in a cluster\\r\\n* 1 load generation EC2 machine of the same spec (c5.4xlarge)\\r\\n* 1kb messages\\r\\n* No processing time as this is a pure throughput/latency benchmark of a single publisher and single consumer.\\r\\n\\r\\nWe test quorum queues and mirrored queues to give an idea of how quorum queues differ from their older counterpart.\\r\\n\\r\\nMirrored queues have one master and one mirror, and quorum queues use a replication factor of three (one leader + two followers). It’s not exactly a fair fight, a replication factor of two with mirrored and a replication factor of three with quorum queues, but those are the most common configurations respectively. All tests use an alpha build of RabbitMQ 3.8.4 with new quorum queue features for handling high load. \\r\\n\\r\\nBenchmarks:\\r\\n\\r\\n1. Increasing in-flight limit, prefetch 1000, ack interval 1\\r\\n1. 1000 in-flight limit, increasing prefetch, ack interval 1\\r\\n1. 1000 in-flight limit, 1000 prefetch, increasing ack interval\\r\\n1. No confirms, no acks\\r\\n\\r\\n## Interpreting these results\\r\\n\\r\\nThe rules:\\r\\n\\r\\n* **Rule 1** - These are synthetic benchmarks, with a specific version of RabbitMQ, with cloud instances (which introduces all kinds of reproducibility issues) and a specific hardware configuration. There is no single benchmark result, there are infinite. So don’t look at specific numbers, look at trends and patterns.\\r\\n* **Rule 2** - These results are using the Java client, not Spring, not Python or any other language or framework. However, what we are testing should hold true for other frameworks as they have to use the same settings, how they use those settings may or may not be under your control.\\r\\n* **Rule 3** - Try out your existing code with these different settings changes and see for yourself!\\r\\n\\r\\n## Benchmark #1 - Increasing in-flight limit, prefetch 1000, ack interval 1\\r\\n\\r\\nThis is a 30 minute benchmark where we increase the in-flight limit every 5 minutes with the following values: 1, 5, 20, 200, 1000, 10000. With the low values, the publishers will be rate limiting themselves pretty aggressively, constraining throughput, but as the limit increases we should see throughput increase.\\r\\n\\r\\n**Mirrored queue**\\r\\n\\r\\n![Fig 1. Mirrored queue with increasing publisher confirm in-flight limit](1-pub-queue-con-mirrored-increasing-inflight.png)\\r\\n\\r\\n**Quorum queue**\\r\\n\\r\\n![Fig 2. Quorum queue with increasing publisher confirm in-flight limit](1-pub-queue-con-qq-increasing-inflight.png)\\r\\n\\r\\nBoth queue types have a similar profile. As we increase the in-flight limit, throughput goes up until we see that the level is so high as to not have any kind of flow control effect. Both see the biggest jump between 20 and 200. A limit of 10000 has no benefit over 1000, all that happens is we increase end-to-end latency.\\r\\n\\r\\nThe quorum queue achieves much higher throughput than the mirrored queue and also has lower 95th percentile latencies. Quorum queue 99.9th percentile latencies reach the mirrored queue latencies where all percentiles cluster around the same value.\\r\\n\\r\\nIn our case, because the brokers and the load generator are all in the same availability zone, network latency is very low. In higher network latency scenarios, we would continue to see large benefits of higher in-flight limits.\\r\\n\\r\\nLastly, remember that if our message rate were 1000 msg/s, then all in-flight limits would look the same. So if you are nowhere close to the queue throughput limit, then these settings won\'t necessarily come into play.\\r\\n\\r\\n## Benchmark #2 - 1000 in-flight limit, increasing prefetch, ack interval 1\\r\\n\\r\\nThis test is a little different to the others. The others are a single run where we dynamically change the behaviour of the load generator. In this test we use a separate run per setting. We have to do this because you’ll see that a prefetch of 1 makes the consume rate so slow, that the queue fills up fast and negatively affects the later phases of the test. So we run each prefetch setting as a completely isolated run.\\r\\n\\r\\n**Mirrored queue**\\r\\n\\r\\n![Fig 3. Mirrored queue with increasing consumer prefetch.](1-pub-queue-con-mirrored-increasing-prefetch.png)\\r\\n\\r\\n**Quorum queue**\\r\\n\\r\\n![Fig 4. Quorum queue with increasing consumer prefetch.](1-pub-queue-con-qq-increasing-prefetch.png)\\r\\n\\r\\nA prefetch of 1, combined with a fast publisher did not go well for either queue type, but quorum queues did especially badly. Quorum queues saw very low consumer throughput with a prefetch 1 and 10, but we also saw the publish rate drop as time went by and the queue filled. \\r\\n\\r\\nIn fact in these first two tests (prefetch 1 and 10), the quorum queue reached around 4 million messages. We know that quorum queues do slow down a bit once they get into the millions of messages.\\r\\n\\r\\nFrom a prefetch of 100 and onwards we start hitting the top throughput as the RabbitMQ consumer channel is not having to block so often (waiting for acks to come in). Setting a high prefetch does not affect end-to-end latency as we see below (for prefetch of 100, 1000, 10000). \\r\\n\\r\\n![Fig 5. End-to-end latency for both queue types with 100, 1000 and 10000 prefetch.](1-pub-queue-con-qq-mirrored-increasing-prefetch-lat.png)\\r\\n\\r\\nThe reason that prefetch doesn’t necessarily increase latency but the in-flight limit can, is that with the in-flight limit we are rate limiting ingress, avoiding buffering in the broker, whereas the prefetch only affects messages already in flight. Whether the messages are buffered in the broker or in the client doesn’t affect latency, especially in a single consumer test. In a multiple consumer test it is conceivable that there could still be an effect.\\r\\n\\r\\n### Some Nuance Around End-to-end Latency\\r\\n\\r\\nOf course the above is predicated on end-to-end latency being from the moment a publisher sends a message to the moment the message is received by a consumer. In your system, end-to-end latency will likely start at an earlier point. So rate limiting the publisher can reduce latency from the point of view of RabbitMQ, but not necessarily your wider system. When it would definitely affect your wider system\'s end-to-end latency is if RabbitMQ got overloaded and materially slowed down.\\r\\n\\r\\n## Benchmark #3 - 1000 in-flight limit, 1000 prefetch, increasing ack interval\\r\\n\\r\\nWe’re back to the dynamic update of settings again, as we’ll see that while the ack interval does affect throughput, it does not affect it as much as prefetch (not even close!). Using an ack interval of 1 is ok, you will still get good throughput, so if that is what you already do and don’t want the complexity of multiple flag usage, then carry on.\\r\\n\\r\\nBut we’ll see next that if you want every last bit of performance, multiple flag usage helps.\\r\\n\\r\\n**Mirrored queue**\\r\\n\\r\\n![Fig 6. Mirrored queue with increasing ack interval](1-pub-queue-con-mirrored-increasing-ack-interval.png)\\r\\n\\r\\n**Quorum queue**\\r\\n\\r\\n![Fig 7. Quorum queue with increasing ack interval](1-pub-queue-con-qq-increasing-ack-interval.png)\\r\\n\\r\\nBoth queue types see the biggest jump in throughput when switching from an ack interval of 1 to 10. After that the peak is around 50-100. That is 5% and 10% respectively of the prefetch. As a general rule of thumb, this tends to be the sweet spot for the ack interval. \\r\\n\\r\\nMirrored queues tend to see a reduction in throughput once you get past the 25-30% of prefetch mark and rapidly drops off past 50%. Quorum queues remained flat in this test, right up to 50%. \\r\\n\\r\\n## Benchmarks #4 - No confirms and acks\\r\\n\\r\\nIn these tests we\'ll not use publisher confirms and the consumer will use auto ack mode (this means that the broker will treat a message as delivered as soon as it transmits it).\\r\\n\\r\\n**Mirrored queue**\\r\\n\\r\\n![Fig 8. Mirrored queue without publisher confirms or consumer acks](1-pub-mirrored-queue-con-no-confirms-acks.png)\\r\\n\\r\\n**Quorum queue**\\r\\n\\r\\n![Fig 9. Quorum queue without publisher confirms or consumer acks](1-pub-qq-con-no-confirms-acks.png)\\r\\n\\r\\nIf we compare those results to using confirms and acks, we see no benefit in throughput. In fact all we see is an increase in end-to-end latency. For mirrored we go from 95th percentile at ~60ms to ~1s. Likewise for quorum queues we go from 95th percentile ~50ms to ~400ms.\\r\\n\\r\\nSo not only do we not see an increase in throughput but we see a worse latency. Of course this is a single queue, things only get worse as we add more queues and load, as we’ll see in the next post. \\r\\n\\r\\nWith a non-replicated classic queue, you will definitely see a difference between confirms/acks vs none. This is because without replication, RabbitMQ doesn’t have to do much work, so the overhead of confirms and acks is noticeable. This isn’t the case when replication is involved, the overhead of confirms/acks is small in comparison.\\r\\n\\r\\n## Final Conclusions\\r\\n\\r\\nAt this point, with a single queue, the conclusions are simple and limited - that is, they apply to a single queue for sure, and will likely apply to multiple queues but not necessarily a stressed system. That is why we have a follow-up post covering exactly the same settings, but with a system under stress.\\r\\n\\r\\nLow broker stress, single queue, high throughput conclusions:\\r\\n\\r\\n1. Low publisher in-flight limits equate to lower throughput as publishers exert their own flow control. Higher in-flight limits equate to higher throughput, but at some point you stop getting gains. Where that point is, is totally dependent on your system and can change as conditions in your system change.\\r\\n1. Low prefetch can be terrible for a high throughput queue with a single consumer. But in a low throughput queue or where there are many many consumers, it will not be so much of a problem (as we’ll see in the next post where we have 100s of consumers).\\r\\n1. An ack interval of 1 is ok, don’t sweat it. But increasing it a little can be beneficial. Up to around 10% of prefetch is a good rule of thumb but as always, it is dependent on your system and local conditions.\\r\\n1. Confirms and acks are necessary for data safety and not using them with a replicated queue doesn’t gain you any performance, quite the opposite, it increased latency. That said, in this single queue test, the loss of the extra flow control exerted by confirms and acks was not a major problem.\\r\\n1. Finally - a single quorum queue outperforms a single mirrored queue significantly.\\r\\n\\r\\nAll these tests were about sending/consuming messages as fast as possible, pushing a single queue to its limit. What we learned is informative but you likely are not in that situation and so you will probably find the next post more useful. In that post we will look at low load and high load scenarios, with different numbers of queues and clients, but seeing the effects of these same three settings on both quorum and mirrored queues. For the stress tests, flow control will become more important, it will help the stressed system to degrade gracefully rather than catch on fire. Expect a larger impact of not using confirms and acks."},{"id":"/2020/05/04/quorum-queues-and-flow-control-the-concepts","metadata":{"permalink":"/rabbitmq-website/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-05-04-quorum-queues-and-flow-control-the-concepts/index.md","source":"@site/blog/2020-05-04-quorum-queues-and-flow-control-the-concepts/index.md","title":"Quorum Queues and Flow Control - The Concepts","description":"As part of our quorum queue series we’re taking a look at flow control, how it protects RabbitMQ from being overloaded and how that relates to quorum queues.","date":"2020-05-04T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":7.835,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Quorum Queues and Flow Control - The Concepts","tags":["Performance"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Quorum Queues and Flow Control - Single Queue Benchmarks","permalink":"/rabbitmq-website/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks"},"nextItem":{"title":"Quorum queues and why disks matter","permalink":"/rabbitmq-website/blog/2020/04/21/quorum-queues-and-why-disks-matter"}},"content":"As part of our quorum queue series we’re taking a look at flow control, how it protects RabbitMQ from being overloaded and how that relates to quorum queues.\\r\\n\\r\\n## What is Flow Control?\\r\\n\\r\\nFlow control is a concept that has been in computer networking and networked software for decades. Essentially it is a mechanism for applying back pressure to senders to avoid overloading receivers. Receivers typically buffer incoming packets/messages as a way of dealing with a send rate that exceeds its processing rate. But receiver buffers cannot grow forever so either the send rate should only transiently exceed receiver processing capacity (bursty traffic) or the sender must be slowed down (back pressure).\\r\\n\\r\\nFlow control is a way of applying this back pressure on the sender, slowing them down so that the receiver’s buffers do not overflow and latencies do not grow too large. In a chain of sender/receivers, this back pressure can propagate up the chain to the origin of the traffic. In more complex graphs of connected components, flow control can balance incoming traffic between fast and slow senders, avoiding overload but allowing the system to reach full utilisation despite different numbers of senders, different rates and different load patterns (steady or bursty).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Flow Control in RabbitMQ\\r\\n\\r\\nRabbitMQ looks much like a network. Each RabbitMQ broker internally is implemented with the actor pattern where different components communicate with each other via message passing, sometimes locally, sometimes over the network. There are also the publishers that send messages to the brokers and the consumers that receive messages from the brokers, both over the network.\\r\\n\\r\\n![Fig 1. A simplified depiction of message flows](network-of-actors.png)\\r\\n\\r\\nAt any point in this chain, bottlenecks can occur causing congestion. Congestion results in buffers and ports filling, data on disk growing and hardware resources running low. If left uncontrolled RabbitMQ could use up all available memory resulting in either a crash or being killed by the OS.\\r\\n\\r\\nTaking the system as a whole (broker and clients) we have four flow control mechanisms available to us:\\r\\n\\r\\n* Credit based flow control\\r\\n* Memory alarms\\r\\n* Publisher confirms\\r\\n* Consumer acknowledgements and prefetch\\r\\n\\r\\n## Credit Based Flow Control\\r\\n\\r\\n[Credit based flow contro](/docs/flow-control)l is a method of rate limiting message ingress. It allows various actors within the system to protect themselves and apply back pressure when they cannot process messages fast enough. It is targeted at only those connections, channels and queues that are having issues, leaving other parts of the system unaffected.\\r\\n\\r\\nThe way it works is that each actor in the system that handles messages uses “credit” as a way of applying back pressure up the chain. If a channel wants to send a message to a queue, it needs credit. The queue grants the channel some initial credit, and then after that, each message that the channel sends to the queue requires a credit. The queue will periodically grant the channel more credit, when it in turn has been able to pass messages onto the persistence layer. If the channel doesn’t have credit, it is blocked from sending messages to the queue until the queue grants it more. This way a channel cannot run roughshod over a queue.\\r\\n\\r\\n![Fig 2. Credit based flow control with classic queues](credit-flow.png)\\r\\n\\r\\nSo we have a chain of credit flow controls that apply back pressure all the way back to the publisher. Ultimately, TCP back pressure will be applied to the publisher because the TCP reader process is not reading from the socket as it is blocked.\\r\\n\\r\\nWhen a connection, channel or queue runs out of credits they are blocked until more credits are granted, this state is known as “flow”. In the management UI you might see that a connection,  channel or queue are in the *flow* state which indicates that flow occurs very recently. This just means that they have temporarily run out of credits and are waiting for the next link in the chain to catch up and grant some credits. This can trigger multiple times a second.\\r\\n\\r\\n![Fig 3. Credit exhaustion.](credit-flow-enter-flow.png)\\r\\n\\r\\n![Fig 4. Credit grants.](credit-flow-exit-flow.png)\\r\\n\\r\\nWhen a queue or connection reaches its throughput limit or a downstream bottleneck, the flow state can kick in many times a second, at various points in the chain, as various actor’s credit amounts reach 0 and then get replenished. \\r\\n\\r\\nBut it doesn’t necessarily stop the broker from running out of memory. Incoming messages are not always the only primary cause of high memory usage, it can also be from large queues and a number of other causes.\\r\\n\\r\\n## Memory Alarms\\r\\n\\r\\nIf the credit based flow control was unable to put the brakes on enough, or memory usage has grown to critical levels for another reason, memory alarms kick in as a last resort to protect the broker from crashing (or being killed by the OS) due to running out of memory.\\r\\n\\r\\nWhen [memory alarms](/docs/memory) kick in, all publishers are blocked. It’s like you turn off the tap on incoming messages across the cluster. Not the targeted rate limiting of credit based flow control, but a sledgehammer. \\r\\n\\r\\nConsumers can continue to consume though, and the hope at this point is that draining the queues somewhat will start bringing down the memory footprint.\\r\\n\\r\\nIn the management UI you will see connections as blocked or blocking when memory alarms are in force.\\r\\n\\r\\n## Publisher Confirms\\r\\n\\r\\nThe primary job of [publisher confirms](/docs/confirms) is data safety but they also play an important role in flow control. \\r\\n\\r\\nThere are three ways of employing publisher confirms:\\r\\n\\r\\n* *Send one at a time*, waiting for each confirm before sending the next (very slow).\\r\\n* *Window based*. Send messages until reaching a window size (time or number of messages) and wait for all confirms before sending the next window.\\r\\n* *Pipelining*. Allow a publisher to continuously send messages but block when the unconfirmed message count (the messages in-flight) reaches a limit. When confirms come in, more messages can be sent until reaching the limit again. \\r\\n\\r\\nThe pipelining (or simply the *asynchronous*) approach provides the highest and most stable throughput. It can be used as an additional protection against broker overload, as the publisher itself places itself in “flow” before even placing pressure on the broker.\\r\\n\\r\\nWhen you don’t use publisher confirms you rely solely on TCP flow control for the link between the publisher and the connection reader process on the broker. With a relatively small number of publishers, TCP flow control can be enough to avoid overloading the broker, but when you have a large number of clients, TCP is not enough and publisher confirms become necessary for cluster stability while under heavy load. Interestingly AMQP 1.0 added link flow control to overcome this problem.\\r\\n\\r\\n## Consumer Acknowledgements and Prefetch\\r\\n\\r\\nUsing manual acknowledgements with a prefetch puts back pressure on RabbitMQ to stop it from overwhelming your consumer clients. It uses the pipelining method to send a constant stream of messages but bounding the number of unacknowledged messages to the size of the prefetch (QoS). With AutoAck mode, we again rely only on TCP back pressure. The various ingress buffers of your clients can fill up fast. \\r\\n\\r\\nIt is highly recommended to use manual acks and a prefetch.\\r\\n\\r\\n## Quorum queues\\r\\n\\r\\nThe credit based flow control chain is different with quorum queues as they have a completely different persistence and replication protocol. Channels send all messages to a Raft cluster leader that in turn passes the message to the WAL and replicates the message to its followers. The Raft consensus algorithm that quorum queues use for replication does not include credit based flow control so this mechanism ends at the channel. \\r\\n\\r\\nRather than using credit as a mechanism for blocking itself when the Raft leader cannot keep up, the channel keeps track of the number of pending Raft commands that the leader has not yet applied. If that number exceeds the *quorum commands soft limit *configuration, then the channel ceases to grant more credits to the reader process.\\r\\n\\r\\n![Fig 5. Credit based flow control in quorum queues.](credit-flow-quorum-queue.png)\\r\\n\\r\\nThe other controls such as memory alarms, publisher confirms and consumer acknowledgements/prefetch are the same for quorum queues as classic queues. \\r\\n\\r\\n## Improvements to quorum queues in the upcoming 3.8.4 release\\r\\n\\r\\nWe identified flow control as one of the weaker areas of quorum queues compared to mirrored queues. We found that quorum queues did not apply back pressure as effectively as mirrored queues while under heavy load from 100s or 1000s of clients. Quorum queues had some new bottlenecks that occurred under these scenarios that could cause memory to grow, relying on memory alarms rather than credit based flow control.\\r\\n\\r\\nWe set about improving that for the next release and have greatly improved this aspect of quorum queues, we’ll write more about those changes when 3.8.4 comes out.\\r\\n\\r\\n## In the next part… using publisher confirms to improve throughput under load\\r\\n\\r\\nSo you know a bit more about RabbitMQ, flow control and quorum queues. You know that publisher confirms can be important for both data safety but also for flow control between publishers and brokers. But how do we implement pipelining? How big an in-flight limit should we use? What effect will different limits have on throughput and latency?\\r\\n\\r\\nAll these question will be answered in the next part of this series. We\'ll run a number of benchmarks against both mirrored and quorum queues and get some answers."},{"id":"/2020/04/21/quorum-queues-and-why-disks-matter","metadata":{"permalink":"/rabbitmq-website/blog/2020/04/21/quorum-queues-and-why-disks-matter","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-04-21-quorum-queues-and-why-disks-matter/index.md","source":"@site/blog/2020-04-21-quorum-queues-and-why-disks-matter/index.md","title":"Quorum queues and why disks matter","description":"Quorum queues are still relatively new to RabbitMQ and many people have still not made the jump from classic mirrored queues. Before you migrate to this new queue type you need to make sure that your hardware can support your workload and a big factor in that is what storage drives you use.","date":"2020-04-21T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":13,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"Quorum queues and why disks matter","tags":["Performance"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Quorum Queues and Flow Control - The Concepts","permalink":"/rabbitmq-website/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts"},"nextItem":{"title":"RabbitMQ Gets an HA Upgrade","permalink":"/rabbitmq-website/blog/2020/04/20/rabbitmq-gets-an-ha-upgrade"}},"content":"Quorum queues are still relatively new to RabbitMQ and many people have still not made the jump from classic mirrored queues. Before you migrate to this new queue type you need to make sure that your hardware can support your workload and a big factor in that is what storage drives you use.\\r\\n\\r\\nIn this blog post we’re going to take a closer look at quorum queues and their performance characteristics on different storage configurations.\\r\\n\\r\\n## HDD or SSD? One drive or multiple drives?\\r\\n\\r\\nThe TL;DR is that we highly recommend SSDs when using quorum queues. The reason for this is that quorum queues are sensitive to IO latency and SSDs deliver lower latency IO than HDDs. With higher IO latency, you\'ll see lower throughput, higher end-to-end latency and some other undesirable effects.\\r\\n\\r\\nFurther down in this post we’ll demonstrate why we recommend this, using various benchmarks with different SSD and HDD configurations.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Why are quorum queues sensitive to IO latency?\\r\\n\\r\\nLet\'s look at the write path on a single broker to see why this is the case. Let\'s remember that both publishing and consuming count as writes. Publishing involves *enqueue* operations and consuming involves *ack* operations, and both must be persisted and replicated. Note that if you use a quorum or mirrored queues without publisher confirms or consumer acknowledgements you need to ask yourself why you are using a replicated queue.\\r\\n\\r\\nOperations first get written to memory and to a Write Ahead Log (WAL). There is a single WAL per broker, which serves all quorum queues on that broker. From there, operations are then written to per-queue segment files by the Segment Writer.\\r\\n\\r\\n![Fig 1. WAL and segment files](wal-and-segments.png)\\r\\n\\r\\n> There is an optimisation however that means enqueue operations (messages) may never need to be written to segment files. Newly arrived messages are kept in memory and messages can be delivered to and acked by consumers before having been written to a segment file. In this case, those messages are not written to disk as they essentially no longer exist as far as the broker is concerned.\\r\\n\\r\\nThis means that for queues where consumers are keeping up, often messages do not get written to segment files at all. By the time an in memory message is ready to be flushed to a segment file, a consumer has acked the message.\\r\\nIf IO latency is high, then the WAL ends up being a bottleneck. Each broker has a single WAL and a single segment writer process, and these act as shared infrastructure that the quorum queue Raft clusters sit on top of. The fsyncing of operations to the active WAL  file is like the beating heart of the Raft clusters. If fsyncs are slow, the throughput across the Raft clusters is slow.\\r\\n\\r\\nFsyncing of the segment files can also become a bottleneck. The WAL consists of one or more files; one file being actively written to and zero or more inactive files that were rolled due to reaching the max WAL file size limit. These inactive WAL files can only be safely removed once all their messages have been written to segment files and/or acknowledged (see optimisation above). If the writing of segment files is slow, then the WAL gets larger and larger as messages cannot be written to segment files fast enough.\\r\\n\\r\\nHDDs are great at large sequential writes but not so great at small or random IO. If your writes have to access multiple files, jumping about the filesystem, then HDDs produce much higher IO latency than SSDs. The great thing about WAL and segment files is that they are append-only files. So HDDs have the potential to deliver decent performance, but only where there is not a lot of random IO contention. As soon as WAL and segment file IO has to contend with other disk IO, performance starts to drop.\\r\\n\\r\\n## Ok, but what does performance with HDDs look like?\\r\\n\\r\\nNow we’re going to run some performance benchmarks with both SSDs and HDDs and analyse the results.\\r\\n\\r\\nThere are four main actors that use disk:\\r\\n\\r\\n* Mnesia and the message store (data)\\r\\n* Logs (logs)\\r\\n* Quorum queue segment files (segment)\\r\\n* Quorum queue WAL (wal)\\r\\n\\r\\nEach of these workloads has different IO patterns and we can try to isolate these disk workloads to improve performance.\\r\\n\\r\\nWe have six clusters that share certain aspects such as number of CPUs but use different types and number of disks.\\r\\n\\r\\nShared:\\r\\n\\r\\n* 3 node clusters\\r\\n* Instance type: c4.4xlarge:\\r\\n  * 16 vCPUs\\r\\n  * 15GB RAM\\r\\n  * 2Gbps EBS instance throughput (the VM has a disk IO throughput ceiling of 2Gbps/250MBs)\\r\\n  * 5Gbps network (625MB/s)\\r\\n\\r\\nAll disks are either 200GB SSDs (io1) or 1TB HDDs (st1). Each has a larger throughput capacity than the c4.4xlarge EC2 instance can use.\\r\\n\\r\\nUnique:\\r\\n\\r\\n* Store all data in a single drive\\r\\n  * Cluster rabbitmq1, SSD1=data/logs/segment/wal\\r\\n  * Cluster rabbitmq10, HDD1=data/logs/segment/wal\\r\\n* Store the WAL on a separate drive, but segment files on same drive as classic queue data\\r\\n  * Cluster rabbitmq4, SSD1=data/logs/segment SSD2=wal\\r\\n  * Cluster rabbitmq13, HDD1=data/logs/segment HDD2=wal\\r\\n* Assign classic queue data, segment files and WAL files their own dedicated drive each\\r\\n  * Cluster rabbitmq7, SSD1=data/logs SSD2=segment SSD3=wal\\r\\n  * Cluster rabbitmq16, HDD1=data/logs HDD2=segment HDD3=wal\\r\\n\\r\\n## Pure Quorum Queue Workload\\r\\n\\r\\nFirst we\'ll test workloads that only consist of quorum queues.\\r\\n\\r\\n### Throughput Benchmark #1 - One Quorum Queue\\r\\n\\r\\nOne publisher, one queue, one consumer, 1kb messages, no rate limit.\\r\\n\\r\\n![Fig 1. Pure quorum queue workload - 1 queue](pure-qq-b1.png)\\r\\n\\r\\nWe see that the SSD clusters rabbitmq1, rabbitmq4 and rabbitmq7 all are reaching around 19k msg/s. The HDD clusters have lower throughput, with rabbitmq13 (2 disks) and rabbitmq16 (3 disks) are only slightly behind at around 17k msg/s. The single HDD cluster clearly lags at around 13k msg/s.\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nFor a single queue workload, separating the WAL from the segment file workload onto separate disks has given us close to SSD performance. \\r\\n\\r\\n### Throughput Benchmark #2 - Four Quorum Queues\\r\\n\\r\\n4 publishers, 4 queues, 4 consumers, 1kb messages, no rate limit.\\r\\n\\r\\n![Fig 2. Pure quorum queue workload - 4 queues](pure-qq-b2.png)\\r\\n\\r\\nWith 4 quorum queues, we see a different story. HDDs outperform their SSD counterparts by ~2k msg/s. We have to remember that when consumers can keep up, operations are usually only written to the WAL files. The WAL is shared between the four queues so we are pushing more bytes through it. WAL files are written to sequentially and our st1 HDD can manage 500MB/s throughput (though the VM itself is restricted to 250MB/s).\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nIn a world of only sequential writes, HDDs can potentially produce similar or even better results to an SSD. A quorum queue only workload, with consumers keeping up should see the vast majority of writes only going to a single append-only WAL file.\\r\\n\\r\\n### Latency Benchmark #1 - 40 Quorum Queues\\r\\n\\r\\n40 publishers, 40 queues, 40 consumers, 1kb messages, 10 msg/s per publisher (400 msg/s total).\\r\\n\\r\\n#### SSDs\\r\\n\\r\\n![Fig 3. Pure quorum queue workload - Latency Test 1 - SSD](pure-qq-b3-ssd.png)\\r\\n\\r\\n#### HDDs\\r\\n\\r\\n![Fig 4. Pure quorum queue workload - Latency Test 1 - HDD](pure-qq-b3-hdd.png)\\r\\n\\r\\nWith a total rate of just 400 1kb messages a second, we see SSDs and HDDs with comparable end-to-end latencies.\\r\\n\\r\\n### Latency Benchmark #2 - 40 Quorum Queues\\r\\n\\r\\n40 publishers, 40 queues, 40 consumers, 1kb messages, 50 msg/s per publisher (2000 msg/s total).\\r\\n\\r\\n![Fig 5. Pure quorum queue workload - Latency Test 2 - SSD](pure-qq-b4-ssd.png)\\r\\n\\r\\n#### HDDs\\r\\n\\r\\n![Fig 6. Pure quorum queue workload - Latency Test 2 - HDD](pure-qq-b4-hdd.png)\\r\\n\\r\\nThis time we see HDDs with significantly higher latencies:\\r\\n\\r\\n* 75th percentile ~4ms vs ~15ms\\r\\n* 99.9th percentile ~20ms vs ~110ms\\r\\n\\r\\nWe also see that the two disk and three disk HDD configurations have lower latency than the single HDD. There is not much difference between the two and three disk configurations as we have no mnesia or message store data competing with quorum segment data.\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nWith higher throughput, we see SSDs producing much lower latencies than HDD.\\r\\n\\r\\n## Light Mixed Workload (Classic Lazy and Quorum)\\r\\n\\r\\nSo far we’ve seen quorum queues tested in isolation, without any classic or mirrored queue load. In this test we’ll see how quorum queues behave in a mixed workload of quorum queues and unreplicated lazy queues. Lazy queues are more disk intensive than normal classic queues and should produce more disk contention.\\r\\n\\r\\n### Throughput Benchmark #1 - One Quorum Queue\\r\\n\\r\\nOne publisher, one queue, one consumer, 1kb messages, no rate limit.\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 10 msg/s per publisher (400 msg/s).\\r\\n\\r\\n![Fig 7. Light mixed workload - 1 quorum queue](mixed-light-qq-b1.png)\\r\\n\\r\\nWe see that with this background lazy queue load, the SSD cluster sees no impact in throughput, sitting at 20k msg/s again. However the single HDD cluster has been seriously impacted, down to just 6k msg/s down from 13k msg/s. The write heavy WAL workload now must compete with the message store which will involve much disk seeking.\\r\\n\\r\\nThe two and three disk HDD clusters do better with just a slight drop in throughput, this is because most writes go to the WAL which has a dedicated disk and still achieves sequential writes.\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nA low non-quorum queue message throughput will impact HDDs more, but the impact can be mitigated by separating workloads onto separate disks.\\r\\n\\r\\n### Throughput Benchmark #2 - Four Quorum Queues\\r\\n\\r\\n4 publishers, 4 queues, 4 consumers, 1kb messages, no rate limit.\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 10 msg/s per publisher (400 msg/s).\\r\\n\\r\\n![Fig 8. Light mixed workload - 4 quorum queues](mixed-light-qq-b2.png)\\r\\n\\r\\nAgain we see the same drop in throughput for HDDs, with the single disk suffering the most.\\r\\n\\r\\n### Latency Benchmark #1 - 40 Quorum Queues\\r\\n\\r\\n40 publishers, 40 queues, 40 consumers, 1kb messages, 10 msg/s per publisher (400 msg/s total).\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 10 msg/s per publisher (400 msg/s).\\r\\n\\r\\n#### SSDs\\r\\n\\r\\n![Fig 9. Light mixed workload - Latency Test 1 - SSD](mixed-light-qq-b3-ssd.png)\\r\\n\\r\\n#### HDDs\\r\\n\\r\\n![Fig 10. Light mixed workload - Latency Test 1 - HDD](mixed-light-qq-b3-hdd.png)\\r\\n\\r\\nLast time, with no mixed workload, we saw SSDs and HDDs with comparable end-to-end latencies. This time however, the single HDD cluster has a major increase in end-to-end latency with 75th at 50ms and 99.9th up to 300ms. The two and three disk configurations fared better with comparable 75th percentile latencies but we saw one peak up to 25ms at 99.9th percentile.\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nWith a light mixed workload, the single HDD configuration fares badly, but the configurations with a separate disk for the WAL did almost as good as the SSDs.\\r\\n\\r\\n### Latency Benchmark #2 - 40 Quorum Queues\\r\\n\\r\\n40 publishers, 40 queues, 40 consumers, 1kb messages, 50 msg/s per publisher (2000 msg/s total).\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 10 msg/s per publisher (400 msg/s).\\r\\n\\r\\n#### SSDs\\r\\n\\r\\n![Fig 11. Light mixed workload - Latency Test 2 - SSD](mixed-light-qq-b4-ssd.png)\\r\\n\\r\\n#### HDDs\\r\\n\\r\\n![Fig 12. Light mixed workload - Latency Test 2 - HDD](mixed-light-qq-b4-hdd.png)\\r\\n\\r\\nAgain we see the single HDD perform the worst, but this time the two and thee disk HDD cluster fare worse, hovering around the 20-60ms mark, compared to the SSDs which hover around 5-15ms.\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nWith a light mixed workload, but higher quorum queue load we see HDDs clearly at a disadvantage to SSDs.\\r\\n\\r\\n## Medium Mixed Workload (Classic Lazy and Quorum)\\r\\n\\r\\nThis time we’ll increase the lazy queue traffic five fold from 400 msg/s to 2000 msg/s and see how our SSD and HDD clusters fare.\\r\\n\\r\\n### Throughput Benchmark #1 - One Quorum Queue\\r\\n\\r\\nOne publisher, one queue, one consumer, 1kb messages, no rate limit.\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 50 msg/s per publisher (2000 msg/s).\\r\\n\\r\\n![Fig 13. Medium mixed workload - 1 quorum queue](mixed-medium-qq-b1.png)\\r\\n\\r\\nThis time HDD throughput has been driven very low. We can see the two and thee disk configurations help, but not by much:\\r\\n\\r\\n* 1 disk: ~300 msg/s\\r\\n* 2 disks: ~1700 msg/s\\r\\n* 3 disks: ~2300 msg/s\\r\\n\\r\\nBut look at the SSDs, they achieve the same throughput as ever.\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nOnce the mixed workload reaches a certain point, quorum queue throughput on HDD drops very low, no matter if you isolate the disk workloads. Obviously there is another factor in play here as the three disk configuration which has isolated segment and WAL file load from classic queues is not enough.\\r\\n\\r\\n### Throughput Benchmark #2 - Four Quorum Queues\\r\\n\\r\\n4 publishers, 4 queues, 4 consumers, 1kb messages, no rate limit.\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 50 msg/s per publisher (2000 msg/s).\\r\\n\\r\\n![Fig 14. Medium mixed workload - 4 quorum queues](mixed-medium-qq-b2.png)\\r\\n\\r\\nThis time the single HDD barely managed a single message. The two and three disk configurations managed around 2300 msg/s.\\r\\n\\r\\nThis time note that the single SSD cluster saw an impact from the lazy queue traffic. The two and three SSD clusters saw almost no impact, demonstrating that quorum queues can benefit from disk workload isolation even on SSDs.\\r\\n\\r\\n### Latency Benchmark #1 - 40 Quorum Queues\\r\\n\\r\\n40 publishers, 40 queues, 40 consumers, 1kb messages, 10 msg/s per publisher (400 msg/s total).\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 50 msg/s per publisher (2000 msg/s).\\r\\n\\r\\n#### SSDs\\r\\n\\r\\n![Fig 15. Medium mixed workload - Latency Test 1 - SSD](mixed-medium-qq-b3-ssd.png)\\r\\n\\r\\n#### HDDs\\r\\n\\r\\n![Fig 16. Medium mixed workload - Latency Test 1 - HDD](mixed-medium-qq-b3-hdd.png)\\r\\n\\r\\nThe single HDD basically was non functional, and the two and three disk configurations saw large latencies with the two disk one reaching above 1 second, despite the low message rate.\\r\\n\\r\\n#### Conclusion\\r\\n\\r\\nHDD cluster end-to-end latency continues to worsen as both quorum queue and non-quorum queue load increases. SSDs remain largely unchanged.\\r\\n\\r\\n### Latency Benchmark #2 - 40 Quorum Queues\\r\\n\\r\\n40 publishers, 40 queues, 40 consumers, 1kb messages, 50 msg/s per publisher (2000 msg/s total).\\r\\n\\r\\nLazy queue workload: 40 publishers, 40 queues, 40 consumers, 16b messages, 50 msg/s per publisher (2000 msg/s).\\r\\n\\r\\n#### SSDs\\r\\n\\r\\n![Fig 17. Medium mixed workload - Latency Test 2 - SSD](mixed-medium-qq-b4-ssd.png)\\r\\n\\r\\n#### HDDs\\r\\n\\r\\n![Fig 18. Medium mixed workload - Latency Test 2 - HDD](mixed-medium-qq-b4-hdd.png)\\r\\n\\r\\nAgain, the single HDD cluster didn’t manage to handle any messages. The three disk configuration, which completely isolates quorum queue load from the lazy queue disk load saw the best latency, but still a much higher latency than the SSDs.\\r\\n\\r\\n## Final Conclusions\\r\\n\\r\\nQuorum queues on SSDs show they are not overly sensitive to mixed workloads but can benefit from a multi-SSD drive configuration under higher loads.\\r\\n\\r\\nWe have also seen that quorum queues do not handle **mixed** workloads very well when running on HDDs. It is possible to mitigate those issues by isolating the segment and WAL files on separate HDDs from the mnesia (meta-data) and message store (classic queue data) workloads, but at a certain classic queue traffic level, the throughput will drop a lot. What that level of load is totally depends on your particular setup.\\r\\n\\r\\nWhen might quorum queues be safe on HDDs? While not recommended you may still get good performance with low queue count pure quorum queue workloads or with mixed workloads which are low volume. But we have seen that quorum queue performance can drop precipitously on HDDs so you are taking a risk. We highly recommend SSDs and discourage the use of HDDs when employing quorum queues.\\r\\n\\r\\nIn the next post of this series we\'ll look at migrating from classic mirrored queues to quorum queues, using a few example workloads to demonstrate what you might expect."},{"id":"/2020/04/20/rabbitmq-gets-an-ha-upgrade","metadata":{"permalink":"/rabbitmq-website/blog/2020/04/20/rabbitmq-gets-an-ha-upgrade","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-04-20-rabbitmq-gets-an-ha-upgrade/index.md","source":"@site/blog/2020-04-20-rabbitmq-gets-an-ha-upgrade/index.md","title":"RabbitMQ Gets an HA Upgrade","description":"This is the first part of a series on quorum queues, our new replicated queue type. We\'ll be covering everything from what quorum queues are, to hardware requirements, migration from mirrored queues and best practices.","date":"2020-04-20T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":8.51,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"RabbitMQ Gets an HA Upgrade","tags":["New Features"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"Quorum queues and why disks matter","permalink":"/rabbitmq-website/blog/2020/04/21/quorum-queues-and-why-disks-matter"},"nextItem":{"title":"This Month in RabbitMQ: March 2020 Recap","permalink":"/rabbitmq-website/blog/2020/04/13/this-month-in-rabbitmq-march-2020-recap"}},"content":"This is the first part of a series on quorum queues, our new replicated queue type. We\'ll be covering everything from what quorum queues are, to hardware requirements, migration from mirrored queues and best practices.\\r\\n\\r\\n## Introducing Quorum Queues\\r\\n\\r\\nMirrored queues, also known as HA queues have been the de facto option for years when requiring extra data safety guarantees for your messages. Quorum queues are the next generation of replicated queue that aim to replace most use cases for mirrored queues and are available from the 3.8 release and onward.\\r\\n\\r\\nIn this blog series we’re going to cover the following:\\r\\n\\r\\n* Part 1 - Understand the need for a new replicated queue type and how it works (this post)\\r\\n* [Part 2 - Why your choice of storage drive matters with quorum queues](/blog/2020/04/21/quorum-queues-and-why-disks-matter)\\r\\n* [Part 3 - Quorum queues and flow control. Concepts.](/blog/2020/05/04/quorum-queues-and-flow-control-the-concepts)\\r\\n* [Part 4 - Quorum queues and flow control. Single Queue Benchmarks.](/blog/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks)\\r\\n* [Part 5 - Quorum queues and flow control. Stress Tests.](/blog/2020/05/15/quorum-queues-and-flow-control-stress-tests)\\r\\n* Part 6 - Quorum queues and cluster/VM Sizing (coming soon)\\r\\n* Part 7 - When and how to migrate from mirrored to quorum queues (coming soon)\\r\\n* Part 8 - Best practices and gotchas (coming soon)\\r\\n* Part 9 - Monitoring and admin operations (coming soon)\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Why Offer a New Type of Replicated Queue?\\r\\n\\r\\nMirrored queues are based on a replication algorithm called Chained Replication. In the context of queues, chained replication forms a ring of queues where there is one leader (the master) and one or more secondaries (mirrors). All messages are published to and consumed from the leader, the leader then replicates those operations to its adjacent mirror which in turn replicates to its adjacent mirror. This continues until reaching the last mirror who then notifies the master that the operation if fully replicated.\\r\\n\\r\\n![Fig 1. Chain replication](ChainReplication3Nodes.png)\\r\\n\\r\\nDue to some edge cases that produced message loss, this algorithm was modified so that the channel process would additionally send the message directly to each mirror. This unfortunately means that the broker receiving messages from a publisher has to send out each message twice, which doubles the network load.\\r\\n\\r\\n![Fig 2. channel sends each message twice to master and mirrors](ChainReplication3NodesDoubleSend.png)\\r\\n\\r\\nThere are also some pain points regarding this replication algorithm which centre on how it handles mirrors that leave the ring either because of a server restart, a node failure or a network partition.\\r\\n\\r\\nWhen a mirror has been out of communication with its peers beyond a certain time limit, it is removed from the ring and the queue continues to be available. The problems occur upon the mirror rejoining the ring again. First the mirror discards all its data and then, optionally, a process called synchronisation begins. \\r\\n\\r\\nSynchronisation is where the master replicates its current messages to a mirror. This is a *stop the world* process where the queue becomes frozen until synchronisation is complete. This becomes a problem if the queue is very big as the period of unavailability can be long.\\r\\n\\r\\n![Fig 3. Stop the world synchronisation](ChainReplication5NodesRejoin.png)\\r\\n\\r\\nAnother option is to not synchronise a rejoining mirror with the master. In this case we end up with lower redundancy but avoid potentially painful synchronisation. Of course, if the queue is empty or has few messages then synchronisation doesn’t pose a big problem.\\r\\n\\r\\nAnother important topic is how it handles network partitions. When a partition occurs that splits a cluster into two halves, we’ll end up with one or more mirrors that lose communications with the master. As an administrator we can choose availability or consistency at this point. The *cluster_partition_handling* configuration determines how RabbitMQ handles the partition.\\r\\n\\r\\nIf we don’t want to lose messages, then we’ll configure the cluster to use *pause-minority* mode. This basically stops all brokers on the minority side of a partition. On the majority side (if there is one) the queue continues to operate, just with reduced redundancy. Once the partition is resolved, the cluster returns to normality. This strategy chooses consistency (albeit with less redundancy) over availability.\\r\\n\\r\\n![Fig 4. Pause minority mode causes unavailability for clients connected to minority side.](PauseMinority.png)\\r\\n\\r\\nIf we want continued availability on both sides of the partition then we can choose *ignore* or *auto-heal* mode. This will allow a mirror to be promoted to master, meaning we have a master on both sides. This allows the queue to continue to receive and deliver messages no matter which side of the partition a client is connected to. Unfortunately, on resolving the partition one side of the partition is chosen as the victim and restarted, *losing* any messages in the queue on that side. This is not an ideal option, but in some scenarios it can still better suit your needs than becoming unavailable.\\r\\n\\r\\n![Fig 5. Auto-heal provides continued availability at the cost of potential data loss.](NonPauseMinority.png)\\r\\n\\r\\nWe needed a better replication algorithm and that is how quorum queues were born.\\r\\n\\r\\n## Quorum Queues\\r\\n\\r\\n[Quorum queues](/docs/quorum-queues) do not use chained replication but are based on the well established and mathematically proven **Raft** protocol. Raft is a consensus algorithm for replicating a log of operations across a cluster of nodes. It requires a quorum (a majority) of participating nodes to be available and to agree on each new operation appended to the distributed log. This is where quorum queues get their name. \\r\\n\\r\\nWhat operations does a queue have? We have *enqueue* operations and *consumer acknowledgemen*t operations. Just like with mirrored queues, all clients interact with a leader, whose job it is to then replicate the enqueues and acks to its followers.\\r\\n\\r\\n![Fig 6. A quorum queue with one leader and two followers](QQ.png)\\r\\n\\r\\nThe algorithm is more efficient and can achieve higher throughput than mirrored queues. It does have higher end-to-end latencies and those latencies closely correspond to the throughput/latency of your disks. Quorum queues only confirm messages once written to disk on a majority and so disk performance plays a large role in quorum queue performance.\\r\\n\\r\\n### No Difficult Decisions\\r\\n\\r\\nThere is no *stop the world* synchronisation, no throwing away data on rejoining, no difficult decisions to make about automatic vs manual synchronisation at all. There is no availability vs consistency choice to make; a quorum queue will only confirm a message once it has been replicated to a majority of nodes. If a majority is down then you lose availability.\\r\\n\\r\\n### Network Partitions\\r\\n\\r\\nWhen it comes to network partitions quorum queues are much simpler. Firstly they use a separate and much faster failure detector that can detect partitions rapidly and trigger fast leader elections meaning that availability is either not impacted or is quickly restored. The *cluster_partition_handling* configuration does not apply to quorum queues though the *pause_minority* mode can still affect a quorum queue as when a minority side is paused, any quorum queue leaders hosted on that node will become unavailable. However due to the speed of the failure detector, in the event of a partition, a leader election should have selected a new leader well before this pause is triggered.\\r\\n\\r\\nQuorum queues are for those scenarios where data safety trumps all. Just remember though that data safety starts with applications doing the right thing, using publisher confirms and consumer acks correctly. Quorum queues do have some limitations and gotchas and we’ll be taking a look at those later in the series.\\r\\n\\r\\n## x-queue-type: classic and quorum\\r\\n\\r\\nNow that we have a new type of queue, we refer to a queue as either a *classic* or a *quorum* queue. A classic queue is the same old queue as before. Declaring a classic queue with the ha-mode, ha-params, ha-sync-mode properties will make it a classic mirrored queue, as will defining a policy with those arguments that matches the queue.\\r\\n\\r\\nYou cannot turn a classic queue into a quorum queue via policies though. The x-queue-type property set to *quorum* must be included in the queue declaration. It is a quorum queue from birth.\\r\\n\\r\\n## Quorum Queues in the Management UI\\r\\n\\r\\nIn the screenshot below, firstly you’ll notice the *x-queue-type: quorum* argument and the *x-quorum-initial-group-size: 3* argument that tells that this queue is a quorum queue with a replication factor of 3 (one leader and two followers).\\r\\n\\r\\n![](QQinManagementUI.png)\\r\\n\\r\\nFig 7. A quorum queue as seen in the management UIWe also can see the members of the queue, which members are online and who the current leader is.\\r\\n\\r\\nDeclaring a quorum queue is as simple as declaring any other queue, simply using the *x-queue-type* argument. By default the quorum size (replicator factor) is 5, though with a smaller cluster, the size will be the size of the cluster itself.\\r\\n\\r\\nFrom the management UI you will see the option to add either a classic or quorum queue.\\r\\n\\r\\n![Fig 8. Quorum queue appears in the new queue type drop-down](ChooseQuorumQueue.png)\\r\\n\\r\\nYou will see the available arguments change when you select Quorum.\\r\\n\\r\\n![Fig 9. Quorum queue arguments](QuorumQueueArguments.png)\\r\\n\\r\\nThere are three new arguments available for quorum queues. Two are related to how many messages are kept in memory. By default all messages are maintained in memory and so if a quorum queue grows in length it can put memory pressure on a cluster. We can limit how much memory is used by messages by setting one or both of the following arguments:\\r\\n\\r\\n* x-max-in-memory-length \\r\\n* x-max-in-memory-bytes\\r\\n\\r\\nThe queue index is still stored in memory however, so a queue that continues to grow in size can still place memory pressure on a cluster. We’ll look more closely at this later in the series.\\r\\n\\r\\nThe new poison message feature is only available for quorum queues and is set using the *x-delivery-limit* argument. Each time a message is redelivered to a consumer, a counter is incremented. Once the redelivery count exceeds the x-delivery-limit, the message gets dropped or dead-lettered (if a DLX exchange has been configured).\\r\\n\\r\\n## Takeaways\\r\\n\\r\\nQuorum queues offer bullet proof safety guarantees and less headaches when it comes to restarting servers. They also place different stresses on your hardware than mirrored queues so before you make the jump, check out our next posts which contain guidance about migrations and required hardware.\\r\\n\\r\\nIn the [next post](/blog/2020/04/21/quorum-queues-and-why-disks-matter) we’ll cover why we recommend SSDs over HDDs and the different performance characteristics we get with each storage drive type."},{"id":"/2020/04/13/this-month-in-rabbitmq-march-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/04/13/this-month-in-rabbitmq-march-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-04-13-this-month-in-rabbitmq-march-2020-recap/index.md","source":"@site/blog/2020-04-13-this-month-in-rabbitmq-march-2020-recap/index.md","title":"This Month in RabbitMQ: March 2020 Recap","description":"Due to the uncertainties of the COVID-19 virus, the RabbitMQ Summit team is canceling the Berlin Summit in June 2020.","date":"2020-04-13T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":3.25,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ: March 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Gets an HA Upgrade","permalink":"/rabbitmq-website/blog/2020/04/20/rabbitmq-gets-an-ha-upgrade"},"nextItem":{"title":"This Month in RabbitMQ, February 2020 Recap","permalink":"/rabbitmq-website/blog/2020/03/10/this-month-in-rabbitmq-february-2020-recap"}},"content":"Due to the uncertainties of the COVID-19 virus, the RabbitMQ Summit team is canceling the Berlin Summit in June 2020.\\r\\nWe do still hope that we can proceed with the plans for a summit in November in New York. Check back for updates.\\r\\n\\r\\nAmong other contributions this month, we have resources on using RabbitMQ successfully in a microservices architecture,\\r\\nwhy you should use messaging in your project with Rabbit and SpringBoot, and many other tips and tricks.\\r\\nSo dive in, the water’s fine! And please stay safe, everyone.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* The 3.7.x series are now covered under the extended support policy (security patches and high severity bug fixes only).\\r\\n3.7.x users are recommended to [upgrade](/docs/upgrade) to 3.8.x releases. [RabbitMQ 3.7.25 has shipped](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.25) to wrap up 3.7.x’s general support timeline.\\r\\n* RabbitMQ .NET client version 5.2.0 and version 6.0.0 are [almost ready for release](https://groups.google.com/d/topic/rabbitmq-users/RA3EkGHJkuA/discussion).\\r\\nPlease test the latest release candidates, there are substantial efficiently improvements in the 6.0 release thanks to our awesome contributors.\\r\\n* Erlang/OTP 22.3 has shipped. Debian and RPM packages produced by the RabbitMQ team are available from [PackageCloud](https://packagecloud.io/rabbitmq/erlang) and [Bintray](https://bintray.com/rabbitmq-erlang)\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* 1 Mar: Renato Groffe wrote about [cloud messaging with RabbitMQ, .NET Core, and Azure Functions](https://medium.com/@renato.groffe/mensageria-na-nuvem-com-rabbitmq-net-core-e-azure-functions-7c2a4f890448) (in Portuguese)\\r\\n* 1 Mar: Rodolfo dos Santos Pinto creates a tutorial showing how to [post and consume messages to a Rabbit queue with 2 .Net Core applications](https://medium.com/@rodolfostopinto97/poc-net-core-rabbitmq-f1fb5d8eb58b) (in Portuguese)\\r\\n* 5 Mar: Alex de Sousa on the benefits and challenges of [Yggdrasil and RabbitMQ Subscriptions](https://dev.to/alexdesousa/yggdrasil-and-rabbitmq-subscriptions-18k4)\\r\\n* 9 Mar: Mcdavid Emereuwa (@mcdavid_95) tells us how to set up an [email service with RabbitMQ, AWS SES and PM2 on NodeJS](https://blog.learningdollars.com/2020/03/09/how-to-set-up-an-email-service-with-rabbitmq-aws-ses-and-pm2-on-nodejs/)\\r\\n* 11 Mar: [Understanding queues with RabbitMQ](https://medium.com/@alfredobautista1/comprendiendo-las-colas-con-rabbitmq-i-6367d749fd6a), Part 1, by Alfredo Bautista Santos (in Spanish)\\r\\n* 11 Mar: [Electing a new president using Node.js, Redis and RabbitMQ](https://medium.com/@dannyhobo/electing-a-new-president-using-node-js-redis-and-rabbitmq-fa58af874d68) (application performance tips) by Danny Hobo (@dannyhobo)\\r\\n* 11 Mar: Simone Pezzano shared thoughts on [using RabbitMQ for microservices architecture](https://www.erlang-solutions.com/blog/using-rabbitmq-for-microservice-architecture-success-guest-blog-by-api-fortress-api.html) successfully\\r\\n* 12 Mar: [Understanding queues with RabbitMQ, Part 2](https://medium.com/@alfredobautista1/comprendiendo-las-colas-con-rabbitmq-ii-866c0ce3a953), by Alfredo Bautista Santos (in Spanish)\\r\\n* 14 Mar: Feyyaz Acet (@feyyazcet) writes about [using .Net Core 3.1 with RabbitMQ and MassTransit](https://medium.com/@feyyazacet/net-core-3-1-ile-masstransit-rabbitmq-de9102114bd6), a lightweight message bus for .Net (in Turkish)\\r\\n* 14 Mar: Part 3: [RabbitMQ Queue with Docker in .NET](https://stefanescueduard.github.io/2020/03/14/rabbitmq-queue-with-docker-in-dotnet/) by Eduard Stefanescu (@EdStefanescu)\\r\\n* 17 Mar: [ElixrMix: Data pipelines through Broadway](https://devchat.tv/elixir-mix/emx-090-data-pipelines-through-broadway-with-alex-koutmos/) with developer Alex Koutmos, expands on his recent blogs also featuring RabbitMQ\\r\\n* 20 Mar: In this tutorial, Rida Shaikh shows how to implement a [Spring Boot + RabbitMQ example to retry messages on exception](https://dzone.com/articles/spring-boot-rabbitmq-tutorial-retry-and-error-hand)\\r\\n* 21 Mar: Ed Stefanescu writes about the Consumer node of the [RabbitMQ topology with Docker in .NET](https://stefanescueduard.github.io/2020/03/21/rabbitmq-consumer-with-docker-in-dotnet/)\\r\\n* 22 Mar: How to [install, run and monitor RabbitMQ in 5 minutes](https://medium.com/@gabrielhidalgoruiz/how-to-install-run-monitoring-rabbitmq-in-5-minutes-3e0325086fe0) by Gabriel Hidalgo Ruiz\\r\\n* 24 Mar: Diego Alexandro de Oliveira explains why you should [use messaging in your project with RabbitMQ and Spring Boot](https://medium.com/totvsdevelopers/spring-boot-rabbitmq-porque-considerar-o-uso-de-mensageria-no-seu-projeto-3aed6637c4b4) (in Portuguese)\\r\\n* 25 Mar: Magomed Aliev discusses [rate limiting with Celery and RabbitMQ](https://medium.com/analytics-vidhya/celery-throttling-setting-rate-limit-for-queues-5b5bf16c73ce)\\r\\n* 25 Mar: Hardik Sondagar with a short tutorial on [how to publish a message with priority in RabbitMQ](https://dev.to/hardiksondagar/how-to-publish-message-with-priority-in-rabbitmq-1jd6)\\r\\n* 27 Mar: Eric Satterwhite (@codedependant): How to send [data change events directly to RabbitMQ with PostgreSQL and Node.js](http://codedependant.net/2020/03/27/heard-of-rabbits-1-postgres-change-data-capture-and-rabbitmq/)\\r\\n* 27 Mar: Gerhard Lazu (@gerhardlazu): [TGIR S01E03: How to contribute to RabbitMQ? Part 1](https://www.youtube.com/watch?v=EWU7WCqD_YA)\\r\\n* 28 Mar: @aleks_kurakin writes about [Spring Boot: messaging, RabbitMQ](https://java-ru-blog.blogspot.com/2020/03/spring-boot-amqp-send-receive-message.html?spref=tw)], sending and receiving messages (in Russian)\\r\\n* 28 Mar: Eduard Stefanescu: [RabbitMQ Headers Exchange with Docker in .NET](https://stefanescueduard.github.io/2020/03/28/rabbitmq-headers-exchange-with-docker-in-dotnet/)\\r\\n* 31 Mar: Narongsak Keawmanee’s 2nd installment of his [blog series on NodeJS and RabbitMQ](https://medium.com/@klogic/simple-application-with-nodejs-and-rabbitmq-b3138dad93e3)\\r\\n\\r\\n## Ready to learn more?\\r\\n\\r\\n* On-demand, online at LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online at Udemy: [RabbitMQ: Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online, $40 buys you early access to Marco Behler’s course, [Building a Real-World Java and RabbitMQ Messaging Application](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)\\r\\n* Online, Pluralsight course: [RabbitMQ by Example](https://www.pluralsight.com/courses/rabbitmq-by-example) gets good reviews"},{"id":"/2020/03/10/this-month-in-rabbitmq-february-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/03/10/this-month-in-rabbitmq-february-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-03-10-this-month-in-rabbitmq-february-2020-recap/index.md","source":"@site/blog/2020-03-10-this-month-in-rabbitmq-february-2020-recap/index.md","title":"This Month in RabbitMQ, February 2020 Recap","description":"This Month in RabbitMQ — February 2020 Recap!","date":"2020-03-10T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":4.745,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, February 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ: March 2020 Recap","permalink":"/rabbitmq-website/blog/2020/04/13/this-month-in-rabbitmq-march-2020-recap"},"nextItem":{"title":"This Month in RabbitMQ, January 2020 Recap","permalink":"/rabbitmq-website/blog/2020/02/12/this-month-in-rabbitmq-january-2020-recap"}},"content":"This Month in RabbitMQ — February 2020 Recap!\\r\\n\\r\\n[RabbitMQ Summit](https://rabbitmqsummit.com/) is coming again! This time, the gathering will be in Berlin on June 9 and the [call for proposals](https://eventil.com/events/rabbitmq-summit-2020/cfp) (to speak at the event)\\r\\nis open until March 22.\\r\\n\\r\\nMark your calendars, brush up on your Deutsch, and buy your tickets for the next chance to immerse yourself in all things RabbitMQ.\\r\\nI’m sure there will be at least a couple of [RabbitMQ influencers](https://content.pivotal.io/blog/top-rabbitmq-influencers-of-2019) there, too :)\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [RabbitMQ 3.8.3 is out](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.3)\\r\\n* [As well as RabbitMQ 3.7.24](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.24)\\r\\n* New preview releases are available for the RabbitMQ .NET client: [6.0.0-pre10](https://www.nuget.org/packages/RabbitMQ.Client/6.0.0-pre10) and [5.2.0-pre2](https://www.nuget.org/packages/RabbitMQ.Client/5.2.0-pre2).\\r\\nThe former has substantial memory allocation reduction contributed by [Stefán Jökull Sigurðarson](https://github.com/stebet). Please test these versions in your pre-production environments. Release candidates should be available soon.\\r\\n* [Hop 3.6.1](https://groups.google.com/d/msg/rabbitmq-users/djLbfmjg5KA/AtgAHaUqCAAJ) is released with a bug fix.\\r\\n* [PerfTest 2.11.0](https://groups.google.com/d/msg/rabbitmq-users/MAO0L0HBqgk/eZoZDbg6AQAJ) is released with new features, usability improvements, dependency upgrades, and a bug fix.\\r\\n* [JMS Client 2.0.0](https://groups.google.com/d/msg/rabbitmq-users/uHNG7-AqlDk/MNskRMCMBwAJ) is released. It is now the new production line.\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* 1-2 Feb: Gabriele Santomaggio (@GSantomaggio) gave a talk on [Debugging and Tracing a Production RabbitMQ node](https://fosdem.org/2020/schedule/event/beam_debugging_tracing_rabbitmq_node/)\\r\\n* 2 Feb: Lovisa Johansson (@lillajja) wrote a post [comparing RabbitMQ and Apache Kafka](https://www.cloudkarafka.com/blog/2020-02-02-which-service-rabbitmq-vs-apache-kafka.html)\\r\\n* 2 Feb: Renjith P wrote a [guide to Nest JS RabbitMQ microservices](https://medium.com/swlh/guide-to-nest-js-rabbitmq-microservices-e1e8655d2853)\\r\\n* 6 Feb: Eran Stiller (@eranstiller) published the first part in his [comparison series of RabbitMQ and Kafka](https://stiller.blog/2020/02/rabbitmq-vs-kafka-an-architects-dilemma-part-1/)\\r\\n* 8 Feb: Oscar Oranagwa (@Oskarr3) wrote about [using the RabbitMQ Source Connector](https://medium.com/@Oskarr3/an-exercise-with-kafka-connectors-589bef785d81) to move messages between RabbitMQ and Kafka as part of a migration from a monolith to microservices\\r\\n* 10 Feb: Zach Ruffin (@faintdeception) published about [stream processing using .NET Core and RabbitMQ](https://zachruffin.com/blog/stream-processing-using-net-core-and-rabbitmq)\\r\\n* 10 Feb: Andrea Mandolo wrote about [clustering RabbitMQ on ECS using EC2 autoscaling groups](https://medium.com/thron-tech/clustering-rabbitmq-on-ecs-using-ec2-autoscaling-groups-107426a87b98)\\r\\n* 11 Feb: Sushant Chaudhary published about asynchronous feature extraction for [an artificial intelligence use case using RabbitMQ](https://medium.com/attentive-ai/asynchronous-feature-extraction-part-1-86a47cfcf762)\\r\\n* 12 Feb: Davide Guida (@DavideGuida82) wrote about [implementing a producer/consumer with System.Threading.Channels](https://www.davideguida.com/how-to-implement-producer-consumer-with-system-threading-channels/)\\r\\n* 13 Feb: Annie Blomgren wrote about [using Prometheus and Grafana with CloudAMQP](https://www.cloudamqp.com/blog/2020-02-13-Prometheus-and-Grafana.html), highlighting the new support in RabbitMQ 3.8\\r\\n* 13 Feb: Tomas Kirda (@tkirda) wrote about [messaging with RabbitMQ in Node.js](https://www.devbridge.com/articles/messaging-with-rabbitmq-in-node-js/)\\r\\n* 13 Feb:Mike Møller Nielsen (@MikeMoelNielsen) published [a video about setting up RabbitMQ dead lettering](https://youtu.be/ovE8NKAwqTI)\\r\\n* 14: Mike Møller Nielsen (@MikeMoelNielsen) published [a video about RabbitMQ dead lettering in Java](https://youtu.be/L8OGw7bK3eU)\\r\\n* 14: Davide Guida (@DavideGuida82) wrote a part 4 in his series about [consuming message queues using .NET Core background workers](https://www.davideguida.com/consuming-message-queues-using-net-core-background-workers-part-4-adding-system-threading-channels/)\\r\\n* 14: Todd Sharp (@recursivecodes) published a video about [building a desktop glucose monitor with Node RED, RabbitMQ, Autonomous DB and the M5Stack](https://youtu.be/I9IMOpZ4YYo)\\r\\n* 15: Naveed Khan (@naveed_125) wrote about [background processing with RabbitMQ, Python, and Flask](https://medium.com/better-programming/background-processing-with-rabbitmq-python-and-flask-5ca62acf409c)\\r\\n* 15: Ömer Özkan wrote about [different RabbitMQ retry topologies](https://medium.com/@ozkan.omer5/rabbitmq-retries-topologies-2e3341d89ca9)\\r\\n* 16: Eran Stiller (@eranstiller) published the second part in his [comparison series of RabbitMQ and Kafka](https://medium.com/better-programming/rabbitmq-vs-kafka-1779b5b70c41)\\r\\n* 16: Saurabh Singh wrote about [how to create a RabbitMQ cluster in Docker/AWS Linux](https://medium.com/@saurabh.singh0829/how-to-create-rabbitmq-cluster-in-docker-aws-linux-4b26a31f90bc)\\r\\n* 17: Artem Matveev published the first in a nine-part series on RabbitMQ, first focused on an [introduction to Erlang and AMQP 0-9-1](https://habr.com/ru/post/488654/) (in Russian)\\r\\n* 17: Saurabh Singh shared sample code for [using RabbitMQ with .NET Core and ReactJS](https://medium.com/@saurabh.singh0829/async-queue-implementation-using-rabbitmq-net-core-reactjs-12d98f9745dc)\\r\\n* 18: Steven Nunez (@_StevenNunez) was a guest on the Elixir Mix podcast, talking about [how FlatIron School uses RabbitMQ with Elixir](https://devchat.tv/elixir-mix/emx-088-adopting-elixir-and-rabbitmq-with-steven-nunez/)\\r\\n* 18: Gleb Zhukov published the first in a three part series on [using RabbitMQ with MonsterMQ](https://habr.com/ru/post/488850/), staring with an intro to RabbitMQ (in Russian)\\r\\n* 18: Sage Pierce wrote about how [Expedia is now open sourcing Rhapsody](https://medium.com/expedia-group-tech/rhapsody-is-now-open-source-cfb4a2aec906), based on the Reactive Streams specification, and features integration with RabbitMQ\\r\\n* 19: Artem Matveev published the [second in a nine-part series on RabbitMQ](https://habr.com/ru/post/489086/), on understanding exchanges (in Russian)\\r\\n* 20: Mohamad Fadhil (@sdil) wrote an [introduction to message queues with RabbitMQ and Python](https://medium.com/better-programming/introduction-to-message-queue-with-rabbitmq-python-639e397cb668)\\r\\n* 20: Lajos Gerecs published about [what you need to know about Quorum Queues](https://www.erlang-solutions.com/blog/rabbitmq-quorum-queues-explained-what-you-need-to-know.html), the new way to run highly available queues in RabbitMQ 3.8\\r\\n* 21: Robert Barnes (@devops_rob) presented about [securing RabbitMQ with Vault](https://www.hashicorp.com/resources/securing-rabbitmq-with-vault), published by HashiCorp\\r\\n* 24: JM Santos wrote about how he handles [long processes using NestJS and RabbitMQ](https://medium.com/@jmaicaaan/how-i-handle-long-processes-using-nest-js-and-rabbitmq-47ae67803c75)\\r\\n* 26: Gleb Zhukov published the second in a three part series on [using RabbitMQ with MonsterMQ](https://habr.com/ru/post/489022/), getting into setting up queues (in Russian)\\r\\n* 27: Gerhard Lazu (@gerhardlazu) published [another installment of TGIR, “Help! RabbitMQ ate my RAM!”](https://youtu.be/dkAhsp-Oxf4)\\r\\n* 27: Alex Kruchkov (@kruchkov_alex) wrote about [how AppsFlyer uses Apache AirFlow with RabbitMQ](https://medium.com/appsflyer/how-appsflyer-uses-apache-airflow-to-run-over-3-5k-daily-jobs-and-more-683106cb24fc)\\r\\n* 28: Gleb Zhukov published the third in a three part series on [using RabbitMQ with MonsterMQ](https://habr.com/ru/post/489692/), getting into exchanges (in Russian)\\r\\n* 29: Eduard Stefanescu (@EdStefanescu) published about [RabbitMQ producers with Docker in .NET](https://stefanescueduard.github.io/2020/02/29/rabbitmq-producer-with-docker-in-dotnet/)\\r\\n* 29: Saurabh Singh wrote about [using SignalR and RabbitMQ with .NET Core ReactJS](https://medium.com/@saurabh.singh0829/create-signalr-rabbitmq-with-net-core-reactjs-f6980b52c51c)\\r\\n* 29: Lovisa Johansson (@lillajja) published a case study about [how FarmBot uses RabbtitMQ hosted by CloudAMQP](https://www.cloudamqp.com/blog/2020-02-29-user-story-how-rabbitmq-transformed-agri-tech-app-farmbot.html)\\r\\n\\r\\n## Learn More\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\n* 5-6 Mar, San Francisco: [Code BEAM SF](https://codesync.global/conferences/code-beam-sf/) which features these talks on RabbitMQ:\\r\\n* A Novel Application Of Rabbitmq For The Reliable Automated Deployment Of Software Updates with Brett Cameron (@brc859844) and Natalya Arbit\\r\\n* How RabbitMQ simplifies routing in a microservices architecture with Jianbo Li and Yijian Yang\\r\\n* 9 Jun, Berlin: [RabbitMQ Summit](https://rabbitmqsummit.com/)\\r\\n* On-demand, online at LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online at Udemy: [RabbitMQ: Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online, $40 buys you early access to Marco Behler’s course, [Building a Real-World Java and RabbitMQ Messaging Application](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)\\r\\n* Online, Pluralsight course: [RabbitMQ by Example](https://www.pluralsight.com/courses/rabbitmq-by-example) gets good reviews\\r\\n* Online: Luxoft is offering a [RabbitMQ course in Russian](https://www.luxoft-training.ru/kurs/platforma_obmena_soobshcheniyami_rabbitmq.html)"},{"id":"/2020/02/12/this-month-in-rabbitmq-january-2020-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/02/12/this-month-in-rabbitmq-january-2020-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-02-12-this-month-in-rabbitmq-january-2020-recap/index.md","source":"@site/blog/2020-02-12-this-month-in-rabbitmq-january-2020-recap/index.md","title":"This Month in RabbitMQ, January 2020 Recap","description":"This Month in RabbitMQ, January 2020 Recap","date":"2020-02-12T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":4.32,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, January 2020 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, February 2020 Recap","permalink":"/rabbitmq-website/blog/2020/03/10/this-month-in-rabbitmq-february-2020-recap"},"nextItem":{"title":"This Month in RabbitMQ, December 2019 Recap","permalink":"/rabbitmq-website/blog/2020/01/09/this-month-in-rabbitmq-december-2019-recap"}},"content":"This Month in RabbitMQ, January 2020 Recap\\r\\n\\r\\nIntroducing TGI RabbitMQ! Inspired by TGI Kubernetes, RabbitMQ engineer, Gerhard Lazu has begun a\\r\\nseries of tutorial videos. Tune in at the end of each month for the latest release. In January,\\r\\nGerhard covered [upgrading from 3.7 to 3.8](https://youtu.be/DynCqFtnSoY).\\r\\nStar and watch the [repository](https://youtu.be/DynCqFtnSoY) for future episode updates.\\r\\n\\r\\nAlso, be sure to check out the [dashboards we’ve published to Grafana](https://grafana.com/orgs/rabbitmq). These are a great way to get started with the new [Prometheus and Grafana support in 3.8](/docs/prometheus).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n* First public beta version of [Pivotal RabbitMQ for Kubernetes](https://network.pivotal.io/products/p-rabbitmq-for-kubernetes).\\r\\n* [Spring AMQP 2.2.3](https://github.com/spring-projects/spring-amqp/releases)\\r\\n* [Hop 3.6.0](https://groups.google.com/d/msg/rabbitmq-users/MEwbDJ8biRc/s4xLPpvYAwAJ) is released with new features and dependency upgrades. The HTTP client for the classic blocking client is now pluggable, making it possible to use OkHttp instead of Apache HTTPComponents.\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* 1 Jan: Hyun Sun Ryu (@hsunryou) wrote about [installing RabbitMQ 3.8 on CentOS 8.0](https://blog.naver.com/hsunryou/221756168969)\\r\\n* 1 Jan: (@Cakazies1) published about [messaging in Golang with RabbitMQ](https://medium.com/@cakazies/messaging-golang-with-rabbitmq-2ed1ccf8314)\\r\\n* 4 Jan: Ben Lovy published a [beginners description](https://dev.to/deciduously/correct-a-beginner-about-buzzword-technologies-4bbe) of several “buzzword-y” technologies, including RabbitMQ, looking for feedback and corrections\\r\\n* 8 Jan: Sunny Beatteay (@SunnyPaxos) published a really interesting article about [how DigitalOcean re-architected a system](https://blog.digitalocean.com/from-15-000-database-connections-to-under-100-digitaloceans-tale-of-tech-debt/) that had grown to 15,000 database connections because they were using MySQL as an event queue, to using RabbitMQ\\r\\n* 8 Jan: Robin Moffatt (@rmoff) wrote about [Streaming messages from RabbitMQ into Kafka](https://rmoff.net/2020/01/08/streaming-messages-from-rabbitmq-into-kafka-with-kafka-connect/) with Kafka Connect\\r\\n* 9 Jan: Dormain Drewitz (@DormainDrewitz) published a list of the [top 10 RabbitMQ Influencers](https://content.pivotal.io/blog/top-rabbitmq-influencers-of-2019) of 2019\\r\\n* 9 Jan: Szymon Mentel (@szymonmentel) published a [5 minute video overview of RabbitMQ](https://youtu.be/ViJNPnZPJn4) along with a [post with notes and links](https://szkolarabbita.pl/rabbitmq-klaster-w-5-minut/) to try it yourself (in Polish)\\r\\n* 9 Jan: Oriol Canalias (@iandarigun) published the first part of an [introduction to RabbitMQ (in Portuguese)](https://medium.com/dev-cave/rabbit-mq-parte-i-c15e5f89d94)\\r\\n* 10 Jan: Gabriele Santomaggio (@GSantomaggio) added Helm support for [his RabbitMQ Operator for Kubernetes](https://github.com/Gsantomaggio/rabbitmq-operator#install-the-rabbitmq-operator-with-helm3)\\r\\n* 12 Jan: Pawel Duda (@pawel_duda) wrote about [why queues can be empty after a restart](https://devmeetsbiz.business.blog/2020/01/12/rabbitmq-queue-empty-after-a-restart-why-even-though-its-durable/) and what to do about it\\r\\n* 13 Jan: Marcin Lewandowski (@marcin_elem84) wrote about [confirming messages in RabbitMQ](https://czterytygodnie.pl/potwierdzanie-wiadomosci-rabbitmq/) (in Polish)\\r\\n* 13 Jan: Davide Guida (@DavideGuida82) wrote about using the [Outbox pattern with RabbitMQ](https://www.davideguida.com/improving-microservices-reliability-part-2-outbox-pattern/) to improve microservices reliability\\r\\n* 15 Jan: Mike Møller Nielsen (@MikeMoelNielsen) published a\\r\\n\\r\\n[video on using a RabbitMQ PerfTest]\\r\\n\\r\\n(https://youtu.be/MEdPLX-PCn8 ) (performance testing tool)\\r\\n* 15 Jan: Oriol Canalias (@iandarigun) published the second part of [an introduction to RabbitMQ in Portuguese](https://medium.com/dev-cave/rabbitmq-parte-ii-fa61a469ba2)\\r\\n* 16 Jan: Renzo Tejada Chung (@TejadaRenzo) published about [using Docker Compose with RabbitMQ](https://renzotejada.com/blog/docker-compose-para-rabbitmq/) (in Spanish)\\r\\n* 17 Jan: Linux Conference Australia 2020 published a talk by Rafael Martinez Guerrero (@rafaelma_) on what goes on behind the scenes of an ELK system, including the role of RabbitMQ ([video](https://youtu.be/4X0bmnb4tVI), [slides](https://e-mc2.net/behind-scenes-elk-system))\\r\\n* 17 Jan: Lovisa Johansson (@lillajja) wrote up the [Annual RabbitMQ Report 2020](https://www.cloudamqp.com/blog/2020-01-17-annual-rabbitmq-report-2020-by-cloudamqp.html) from CloudAMQP\\r\\n* 17 Jan: Samuel Owino (@SamProgramiz) published an [introduction to AMQP 0.9.1](https://medium.com/@samuelowino43/advanced-message-queueing-protocol-ampq-0-9-1-617209d2d6ec), which is one of the protocols supported in RabbitMQ\\r\\n* 18 Jan: Deependra Kushwah wrote up [installing RabbitMQ on Windows](https://beetechnical.com/windows/rabbitmq-installation-on-windows/)\\r\\n* 25 Jan: Narongsak Keawmanee published an introduction to [using RabbitMQ with Node.js](https://medium.com/@klogic/introduction-to-rabbitmq-with-nodejs-3f1ab928ed50)\\r\\n* 27 Jan: Todd Sharp (@recursivecodes) published about [getting started with RabbitMQ in Oracle Cloud](https://blogs.oracle.com/developers/getting-started-with-rabbitmq-in-the-oracle-cloud)\\r\\n* 27 Jan: Todd Sharp (@recursivecodes) also published a video about how to install and [run RabbitMQ in Oracle Cloud](https://youtu.be/9kVBZ5MQV6I)\\r\\n* 27 Jan: Abhishek Yadav wrote an explainer about [RabbitMQ as a Service Bus in the context of ASP.NET Core](https://www.c-sharpcorner.com/article/rabbitmq-service-bus/)\\r\\n* 28 Jan: Richard Seroter (@rseroter) wrote about trying out the new [replicated, durable quorum queues in RabbitMQ 3.8](https://seroter.wordpress.com/2020/01/28/lets-try-out-the-new-durable-replicated-quorum-queues-in-rabbitmq/)\\r\\n* 28 Jan: Nur Erkartal published about [using the Outbox pattern with RabbitMQ at Trendyol](https://medium.com/trendyol-tech/outbox-pattern-story-at-trendyol-fcb35fe056d7)\\r\\n* 29 Jan: Lovisa Johansson (@lillajja) wrote about [message priority in RabbitMQ](https://www.cloudamqp.com/blog/2020-01-29-message-priority-in-rabbitmq.html)\\r\\n* 30 Jan: Nicholas Barrett (@T00MEKE) published about [setting up a RabbitMQ cluster in Kubernetes](https://nick.barrett.org.nz/setting-up-rabbitmq-ha-in-kubernetes-with-external-https-and-amqps-access-1ce1f3632dd2) with external HTTPS and AMQPS access\\r\\n* 30 Jan: Lovisa Johansson (@lillajja) wrote about [RabbitMQ and Erlang upgrades](https://www.cloudamqp.com/blog/2020-01-30-rabbitmq-erlang-upgrades.html)\\r\\n* 31 Jan: Georgy @georgysay wrote about [using RabbitMQ with .NET Core](https://habr.com/ru/post/486416/) (in Russian)\\r\\n* 31 Jan: Gerhard Lazu (@gerhardlazu) published the first episode of TGI RabbitMQ on [how to upgrade from RabbitMQ 3.7 to 3.8](https://youtu.be/DynCqFtnSoY)\\r\\n\\r\\n## Ready to learn more?\\r\\n\\r\\n* 13 Feb, online: Free webinar on How to [Build Reliable Streaming Pipelines with RabbitMQ and Project Reactor](https://content.pivotal.io/rabbitmq/feb-13-how-to-build-reliable-streaming-pipelines-with-rabbitmq-and-project-reactor-webinar?utm_campaign=reactor-streaming-webinar-blog&amp;utm_source=rabbitmq&amp;utm_medium=website)\\r\\n* 20 Feb, online: Hashitalks 2020 features a talk on [Securing RabbitMQ with Vault](https://events.hashicorp.com/hashitalks2020) by Robert Barnes (@devops_rob)\\r\\n* 28 Feb, online: TGIR S01E02: Help! RabbitMQ ate my RAM!\\r\\n* 5-6 Mar, San Francisco: [Code BEAM SF](https://codesync.global/conferences/code-beam-sf/) which features these talks on RabbitMQ:\\r\\n* A Novel Application Of Rabbitmq For The Reliable Automated Deployment Of Software Updates with Brett Cameron (@brc859844) and Natalya Arbit\\r\\n* How RabbitMQ simplifies routing in a microservices architecture with Jianbo Li and Yijian Yang\\r\\n* On-demand, online at LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online at Udemy: [RabbitMQ: Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online, $40 buys you early access to Marco Behler’s course, [Building a Real-World Java and RabbitMQ Messaging Application](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)\\r\\n* Online, Pluralsight course: [RabbitMQ by Example](https://www.pluralsight.com/courses/rabbitmq-by-example) gets good reviews\\r\\n* Online: Luxoft is offering a [RabbitMQ course in Russian](https://www.luxoft-training.ru/kurs/platforma_obmena_soobshcheniyami_rabbitmq.html)\\r\\n* Various: South Africa: [Jumping Bean offers RabbitMQ training](https://www.jumpingbean.co.za/rabbitmq)"},{"id":"/2020/01/09/this-month-in-rabbitmq-december-2019-recap","metadata":{"permalink":"/rabbitmq-website/blog/2020/01/09/this-month-in-rabbitmq-december-2019-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2020-01-09-this-month-in-rabbitmq-december-2019-recap/index.md","source":"@site/blog/2020-01-09-this-month-in-rabbitmq-december-2019-recap/index.md","title":"This Month in RabbitMQ, December 2019 Recap","description":"This Month in RabbitMQ — December Recap!","date":"2020-01-09T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":4.695,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, December 2019 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, January 2020 Recap","permalink":"/rabbitmq-website/blog/2020/02/12/this-month-in-rabbitmq-january-2020-recap"},"nextItem":{"title":"LAIKA Gets Creative with RabbitMQ As the Animation Company\'s IT Nervous System","permalink":"/rabbitmq-website/blog/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system"}},"content":"This Month in RabbitMQ — December Recap!\\r\\n\\r\\nHappy new year! 3.8.x has been available for over three months now and we’re seeing a lot of great uptake. This is good news,\\r\\nsince the upgrade process is even easier with the addition of [feature flags](/docs/feature-flags). Keep up the upgrading!\\r\\n\\r\\nOver at the [CloudAMQP blog](https://www.cloudamqp.com/blog/index.html), you’ll now find videos transcripts of all the RabbitMQ Summit talks.\\r\\nThose are useful if you didn’t make it to the event and want to know what’s in the talk before watching the full 30 minute replay.\\r\\n\\r\\nTake a look at [Observe and Understand RabbitMQ](https://www.cloudamqp.com/blog/2019-12-10-observe-and-understand-rabbitmq.html), for example.\\r\\n\\r\\nWe also published a [new case study about LAIKA](/blog/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system), the animation company that brought you Coraline, The BoxTrolls, and Missing Link.\\r\\nIf you are interested in having your use case for RabbitMQ profiled on rabbitmq.com, drop a note in the mailing list or email info@rabbitmq.com.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* RabbitMQ 3.8.2 has been released\\r\\n* and so has 3.7.23\\r\\n* There is a [new support policy for RabbitMQ Java libraries](https://groups.google.com/d/msg/rabbitmq-users/F9f0ymQLSYE/59nBVlWPBQAJ). Please read it if you use them!\\r\\n* [Reactor RabbitMQ 1.4.1](https://groups.google.com/d/msg/rabbitmq-users/W4OqI-cTP8Y/fiIQJ7FgBAAJ) is released with a new feature.\\r\\n* [PerfTest 2.10.0](https://groups.google.com/d/msg/rabbitmq-users/jHaEvZr_Oxg/YXasq2dWBQAJ) is released with usability improvements and dependency upgrades.\\r\\n* [Java Client 5.8.0](https://groups.google.com/d/msg/rabbitmq-users/wlSB7BxbhrU/-6HddX7vAQAJ) is released with a new feature (OAuth 2 support), a usability improvement, and dependency upgrades.\\r\\n* [JMS Client 2.0.0.RC1](https://groups.google.com/d/msg/rabbitmq-users/JWC1WP53KL0/i9UJqcmOBQAJ) is released. It will become the main production line before 1.x goes end-of-life this year. Please try it out before it goes GA!\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* 2 Dec: Mike Møller Nielsen (@MikeMoelNielsen) published a\\r\\n\\r\\n[video on how to setup RabbitMQ and DataDog in Docker]\\r\\n\\r\\n(https://youtu.be/1piLrhGuzu4) and then have the DataDog-agent pick up metrics and logs\\r\\n* 2 Dec: Kailash Yogeshwar wrote about [clustering RabbitMQ with Docker Compose](https://medium.com/@kailashyogeshwar/rabbitmq-cluster-using-docker-compose-7397ea378d73)\\r\\n* 3 Dec: Josh Justice (@CodingItWrong) wrote the first part in a series on [live updates with queues, websockets, and push notifications](https://www.bignerdranch.com/blog/live-updates-with-queues-websockets-and-push-notifications-part-1-rabbitmq-queues-and-workers/) using RabbitMQ Queues and Workers\\r\\n* 4 Dec: Mike Møller Nielsen (@MikeMoelNielsen) published a [video on using the RabbitMQ REST API with Spring Boot](https://youtu.be/mAo_1At32-Q)\\r\\n* 5 Dec: Alex Koutmos (@akoutmos) wrote part 2 of his series on [Broadway, RabbitMQ, and the rise of Elixir](https://akoutmos.com/post/broadway-rabbitmq-and-the-rise-of-elixir-two/)\\r\\n* 6 Dec: Mike Møller Nielsen (@MikeMoelNielsen) published a [video on building a customer RabbitMQ Docker image](https://youtu.be/I8QHPfMhqAU) with custom configuration and definitions\\r\\n* 6 Dec: Otavio Santana (@otaviojava) wrote about [how to scale your application with Spring and RabbitMQ](https://dzone.com/articles/scale-your-application-with-spring-and-rabbitmq)\\r\\n* 8 Dec: Sofiene Memmi wrote about how to [scrape your service RabbitMQ messages with Prometheus and Kubernetes](https://medium.com/@sofienememmi/scrape-your-service-rabbitmq-messages-with-prometheus-kubernetes-b4f711993f19)\\r\\n* 8 Dec: Bekir Aytaç A?MA (@AytacAgma) wrote about [what is RabbitMQ and how to install it](https://www.aytacagma.com/rabbitmq-nedir-ve-nasil-kurulur/) (in Turkish)\\r\\n* 9 Dec: Bora Ka?mer (@CoderBora) wrote about [audit logging in MongoDB using RabbitMQ and NodeJS](http://www.borakasmer.com/nodejs-uzerinde-rabbitmq-kullanarak-mongodbde-audit-log-tutma/) (in Turkish)\\r\\n* 10 Dec: Mike Møller Nielsen (@MikeMoelNielsen) published a\\r\\n\\r\\n[video on how to set up a highly available RabbitMQ using a reverse proxy with Ngnix]\\r\\n\\r\\n(https://youtu.be/Gtq9nBr1Ca0) for multiple protocols\\r\\n* 10 Dec: Ryan Cocks wrote about [TLS for RabbitMQ using Kamatera Hosting for Node.js](https://medium.com/@ryan_4378/ssl-for-rabbitmq-using-kamatera-hosting-node-js-ed91c5fc5b2e)\\r\\n* 11 Dec: Shaurya Bajajwrote a [layperson’s guide to message brokers, featuring RabbitMQ](https://medium.com/@curiousGuy13/a-laymans-guide-to-message-brokers-be0259ed67da)\\r\\n* 12 Dec: Lovisa Johansson (@lillajja) wrote a [blog comparing RabbitMQ with Apache Kafka](https://www.cloudamqp.com/blog/2019-12-12-when-to-use-rabbitmq-or-apache-kafka.html)\\r\\n* 12 Dec: Peter Morlion (@petermorlion) released a course on LinkedIn Learning on [Learning RabbitMQ](https://www.linkedin.com/learning/learning-rabbitmq/connect-your-services-with-asynchronous-messaging?u=2171914)\\r\\n* 12 Dec: Gerhard Lazu (@gerhardlazu) hosted [Understanding RabbitMQ: New Metrics Subssystem](https://content.pivotal.io/webinars/dec-12-understand-rabbitmq-for-developers-and-operators-webinar?utm_campaign=this-month-understanding-rabbitmq&amp;utm_source=rabbitmq&amp;utm_medium=website) webinar\\r\\n* 13 Dec: Sergey Suslov (@sergeysuslovnsk) published about [communicating using RabbitMQ in Node.js](https://medium.com/swlh/communicating-using-rabbitmq-in-node-js-e63a4dffc8bb)\\r\\n* 14 Dec: Mike Møller Nielsen (@MikeMoelNielsen) published a [video on how to put 2 RabbitMQ instances into a cluster](https://youtu.be/YPXC_ERdjCo)\\r\\n* 15 Dec: Joor Loohuis (@joorloohuis) wrote about the [prefetch count setting in RabbitMQ](https://medium.com/@joor.loohuis/about-the-prefetch-count-in-rabbitmq-5f2f5611063b)\\r\\n* 16 Dec: Matthew Viegas (@mateuscviegas) wrote [an introduction to RabbitMQ for .NET Core](https://dev.to/mviegas/pt-br-introducao-ao-rabbitmq-com-net-core-15oc) (in Portugese)\\r\\n* 16 Dec: Diogo Bemfica (@diobemfica) wrote about [topic exchanges in RabbitMQ](https://diogobemfica.com.br/exchanges-tipo-topic-no-rabbitmq) (in Portuguese)\\r\\n* 16 Dec: Dormain Drewitz (@DormainDrewitz) published a [case study on how the animation company, LAIKA, uses RabbitMQ](/blog/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system)\\r\\n* 19 Dec: InfoQ published a [talk on RabbitMQ and Kafka](https://www.infoq.com/presentations/rabbitmq-kafka/) by Zoe Vance and Madhav Sathe (@madhav_sathe)\\r\\n* 19 Dec: James Ellis wrote about [how to use Celery and RabbitMQ with Django](https://morioh.com/p/b9f71324b5b1)\\r\\n* 19 Dec: Jared Ruckle (@jaredruckle) wrote about how [RabbitMQ for Pivotal Platform now runs RabbitMQ 3.8](https://content.pivotal.io/blog/any-company-can-become-a-software-driven-organization-the-new-release-of-pivotal-platform-gives-you-the-blueprint#The%20new%20RabbitMQ%20open%20source%20release%20comes%20to%20Pivotal%20Platform)\\r\\n* 20 Dec: Erlang Solutions (@ErlangSolutions) published a roundup of [their best of RabbitMQ](https://www.erlang-solutions.com/blog/rabbitmq-highlights-2019-best-of-the-beam.html) from 2019\\r\\n* 20 Dec: Lukáš Meš?an (@arzzen) wrote about the RabbitMQ [connection error “Broken pipe or closed connection”](https://lukasmestan.com/rabbitmq-broken-pipe-or-closed-connection/) and various solutions\\r\\n* 20 Dec: VMware education and certification published a [video on vRA RabbitMQ](https://youtu.be/6TP_4CiF8-E) as part of their vCloud Automation University\\r\\n* 23 Dec: Diogo Bemfica (@diobemfica) wrote about [RabbitMQ Exchange headers](https://diogobemfica.com.br/exchanges-tipo-headers-no-rabbitmq) (in Portuguese)\\r\\n* 24 Dec: Alexander Nnakwue (@alex_nnakwue) wrote about [understanding message queuing systems using RabbitMQ](https://blog.logrocket.com/understanding-message-queuing-systems-using-rabbitmq/)\\r\\n* 25 Dec: Luiz Duarte (@luiztools) wrote about [asynchronous processing of queued tasks in RabbitMQ and Node.js](https://www.luiztools.com.br/post/processamento-assincrono-de-tarefas-com-filas-no-rabbitmq-e-node-js/) (in Portuguese)\\r\\n* 27 Dec: Alen Ibric wrote an [introduction to RabbitMQ](https://www.alenibric.com.tr/2019/12/27/rabbitmq-message-broker/)\\r\\n* 29 Dec: Thiago Brito (@devbrito91) wrote a [post on messaging](https://medium.com/@devbrito91/mensageria-1330c6032049) (in Portuguese)\\r\\n* 30 Dec: Diogo Bemfica (@diobemfica) wrote about [RabbitMQ properties](https://diogobemfica.com.br/propriedades-do-rabbitmq) (in Portuguese)\\r\\n\\r\\n## Training\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* 31 Jan: [How to upgrade from RabbitMQ 3.7 to 3.8 in prod?](https://github.com/rabbitmq/tgir/pull/3)\\r\\n* 13 Feb: free online webinar on [How to Build Reliable Streaming Pipelines with RabbitMQ and Project Reactor](https://content.pivotal.io/rabbitmq/feb-13-how-to-build-reliable-streaming-pipelines-with-rabbitmq-and-project-reactor-webinar?utm_campaign=reactor-streaming-webinar-blog&amp;utm_source=rabbitmq&amp;utm_medium=website)\\r\\n* On-demand, online @ LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online @ Udemy: [RabbitMQ: Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online: $40 buys you early access to Marco Behler’s course, [Building a real-world Java and RabbitMQ messaging (AMQP)](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application) application\\r\\n* Online: Pluralsight course: [RabbitMQ by Example](https://www.pluralsight.com/courses/rabbitmq-by-example) gets good reviews"},{"id":"/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system","metadata":{"permalink":"/rabbitmq-website/blog/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-12-16-laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system/index.md","source":"@site/blog/2019-12-16-laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system/index.md","title":"LAIKA Gets Creative with RabbitMQ As the Animation Company\'s IT Nervous System","description":"Based in Portland, Oregon, LAIKA is a premier stop-motion animation company. With award-winning films like Coraline, ParaNorman, The BoxTrolls, Kubo and the Two Strings, and most recently, Missing Link, LAIKA is recognized for its unique aesthetic. Producing films the way LAIKA does is at the intersection of high-tech and analog.","date":"2019-12-16T00:00:00.000Z","tags":[{"inline":true,"label":"Case Studies","permalink":"/rabbitmq-website/blog/tags/case-studies"}],"readingTime":4.705,"hasTruncateMarker":true,"authors":[{"name":"Dormain Drewitz","key":"ddrewitz","page":null}],"frontMatter":{"title":"LAIKA Gets Creative with RabbitMQ As the Animation Company\'s IT Nervous System","tags":["Case Studies"],"authors":["ddrewitz"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, December 2019 Recap","permalink":"/rabbitmq-website/blog/2020/01/09/this-month-in-rabbitmq-december-2019-recap"},"nextItem":{"title":"This Month in RabbitMQ, November 2019 Recap","permalink":"/rabbitmq-website/blog/2019/12/07/this-month-in-rabbitmq-november-2019-recap"}},"content":"Based in Portland, Oregon, [LAIKA](https://www.laika.com/) is a premier stop-motion animation company. With award-winning films like *Coraline*, *ParaNorman*, *The BoxTrolls*, *Kubo and the Two Strings*, and most recently, *Missing Link*, LAIKA is recognized for its unique aesthetic. Producing films the way LAIKA does is at the intersection of high-tech and analog.\\r\\n\\r\\nLAIKA\'s small IT team is passionate about the animation business. \\"We support the production, making the movie.\\" explained Mahlon Smith, Senior Technologist at LAIKA. The team is behind the scenes, amongst set carpenters, painters, and film directors. \\"We enable the production as efficiently as possible. Every dollar saved is a dollar we can apply towards the screen.\\"\\r\\n\\r\\nThis sense of fiscal responsibility steers the team towards reusable technologies. Particularly when it comes to integration. With that frugality in mind, the team began looking at RabbitMQ as far back as 2009. What they\'ve learned from using RabbitMQ over the last six years is how to solve more with a flexible messaging backbone.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Challenge: \\"Everything that happens is an event\\"\\r\\n\\r\\nOperating IT for an animation company comes with some unique challenges. Cycling through film design, set production, and filming has artists coming and going. \\"Our industry historically has been a  nomadic population,\\" explains Smith. For a company of its size, the volume of identity management activities was very high. \\r\\n\\r\\nBroadly speaking, LAIKA\'s IT team faces challenges that are ubiquitous today. \\"We have a variety of in-house and third party systems,\\" said Smith. The number of environments that need to be integrated are ever growing. New software and systems are being introduced, while existing systems are rarely retired. \\r\\n\\r\\nFinally, there\'s an ever-present need to troubleshoot. Between network events, desktop support, to the render farms themselves, getting alerts and insights into activities is critical. As Will Fife, Senior Systems Administrator at LAIKA notes, \\"Increasingly, everything that happens has an event or does something because of an event.\\" \\r\\n\\r\\n## RabbitMQ: \\"It\'s the nervous system of the company\\"\\r\\n\\r\\nFaced with a dynamic user population, the IT team developed  a toolset to provision accounts across discrete systems. They adopted RabbitMQ, the most popular open source message broker to integrate between systems. For example, a new user needs a phone extension provisioned, but the standard LDAP identity doesn\'t have direct access to the phone system. Using RabbitMQ, a new user account creation event lands in a queue. The phone system listens to that queue and provisions an extension.  \\r\\n\\r\\n\\"Our desktop support admins can create a new user account and we have some consistency and reliability in knowing that account is now pushed out to all the places it needs to be,\\" explained Smith. The team is starting to use the [web socket layer for RabbitMQ](/docs/web-stomp) to send live updates to a browser. This empowers the desktop support team to see what\'s going on in real-time to troubleshoot user issues.\\r\\n\\r\\nAs LAIKA adds new software and systems, that event-driven approach to adding new users simplifies tedious processes. \\"Over time, we\'ve added more and more listeners to the new user event that do additional tasks and additional things. It makes that more resilient,\\" says Fife. \\r\\n\\r\\nRabbitMQ\'s ability to set policies stood out against other messaging tools like NATS or NSQ. For example, the team can use policies to make sure that private information stays on a very secure V-host with limited access.\\r\\n\\r\\nRabbitMQ has become something of an IT Swiss Army knife for LAIKA. \\"We control most of our VMs on the network over AMQP,\\" explains Fife. \\"This includes starting them, shutting them down, destroying them, creating them, creating storage for them.\\" If a VM doesn\'t reboot in an expected amount of time, an app reading the RabbitMQ queue notifies the owner by chat.\\r\\n\\r\\nWhile LAIKA does around 90% of it\'s internal coding in Ruby, the IT team appreciates that RabbitMQ itself is language agnostic. \\"The [STOMP layer that RabbitMQ provides](/docs/stomp) makes it so you can trivially participate in network events with just a raw socket,\\" says Smith.\\r\\n\\r\\nBecause it\'s easy to extend and integrate with, RabbitMQ has become the go-to integration tool. \\"If we require any sort of communication between systems, that’s what we’re going to use,\\" says Smith. \\"It’s the nervous system of our information technology environment.\\"\\r\\n\\r\\n## \\"We know we have a path to integrate\\"\\r\\n\\r\\nUsing RabbitMQ as the messaging backbone has reduced a lot of effort for the IT team. \\"From an IT perspective, once we had it deployed and our framework in place, now when we spin something up it’s almost zero effort,\\" says Smith.\\r\\n\\r\\nFrom new users to VM operations, IT has automated tasks and reduced the risk of error. A recent building move, for example, was simplified by adding listeners to an event queue to provision network ports. \\r\\n\\r\\nThe eventing model of RabbitMQ means that the team doesn\'t have to hardcode integrations. \\"We can loosely couple things. We don\'t need concrete contracts between systems,\\" says Smith.\\r\\n\\r\\nThe flexibility and support for policies keeps the LAIKA team coming back to RabbitMQ for more use cases. The more it integrates, the more useful it becomes to solving the next challenge.\\r\\n\\r\\n\\"It\'s a component that now has so much stuff flowing through it, that\'s the first place we go when solving a problem because we know the information is on the wire there, or can be with minimal effort.\\" says Smith. \\"We know that we have a path to integrate with that event stream when a new problem presents itself.\\"\\r\\n\\r\\n### Hear from more RabbitMQ users\\r\\n\\r\\n* Bloomberg: [Growing a farm of rabbits to scale financial applications](https://content.pivotal.io/rabbitmq/keynote-growing-a-farm-of-rabbits-to-scale-financial-applications-will-hoy-david-liu)\\r\\n* Goldman Sachs: [Scaling RabbitMQ](https://content.pivotal.io/rabbitmq/keynote-scaling-rabbitmq-at-goldman-sachs-jonathan-skrzypek)\\r\\n* Softonic: [From a monolith architecture to microservices and event-based communication](https://www.cloudamqp.com/blog/2019-01-18-softonic-userstory-rabbitmq-eventbased-communication.html)"},{"id":"/2019/12/07/this-month-in-rabbitmq-november-2019-recap","metadata":{"permalink":"/rabbitmq-website/blog/2019/12/07/this-month-in-rabbitmq-november-2019-recap","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-12-07-this-month-in-rabbitmq-november-2019-recap/index.md","source":"@site/blog/2019-12-07-this-month-in-rabbitmq-november-2019-recap/index.md","title":"This Month in RabbitMQ, November 2019 Recap","description":"Last month was a big one for the RabbitMQ community because RabbitMQ Summit happened in London! If you missed the event, or if you were at the event, but missed a session in the other track, all the recordings are now available. Also, be sure to check out our overview blog for an easy-to-digest summary of what’s new in RabbitMQ 3.8.","date":"2019-12-07T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":3.555,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, November 2019 Recap","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"LAIKA Gets Creative with RabbitMQ As the Animation Company\'s IT Nervous System","permalink":"/rabbitmq-website/blog/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system"},"nextItem":{"title":"This Month in RabbitMQ: September & October 2019","permalink":"/rabbitmq-website/blog/2019/11/13/this-month-in-rabbitmq-november-2019"}},"content":"Last month was a big one for the RabbitMQ community because RabbitMQ Summit happened in London! If you missed the event, or if you were at the event, but missed a session in the other track, [all the recordings](https://www.youtube.com/watch?v=InqY3l69yCs&amp;list=PLDUzG2yLXrU7gQAzZwMEkjkfTy0L5FsJx) are now available. Also, be sure to check out our overview blog for an easy-to-digest [summary of what’s new in RabbitMQ 3.8](/blog/2019/11/11/rabbitmq-3-8-release-overview).\\r\\n\\r\\nMore new 3.8 features and lessons learned will be covered in [an upcoming webinar](https://content.pivotal.io/webinars/dec-12-understand-rabbitmq-for-developers-and-operators-webinar?utm_campaign=rabbitmq-devops-erlang_q419&amp;utm_source=twitter&amp;utm_medium=social),\\r\\nby RabbitMQ core team member Gerhard Lazu. Tune in on December 12th!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n* [RabbitMQ 3.7.22](https://groups.google.com/forum/#!msg/rabbitmq-users/9ztCUW7RaMU/JkQQXXOEBgAJ) and [3.8.2](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.2) were released, both include a patch for [CVE-2019-11287](https://pivotal.io/security/cve-2019-11287)\\r\\n* [Kubernetes peer discovery example](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_peer_discovery_k8s/tree/master/examples/minikube) was updated\\r\\nand is now a more complete. Speaking for Kubernetes, you can sign up to beta test Pivotal\'s [RabbitMQ for Kubernetes](https://pivotal.io/pivotal-rabbitmq-on-kubernetes)!\\r\\n* [Reactor RabbitMQ 1.4.0](https://groups.google.com/d/msg/rabbitmq-users/aY4aOtUPneg/p9GDDsSDBgAJ) is released as part of the [Reactor Dysprosium-SR2 release train](https://projectreactor.io/docs). This release comes with a new feature, a usability improvement, and a dependency upgrade.\\r\\n* There were several new Erlang releases, already available via our [Debian](https://github.com/rabbitmq/erlang-debian-package/) and [RPM packages](https://github.com/rabbitmq/erlang-rpm) on [PackageCloud](https://packagecloud.io/rabbitmq/erlang/), [GitHub](https://github.com/rabbitmq/erlang-rpm/releases), and other places. There\'s now an RPM package produced for CentOS/RHEL 8.\\r\\n* [Hop 3.5.0](https://groups.google.com/d/msg/rabbitmq-users/fOhiRVFnYJg/6BRKqhH4AwAJ) is released with a new feature, a few bug fixes, and dependency upgrades.\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* 4 Nov: Yuki Nishiwaki and Bhor Dinesh (@Dinesh_bhor) shared their slides from their OpenStack Shanghai Summit talk, [How we used RabbitMQ in Wrong Way at Scale](https://speakerdeck.com/line_developers/how-we-used-rabbitmq-in-wrong-way-at-a-scale). Note that the talk covers RabbitMQ 3.6.\\r\\n* 5 Nov: Davide Guida (@DavideGuida82) published the third part in a series about microservices consuming message queues [using .NET Core background workers and RabbitMQ](https://www.davideguida.com/consuming-message-queues-using-net-core-background-workers-part-3-the-code-finally/)\\r\\n* 5 Nov: Denis Germain (@zwindler) published [a recap of the RabbitMQ Summit](https://blog.zwindler.fr/2019/11/05/recap-du-rabbitmq-summit-2019/) (in French)\\r\\n* 6 Nov: Ran Ribenzaft (@ranrib) wrote about [distributed tracing through RabbitMQ using Node.js and Jaeger](https://epsagon.com/blog/distributed-tracing-through-rabbitmq-using-node-js-jaeger/)\\r\\n* 7 Nov: Kacper Mentel (@kacper_mentel) wrote about [how to debug RabbitMQ based on a real-world example](https://www.erlang-solutions.com/blog/how-to-debug-your-rabbitmq.html)\\r\\n* 8 Nov: Lovisa Johansson (@lillajja) updated her post on [best practices for high performance (low latency) RabbitMQ](https://www.cloudamqp.com/blog/2018-01-08-part2-rabbitmq-best-practice-for-high-performance.html)\\r\\n* 8 Nov: Hussein Nasser (@hnasr) published a [video tutorial introducing publish and subscribe approaches](https://youtu.be/O1PgqUqZKTA)\\r\\n* 8 Nov: GoLab Conference published a video featuring Gabriele Vaccari explaining how to build [an event-driven notification system in Go and RabbitMQ](https://youtu.be/HTM2UDzk7mY)\\r\\n* 9 Nov: Thiago Vivas (@Tva88s) wrote about [using .NET Core with RabbitMQ for async operations](https://www.c-sharpcorner.com/article/using-net-core-with-rabbitmq-for-async-operations/)\\r\\n* 10 Nov: Alex Koutmos (@akoutmos) published the first in a series about [Broadway, RabbitMQ, and the rise of Elixir](https://akoutmos.com/post/broadway-rabbitmq-and-the-rise-of-elixir/)\\r\\n* 10 Nov: Soumil Nitin Shah published the first in a series of video tutorials on [using RabbitMQ with Python](https://www.youtube.com/watch?v=eSN0otKzYOE), starting with the basics\\r\\n* 13 Nov: Dormain Drewitz (@DormainDrewitz) published [a summary of the expert panel at RabbitMQ Summit 2019](https://content.pivotal.io/blog/rabbitmq-3-8-steals-the-show-at-rabbitmq-summit-2019-expert-panel)\\r\\n* 14 Nov: Szymon Mentel (@szymonmentel) wrote about [high availability in RabbitMQ](https://szkolarabbita.pl/o-systemach-wysokiej-dostepnosci-na-przykladzie-rabbitmq/), covering the traditional mirrored queues method, but also noting the new quorum queues in 3.8 (in Polish)\\r\\n* 19 Nov: John Tucker published [an article on Web-Worker RPC with RabbitMQ](https://codeburst.io/web-worker-rpc-with-rabbitmq-1c6d90939f7)\\r\\n* 20 Nov: Bahadir Tasdemir of Trendyol wrote about [event-driven microservices architecture with RabbitMQ](https://medium.com/trendyol-tech/event-driven-microservice-architecture-91f80ceaa21e)\\r\\n* Nov 20: Cagri Aslanbas wrote about a dockerized [messaging implementation in Django with RabbitMQ and Celery](https://medium.com/@cagrias/a-dockerized-pub-sub-message-queue-implementation-in-django-by-using-rabbitmq-and-celery-20d349dc60b6)\\r\\n* 21 Nov: Dormain Drewitz (@DormainDrewitz) published a [podcast interview](https://content.pivotal.io/podcasts/modernizing-from-mainframe-to-net-core-at-travelers-insurance) with Viraj Naik of Travelers Insurance and Rohit Kelapure from Pivotal. Their dicussion about modernizing a workload off of mainframe to .NET Core included how RabbitMQ was used.\\r\\n* 22 Nov: Shivam Aggarwal (@shivama205) published [an overview of the new Quorum Queues feature in RabbitMQ 3.8](https://medium.com/@shivama205/rabbbitmq-quorum-queues-829cec655792)\\r\\n* 24 Nov: The techno journals (@JournalsTechno) wrote about [installing RabbitMQ](https://www.thetechnojournals.com/2019/11/installing-rabbit-mq.html)\\r\\n* 29 Nov: David Ireland published a [recap of RabbitMQ Summit](https://tech.labs.oliverwyman.com/blog/2019/11/29/rabbitmq-summit-2019-report/)\\r\\n* 30 Nov: Mike Møller Nielsen (@MikeMoelNielsen) published a [video to demonstrate RabbitMQ Firehose tracing](https://youtu.be/ftIKXFLdYZQ)\\r\\n\\r\\n## Ready to learn more?\\r\\n\\r\\nCheck out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* 12 December 2019, online webinar: [Understanding RabbitMQ: For Developers and Operators](https://content.pivotal.io/webinars/dec-12-understand-rabbitmq-for-developers-and-operators-webinar?utm_campaign=this-month-understanding-rabbitmq&amp;utm_source=rabbitmq&amp;utm_medium=website)\\r\\n* 16 December 2019, Lyon, France: [JUG Meetup](https://www.meetup.com/fr-FR/lyonjug/events/266379924)\\r\\n* On-demand, online at LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online at Udemy: [RabbitMQ : Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online: $40 buys you early access to Marco Behler’s course, [Building a real-world Java and RabbitMQ messaging (AMQP) application](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)\\r\\n* Online at Pluralsight: [RabbitMQ by Example](https://www.pluralsight.com/courses/rabbitmq-by-example) gets good reviews"},{"id":"/2019/11/13/this-month-in-rabbitmq-november-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/11/13/this-month-in-rabbitmq-november-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-11-13-this-month-in-rabbitmq-november-2019/index.md","source":"@site/blog/2019-11-13-this-month-in-rabbitmq-november-2019/index.md","title":"This Month in RabbitMQ: September & October 2019","description":"This Month (and the month before) in RabbitMQ — October and September recap!","date":"2019-11-13T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":5.225,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ: September & October 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, November 2019 Recap","permalink":"/rabbitmq-website/blog/2019/12/07/this-month-in-rabbitmq-november-2019-recap"},"nextItem":{"title":"RabbitMQ 3.8 Release Overview","permalink":"/rabbitmq-website/blog/2019/11/11/rabbitmq-3-8-release-overview"}},"content":"This Month (and the month before) in RabbitMQ — October and September recap!\\r\\n\\r\\nWe’re a little behind this month! At the beginning of October, we [shipped RabbitMQ 3.8](/blog/2019/11/11/rabbitmq-3-8-release-overview). That’s right, folks, [RabbitMQ 3.8 is finally out](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0)!\\r\\n\\r\\nHeadline features include:\\r\\n\\r\\n* [Quorum Queues](/docs/quorum-queues): a new replicated queue type with many improvements over classic mirrored queues\\r\\n* [Feature flags](/docs/feature-flags) allow for mixed-version clusters and simplified upgrades\\r\\n* Built-in [Prometheus and Grafana-based monitoring](/docs/prometheus)\\r\\n* [OAuth 2 (JWT token) support](https://github.com/rabbitmq/rabbitmq-auth-backend-oauth2) for authentication and authorization\\r\\n* and more\\r\\n\\r\\nYou’ll find some early reviews from folks in the community who have been kicking the tires in the community updates section below.\\r\\nMake sure you are all over the [upgrades best practices](/docs/upgrade)\\r\\nto avoid potential hazards of [upgrading](/docs/upgrade) to RabbitMQ 3.8.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nOh, and there were some other rather meaningful ecosystem announcements out there:\\r\\n\\r\\n* Boomi announced a real-time listener for RabbitMQ\\r\\n* Microsoft Azure announced [RabbitMQ extension for Azure Functions](https://dev.to/azure/announcing-the-rabbitmq-extension-for-azure-functions-2mbo)\\r\\n\\r\\nSpringOne Platform 2019 talks that highlighted RabbitMQ:\\r\\n\\r\\n* [RabbitMQ and Kafka](https://springoneplatform.io/2019/sessions/rabbitmq-kafka) with Zoe Vance and Madhav Sathe\\r\\n* A [Tale of Transformation](https://springoneplatform.io/2019/sessions/a-tale-of-transformation-changing-the-way-we-deliver-and-transform-product-data-at-dell): Changing the Way We Deliver and Transform Product Data at Dell with Deepali Kishnani and Joe Toubia\\r\\n* [Building the Pivotal RabbitMQ for Kubernetes](https://www.youtube.com/watch?v=cYYRnvhmv1M) Beta with Zoe Vance and Chunyi Lyu\\r\\n* [Building Reactive Pipelines](https://www.youtube.com/watch?v=x4PImMjPa7k): How to Go from Scalable Apps to (Ridiculously) Scalable Systems with Mark Heckler\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [RabbitMQ 3.8.1](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.1) was released with bug fixes and improvements in quorum queues memory performance\\r\\n* Spring for RabbitMQ (Spring AMQP) 2.2 is [now available](https://spring.io/blog/2019/10/02/spring-for-rabbitmq-spring-amqp-2-2-is-now-available)\\r\\n* RabbitMQ for Kubernetes went into beta… and there\'s a [separate post about that](https://content.pivotal.io/blog/against-the-backdrop-of-vmware-tanzu-here-s-how-pivotal-platform-s-new-release-helps-you-build-modern-apps#RabbitMQ)\\r\\n* [Reactor RabbitMQ 1.3.0](https://groups.google.com/d/msg/rabbitmq-users/faaGTV7cWrA/Yy5OdCAzBwAJ) is released as part of the [Reactor Dysprosium release train](https://projectreactor.io/docs). It comes with tons of new things, try it out!\\r\\n* [Java Client 5.8.0.RC2](https://groups.google.com/d/msg/rabbitmq-users/wnWPhOjdE3Y/aC4KEZWsBAAJ) is released with OAuth 2 support. Try it out with RabbitMQ 3.8 before we release 5.8.0.GA!\\r\\n* [JMS Client 1.14.0](https://groups.google.com/d/msg/rabbitmq-users/jLkf8RnOJ9Y/D6J3Ek17AQAJ) is released with a new feature and a usability improvement.\\r\\n* [PerfTest 2.9.0](https://groups.google.com/d/msg/rabbitmq-users/gsEV_CWUcB4/Ye8klw45BgAJ) is released with a new feature, a usability enhancement, bug fixes, and dependency upgrades. [2.9.1](https://groups.google.com/d/msg/rabbitmq-users/YW2fFddt__0/3tW3I05pCwAJ) came out shortly after with a small bug fix.\\r\\n* [Hop 3.5.0.RC1](https://groups.google.com/d/msg/rabbitmq-users/5hmJUyc7ffg/aQDqw19iCAAJ) is released with dependency upgrades. Another RC is around the corner.\\r\\n\\r\\nSeveral updates to 3.7.x with bug fixes:\\r\\n\\r\\n* [3.7.18](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.18) also includes a security vulnerability fix\\r\\n* [3.7.19](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.19)\\r\\n* [3.7.20](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.20)\\r\\n* [3.7.21](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.21)\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* Sept 2: Nitzan Shapira (@nitzanshapira) published a [comparison of tracing](https://epsagon.com/blog/kafka-rabbitmq-or-kinesis-solution-comparison/) in several messaging systems including RabbitMQ\\r\\n* Sept 3: Syed Sirajul Islam Anik (@sirajul_anik) wrote about [RabbitMQ for PHP developers](https://medium.com/@sirajul.anik/rabbitmq-for-php-developers-c17cd019a90)\\r\\n* Sept 6: Josh Long (@starbuxman) published a [podcast interview with Gary Russell](https://spring.io/blog/2019/09/06/a-bootiful-podcast-gary-russell) (@gprussell) talking about RabbitMQ, Spring Integration and more\\r\\n* Sept 7: Dhiraj Ray (@only2dhir) shared a [Spring Boot RabbitMQ example](https://www.devglan.com/spring-boot/springboot-rabbitmq-example)\\r\\n* Sept 8: Nishadi Wickramanayaka (@wickramanayaka_) wrote an [introduction to RabbitMQ](https://freetechorb.wordpress.com/2019/09/08/rabbitmq-introduction/)\\r\\n* Sept 11: Richard Hooper (@Pixel_Robots) published about scaling an Azure VMSS based on [RabbitMQ queue size using an Azure Logic App](https://pixelrobots.co.uk/2019/09/scale-an-azure-vmss-based-on-rabbitmq-queue-size-using-an-azure-logic-app/)\\r\\n* Sept 12: Maciej Chada?a wrote about [fighting deadlocks with RabbitMQ](https://medium.com/@maciejcha/fighting-deadlocks-with-rabbitmq-8467ac06e3e7)\\r\\n* Sept 12: Paul Redmond (@paulredmond) wrote about a library that strives to be a [painless way to use RabbitMQ with Laravel](https://laravel-news.com/amqp)\\r\\n* Sept 13: More serverless! Mark Purcell (@PurcellMk) published about [OpenWhisk and RabbitMQ](https://medium.com/openwhisk/openwhisk-and-rabbitmq-c5dae08e051e)\\r\\n* Sept 14: Igor Zhivilo (@warolv) published the first in a series on RabbitMQ. Part 1 explains [how to break apart your application with RabbitMQ](https://medium.com/splitting-your-app-with-rabbitmq/splitting-your-app-into-smaller-apps-using-rabbitmq-b6e4ef29d1da). Part 2 covers [RabbitMQ publisher resiliency to failures](https://medium.com/@warolv/handling-rabbitmq-publisher-failures-914ff08ccbb2). Part 3 focuses on [handling RabbitMQ consumer failures with maxretry handler](https://medium.com/@warolv/handling-rabbitmq-consumer-failures-with-maxretry-handler-eb0332ab98e0).\\r\\n* Sept 15: Muhammad Nabeel published about how to [install RabbitMQ on RHEL 8 or CentOS 8](https://www.osradar.com/how-to-install-rabbitmq-on-rhel-8-centos-8/)\\r\\n* Sept 19: Catcher Wong (@catcherwong) wrote about [publishing RabbitMQ messages in ASP.NET Core](https://www.c-sharpcorner.com/article/publishing-rabbitmq-message-in-asp-net-core/)\\r\\n* Sept 24: Lovisa Johansson (@lillajja) published the part 4 of her series on [RabbitMQ for beginners](https://www.cloudamqp.com/blog/2015-09-03-part4-rabbitmq-for-beginners-exchanges-routing-keys-bindings.html), focusing on Exchanges, routing keys, and bindings\\r\\n* Sept 24: Jack Vamvas (@jackvamvas) published about how to [use curl with RabbitMQ HTTP API](https://www.dba-ninja.com/2019/09/how-to-use-curl-for-a-rabbitmq-connection.html)\\r\\n* Sept 25: Mark Heckler (@mkheck) published an interview with Zoe Vance on RabbitMQ and Kafka, and [building reliable services on Kubernetes](https://content.pivotal.io/springone-platform-2019-previews/springone-platform-preview-rabbitmq-and-kafka-and-building-reliable-services-on-kubernetes)\\r\\n* Sept 25: Francesco Bonizzi (@fbonizzi90) wrote about [quickly getting RabbitMQ up and running on Windows with Docker](https://levelup.gitconnected.com/rabbitmq-with-docker-on-windows-in-30-minutes-172e88bb0808)\\r\\n* Sept 26: Wojtek Suwa?a (@wojtek_suwala) published the seventh post on a series about building microservices with .NET Core, this one focusing on [transactional outboxes with RabbitMQ](https://altkomsoftware.pl/en/blog/microservices-outbox-rabbitmq/)\\r\\n* Sept 28: Aditi Mittal published a [quick introduction to RabbitMQ](https://medium.com/@aditi.mittalborn97/quick-introrabbitmq-bb2a06c7f39c)\\r\\n* Oct 8: David McKenna wrote a [brief history of APIs](https://dzone.com/articles/api-is-dead-long-live-the-apis), noting RabbitMQ and messaging protocol role in how integration is evolving\\r\\n* Oct 11: Sven Varkel (@svenvarkel) published about [building a dockerized developer environment](https://dev.to/svenvarkel/dockerized-sailsjs-reactjs-mongodb-redis-rabbitmq-nginx-denvironment-325n) with SailsJS, ReactJS, MongoDB, Redis, RabbitMQ, and Nginx\\r\\n* Oct 12: Ratul Basak wrote about [clustering RabbitMQ using Terraform and Ansible](https://medium.com/@ratulbasak93/rabbitmq-cluster-setup-using-terraform-and-ansible-in-aws-fbd72f386b66)\\r\\n* Oct 13: Johnson Duke published about building a minimalistic [message queue in Node.js with RabbitMQ](https://morioh.com/p/8bc4fb039a9a)\\r\\n* Oct 13: Deshan Madurajith (@DMadurajith) wrote a great set of [mistakes you can make with RabbitMQ](https://medium.com/@deshan.m/6-fantastic-mistakes-that-you-can-do-using-rabbitmq-nodejs-cbf5db99613c). Great lessons learned!\\r\\n* Oct 18: Lovisa Johansson (@lillajja) published about [what is new in RabbitMQ 3.8](https://www.cloudamqp.com/blog/2019-10-18-rabbitmq-version-3-8.html)\\r\\n* Oct 19: @itseranga published about [building reactive, asynchronous, polyglot microservices](https://medium.com/rahasak/reactive-microservices-with-golang-rabbitmq-and-protobuf-af025f4ec27)\\r\\n* Oct 23: Monica Sarbu (@monicasarbu) wrote about how Elastic is introducing [Integration Plugins for Logstash](https://www.elastic.co/blog/logstash-lines-introduce-integration-plugins), including RabbitMQ. Sounds handy!\\r\\n* Oct 23: Szymon Mentel (@szymonmentel) published on [RabbitMQ 3.8 and Quorum Queues](https://szkolarabbita.pl/rabbitmq-3-8-i-quorum-queues/)\\r\\n* Oct 25: Szymon Mentel (@szymonmentel) published on [“gotchas” with RabbitMQ Mirrored Queues](https://www.erlang-solutions.com/blog/rabbitmq-mirrored-queues-gotchas.html)… great to review as you are researching the new Quorum Queues introduced in 3.8\\r\\n* Oct 25: Matthew Harper published part 3 of his guide to [getting started with .NET Core, Docker, and RabbitMQ](https://medium.com/trimble-maps-engineering-blog/getting-started-with-net-core-docker-and-rabbitmq-part-3-66305dc50ccf)\\r\\n* Oct 25: Brian McClain (@BrianMMcClain) wrote about how to [get started with Spring Cloud Stream](https://content.pivotal.io/practitioners/getting-started-with-spring-cloud-stream), noting RabbitMQ as one of the messaging options available\\r\\n\\r\\n## Webinars and Training\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* 12 December 2019, online: [Understanding RabbitMQ: For Developers and Operators](https://content.pivotal.io/webinars/dec-12-understand-rabbitmq-for-developers-and-operators-webinar?utm_campaign=this-month-understanding-rabbitmq&amp;utm_source=rabbitmq&amp;utm_medium=website) with RabbitMQ core team member Gerhard Lazu\\r\\n* On-demand, online @ LearnFly: Learn [RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online @ Udemy: RabbitMQ : [Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online: $40 buys you early access to Marco Behler’s course, [Building a real-world Java and RabbitMQ messaging (AMQP) application](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)\\r\\n* Online @ Pluralsight: [RabbitMQ by Example](https://www.pluralsight.com/courses/rabbitmq-by-example) has good reviews"},{"id":"/2019/11/11/rabbitmq-3-8-release-overview","metadata":{"permalink":"/rabbitmq-website/blog/2019/11/11/rabbitmq-3-8-release-overview","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-11-11-rabbitmq-3-8-release-overview/index.md","source":"@site/blog/2019-11-11-rabbitmq-3-8-release-overview/index.md","title":"RabbitMQ 3.8 Release Overview","description":"RabbitMQ 3.8 has just been released and has some major new features which focus on reliability, operations, and observability.","date":"2019-11-11T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":5.37,"hasTruncateMarker":true,"authors":[{"name":"Jack Vanlightly","key":"jvanlightly","page":null}],"frontMatter":{"title":"RabbitMQ 3.8 Release Overview","tags":["Updates","New Features"],"authors":["jvanlightly"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ: September & October 2019","permalink":"/rabbitmq-website/blog/2019/11/13/this-month-in-rabbitmq-november-2019"},"nextItem":{"title":"This Month in RabbitMQ — September 2019","permalink":"/rabbitmq-website/blog/2019/09/09/this-month-in-rabbitmq-september-2019"}},"content":"RabbitMQ 3.8 has just been released and has some major new features which focus on reliability, operations, and observability.\\r\\n\\r\\nYou can find the new 3.8 release on the [GitHub releases page](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0) which includes information about what is included in the release as well as various installation assets. See our [upgrade guide](/docs/upgrade) for more information about upgrading to 3.8.0.\\r\\n\\r\\nOur team dedicates this release to [Joe Armstrong](https://en.wikipedia.org/wiki/Joe_Armstrong_(programmer)), the creator of Erlang. Joe’s work in the fields of concurrent and distributed systems benefits RabbitMQ to this day. Equally importantly, Joe was a rare example of a brilliant engineer who was also very humble and kind.\\r\\n\\r\\nLet’s take a quick look at the new features in this release.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Quorum Queues\\r\\n\\r\\nFor years, RabbitMQ has offered mirrored queues, also known as HA queues, as a solution for both high availability and data safety. Messages are replicated from a **queue master** to one or more **mirrors** so that in the event of the loss of a broker, a mirror can be promoted to master and the queue continues to be available without loss of **confirmed** messages.\\r\\n\\r\\nQuorum queues are the next generation of replicated queue and offer both better performance and solve some of the pain points of mirrored queues. Quorum queues use the well established Raft protocol which has now been implemented in countless data systems as a means of achieving reliable and fault tolerant state replication.\\r\\n\\r\\n![Shows a quorum queue consisting of one leader and two followers](QQ.png)\\r\\n\\r\\nOne of the main pain points around mirrored queues was blocking synchronization coupled with throwing away data on leaving and rejoining a cluster. This made applying OS patches difficult if queues were large in size as the administrator was forced to choose between lower redundancy or a period of unavailability. Quorum queues completely avoid this issue by not throwing away data and making replication to a single node non blocking. Quorum queues also avoid split-brain scenarios that could provoke message loss and always favour consistency over availability.\\r\\n\\r\\nFrom now on we will be referring to classic and quorum queues.\\r\\n\\r\\nRead more about quorum queues [in documentation guides](/docs/quorum-queues).\\r\\n\\r\\n## Feature Flags\\r\\n\\r\\nPrior to the new feature flag sub-system, upgrades to RabbitMQ required cluster-wide shutdown. Feature flags allow for rolling upgrades of a cluster enabling continued availability.\\r\\n\\r\\nAs Jean-Sébastien Pédron described in  [this blog](/blog/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags):\\r\\n\\r\\n> New in RabbitMQ 3.8.0 is the feature flags subsystem: when a single node in a 3.7.x cluster is upgraded to 3.8.0 and restarted, it will not immediately enable the new features or migrate its database schema because the feature flags subsystem told it not to. It could determine this because RabbitMQ 3.7.x supports no feature flags at all, therefore new features or behaviours in RabbitMQ 3.8.0 cannot be used before all nodes in the cluster are upgraded.\\r\\n\\r\\n![Multi-step process of upgrading and enabling feature flags](FeatureFlags.png)\\r\\n\\r\\nRead more about feature flags [in documentation guides](/docs/feature-flags).\\r\\n\\r\\n## Prometheus and Grafana Monitoring Support\\r\\n\\r\\nMany systems come with their own custom monitoring visualization solution, the Management Plugin has has been this solution in RabbitMQ for years. The new paradigm is for applications and infrastructure to expose metrics to external observability platforms and delegate the storing, indexing and alerting to those specialized tools. Both Prometheus and Grafana have become an industry standard in the systems observability space and provide powerful visualization and exploratory data analysis capabilities.\\r\\n\\r\\nRabbitMQ 3.8 comes with new support for exposing its metrics via a Prometheus endpoint. Additionally, many more metrics are now available, vastly improving the overall observability of RabbitMQ. Visualizing these metrics is now as simple as importing pre-built dashboards into Grafana.\\r\\n\\r\\n![The RabitMQ overview Grafana dashboard](rabbitmq-overview-dashboard.png)\\r\\n\\r\\nPrometheus and Grafana support has a dedicated [documentation guide](/docs/prometheus).\\r\\n\\r\\n## OAuth 2.0 Support\\r\\n\\r\\nRabbitMQ 3.8 allows clients to use JWT access tokens for authentication and authorization. Clients obtain an access token from an OAuth2.0 provider, through any grant type they wish, and use that token to gain access to RabbitMQ. OAuth 2.0 tokens use **scopes** to communicate what set of permissions a particular client has been granted and RabbitMQ permissions are mapped onto these scopes.\\r\\n\\r\\nRead more about OAuth2.0 support [in the docs](https://github.com/rabbitmq/rabbitmq-auth-backend-oauth2).\\r\\n\\r\\n## Additional CLI Tools\\r\\n\\r\\nYou can perform various levels of [health checks](/docs/monitoring#health-checks) with the rabbitmq-diagostics CLI tool. The checks range from basic pings to checking queues and vhosts are running to in-depth runtime information.\\r\\n\\r\\nWe have a new CLI tool, **rabbitmq-queues**, which gives us the ability to modify quorum queue memberships but also gives us new master/leader rebalancing functionality for both quorum and mirrored queues.\\r\\n\\r\\nOne of the pain points of performing a rolling upgrade to the servers of a RabbitMQ cluster was that queue masters would end up concentrated on one or two servers. The new **rebalance** command will automatically rebalance masters across the cluster. \\r\\n\\r\\n`rabbitmq-queues` has a [man page](/docs/man/rabbitmq-queues.8).\\r\\n\\r\\n## Single Active Consumer (SAC)\\r\\n\\r\\nSAC is also the next generation of an existing feature - exclusive consumers. The objective of exclusive consumers is to ensure that only a single consumer can consume a given queue at a time. The consumer uses the \\"exclusive\\" flag when registering itself, and the registration only succeeds if no other consumer is already registered.\\r\\n\\r\\nSAC improves on this by making exclusivity a feature of the queue itself and making the process transparent to clients. If a second consumer registers itself, the registration succeeds and the consumer sits idle ready to become active if the currently active consumer shuts down or crashes. This gives us an automatic active-backup consumer strategy for when we want only a single consumer, but a secondary to take over quickly in the event the active goes away.\\r\\n\\r\\n![Shows two consumers on a queue where only one is active](SAC.png)\\r\\n\\r\\nRead more about Single Active Consumer [in the Consumers guide](/docs/consumers#single-active-consumer).\\r\\n\\r\\n## And...\\r\\n\\r\\n* Messages can now be deadlettered from the tail of a classic queue with the new queue overflow configuration *reject-publish-dlx.*\\r\\n* High queue creation/deletion rates (queue churn) are now less costly.\\r\\n* Maximum message size is now configurable.\\r\\n* Quorum queues come with a new poison message feature that allows you to configure messages to be dropped after a given number of redeliveries by setting the delivery-limit policy.\\r\\n* RabbitMQ for Kubernetes is coming. Sign up to the [beta](https://pivotal.io/pivotal-rabbitmq-on-kubernetes).\\r\\n\\r\\nIf you’re more of a classroom learner, I recommend watching the webinar, \\"[What\'s new in RabbitMQ 3.8?](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_campaign=rabbitmq-blog-3.8-webinar-q319&amp;utm_source=rabbitmq&amp;utm_medium=website)\\"\\r\\n\\r\\nPlease give 3.8 a try and let us know what you think on the RabbitMQ mailing list!"},{"id":"/2019/09/09/this-month-in-rabbitmq-september-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/09/09/this-month-in-rabbitmq-september-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-09-09-this-month-in-rabbitmq-september-2019/index.md","source":"@site/blog/2019-09-09-this-month-in-rabbitmq-september-2019/index.md","title":"This Month in RabbitMQ — September 2019","description":"Welcome back for another edition of This Month in RabbitMQ! Exciting news is that the first release candidate for RabbitMQ 3.8 is now available!","date":"2019-09-09T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":3.995,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — September 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.8 Release Overview","permalink":"/rabbitmq-website/blog/2019/11/11/rabbitmq-3-8-release-overview"},"nextItem":{"title":"This Month in RabbitMQ — August 2019","permalink":"/rabbitmq-website/blog/2019/08/12/this-month-in-rabbitmq-august-2019"}},"content":"Welcome back for another edition of This Month in RabbitMQ! Exciting news is that the [first release candidate for RabbitMQ 3.8](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0-rc.1) is now available!\\r\\n\\r\\nBe sure to catch up on what is new in 3.8 by reading the release notes and watching this [webinar replay](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_campaign=rabbitmq-blog-3.8-webinar-q319&amp;utm_source=rabbitmq&amp;utm_medium=website).\\r\\n\\r\\nWe are starting to countdown until [RabbitMQ Summit](https://rabbitmqsummit.com/) in London on November 4.\\r\\nThe RabbitMQ team is looking forward to sharing updates on the project,\\r\\nbut we’re also looking forward to hearing from end-users like Bloomberg, WeWork, Softonic, and Zalando.\\r\\nBe sure to register and snag a spot in one of the training add-on courses.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [First release candidate for RabbitMQ 3.8](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0-rc.1) is available for community testing\\r\\n* [Next generation Prometheus support](/docs/prometheus) has been thoroughly reviewed with the help of [Brian Brazil](https://github.com/brian-brazil)\\r\\n* Erlang 20.3 support is [being discontinued](https://groups.google.com/forum/#!searchin/rabbitmq-users/ANN|sort:date/rabbitmq-users/9tc_OE1eMPk/ly1NEISwBwAJ) soon. Please [upgrade to a supported version](/docs/which-erlang)\\r\\n* New Spring Integration and Spring AMQP [releases are available](https://spring.io/blog/2019/08/08/new-spring-integration-amqp-kafka-maintenance-and-milestone-releases)\\r\\n* [php-amqplib 2.10.0](https://github.com/php-amqplib/php-amqplib/releases/tag/v2.10.0) is released\\r\\n* [JMS client 1.13.0](https://groups.google.com/d/msg/rabbitmq-users/XFbLrNYnF78/UXBKPOVBAQAJ) is released with a new feature (support for publisher confirms), bug fixes, and dependency upgrades\\r\\n* [Ra](https://github.com/rabbitmq/ra/), our Raft implementation library, has gone 1.0\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\n* August 1: Aidan Ruff published on [RabbitMQ as an MQTT broker](https://tech.scargill.net/rabbitmq-mqtt-broker/)\\r\\n* August 4: Antonio Musarra wrote about [using CloudAMQP RabbitMQ service for MQTT](https://www.dontesta.it/2019/08/04/raspberry-pi-sense-hat-come-pubblicare-dati-cloudamqp-mqtt/)\\r\\n* August 5: TekLoon followed up on a post from July, this time about [how they deploy a microservice to Heroku with RabbitMQ](https://medium.com/better-programming/how-i-deploy-microservice-to-heroku-with-rabbitmq-876499c797cc)\\r\\n* August 5: Júlio Falbo (@juliofalbo77) from TradeShift wrote about [an open source library that helps integrate Spring Boot with RabbitMQ](https://medium.com/tradeshift-engineering/spring-rabbitmq-tuning-f94723598312), as an alternative to Spring AMQP\\r\\n* August 9: Erlang Solutions published a video from at a Meetup in Krakow where Szymon Mentel (@szymonmentel) presents [examples of how to achieve high availability in RabbitMQ](https://www.youtube.com/watch?v=MFH-GDYdxwQ&amp;utm_source=dlvr.it&amp;utm_medium=twitter)\\r\\n* August 9: The Italian Agile Movement published a video of Gabriele Santomaggio (@GSantomaggio) speaking (in Italian) on [microservices integration and how RabbitMQ compares](https://vimeo.com/351826121) to other open source messaging technologies\\r\\n* August 12: Brant Burnett (@btburnett3) wrote about [blue/green deployments in the context of messaging on Kubernetes](https://btburnett.com/kubernetes/microservices/continuous%20delivery/2019/08/12/shawarma.html) using Shawarma\\r\\n* August 12: Alexander Ma published the [second part of an introduction to microservices](https://medium.com/@alexma6614/rabbitmq-flask-go-tutorial-pt-2-7161feb654c6) using Python, Go, RabbitMQ, and Redis\\r\\n* August 12: Wojciech Suwa?a published part 6 in a series on building microservices on .NET Core. This part was focused on [real-time server-client communication with SignalR and RabbitMQ](https://altkomsoftware.pl/en/blog/building-microservices-6/)\\r\\n* August 13: Radu Vunvulea (@RaduVunvulea) wrote about [using MQTT protocol inside Azure with RabbitMQ on top of AKS](http://vunvulearadu.blogspot.com/2019/08/mqtt-protocol-inside-azure-rabbitmq-on.html)\\r\\n* August 16: Angga Kusumandaru (@ndaruoke) wrote about [using RabbitMQ, Bunny and Sneakers](https://medium.com/@kusumandaru/publish-subscribe-on-ruby-on-rails-6aa6893ef819) to set up a publish and subscribe architecture in Ruby on Rails\\r\\n* August 17: Marius Jaraminas published about [What is RabbitMQ and Why it’s Needed?](https://codespacelab.com/index.php/2019/08/17/what-is-rabbitmq-and-why-its-needed/). He also published about how to [avoid having a single messaging point of failure](https://codespacelab.com/index.php/2019/08/17/rabbitmq-single-point-of-failure/)\\r\\n* August 18: Luke Mwila (@LuKE9ine) wrote [A Quick Guide To Understanding RabbitMQ &amp; AMQP 0-9-1](https://medium.com/swlh/a-quick-guide-to-understanding-rabbitmq-amqp-ba25fdfe421d)\\r\\n* August 19: Marius Jaraminas at it again with [RabbitMQ and Spring Cloud Stream](https://codespacelab.com/index.php/2019/08/19/rabbitmq-and-spring-cloud-stream/)\\r\\n* August 21: Quintessence Anx (@QuintessenceAnx) published the first part of a blog series on [monitoring RabbitMQ with the ELK Stack and Logz.io](https://logz.io/blog/monitoring-rabbitmq-with-elk-and-logz-io-part-1/)\\r\\n* August 22: Rocky Lhotka (@RockyLhotka) wrote about his recent work on a data portal channel [based on using RabbitMQ as the underlying transport](http://www.lhotka.net/weblog/RabbitMQDataPortalChannelInCSLA5.aspx)\\r\\n* August 22: Olushola Karokatose (@Olushola_k) published about [getting started with Golang by building a project with RabbitMQ](https://dev.to/olushola_k/working-with-rabbitmq-in-golang-1kmj)\\r\\n* August 23: Marlon Monçores wrote about [using Spring Cloud Stream and RabbitMQ](https://medium.com/m4u-tech/mantendo-a-velocidade-de-entrega-mesmo-com-mensagens-ruins-spring-cloud-rabbitmq-383dbd92efae) (in Portuguese)\\r\\n* August 26: Surat Pyari (@suratpyaridb) published another part in her series on microservices with Sinatra, this time walking through [how to queue requests with RabbitMQ](https://blazarblogs.wordpress.com/2019/08/26/rabbitmq-in-sinatra-an-addition-for-micro-service/)\\r\\n* August 26: Syed Sirajul Islam Anik (@sirajul_anik) wrote a [thorough introduction to RabbitMQ](https://medium.com/@sirajul.anik/easy-peasy-rabbitmq-squeezy-820b1c632465)\\r\\n* August 28: Marius Jaraminas publishes a FOURTH blog on [RabbitMQ Scalability Testing](https://codespacelab.com/index.php/2019/08/28/rabbitmq-scalability-testing/)\\r\\n* August 29: Nicolas Judalet (@JudaletNicolas) wrote an [Introduction to Event-driven Architectures With RabbitMQ](https://blog.theodo.com/2019/08/event-driven-architectures-rabbitmq/)\\r\\n* August 30: Mike Møller Nielsen (@MikeMoelNielsen) published a [video explaining the fan-out, topic, and direct exchange  types](https://www.youtube.com/watch?v=lqrCNhiTgTo&amp;feature=youtu.be) in RabbitMQ\\r\\n\\r\\n## Events and Training\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* 12 September 2019, Bern: DevOps Meetup on Observability and DevOps: [Value Stream Mapping with RabbitMQ](https://www.meetup.com/DevOps-Bern/events/262813160/)\\r\\n* 30 September 2019, NYC: [RabbitMQ Express](https://codesync.global/conferences/code-beam-lite-nyc/training/)\\r\\n* 4 November 2019, London, UK: [RabbitMQ Summit](https://rabbitmqsummit.com/)\\r\\n* 5-6 November 2019, London, UK: Various trainings available as part of the [RabbitMQ Summit](https://rabbitmqsummit.com/#training)\\r\\n* 6-8 November 2019, London, UK: CodeMesh LDN features a [talk from Ayande Dube](https://codesync.global/conferences/code-mesh-ldn/) (@dube_aya) on messaging wars: RabbitMQ, Kafka or ZeroMQ?\\r\\n* On-demand, online at LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online at Udemy: [RabbitMQ : Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online: $40 buys you early access to Marco Behler’s course, [Building a real-world Java and RabbitMQ messaging (AMQP) application](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)"},{"id":"/2019/08/12/this-month-in-rabbitmq-august-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/08/12/this-month-in-rabbitmq-august-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-08-12-this-month-in-rabbitmq-august-2019/index.md","source":"@site/blog/2019-08-12-this-month-in-rabbitmq-august-2019/index.md","title":"This Month in RabbitMQ — August 2019","description":"Welcome back for another edition of This Month in RabbitMQ! Some big news last month was Pivotal announced a forthcoming alpha of Pivotal RabbitMQ for Kubernetes.","date":"2019-08-12T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":4.025,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — August 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — September 2019","permalink":"/rabbitmq-website/blog/2019/09/09/this-month-in-rabbitmq-september-2019"},"nextItem":{"title":"This Month in RabbitMQ — July 2019","permalink":"/rabbitmq-website/blog/2019/07/09/this-month-in-rabbitmq-july-2019"}},"content":"Welcome back for another edition of This Month in RabbitMQ! Some big news last month was Pivotal announced a forthcoming alpha of Pivotal RabbitMQ for Kubernetes.\\r\\n\\r\\nYou can inquire about the alpha here. As part of that announcement, RabbitMQ was mentioned in coverage in\\r\\n[Business Insider](https://urldefense.proofpoint.com/v2/url?u=https-3A__www.businessinsider.com_pivotal-2Dpas-2Dkubernetes-2Dwall-2Dstreet-2Drob-2Dmee-2D2019-2D7&amp;d=DwMGaQ&amp;c=lnl9vOaLMzsy2niBC8-h_K-7QJuNJEsFrzdndhuJ3Sw&amp;r=HNaEFhtuH9k7pH023_PQLQ&amp;m=Dm_L-EU0Cj9GYRR86q6DKNZKjh987nlPsM-_-o4_AdU&amp;s=nmkWhPL5akypjR2NuDV1rGsjfnzy0cMwFTc6DljTNLA&amp;e=), [Container Journal](https://urldefense.proofpoint.com/v2/url?u=https-3A__containerjournal.com_2019_07_16_pivotal-2Dsoftware-2Dembraces-2Dkubernetes_&amp;d=DwMGaQ&amp;c=lnl9vOaLMzsy2niBC8-h_K-7QJuNJEsFrzdndhuJ3Sw&amp;r=HNaEFhtuH9k7pH023_PQLQ&amp;m=Dm_L-EU0Cj9GYRR86q6DKNZKjh987nlPsM-_-o4_AdU&amp;s=_HAFWbcG2YCTgh_9WKGtB35pASH9Xx0v2-9SNkVWcCM&amp;e=), [SiliconANGLE](https://urldefense.proofpoint.com/v2/url?u=https-3A__siliconangle.com_2019_07_16_pivotal-2Dlets-2Ddevelopers-2Dgo-2Dkubernetes-2Dnew-2Dapplication-2Dservice_&amp;d=DwMGaQ&amp;c=lnl9vOaLMzsy2niBC8-h_K-7QJuNJEsFrzdndhuJ3Sw&amp;r=HNaEFhtuH9k7pH023_PQLQ&amp;m=Dm_L-EU0Cj9GYRR86q6DKNZKjh987nlPsM-_-o4_AdU&amp;s=zp6rndnU4hRY6pqXxzTBJ7Ta5ka1pSapoNhO3ltmpBA&amp;e=), [Storage Review](https://urldefense.proofpoint.com/v2/url?u=https-3A__www.storagereview.com_pivotal-5Fannounces-5Falpha-5Fpas-5Fon-5Fkubernetes&amp;d=DwMGaQ&amp;c=lnl9vOaLMzsy2niBC8-h_K-7QJuNJEsFrzdndhuJ3Sw&amp;r=HNaEFhtuH9k7pH023_PQLQ&amp;m=Dm_L-EU0Cj9GYRR86q6DKNZKjh987nlPsM-_-o4_AdU&amp;s=KXYZlfGxqtmZ8SxG1Lxbxifn8vR_ikcKTJhxgTP5RzA&amp;e=), [The New Stack](https://urldefense.proofpoint.com/v2/url?u=https-3A__thenewstack.io_the-2Dpivotal-2Dapplication-2Dservice-2Daddresses-2Dkubernetes-2Dcomplexity_&amp;d=DwMGaQ&amp;c=lnl9vOaLMzsy2niBC8-h_K-7QJuNJEsFrzdndhuJ3Sw&amp;r=HNaEFhtuH9k7pH023_PQLQ&amp;m=Dm_L-EU0Cj9GYRR86q6DKNZKjh987nlPsM-_-o4_AdU&amp;s=V_N831y8xq8tN4C22uWzyRVazEMo5jeH2I_UWkXLTHI&amp;e=), and [ZDNet](https://urldefense.proofpoint.com/v2/url?u=https-3A__www.zdnet.com_article_pivotal-2Dfully-2Dembraces-2Dkubernetes_&amp;d=DwMGaQ&amp;c=lnl9vOaLMzsy2niBC8-h_K-7QJuNJEsFrzdndhuJ3Sw&amp;r=HNaEFhtuH9k7pH023_PQLQ&amp;m=Dm_L-EU0Cj9GYRR86q6DKNZKjh987nlPsM-_-o4_AdU&amp;s=nkU6qz4ibApb19l12jVYGvMwOsku1373gohti28olLg&amp;e=). Pretty cool!\\r\\n\\r\\nBefore we move on to the update from the core team and our wonderful community, a reminder that prices for [RabbitMQ Summit](https://rabbitmqsummit.com/) go up on August 22, so get your tickets now!\\r\\n\\r\\nYou can add on RabbitMQ training to your ticket—basic and advanced courses are available. Great talks planned from Bloomberg,\\r\\nWeWork, Softonic, the Erlang Solutions and CloudAMQP teams, as well as the core RabbitMQ engineers, of course.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [RabbitMQ 3.7.17](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.17) has been released with a bunch of bug fixes\\r\\n* [Pika 1.1.0](https://github.com/pika/pika/blob/master/CHANGELOG.rst#110-2019-07-16) is released\\r\\n* [Reactor RabbitMQ 1.3.0.M2](https://groups.google.com/d/msg/rabbitmq-users/dt16lIszpT4/w-6VkX6_BwAJ) was released as part of the Reactor Dysprosium-M3 release train. Lots of goodies in this pre-release!\\r\\n* [Java client 5.7.3](https://groups.google.com/d/msg/rabbitmq-users/qYaF5DoUXzI/qmWLCQc4BgAJ) (for Java 8+) and [4.11.3](https://groups.google.com/d/msg/rabbitmq-users/exRMdS-7NwQ/GmDoryE3BgAJ) (for Java 6 &amp; 7) are released with a bug fix and upgrades of optional dependencies (along with 5.7.2 and 4.11.2)\\r\\n* [php-amqplib 2.10.0-rc.1](https://github.com/php-amqplib/php-amqplib/releases/tag/v2.10.0-rc1) is out\\r\\n* [JMS client 1.12.0](https://groups.google.com/d/msg/rabbitmq-users/TYd0c9ioJCs/WcLmsvLSBQAJ) is released with a bug fix and dependency upgrades\\r\\n* [Hop 3.3.0](https://groups.google.com/d/msg/rabbitmq-users/61mZ_wbyctE/AUa5zaQ5BgAJ) is released with new features, bug fixes and dependency upgrades.\\r\\n* [Erlang 20.3 support retirement schedule](https://groups.google.com/forum/#!searchin/rabbitmq-users/ANN|sort:date/rabbitmq-users/9tc_OE1eMPk/ly1NEISwBwAJ) is announced.\\r\\nPlease upgrade to [Erlang 22 or at least 21.3.x](/docs/which-erlang) soon!\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\n* July 2: Adam Johnson (@AdamChainz) reblogged about [Celery, RabbitMQ, and Warrens](https://adamj.eu/tech/2019/07/02/celery-rabbits-and-warrens/)\\r\\n* July 4: Chetan Khatri (@khatri_chetan) published about how to [set up an Airflow multi-node cluster with Celery &amp; RabbitMQ](https://www.accionlabs.com/articles/2019/7/4/how-to-setup-airflow-multi-node-cluster-with-celery-amp-rabbitmq)\\r\\n* July 4: Chung Khanh Duy (@duychung) wrote about [creating work queue(s) with Spring Boot and RabbitMQ](https://medium.com/@chungkhanhduy/create-work-s-queue-with-spring-and-rabbitmq-978cad149672)\\r\\n* July 4: Mirko Maggiano (@magmir) published about [configuring TLS support in RabbitMQ](https://mirkomaggioni.com/2019/07/04/rabbitmq-tls-configuration/)\\r\\n* July 5: Thiago Adriano (@programadriano) wrote about [creating workers with Node.js and RabbitMQ](https://www.mundojs.com.br/2019/07/05/rabbitmq-criando-workers-com-node-js/#page-content) (in Portuguese)\\r\\n* July 5: Mirko Maggioni (@magmir) wrote about [monitoring RabbitMQ](https://mirkomaggioni.com/2019/07/05/monitoring-rabbitmq/)\\r\\n* July 9: Sakthi Saravanan (@sakthis02) published an [introduction to RabbitMQ](https://medium.com/@sakthishanmugam02/rabbitmq-an-introduction-b84370fcf31)\\r\\n* July 11: Alexy da Cruz (@geomtech9) wrote about [monitoring RabbitMQ with Grafana and Telegraf](https://alexydacruz.fr/monitoring/monitorer-rabbitmq-grace-a-grafana-et-telegraf/) (in French)\\r\\n* July 13: Rémi Goyard (@mimiz33) wrote about [the road to microservices with Node.js events and RabbitMQ](https://medium.com/@rgoyard/road-to-microservices-with-node-js-events-and-rabbitmq-17acd4b199f3)\\r\\n* July 14: Renato Groffe () published an update about [using .NET Core 2.2 with ASP.NET Core 2.2 and RabbitMQ](https://medium.com/@renato.groffe/net-core-2-2-asp-net-core-2-2-rabbitmq-exemplos-utilizando-mensageria-deb54ce63713) (in Portugese)\\r\\n* July 15: Sakthi Saravanan (@sakthis02) explains [RabbitMQ connections vs channels](https://medium.com/@sakthishanmugam02/rabbitmq-connection-vs-channel-aed1188a7f3a)\\r\\n* July 16: Code Sync published Ayanda Dube’s (@dube_aya) talk on [Innovative unorthodox design patterns used in RabbitMQ](https://www.youtube.com/watch?v=zYN9L8xZ4CU&amp;feature=youtu.be)\\r\\n* July 16: Tarun Batra wrote about [polling reliably at scale using dead lettering](https://blog.smallcase.com/polling-reliably-at-scale-using-dlqs/)\\r\\n* July 17: Genny Paudice published about [high availability with RabbitMQ](https://www.blexin.com/it-IT/Article/Blog/Alta-affidabilit-con-RabbitMQ-47) (in Italian)\\r\\n* July 17: Rafael Honorio wrote a [getting started with RabbitMQ article](https://medium.com/@rafael.hs/rabbitmq-primeiros-passos-ae092d34a31f) in Portuguese\\r\\n* July 17: The team at Royal Cyber (@RoyalCyberUSA) published about [integrating Dell Boomi with RabbitMQ](http://blog.royalcyber.com/middleware/integrating-dell-boomi-with-rabbitmq/)\\r\\n* July 20: Teerapong Singthong (@iamgoangle) wrote about [interesting best practices with RabbitMQ](https://medium.com/iamgoangle/%E0%B8%AA%E0%B8%B4%E0%B9%88%E0%B8%87%E0%B8%97%E0%B8%B5%E0%B9%88%E0%B8%99%E0%B9%88%E0%B8%B2%E0%B8%AA%E0%B8%99%E0%B9%83%E0%B8%88%E0%B9%80%E0%B8%81%E0%B8%B5%E0%B9%88%E0%B8%A2%E0%B8%A7%E0%B8%81%E0%B8%B1%E0%B8%9A-rabbitmq-%E0%B9%81%E0%B8%A5%E0%B8%B0-amqp-best-practices-108f6076c330) (in Thai)\\r\\n* July 24: Matthew Harper () published the first part in a series about [getting started with .NET Core, Docker, and RabbitMQ](https://medium.com/trimble-maps-engineering-blog/getting-started-with-net-core-docker-and-rabbitmq-part-1-a62601e784bb)\\r\\n* July 24: Shivam Aggarwal (@shivama205) wrote about [RabbitMQ best practices](https://medium.com/@shivama205/rabbitmq-best-practices-67a27ef72a57)\\r\\n* July 25: Ryan Ermita (@ryanermita) published about [learning RabbitMQ](https://medium.com/ryans-dev-notes/learning-rabbitmq-3f59d11f66b4) in order to migrate from using Redis as a message broker as he adopts a microservices architecture\\r\\n* July 25: Gerhard Lazu (@gerhardlazu) shared his slides from his talk, “[Make Your System Observable](https://gerhard.io/slides/observable-systems-alpha/#/) - early preview of Observe and Understand RabbitMQ, one of the many RabbitMQ Summit talks\\r\\n* July 27: Dmitriy Larionov (@larionov_pro) wrote about [why you would use RabbitMQ in a microservices architecture](https://larionov.pro/en/articles/2019/msa-rabbitmq-why/)\\r\\n* July 27: Sajjad Hassanzadeh (@hassanzadeh_sd)  published [Celery and RabbitMQ in Django, Monitoring with Flower](https://medium.com/@hassanzadeh.sd/celery-and-rabbitmq-in-django-just-couple-of-steps-to-get-async-working-and-monitoring-with-flower-707dcd7254e8)\\r\\n* July 29: TekLoon () wrote a step-by-step guide to [building event-driven microservices with RabbitMQ](https://medium.com/better-programming/a-step-by-step-guide-to-building-event-driven-microservices-with-rabbitmq-deeb85b3031c)\\r\\n* July 29: Sergey Valuy (@Smartum_Pro) published about [using RabbitMQ in a messenger app architecture](https://dev.to/smartym/how-to-use-rabbitmq-for-building-a-messenger-app-architecture-19ma)\\r\\n\\r\\nWe also came across this article in the International Journal of Research Studies in Computer Science and Engineering (IJRSCSE) on [Distributing Messages Using Rabbitmq with Advanced Message Exchanges](https://www.arcjournals.org/pdfs/ijrscse/v6-i2/4.pdf)\\r\\n\\r\\n## Events and Training Courses\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* 12 September 2019, Bern: DevOps Meetup on [Observability and DevOps Value Stream Mapping](https://www.meetup.com/DevOps-Bern/events/262813160/) with RabbitMQ core team member Gerhard Lazu\\r\\n* 30 September 2019, NYC: [RabbitMQ Express](https://codesync.global/conferences/code-beam-lite-nyc/training/)\\r\\n* 4 November 2019, London, UK: [RabbitMQ Summit](https://rabbitmqsummit.com/)\\r\\n* 5-6 November 2019, London, UK: Various [trainings available as part of the RabbitMQ Summit](https://rabbitmqsummit.com/#training)\\r\\n* On-demand, online from LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online from Udemy: [Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online: $40 buys you early access to Marco Behler’s course, [Building a real-world Java and RabbitMQ messaging application](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)"},{"id":"/2019/07/09/this-month-in-rabbitmq-july-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/07/09/this-month-in-rabbitmq-july-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-07-09-this-month-in-rabbitmq-july-2019/index.md","source":"@site/blog/2019-07-09-this-month-in-rabbitmq-july-2019/index.md","title":"This Month in RabbitMQ — July 2019","description":"Welcome back for another edition of This Month in RabbitMQ! In June, we saw the RabbitMQ Summit agenda start to go live, featuring some great returning speakers as well as new faces. There are also a couple of training sessions offered to add onto your ticket. It’s a great way to immerse yourself in all things RabbitMQ for a couple of days. Registration is open, so book your tickets now before the prices go up in August!","date":"2019-07-09T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":3.15,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — July 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — August 2019","permalink":"/rabbitmq-website/blog/2019/08/12/this-month-in-rabbitmq-august-2019"},"nextItem":{"title":"This Month in RabbitMQ — June 2019","permalink":"/rabbitmq-website/blog/2019/06/06/this-month-in-rabbitmq-june-2019"}},"content":"Welcome back for another edition of This Month in RabbitMQ! In June, we saw the [RabbitMQ Summit](https://rabbitmqsummit.com/) agenda start to go live, featuring some great returning [speakers](https://rabbitmqsummit.com/#speakers) as well as new faces. There are also a couple of [training sessions](https://rabbitmqsummit.com/#training) offered to add onto your ticket. It’s a great way to immerse yourself in all things RabbitMQ for a couple of days. Registration is open, so book your tickets now before the prices go up in August!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [RabbitMQ 3.7.16](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.16) has been released with bug fixes, usability improvements and new `rabbitmq-diagnostics` commands\\r\\n* [PerfTest 2.8.1](https://groups.google.com/d/msg/rabbitmq-users/Lwmhc3zJzFo/nF1psWltAQAJ) was released with a couple of bug fixes\\r\\n* [Reactor RabbitMQ 1.3.0.M1](https://github.com/reactor/reactor-rabbitmq/releases/tag/v1.3.0.M1) was released as part of the Reactor Dysprosium-M2 release train. More goodies to come in the next few weeks!\\r\\n* [March Hare](https://github.com/ruby-amqp/march_hare/) 4.0 was released, now based on the 5.7.x series of the RabbitMQ Java client\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\nJune 5: Vermaden (@vermaden) wrote about [setting up RabbitMQ cluster on FreeBSD Jails](https://vermaden.wordpress.com/2019/06/05/rabbitmq-cluster-on-freebsd-containers/)\\r\\n\\r\\nJune 5: Josh Smeaton (@jarshwah) of Kogan published about [monitoring Celery queue length with RabbitMQ](https://devblog.kogan.com/blog/celery-queue-length)\\r\\n\\r\\nJune 7: Emre Tiryaki (@emrtryki) from Hepsiburada published about [event ordering with RabbitMQ using the consistent hash exchange](https://medium.com/hepsiburadatech/rabbitmq-ile-event-ordering-consistent-hash-exchange-kullan%C4%B1m%C4%B1-cf45b7292e53) (in Turkish)\\r\\n\\r\\nJune 8: Cleison Ferreira Melo (Cleison Ferreira Melo) wrote another installment of his series on building a microservices application, [focused on the RabbitMQ container and connection](https://medium.com/@cleisonferreiramelo/the-journey-to-building-a-full-microservice-app-rabbitmq-container-and-connection-9ea39ba8fa7d)\\r\\n\\r\\nJune 8: Jose Alonso Romero Matias published a four-part video series (in Spanish) showing how to create a messaging project that emulates the sending of invoices through a service, using RabbitMQ: [part 1,](https://www.youtube.com/watch?v=lkvu1BVB064&amp;feature=youtu.be) [part 2](https://www.youtube.com/watch?v=IPF-Xt1noz0) on dependency injection with RabbitMQ, [part 3](https://www.youtube.com/watch?v=o0U7XGYA32w) on creating and testing the invoice handler,  [part 4](https://www.youtube.com/watch?v=8nk_pSlVBps)\\r\\n\\r\\nJune 9: Gilles Robert (@ask4gilles) released [v2.0.3 of @opentracing Spring RabbitMQ](https://github.com/opentracing-contrib/java-spring-rabbitmq) with a bunch of new instrumented methods on AmqpTemplate and documentation improvements\\r\\n\\r\\nJune 11: Marco Behler (@MarcoBehler) published a video on [How to Consume RabbitMQ Messages From Queues With Java](https://www.youtube.com/watch?v=BS7tY-Exo0w)\\r\\n\\r\\nJune 13: Maksim Martianov wrote about [Kubernetes worker autoscaling based on RabbitMQ queue depth](https://itnext.io/kubernetes-workers-autoscaling-based-on-rabbitmq-queue-size-cb0803193cdf)\\r\\n\\r\\nJune 14: [Bartha Bela Tibor](https://medium.com/@beeci) published about [RabbitMQ in Docker with Alpine Linux](https://medium.com/@beeci/rabbitmq-integrated-in-docker-container-with-alpine-linux-fdceb4768d01)\\r\\n\\r\\nJune 17: [Rafael Capuano](https://medium.com/@rafacapuano) published (in Portuguese) a three-part series on the external configuration store pattern, using RabbitMQ for  configuration change propagation: [part 1](https://medium.com/@rafacapuano/conhecendo-o-external-configuration-store-pattern-parte-1-contextualizando-fa7285e20860) on contextualizing, [part 2](https://medium.com/@rafacapuano/conhecendo-o-external-configuration-store-pattern-parte-2-criando-a-api-2f1e3b91017c) on creating the API, and [part 3](https://medium.com/@rafacapuano/conhecendo-o-external-configuration-store-pattern-parte-3-criando-o-client-56f2d118a66e) on creating the client\\r\\n\\r\\nJune 18: Ram N. [published a video and resource links](https://dzone.com/articles/how-to-sendreceive-product-object-tofrom-queuespri) on how to send and receive product objects to or from a queue\\r\\n\\r\\nJune 19: IBM published a tutorial on [invoking serverless functions through a message broker](https://developer.ibm.com/tutorials/build-serverless-app-drives-workload-through-message-broker/)\\r\\n\\r\\nJune 23: Karol Galanciak (@Azdaroth) published the third part in a series on [Messages on Rails](https://karolgalanciak.com/blog/2019/06/23/messages-on-rails-part-3-rabbitmq/), this one focused on RabbitMQ\\r\\n\\r\\nJune 25: Dhananjay Singh wrote about [Spring Cloud Stream with RabbitMQ: Message-Driven Microservices](https://stackabuse.com/spring-cloud-stream-with-rabbitmq-message-driven-microservices/)\\r\\n\\r\\nJune 27: Ranga Karanam () published on DZone about [Asynchronous Communication With Queues and Microservices](https://dzone.com/articles/asynchronous-communication-with-queues-and-microse): A Perfect Combination?\\r\\n\\r\\nJune 28: Davide Guida (@DavideGuida82) published the first in a series on [using message queues in .NET Core](https://www.davideguida.com/it/usare-code-di-messaggi-in-net-core-parte-1-le-code/) (in Italian)\\r\\n\\r\\nJune 29: Teerapong Singthong (@iamgoangle) wrote about [Go Messaging System with RabbitMQ](https://medium.com/iamgoangle/go-messaging-system-%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-rabbitmq-%E0%B9%81%E0%B8%A5%E0%B8%B0-go-amqp-9e2e88051f5b) and RabbitMQ client for Go (in Thai)\\r\\n\\r\\nJune 30: Md. Al-Amin published about [Solving RabbitMQ High CPU/Memory Usages Problem With Celery](https://medium.com/@alaminopu.me/solving-rabbitmq-high-cpu-memory-usages-problem-with-celery-d4172ba1c6b3)\\r\\n\\r\\n### Ready to learn more?\\r\\n\\r\\nCheck out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\n* 9 July 2019, Krakow, Poland: [High Availability with RabbitMQ](https://www.meetup.com/Elixir-Krakow/events/262472450/) at Krakow Elixir meetup\\r\\n* 4 November 2019, London, UK: [RabbitMQ Summit 2019](https://rabbitmqsummit.com/)\\r\\n* 5-6 November 2019 in London, UK: various [training sessions available as part of the RabbitMQ Summit](https://rabbitmqsummit.com/#training)\\r\\n* On-demand, online on LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online on Udemy: [RabbitMQ : Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)\\r\\n* Online: $40 buys you early access to Marco Behler’s course, [Building a real-world Java and RabbitMQ messaging applications](https://www.marcobehler.com/courses/30-building-a-real-world-java-and-rabbitmq-messaging-amqp-application)"},{"id":"/2019/06/06/this-month-in-rabbitmq-june-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/06/06/this-month-in-rabbitmq-june-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-06-06-this-month-in-rabbitmq-june-2019/index.md","source":"@site/blog/2019-06-06-this-month-in-rabbitmq-june-2019/index.md","title":"This Month in RabbitMQ — June 2019","description":"Welcome back for another edition of This Month in RabbitMQ! Keep sharing your war stories and lessons learned out there,","date":"2019-06-06T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":3.12,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — June 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — July 2019","permalink":"/rabbitmq-website/blog/2019/07/09/this-month-in-rabbitmq-july-2019"},"nextItem":{"title":"This Month in RabbitMQ — May 2019","permalink":"/rabbitmq-website/blog/2019/05/13/this-month-in-rabbitmq-may-2019"}},"content":"Welcome back for another edition of This Month in RabbitMQ! Keep sharing your war stories and lessons learned out there,\\r\\nand tweet them with #rabbitMQ to get them on our radar for inclusion in these write-ups.\\r\\n\\r\\nAs we march towards RabbitMQ 3.8 going GA, be sure to catch the replay of the webinar we did last month on [what’s new in RabbitMQ 3.8](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_source=blog&amp;utm_medium=email-link&amp;utm_campaign=rabbitmq-3.8-what\'s-new&amp;utm_term=q219).\\r\\n\\r\\n[Jack Vanlightly](https://jack-vanlightly.com/home) also did some coverage on the [Single Active Consumer](https://www.cloudamqp.com/blog/2019-04-23-rabbitmq-3-8-feature-focus-single-active-consumer.html) feature in 3.8, adding to his earlier coverage on [Quorum Queues](https://jack-vanlightly.com/blog/2018/11/20/quorum-queues-making-rabbitmq-more-competitive).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [RabbitMQ 3.7.15](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.15) was released, includes initial support for Erlang 22\\r\\n* [Erlang 22 is now GA](http://www.erlang.org/news/132) with a new inter-node communication implementation and initial TLSv1.3 server support\\r\\n* Erlang 22.0.2 and 21.3.8.3 were released, addressing [ERL-934](https://bugs.erlang.org/browse/ERL-934) and [ERL-938](https://bugs.erlang.org/browse/ERL-938), an issue that affected RabbitMQ environments that used TLS and had a high data ingestion volume.\\r\\n* [RabbitMQ Docker image](https://github.com/docker-library/rabbitmq) has [transitioned to use Erlang 22](https://github.com/docker-library/rabbitmq/issues/336)\\r\\n* [PerfTest 2.8.0](https://groups.google.com/d/msg/rabbitmq-users/1mN4olzZOgA/MjH-4kLoAwAJ) has been released with lots of goodies: new options to vary message size and publishing rate, optional polling consumers (instead of asynchronous consumers by default), optionally nack messages instead of acking them, and dependency upgrades\\r\\n* [Java client 5.7.1](https://groups.google.com/d/msg/rabbitmq-users/PDHubBIzhEc/k6qx5zLdAwAJ) (for Java 8+) and [4.11.1](https://groups.google.com/d/msg/rabbitmq-users/eg_FoB8eyMY/Xre89S7dAwAJ) (for Java 6 &amp; 7) have been released with a bug fix\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\nMay 1: Denis Orehovsky ([@apirobotme](https://twitter.com/apirobotme)) published about [Distributed systems with RabbitMQ.](https://apirobot.me/blog//posts/distributed-systems-with-rabbitmq)\\r\\n\\r\\nMay 1: Sam Bently ([@sambentley00](https://twitter.com/sambentley00)) published about [Building An External Rabbitmq Service For VCloud Director](https://beardedsamwise.wordpress.com/2019/05/01/building-an-external-rabbitmq-service-for-vcloud-director/), with particular attention to SSL requirements.\\r\\n\\r\\nMay 1: [Nerengen Babu](https://medium.com/@nerengenbabu) published [Integrating RabbitMQ with SpringBoot Application](https://medium.com/@nerengenbabu/integrating-rabbitmq-with-springboot-application-reciever-part-ad8b0f90cdb9) (Receiver Part).\\r\\n\\r\\nMay 5: Chetan Khatri (@khatri_chetan)wrote about How to [Setup Airflow Multi-Node Cluster with Celery &amp; RabbitMQ](https://medium.com/@khatri_chetan/how-to-setup-airflow-multi-node-cluster-with-celery-rabbitmq-cfde7756bb6a)\\r\\n\\r\\nMay 6: [mastanggt](https://habr.com/users/mastanggt/) wrote about [migrating RabbitMQ to/within Kubernetes](https://habr.com/ru/company/flant/blog/450662/) (in Russian).\\r\\n\\r\\nMay 8: Nikita wrote about [RabbitMQ Fetching Remote Data](https://dvelp.co.uk/articles/rabbitmq), particularly in Rails.\\r\\n\\r\\nMay 10: Jacques Roussel published about [Using the Ansible Operator-sdk To Build A RabbitMQ Operator for Kubernetes](https://www.objectif-libre.com/en/blog/2019/05/10/using-the-operator-sdk-to-build-a-rabbitmq-operator/).\\r\\n\\r\\nMay 10: [Aamer Mohammed](https://medium.com/@aamermail) compares several different messaging technologies, including RabbitMQ, in the context of [Asynchronous communication in Microservices](https://medium.com/@aamermail/asynchronous-communication-in-microservices-14d301b9016).\\r\\n\\r\\nMay 13: [Jind?ich Hrabal](https://medium.com/@jindrich.hrabal) ([@Backglite](https://twitter.com/Backglite)) published on [Dead Letter Queue Reprocessing with Spring Integration and RabbitMQ](https://medium.com/zoom-techblog/dead-letter-queue-reprocessing-a2c041f64e65).\\r\\n\\r\\nMay 14: [Prashant Vats](https://medium.com/@prashant.vats) published on [Kubernetes pod autoscaling in response to the change in the RabbitMQ queue](https://medium.com/@prashant.vats/kubernetes-pod-autoscaling-in-response-to-the-change-in-the-rabbitmq-queue-3048b02413ef).\\r\\n\\r\\nMay 14: [Francisco Cardoso](https://medium.com/@francardoso) published about [what’s different in AMQP 1.0 compared to AMQP 0-9-1](https://medium.com/totvsdevelopers/diferen%C3%A7as-do-amqp-1-0-para-as-vers%C3%B5es-anteriores-9db828cc9e3e) (in Portugese).\\r\\n\\r\\nMay 17: [Lakmini Wathsala](https://medium.com/@wathsalakoralege) published [How to integrate WSO2 EI with RabbitMQ](https://medium.com/@wathsalakoralege/how-to-integrate-wso2-ei-with-rabbitmq-without-passing-credentials-from-address-uri-31f2453bcf0b) without passing credentials from address URI.\\r\\n\\r\\nMay 20: [Lukasz Lenart](https://medium.com/@lukaszlenart) ([@lukaszlenart](https://twitter.com/lukaszlenart)?) published on [How to configure RabbitMQ via definitions](https://medium.com/@lukaszlenart/how-to-configure-rabbitmq-properly-fa39b2d4cda2).\\r\\n\\r\\nMay 24: Jeroen Jacobs ([@jeroen1205](https://twitter.com/jeroen1205)) wrote about [troubleshooting sync issues with classic mirrored queues](https://tothepoint.group/blog/rabbitmq-mirrored-queues-troubleshooting-sync-issues/).\\r\\n\\r\\nMay 24: Lovisa Johansson ([@lillajja](https://twitter.com/lillajja)) answered the question \\"[What is the message size limit in RabbitMQ](https://www.cloudamqp.com/blog/2019-05-24-what-is-the-message-size-limit-in-rabbitmq.html)?\\"\\r\\n\\r\\nMay 24: [Ryan Gunn](https://talkdotnet.wordpress.com/author/icidis/) ([@Icidis](https://twitter.com/Icidis)) published about [Blazor, RabbitMQ and MQTT using Paho with JSInterop](https://talkdotnet.wordpress.com/2019/05/24/blazor-rabbitmq-and-mqtt-using-paho-with-jsinterop/).\\r\\n\\r\\nMay 27: [Marcela Sisiliani](https://medium.com/@marcelasisiliani) ([@ma_sisiliani](https://twitter.com/ma_sisiliani)) wrote an [introduction to the world of queues](https://medium.com/@marcelasisiliani/rabbitmq-introducao-ao-mundo-das-filas-9d959e169519) (in Portugese).\\r\\n\\r\\nMay 28: Hervé Beraud ([@4383hberaud](https://twitter.com/4383hberaud)) published about [How To Play With RabbitMQ And Python Quickly](https://herve.beraud.io/rabbitmq/python/amqp/kombu/2019/05/28/play-with-rabbitmq-and-python.html).\\r\\n\\r\\nMay 28: Jack Vanlightly ([@vanlightly](https://twitter.com/vanlightly)) wrote about [Maintaining Long-Lived Connections with AMQProxy](https://www.cloudamqp.com/blog/2019-05-29-maintaining-long-lived-connections-with-AMQProxy.html) and about [Publishing Throughput - Asynchronous vs Synchronous](https://www.cloudamqp.com/blog/2019-05-29-publishing-throughput-asynchronous-vs-synchronous.html).\\r\\n\\r\\nMay 28: Tomas Henriquez (@Hassek85) published about [how he sets up RabbitMQ clusters to scale](https://hassek.github.io/#rabbitmq-cluster-setup-guideline), noting using the consistent hash plugin and mirrored queues .\\r\\n\\r\\nMay 29: [Mohamed Elhachmi](https://medium.com/@mohamedelhachmi) published about [Efficient design for daemons tasks](https://medium.com/async-solutions/efficient-design-for-daemons-tasks-afcbc2c02732).\\r\\n\\r\\nMay 29: [Denis Setianto](https://medium.com/@denissetianto) published [How to Install RabbitMQ Server on Ubuntu 18.04 &amp; 16.04](https://medium.com/@denissetianto/how-to-install-rabbitmq-server-on-ubuntu-18-04-16-04-lts-8ca63b417d43) LTS.\\r\\n\\r\\n## Ready to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n6 June 2019, online: [Boosting Microservice Performance with Messaging and Spring](https://content.pivotal.io/webinars/jun-6-boosting-microservice-performance-with-kafka-rabbitmq-and-spring-webinar?utm_campaign=spring-kafka-rabbitmq-q219&amp;utm_source=twitter&amp;utm_medium=social).\\r\\n\\r\\n4 November 2019: London: [RabbitMQ Summit 2019](https://rabbitmqsummit.com/).\\r\\n\\r\\nOn-demand, online: LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring).\\r\\n\\r\\nOn-demand, online: Udemy: [RabbitMQ: Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)."},{"id":"/2019/05/13/this-month-in-rabbitmq-may-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/05/13/this-month-in-rabbitmq-may-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-05-13-this-month-in-rabbitmq-may-2019/index.md","source":"@site/blog/2019-05-13-this-month-in-rabbitmq-may-2019/index.md","title":"This Month in RabbitMQ — May 2019","description":"Couple of key public service announcements this month. First, the deadline for submitting a talk for RabbitMQ Summit 2019 (5 November in London UK) was May 10. We had a great line-up last year at the inaugural event and we’re looking forward to an even better event this fall.","date":"2019-05-13T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.935,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — May 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — June 2019","permalink":"/rabbitmq-website/blog/2019/06/06/this-month-in-rabbitmq-june-2019"},"nextItem":{"title":"Simplifying rolling upgrades between minor versions with feature flags","permalink":"/rabbitmq-website/blog/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags"}},"content":"Couple of key public service announcements this month. First, the deadline for [submitting a talk for RabbitMQ Summit 2019](https://rabbitmqsummit.com/) (5 November in London UK) was May 10. We had a great line-up last year at the inaugural event and we’re looking forward to an even better event this fall.\\r\\n\\r\\nThen, on May 23, we’ll be doing an overview of [what’s new in RabbitMQ 3.8](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_source=blog&amp;utm_medium=email-link&amp;utm_campaign=rabbitmq-3.8-what\'s-new&amp;utm_term=q219) (beta 4 of which [has dropped recently](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0-beta.4)). Whether you’re a couple versions behind, or on [the latest](/release-information) 3.7.14 release, you’re going to want to learn about the latest features and changes.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [RabbitMQ 3.7.15-beta.1](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.15-beta.1) is available for community testing\\r\\n* And so is [3.8.0-beta.4](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0-beta.4).\\r\\n* Team RabbitMQ has published an overview of a new [feature flag subsystem](/blog/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags) shipping in RabbitMQ 3.8. The purpose of this subsystem is to simplify rolling upgrades between releases that have incompatible or potentially incompatible changes.\\r\\n* [RabbitMQ Docker image](https://github.com/docker-library/rabbitmq) now ships RabbitMQ 3.7.14 and 3.7.15-beta.1 on latest Erlang and OpenSSL 1.1.1b\\r\\n* [Java client 5.7.0](https://groups.google.com/d/msg/rabbitmq-users/-BhkggixlsU/w5P3_geiBAAJ) (for Java 8+) and [4.11.0](https://groups.google.com/d/msg/rabbitmq-users/du44LNT4zRU/OWlPdgCiBAAJ) (for Java 6 &amp; 7) have been released with usability improvements and dependency upgrades.\\r\\n* [Reactor RabbitMQ 1.2.0 GA](https://groups.google.com/d/msg/rabbitmq-users/e4fE-9X-QKs/porAB9GiBAAJ) has been released, with a bug fix, dependency upgrades, and improvements in the publisher confirms support. [Reactor RabbitMQ](https://github.com/reactor/reactor-rabbitmq)) is a reactive API for RabbitMQ based on [Reactor](http://projectreactor.io/) and RabbitMQ Java client. Reactor RabbitMQ goal is to enable messages to be published to and consumed from RabbitMQ using functional APIs with non-blocking back-pressure and very low overhead.\\r\\n* Debian and RPM packages of several latest Erlang and Elixir releases are now available in Team RabbitMQ\'s [Erlang Bintray repository](https://bintray.com/rabbitmq-erlang/)\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\n* The CloudAMQP team published an article by Jack Vanlightly ([@vanlightly](https://twitter.com/vanlightly)) on [Quorum Queues Internals—A deep dive](https://www.cloudamqp.com/blog/2019-04-03-quorum-queues-internals-a-deep-dive.html). This is a continuation to their [post on quorum queues](https://www.cloudamqp.com/blog/2019-03-28-rabbitmq-quorum-queues.html) from March.\\r\\n* Thanks to Gavin Roy ([@crad](https://twitter.com/Crad)), [RabbitPy 2.0 now available](https://pypi.org/project/rabbitpy/)\\r\\n* Pankaj Panigrahi ([@pnkjPanigrahi](https://twitter.com/pnkjPanigrahi)) published on [Implementing RabbitMQ with Node.JS](https://medium.com/@pankaj.panigrahi/implementing-rabbitmq-with-node-js-93e15a44a9cc)\\r\\n* Simon Benitez over at Erlang Solutions published on how RabbitMQ is used as for [inter-service communication in an open source continuous delivery system](https://www.erlang-solutions.com/blog/ex_rabbit_pool-open-source-amqp-connection-pool.html)\\r\\n* Anthony Valentin wrote about [a tool for visualizing RabbitMQ topology and metrics, called AliceMQ](https://medium.com/@90valentin/visualizing-your-rabbitmq-instance-with-alicemq-787a422c03de)\\r\\n* Jason Farrell ([@jfarrell](https://twitter.com/jfarrell)) shared a demo of a [.NET Core Hosted Service](https://github.com/xximjasonxx/kubedemo) feeding stock price data into RabbitMQ and via PubSub communicating to a .NET Core Web app via @SignalR, all running in Kubernetes\\r\\n* [In French] Zwindler wrote about RabbitMQ basics and best practices [RabbitMQ basics and best practices](https://blog.zwindler.fr/2019/04/16/suivez-le-lapin-orange-intro-et-bonnes-pratiques-dinfra-rabbitmq/)\\r\\n* Bart?omiej Klimczak ([@kabanek](https://twitter.com/kabanek)) shared some [lessons learned from using RabbitMQ](https://medium.com/@bartlomiej.kielbasa/learning-on-mistakes-ff88532b259) as the heart of the platform used by the Brainly team\\r\\n* Odelucca ([@_odelucca](https://twitter.com/_odelucca)) published the second part of his series on [building a recommendation algorithm using Python and RabbitMQ](https://medium.com/@odelucca/recommendation-algorithm-using-python-and-rabbitmq-part-2-connecting-with-rabbitmq-aa0ec933e195)\\r\\n* Muutech published about the [importance of monitoring a messaging system like RabbitMQ](https://www.muutech.com/en/message-queues-today/), using an automotive supplier example\\r\\n* Vitaliy Samofal wrote the first part of [an introduction to messaging technologies](https://freshcodeit.com/blog-introduction-to-message-brokers-part-1-apache-kafka-vs-rabbitmq), focused on comparing RabbitMQ and Apache Kafka (also [published on HackerNoon](https://hackernoon.com/introduction-to-message-brokers-part-1-apache-kafka-vs-rabbitmq-8fd67bf68566))\\r\\n* HelloFresh updated [Kandalf](https://github.com/hellofresh/kandalf), a RabbtiMQ-Kafka bridge\\r\\n\\r\\n## Ready to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* 16-17 May 2019 — Stockholm — See Karl Nilsson and Ayanda Dube speak about RabbitMQ at [Code BEAM](https://codesync.global/conferences/code-beam-sto-2019/)\\r\\n* 23 May 2019 — Online Webinar: [What’s new in RabbitMQ 3.8](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_source=blog&amp;utm_medium=email-link&amp;utm_campaign=rabbitmq-3.8-what\'s-new&amp;utm_term=q219)\\r\\n* 5 November 2019 — London — [RabbitMQ Summit](https://rabbitmqsummit.com/)\\r\\n* On-demand, online at LearnFly: [Learn RabbitMQ Asynchronous Messaging with Java and Spring](https://www.learnfly.com/learn-rabbitmq-asynchronous-messaging-with-java-and-spring)\\r\\n* On-demand, online at Udemy: RabbitMQ: [Messaging with Java, Spring Boot And Spring MVC](https://www.udemy.com/rabbitmq-messaging-with-java-spring-boot-and-spring-mvc/)"},{"id":"/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags","metadata":{"permalink":"/rabbitmq-website/blog/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-04-23-simplifying-rolling-upgrades-between-minor-versions-with-feature-flags/index.md","source":"@site/blog/2019-04-23-simplifying-rolling-upgrades-between-minor-versions-with-feature-flags/index.md","title":"Simplifying rolling upgrades between minor versions with feature flags","description":"In this post we will cover feature flags, a new subsystem in RabbitMQ 3.8. Feature flags will allow a rolling cluster upgrade to the next minor version, without requiring all nodes to be stopped before upgrading.","date":"2019-04-23T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.725,"hasTruncateMarker":true,"authors":[{"name":"Jean-Sébastien Pédron","url":"https://github.com/dumbbell","imageURL":"https://github.com/dumbbell.png","key":"jpedron","page":null}],"frontMatter":{"title":"Simplifying rolling upgrades between minor versions with feature flags","tags":["New Features"],"authors":["jpedron"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — May 2019","permalink":"/rabbitmq-website/blog/2019/05/13/this-month-in-rabbitmq-may-2019"},"nextItem":{"title":"This Month in RabbitMQ — April 3, 2019","permalink":"/rabbitmq-website/blog/2019/04/03/this-month-in-rabbitmq-april-3-2019"}},"content":"In this post we will cover **[feature flags](/docs/feature-flags)**, a new subsystem in RabbitMQ 3.8. Feature flags will allow a rolling cluster upgrade to the next minor version, without requiring all nodes to be stopped before upgrading.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Minor Version Upgrades Today: RabbitMQ 3.6.x to 3.7.x\\r\\n\\r\\nIt you had to upgrade a cluster from RabbitMQ 3.6.x to 3.7.x, you probably had to use one of the following solutions:\\r\\n\\r\\n* Deploy a new cluster alongside the existing one (this strategy is known as the [blue-green deployment](/docs/blue-green-upgrade)), then migrate data & clients to the new cluster\\r\\n* Stop all nodes in the existing cluster, upgrade the last node that was stopped first, then continue upgrading all other nodes, one-by-one\\r\\n\\r\\nBlue-green deployment strategy is low risk but also fairly complex to automate. On the other hand, a cluster-wide shutdown affects availability. Feature flags are meant to provide a 3rd option by making rolling cluster upgrades possible and reasonably easy to automate.\\r\\n\\r\\n## The Feature Flags Subsystem\\r\\n\\r\\nFeature flags indicate a RabbitMQ node\'s capabilities to its cluster peers. Previously nodes used versions to assess compatibility with cluster versions. There are many ways in which nodes in a distributed system can become incompatible, including Erlang and dependency versions. Many of those aspects are not reflected in a set of version numbers. Feature flags is a better approach as it can reflect more capabilities of a node, whether it is a particular feature or internal communication protocol revision. In fact, with some message protocols RabbitMQ supports clients have a mechanism for clients to indicate their capabilities. This allows client libraries to evolve and be upgraded independently of RabbitMQ nodes.\\r\\n\\r\\nFor example, RabbitMQ 3.8.0 introduces a new queue type, [quorum queues](/docs/quorum-queues). To implement them, an internal data structure and a database schema were modified. This impacts the communication with other nodes because the data structure is exchanged between nodes, and internal data store schema is replicated to all nodes.\\r\\n\\r\\nWithout the feature flags subsystem, it would be impossible to have a RabbitMQ 3.8.0 node inside a cluster where other nodes are running RabbitMQ 3.7.x. Indeed, the 3.7.x nodes would be unable to understand the data structure or the database schema from 3.8.0 node. The opposite is also true. That\'s why RabbitMQ today prevents this from happening by comparing versions and by denying clustering when versions are considered incompatible (the policy considers different minor/major versions to be incompatible).\\r\\n\\r\\nNew in RabbitMQ 3.8.0 is the feature flags subsystem: when a single node in a 3.7.x cluster is upgraded to 3.8.0 and restarted, it will not immediately enable the new features or migrate its database schema because the feature flags subsystem told it not to. It could determine this because RabbitMQ 3.7.x supports no feature flags at all, therefore new features or behaviours in RabbitMQ 3.8.0 cannot be used before all nodes in the cluster are upgraded.\\r\\n\\r\\nAfter a partial upgrade of a cluster to RabbitMQ 3.8.0, all nodes are acting as 3.7.x nodes with regards to incompatible features, even the 3.8.0 one. In this situation, quorum queues are unavailable. Operator must finish the upgrade by upgrading all nodes. When that is done, the operator can decide to enable the new feature flags provided by RabbitMQ 3.8.0: one of them enables quorum queues. This is done using RabbitMQ CLI tools or [management UI](/docs/management) and supposed to be performed by deployment automation tools. The idea is that the operator needs to confirm that her cluster doesn\'t have any remaining RabbitMQ 3.7.x nodes that might rejoin the cluster at a later point.\\r\\n\\r\\nOnce a new feature flag is enabled, it is impossible to add a node that runs an older version to that cluster.\\r\\n\\r\\n## Demo with RabbitMQ 3.8.0\\r\\n\\r\\nLet\'s go through a complete upgrade of a RabbitMQ 3.7.x cluster. We will take a look at the feature flags in the process.\\r\\n\\r\\nWe have the following 2-node cluster running RabbitMQ 3.7.12:\\r\\n\\r\\n![](01-list-of-nodes-on-node-A-running-3.7.x.png)\\r\\n\\r\\nWe now upgrade node A to RabbitMQ 3.8.0 and restart it. Here is what the management overview page looks like after the node is restarted:\\r\\n\\r\\n![](02-list-of-nodes-on-node-A-running-3.8.x.png)\\r\\n\\r\\nWe can see the difference of versions in the list of nodes: their version is displayed just below their node name.\\r\\n\\r\\nThe list of feature flags provided by RabbitMQ 3.8.0 is now available in the management UI on node A:\\r\\n\\r\\n![](03-list-of-feature-flags-on-node-A-running-3.8.x.png)\\r\\n\\r\\nThis page will not exist on node B because it is still running RabbitMQ 3.7.12.\\r\\n\\r\\nOn node A, we see that the `quorum_queue` feature flag is marked as `Unavailable`. The reason is that node B (still running RabbitMQ 3.7.12) does not known about `quorum_queue` feature flag, therefore node A is not allowed to use that new feature flag. This feature flag cannot be enabled until all nodes in the cluster support it.\\r\\n\\r\\nFor instance, we could try to declare a quorum queue on node A, but it is denied:\\r\\n\\r\\n![](04-quorum-queue-declare-denied-on-node-A-running-3.8.x.png)\\r\\n\\r\\nAfter node B is upgraded, feature flags are available and they can be enabled. We proceed and enable `quorum_queue` by clicking the `Enable` button:\\r\\n\\r\\n![](05-quorum_queue-feature-flag-enabled-on-node-B-running-3.8.x.png)\\r\\n\\r\\nNow, we can declare a quorum queue:\\r\\n\\r\\n![](06-quorum-queue-declare-accepted-on-node-A-running-3.8.x.png)\\r\\n\\r\\n## To Learn More\\r\\n\\r\\nThe [Feature Flags subsystem documentation](/docs/feature-flags) describes in greater details how it works and what operators and plugin developers should pay attention to.\\r\\n\\r\\nNote that feature flags are not a guarantee that a cluster shutdown will never be required for upgrades in the future: the ability to implement a change using a feature flag depends on the nature of the change, and is decided on a case-by-case basis. Correct behaviour of a distributed system may require that all of its components behave in a certain way, and sometimes that means that they have to be upgraded in lockstep.\\r\\n\\r\\nPlease give feature flags a try and let us know what you think on the [RabbitMQ mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users)!"},{"id":"/2019/04/03/this-month-in-rabbitmq-april-3-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/04/03/this-month-in-rabbitmq-april-3-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-04-03-this-month-in-rabbitmq-april-3-2019/index.md","source":"@site/blog/2019-04-03-this-month-in-rabbitmq-april-3-2019/index.md","title":"This Month in RabbitMQ — April 3, 2019","description":"RabbitMQ 3.8 is coming! If you haven’t already played with the beta (version 3 is now available), it’s time to start familiarizing yourself with what’s coming. Karl Nilsson and I will present on a webinar in May to walk through what’s new, so please register and attend.","date":"2019-04-03T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":3.095,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — April 3, 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Simplifying rolling upgrades between minor versions with feature flags","permalink":"/rabbitmq-website/blog/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags"},"nextItem":{"title":"This Month in RabbitMQ — March 7, 2019","permalink":"/rabbitmq-website/blog/2019/03/08/this-month-in-rabbitmq-march-7-2019"}},"content":"RabbitMQ 3.8 is coming! If you haven’t already played with the beta ([version 3](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0-beta.3) is now available), it’s time to start familiarizing yourself with what’s coming. Karl Nilsson and I will present on a webinar in May to walk through what’s new, so please [register](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_source=blog&amp;utm_medium=email-link&amp;utm_campaign=rabbitmq-3.8-what\'s-new&amp;utm_term=q219) and attend.\\r\\n\\r\\nWe are also starting to look forward to the next [RabbitMQ Summit,](https://rabbitmqsummit.com/) once again in London this coming November. The [call for talks is open until May 10](https://eventil.com/events/rabbitmq-summit-2019/cfp), so please consider sharing how you are using RabbitMQ or something you have tried and learned and want to share with the community.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* [RabbitMQ 3.7.14](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.14) is out.\\r\\n* Erlang packages produced by Team RabbitMQ now use a [separate Bintray org](https://bintray.com/rabbitmq-erlang/). The packages will [removed from the main Bintray org](https://groups.google.com/forum/#!msg/rabbitmq-users/Gu55prdJ7uM/tftnTT_ZAwAJ) on April 29th, 2019. See [Debian](/docs/install-debian) and [RPM](https://github.com/rabbitmq/erlang-rpm) installation instructions to learn how to set up the new repositories.\\r\\n* Pika, the most popular Python client for RabbitMQ, [shipped version 1.0](https://groups.google.com/d/msg/rabbitmq-users/1wuoQYNg9QY/5uH33h15AQAJ)\\r\\n* [php-amqplib 2.9.1](https://groups.google.com/d/topic/rabbitmq-users/ks4kk-raJAw/discussion) is now available\\r\\n* New [documentation guide on Runtime Tuning](/docs/runtime) is live.\\r\\n* [Hop 3.2.0](https://github.com/rabbitmq/hop) has been released with usability changes and dependency upgrades.\\r\\n* [PerfTest 2.7.0](https://groups.google.com/d/msg/rabbitmq-users/v2V0YI_tifg/fuEbtY6hBQAJ) has been released, with dependency upgrades.\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\n* Updates to [OpenTracing for Spring and RabbitMQ](https://github.com/opentracing-contrib/java-spring-rabbitmq)\\r\\n* Ahmad Kamil Almasyhur published an introduction to [RabbitMQ in the context of microservices](https://medium.com/@ahmadkamilalmasyhur/rabbitmq-what-is-that-10c74ac7620a) and the single responsibility principle\\r\\n* Ilya Khaprov ([@dead_trickster](https://twitter.com/dead_trickster)) released a new version of [RabbitMQ metrics exporter for Prometheus](https://github.com/deadtrickster/prometheus_rabbitmq_exporter/releases/tag/v3.7.2.5)\\r\\n* Bartosz Szafran ([@bartosz_szafran](https://twitter.com/bartosz_szafran) ) [dissects RabbitMQ’s topic exchanges](https://www.erlang-solutions.com/blog/rabbit-s-anatomy-understanding-topic-exchanges.html)\\r\\n* Robert Witkowski ([@rwitkowski_asc](https://twitter.com/rwitkowski_asc)) published on [Micronaut with RabbitMQ Integration](https://altkomsoftware.pl/en/blog/micronaut-rabbitmq/)\\r\\n* Jonas Neustock ([@NeustockJonas](https://twitter.com/NeustockJonas)) wrote about [how to use RabbitMQ with the constraints of operating behind a firewall](https://medium.com/@jonasbusse/how-to-build-an-on-premise-connection-with-rabbitmq-821f4e9a7d62) or on a corporate network\\r\\n* Mark Heckler ( [@mkheck](https://twitter.com/mkheck)) shared the scripts/config he uses to spin up/down Docker containers for RabbitMQ &amp; Apache Kafka to use in his [talk series on Spring Cloud Stream](https://github.com/mkheck/LocalMessaging)\\r\\n* John Canassa (**@john_canessa**) wrote about an experiment with a work queue [using RabbitMQ on a Windows 10 machine](http://www.johncanessa.com/2019/03/11/rabbitmq-work-queues/)\\r\\n* Lee Conlin ([@hades200082](https://twitter.com/hades200082) ?) published a three-part series on Kentico (a .NET-based CMS) and RabbitMQ integration: [part 1](https://medium.com/distinctionuk/kentico-rabbitmq-integration-part-1-outbound-integration-7c1cdb15b38a), [part 2](https://medium.com/distinctionuk/kentico-rabbitmq-integration-part-2-inbound-integration-592e550f82b2), [part 3](https://medium.com/distinctionuk/kentico-rabbitmq-integration-part-3-external-workers-4b34b370a5ec)\\r\\n* Piotr Nosek and Mateusz Bartkowiak published about how [MongoooseIM 3.3.0 adds support for RabbitMQ integration](https://www.erlang-solutions.com/blog/mongooseim-3-3-0-supporting-happy-relations.html)\\r\\n* Igor Kuznetsov ([@igkuz](https://twitter.com/igkuz)), CTO at Setka, wrote about their collection of analytics for web sites and how this requires rate limiting on outgoing requests to avoid being mislabeled as a DDoS attack and banned. He then describes [how they use RabbitMQ dead letter exchange for retries and scheduled tasks](https://medium.com/@igkuz/ruby-retry-scheduled-tasks-with-dead-letter-exchange-in-rabbitmq-9e38aa39089b)\\r\\n* Curtis Strain wrote about [publishing to RabbitMQ from AWS Lambda](https://medium.com/learningsam/publish-to-rabbitmq-from-aws-lambda-cdb66f9f35c5) and [consuming a RabbitMQ message from Lambda](https://medium.com/@curtis.strain/consume-a-rabbitmq-message-from-aws-lambda-b82953a6b1f6)\\r\\n* Simon Seller wrote about building a [machine learning-powered system that uses RabbitMQ](https://aptira.com/machine-learning-rabbitmq/), detecting and reporting anomalies both as they arrive and when they are fixed\\r\\n* Simone Pezzano ([@theirish81](https://twitter.com/theirish81)) published about the [architecture of API Fortress](https://medium.com/@simone.pezzano/a-digital-symphony-the-architecture-of-api-fortress-f2ad70ea5ffe), including how RabbitMQ and Akka are used\\r\\n* Odelucca ([@_odelucca](https://twitter.com/_odelucca)) published the first in a series about [building a recommendation algorithm using Python and RabbitMQ](https://medium.com/@odelucca/python-recommendation-algorithm-using-rabbitmq-part-1-bc94a27f8034)\\r\\n* Guilherme Caminha ([@GPKCaminha](https://twitter.com/GPKCaminha)) wrote an introduction to [Python microservices with Nameko](https://www.toptal.com/python/introduction-python-microservices-nameko), which is built with RabbitMQ\\r\\n* Berguiga Mohamed Amine outlined a hands-on lab for [getting started with RabbitMQ and Spring](https://medium.com/@m.a.berguiga/hand-on-labs-for-rabbitmq-e765354ea064)\\r\\n\\r\\n## Upcoming Courses and Webinars\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ\\r\\n\\r\\n* 9 April 2019 — Live/Online — [Pivotal Academy course on RabbitMQ](https://academy.pivotal.io/confirm-course?courseid=EDU-1099)\\r\\n* 15 April 2019 — London — [FLEX course on RabbitMQ](https://www.flane.co.uk/course-schedule/pivotal-rmq)\\r\\n* 16-17 May 2019 — Stockholm — See Karl Nilsson and Ayande Dube speak about RabbitMQ at [Code BEAM](https://codesync.global/conferences/code-beam-sto-2019/)\\r\\n* 23 May 2019 — Online — Webinar: [What’s new in RabbitMQ 3.8](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_source=blog&amp;utm_medium=email-link&amp;utm_campaign=rabbitmq-3.8-what\'s-new&amp;utm_term=q219)\\r\\n* 5 November 2019 — London — [RabbitMQ Summit](https://rabbitmqsummit.com/)"},{"id":"/2019/03/08/this-month-in-rabbitmq-march-7-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/03/08/this-month-in-rabbitmq-march-7-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-03-08-this-month-in-rabbitmq-march-7-2019/index.md","source":"@site/blog/2019-03-08-this-month-in-rabbitmq-march-7-2019/index.md","title":"This Month in RabbitMQ — March 7, 2019","description":"Welcome back for another issue of This Month in RabbitMQ. Did you know that RabbitMQ was the seventh highest paying tech skill in 2018? AND, that average pay grew a healthy 5.3% since 2017. It’s no wonder that we keep seeing more folks in the community sharing how they are getting started—or getting better—with RabbitMQ. In that spirit, read on for the latest project updates, community writings, and upcoming trainings!","date":"2019-03-08T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.505,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — March 7, 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — April 3, 2019","permalink":"/rabbitmq-website/blog/2019/04/03/this-month-in-rabbitmq-april-3-2019"},"nextItem":{"title":"This Month in RabbitMQ — Feb 7, 2019","permalink":"/rabbitmq-website/blog/2019/02/07/this-month-in-rabbitmq-feb-7-2019"}},"content":"Welcome back for another issue of This Month in RabbitMQ. Did you know that [RabbitMQ was the seventh highest paying tech skill in 2018](https://www.zdnet.com/article/best-paying-programming-languages-skills-here-are-the-top-earners/)? AND, that average pay grew a healthy 5.3% since 2017. It’s no wonder that we keep seeing more folks in the community sharing how they are getting started—or getting better—with RabbitMQ. In that spirit, read on for the latest project updates, community writings, and upcoming trainings!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project updates\\r\\n\\r\\n* The [third beta of RabbitMQ 3.8](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0-beta.3) is available now, featuring more work on Raft-based [Quorum Queues](/docs/quorum-queues) and [Feature Flags](/docs/feature-flags) for mixed version clusters. Give it a try and  share feedback on the mailing list.\\r\\n* [RabbitMQ 3.7.13](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.13) is here, with bug fixes and minor usability improvements.\\r\\n* Pika had two new releases: [1.0.0-beta.2](https://github.com/pika/pika/releases/tag/1.0.0b2) and [0.13.1](https://github.com/pika/pika/releases/tag/0.13.1)\\r\\n* php-amqplib [2.9.0-beta.1 is out](https://github.com/php-amqplib/php-amqplib/releases/tag/v2.9.0-beta.1)\\r\\n* [RabbitMQ Chef Cookbook 5.7.0](https://github.com/rabbitmq/chef-cookbook/blob/v5.x/CHANGELOG.md#v570-2019-03-06) was released.\\r\\n*  [PerfTest 2.6.0](https://groups.google.com/d/msg/rabbitmq-users/8fQJsVhpj54/zFhna2-HGAAJ) has been released, with dependency updates, brand new Ubuntu-based Docker image, and updated Alpine-based Docker image.\\r\\n* Hop 3.1.1 GA has been released with a bug fix. [Hop](https://github.com/rabbitmq/hop) is a RabbitMQ HTTP API client for Java, Groovy, and other JVM languages.\\r\\n* Several long deprecated Bintray repositories [were removed](https://groups.google.com/d/msg/rabbitmq-users/Wv6MBRGO9rc/IOIfBaIYBwAJ).\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\n* Shuo-Huan Chang released [rmqctl](https://github.com/vsdmars/rmqctl/), an alternative management tool for RabbitMQ inspired by [kubectl](https://kubernetes.io/docs/reference/kubectl/overview/)\\r\\n* Rohit Kelapure (@RKela) shares [useful guidance and links](http://cloud.rohitkelapure.com/2019/02/how-healthy-is-your-rabbit.html) on creating a healthy RabbitMQ, noting that most of the performance problems are generated by the application, and rarely due to misconfiguration of RabbitMQ\\r\\n* Lukasz Lenart (@lukaszlenart) shared [learnings on configuring RabbitMQ](https://blog.softwaremill.com/this-month-at-softwaremill-weve-learned-january-19-c4c7c622141b)\\r\\n* Robert Witkowski (@rwitkowski_asc) shares [an architecture for insurance sales portal with RabbitMQ and Micronaut](https://github.com/asc-lab/micronaut-microservices-poc/tree/rabbitmq)\\r\\n* Stephen Miller of East Texas Software (@ETX_Software) published a [Docker and C# RabbitMQ \\"Hello World\\" example](https://www.easttexassoftware.com/post/docker-c-rabbitmq-hello-world)\\r\\n* Alok Singhal published (again!), this time on [Monitoring RabbitMQ with Prometheus and Grafana](https://medium.com/@aloksinghal/monitoring-rabbitmq-with-prometheus-and-grafana-302f9ad7d87)\\r\\n* John Reese (@johnpreese) shares [Rabbit Viz](https://github.com/plexsystems/rabbit-viz), a tool for visualizing RabbitMQ broker definitions\\r\\n* Kashish Verma wrote about [Reusing Connections Lambda Functions](https://medium.com/walkin/reusing-connections-lambda-functions-poc-1eb8068fd1db) (POC)\\r\\n* Radwan Nizam published a tutorial on [MQTT Client Load Balancing With RabbitMQ and Spring Cloud](https://dzone.com/articles/mqtt-client-load-balancing-with-rabbitmq-and-sprin)\\r\\n* Alex from Konstankino (@konstankino) published on [RabbitMQ for Inter-Process Communications](https://medium.com/@konstankino/rabbitmq-for-inter-process-communications-7a2e3ed7ac43)\\r\\n* Abu Ashraf Masnun (@masnun) published [Work queue with Go and RabbitMQ](https://medium.com/@masnun/work-queue-with-go-and-rabbitmq-b8c295cde861)\\r\\n* Gago.io published a [Q&amp;A on RabbitMQ](https://gago.io/blog/rabbitmq-amqp-4-qna/) (in Portuguese)\\r\\n* Tom Ketels wrote about how [RabbitMQ for Magento is now available on Hypernode](https://www.hypernode.com/blog/performance/now-available-on-hypernode-rabbitmq-for-magento)\\r\\n* Krishna Kumar Dey explains the basics of Celery with an example of [Setting Up a task Queue using Celery and RabbitMQ](https://medium.com/@krishnadey30/setting-up-a-task-queue-using-celery-and-rabbitmq-e73f8fd15de0)\\r\\n* Catcher Wong (@catcherwong) wrote about [Consuming RabbitMQ Messages In ASP.NET Core](https://www.c-sharpcorner.com/article/consuming-rabbitmq-messages-in-asp-net-core/)\\r\\n* Artem Rys (@) writes about using [RabbitMQ Scrapy Item Publisher in Python](https://medium.com/python4you/rabbitmq-scrapy-item-publisher-in-python-4c66a985e3cb)\\r\\n\\r\\n## Training\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\n* 21 March 2019, Bologna: RabbitMQ training at [CodeBEAM Italy](https://codesync.global/conferences/code-beam-lite-italy/#training)\\r\\n* 9 April 2019, Live/Online: Pivotal Academy [course on Pivotal RabbitMQ](https://academy.pivotal.io/confirm-course?courseid=EDU-1099)\\r\\n* 15 April 2019, London: [Fast Lane course on RabbitMQ](https://www.flane.co.uk/course-schedule/pivotal-rmq)\\r\\n* 16-17 May 2019, Stockholm: See Karl Nilsson and Ayande Dube speak about RabbitMQ at [Code BEAM Stockholm](https://codesync.global/conferences/code-beam-sto-2019/)"},{"id":"/2019/02/07/this-month-in-rabbitmq-feb-7-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/02/07/this-month-in-rabbitmq-feb-7-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-02-07-this-month-in-rabbitmq-feb-7-2019/index.md","source":"@site/blog/2019-02-07-this-month-in-rabbitmq-feb-7-2019/index.md","title":"This Month in RabbitMQ — Feb 7, 2019","description":"Welcome back for another issue of This Month in RabbitMQ. Hopefully you are finding this new series helpful to keep up with the latest project updates and community topics. As we look across the different articles published throughout the month, it’s clear that it truly has a polyglot community. From Spring and .NET, to Ruby and Node.js, there are active users of RabbitMQ out there writing in many different languages. It’s a polyglot world, and we’re connecting it all together!","date":"2019-02-07T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.67,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — Feb 7, 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — March 7, 2019","permalink":"/rabbitmq-website/blog/2019/03/08/this-month-in-rabbitmq-march-7-2019"},"nextItem":{"title":"This Month in RabbitMQ — Jan 8, 2019","permalink":"/rabbitmq-website/blog/2019/01/08/this-month-in-rabbitmq-jan-8-2019"}},"content":"Welcome back for another issue of This Month in RabbitMQ. Hopefully you are finding this new series helpful to keep up with the latest project updates and community topics. As we look across the different articles published throughout the month, it’s clear that it truly has a polyglot community. From Spring and .NET, to Ruby and Node.js, there are active users of RabbitMQ out there writing in many different languages. It’s a polyglot world, and we’re connecting it all together!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n* [RabbitMQ 3.7.11](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.11) is available. It focuses on bug fixes and minor usability improvements. In particular, this release adds several new [rabbitmq-diagnostics](/docs/man/rabbitmq-diagnostics.8) commands useful for diagnostics and health checks. This is also the first release to require Erlang/OTP 20.3.\\r\\n* [Second beta](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.8.0-beta.2) of RabbitMQ 3.8.0 is also out. [Quorum queues](/docs/quorum-queues) are now more stable, polished, and support more features. Give them a try!\\r\\n* [RabbitMQ Docker image](https://hub.docker.com/_/rabbitmq) now provides the latest RabbitMQ and Erlang. The image is also [automatically updated](https://github.com/docker-library/rabbitmq/pull/305) when new RabbitMQ and Erlang releases come out.\\r\\n* The Docker image now can be used to easily [test RabbitMQ 3.8.0 beta releases](https://github.com/docker-library/rabbitmq/pull/302).\\r\\n* [Reactor RabbitMQ 1.1.0](https://groups.google.com/d/msg/rabbitmq-users/x3L2HPWuP1Y/5OH2iZmyFwAJ) GA has been released, with bug fixes, dependency upgrades, and new features.\\r\\n* [Java client 5.6.0](https://groups.google.com/d/msg/rabbitmq-users/y20hnH1ZnMA/fpchrvR1FgAJ) for (Java 8+) and [4.10.0](https://groups.google.com/d/msg/rabbitmq-users/Fl8MdG2ZfeU/wJoSROd1FgAJ) for (Java 6 &amp; 7) have been released with bug fixes and new features.\\r\\n* Hop 3.1.0 GA has been released with a new feature and dependency upgrade. [Hop](https://github.com/rabbitmq/hop) is a RabbitMQ HTTP API client for Java, Groovy, and other JVM languages.\\r\\n* [JMS client 1.10.2](https://groups.google.com/d/msg/rabbitmq-users/AvTbZgiQFa8/jIADaoNoFwAJ) has been released with a bug fix.\\r\\n* [Monitoring doc guide](/docs/monitoring) has been expanded with a new section on health checks\\r\\n* CLI tools now provide a [range of progressive health checks](https://github.com/rabbitmq/rabbitmq-cli/issues/292) that operators can use individually or in combination\\r\\n* [OpenSUSE repositories were updated](https://groups.google.com/forum/#!msg/rabbitmq-users/4azFra05kFI/Ha8jN1tEGAAJ) to provide most recent RabbitMQ and Erlang versions\\r\\n\\r\\n## Community writings and resources\\r\\n\\r\\n* [Jayakrishnan](https://twitter.com/that_coder) published about [getting started with RabbitMQ and Node.js](https://thatcoder.space/getting-started-with-rabbitmq-and-node-js/)\\r\\n* [Jason Goldberg](https://twitter.com/betashop) noted how RabbitMQ is a \\"key element\\" of the OST KIT in [Inside the OST Technology Stack as We Prepare for Pilot Launches](https://medium.com/ostdotcom/inside-the-ost-technology-stack-as-we-prepare-for-pilot-launches-bcab8e87598e)\\r\\n* [Wander Costa](https://twitter.com/rwanderc) published on the MyTaxi engineering blog about [using Spring Boot with multiple RabbitMQ Brokers](https://inside.mytaxi.com/springboot-with-multiple-rabbitmq-brokers-cec203c3f77)\\r\\n* Alok Singhal published about [RabbitMQ Queues — High Availability and Migration](https://medium.com/@aloksinghal/rabbitmq-queues-high-availability-and-migration-d75d63e1199a)\\r\\n* Julio Falbo published on [Different types of RabbitMQ Exchanges](https://medium.com/devopslinks/different-types-of-rabbitmq-exchanges-9fefd740505d)\\r\\n* Tr?n Ti?n ??c highlights the importance of error handling in his post [RabbitMQ EventBus system](https://medium.com/linagora-engineering/rabbitmq-eventbus-system-b159f46704be)\\r\\n* [Daniel Battaglia](https://twitter.com/daniel_bytes) published how Kontena builds [Event-Driven Microservices with RabbitMQ and Ruby](https://ghost.kontena.io/event-driven-microservices-with-rabbitmq-and-ruby/)\\r\\n* Akshay Patel published on [.NET Core Web API Logging Using NLog In RabbitMQ](https://www.c-sharpcorner.com/article/net-core-web-api-logging-using-nlog-in-rabbitmq/)\\r\\n* Java In Use published a post and video on how to [Build a Chat Application using Spring Boot + WebSocket + RabbitMQ](https://www.javainuse.com/spring/boot-websocket-chat)\\r\\n* [Lovisa Johansson](https://twitter.com/lillajja) &amp; [Elin Vinka](https://twitter.com/linneajohanna) published a case study about how Softonic is using RabbitMQ in an [event-based microservices architecture to support 100 million users a month](https://www.cloudamqp.com/blog/2019-01-18-softonic-userstory-rabbitmq-eventbased-communication.html)\\r\\n* [Robert Novotny](https://twitter.com/RoboNovotny) published [Enforcing Spring Cloud Contracts Over AMQP](https://novotnyr.github.io/scrolls/enforcing-spring-cloud-contracts-over-amqp/)\\r\\n\\r\\n## Upcoming Events\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\n* 25 February 2019 — [Pivotal RabbitMQ Course](https://www.flane.co.uk/course-schedule/pivotal-rmq) — Ljubljana/Online\\r\\n* 15 April 2019 — [Pivotal RabbitMQ Course](https://www.flane.co.uk/course-schedule/pivotal-rmq) — London"},{"id":"/2019/01/08/this-month-in-rabbitmq-jan-8-2019","metadata":{"permalink":"/rabbitmq-website/blog/2019/01/08/this-month-in-rabbitmq-jan-8-2019","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2019-01-08-this-month-in-rabbitmq-jan-8-2019/index.md","source":"@site/blog/2019-01-08-this-month-in-rabbitmq-jan-8-2019/index.md","title":"This Month in RabbitMQ — Jan 8, 2019","description":"Happy New Year! Welcome back for another installment of This Month in RabbitMQ. Between running a webinar and publishing a new page,","date":"2019-01-08T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.79,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ — Jan 8, 2019","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — Feb 7, 2019","permalink":"/rabbitmq-website/blog/2019/02/07/this-month-in-rabbitmq-feb-7-2019"},"nextItem":{"title":"This Month in RabbitMQ, November 2018","permalink":"/rabbitmq-website/blog/2018/12/04/this-month-in-rabbitmq-dec-4-2018"}},"content":"Happy New Year! Welcome back for another installment of This Month in RabbitMQ. Between running a webinar and publishing a new page,\\r\\nwe made a lot of progress in promoting RabbitMQ \\"best practices\\" in December. Watch for more content to help everyone in\\r\\nthe Rabbit community know how to run Rabbit smoothly.\\r\\n\\r\\nThere were plenty of other great developments from RabbitMQ engineering, including 1.0 of Reactor RabbitMQ,\\r\\nand great insights shared across the community. Read on!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n* RabbitMQ 3.7.10 [has been released](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.10)\\r\\n* Erlang 19.3 support [has been discontinued](https://groups.google.com/forum/#!msg/rabbitmq-users/G4UJ9zbIYHs/qCeyjkjyCQAJ) for future RabbitMQ releases\\r\\n* Reactor RabbitMQ 1.0.0 GA [has been released](https://groups.google.com/forum/#!msg/rabbitmq-users/FJ4UgMrr3-Q/xQDEGxlrCAAJ). [Reactor RabbitMQ](https://github.com/reactor/reactor-rabbitmq) is a reactive API for RabbitMQ based on [Reactor](http://projectreactor.io) and RabbitMQ Java client. Reactor RabbitMQ goal is to enable messages to be published to and consumed from RabbitMQ using functional APIs with non-blocking back-pressure and very low overhead.\\r\\n* [Java client 5.5.2](https://groups.google.com/d/msg/rabbitmq-users/Wk1T3iZBJR4/Y4lLTGXVDgAJ) (for Java 8+) and [4.9.2](https://groups.google.com/d/msg/rabbitmq-users/8Gef5g-KNRU/o8mQEl7VDgAJ) (for Java 6 &amp; 7) have been released.\\r\\n* PerfTest 2.5.0 [has been released](https://groups.google.com/d/msg/rabbitmq-users/9AycV2eEC0s/UvE2StsrDwAJ) with lot of goodies: new publisher confirm latency metrics, dependency upgrades, new Linux native executable created with [GraalVM](https://www.graalvm.org/), and new Docker image.\\r\\n* New [doc guide on connections](/docs/connections)\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* All the [videos from the RabbitMQ Summit](https://www.youtube.com/channel/UCp20sSF_JZv5aqpxICo-ZpQ/videos) are posted!\\r\\n* [Lovisa Johansson](https://twitter.com/lillajja) published an [Introduction to Message Queuing and RabbitMQ on Manifold](https://blog.manifold.co/introduction-to-message-queuing-and-rabbitmq-6cb8e6e9b2)\\r\\n* Adrian Huna of Showmax published [Building a scalable, highly reliable, asynchronous user service](https://tech.showmax.com/2018/12/building-scalable-highly-reliable-asynchronous-user-service/), explaining how they leverage RabbitMQ to orchestrate the delivery of the GDPR data access report and data erasure in a microservices architecture.\\r\\n* [Lovisa Johansson](https://twitter.com/lillajja) shared some data about how [43% of all clusters at CloudAMQP are now running RabbitMQ 3.7](https://www.cloudamqp.com/blog/2018-12-03-rabbitmq-version-distribution-on-cloudamqp.html)\\r\\n* [Gabriele Santomaggio](https://twitter.com/GSantomaggio) shared an [example on GitHub](https://github.com/Gsantomaggio/rabbitmqexample/tree/master/vagrant_cluster) for creating a RabbitMQ cluster using Vagrant\\r\\n* The Runtastic team published on [Handling Dead Letters in RabbitMQ Using a Dead-Letter Exchange](https://www.runtastic.com/blog/en/message-bus-dead-letter-exchange/)\\r\\n* [Elin Vinka](https://twitter.com/linneajohanna) summarized [key takeaways from RabbitMQ Summit 2018](https://www.cloudamqp.com/blog/2018-12-14-rabbitmqsummit-2018-recap.html)\\r\\n* Fabrizio Micheloni walks through using the fanout exchange (with a handy example project) in his post, [Topic-like architecture with RabbitMQ and Spring Boot](https://medium.com/@fabrizio.micheloni1994/topic-like-architecture-with-rabbitmq-and-spring-boot-c5f73b27f098)\\r\\n* IBM announced [General Availability of IBM Cloud Messages for RabbitMQ](https://www.ibm.com/blogs/bluemix/2018/12/ibm-cloud-databases-for-etcd-elasticsearch-and-messages-for-rabbitmq-are-now-generally-available/)\\r\\n* Roman Pyatyshev of MegaFon published on Habr about [building a highly-available architecture with RabbitMQ](https://habr.com/post/434016/) for one of Russia’s largest telcos (in Russian)\\r\\n* [Onur Destanoglu](https://twitter.com/Feralan_Paladin) of Hapsiburada published [Migrating RabbitMQ in a High Traffic Setup](https://medium.com/hepsiburadatech/migrating-rabbitmq-in-a-high-traffic-setup-39d73fcc8b04)\\r\\n* Also from the Hepsiburada team, Ahmet Vehbi Olgac published on [Implementing Highly Available RabbitMQ Cluster on Docker Swarm using Consul-based Discovery](https://medium.com/hepsiburadatech/implementing-highly-available-rabbitmq-cluster-on-docker-swarm-using-consul-based-discovery-45c4e7919634). He notes that \\"We used this infrastructure during this year’s Black Friday, and had zero problems.\\"\\r\\n* [Piotr Minkowski](https://twitter.com/piotr_minkowski) published a post on setting up a [RabbitMQ Cluster with Consul and Vault](https://piotrminkowski.wordpress.com/2018/12/27/rabbitmq-cluster-with-consul-and-vault/)\\r\\n* On DZone, [Ramesh Fadatare](https://twitter.com/FadatareRamesh) published [How RabbitMQ Works and RabbitMQ Core Concept](https://dzone.com/articles/how-rabbitmq-works-and-rabbitmq-core-concepts-1) \\r\\n* Alok Singhal published [RabbitMQ Best Practices — Part 1](https://medium.com/@aloksinghal/rabbitmq-best-practices-part-1-6f66522e4fe)\\r\\n* [CodeSync](https://twitter.com/CodeMeshIO) published a talk by Daniil Fedotov from Code Mesh LDN 18 about [implementing Raft in RabbitMQ](https://youtu.be/1ntKuapkqq4)\\r\\n* Rick van de Loo explains [how to use RabbitMQ on Hypernode](https://support.hypernode.com/changelog/platform/release-6052-rabbitmq-on-hypernode/)\\r\\n\\r\\n## Upcoming Events\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\n* 22 January 2019 — [Pivotal RabbitMQ Course](https://pivotal.io/training/courses/pivotal-rabbitmq-training)\\r\\n* 25 February 2019 — [Pivotal RabbitMQ Course](https://www.flane.co.uk/course-schedule/pivotal-rmq) — Ljubljana/Online\\r\\n* 27 February 2019 — [RabbitMQ Express at Code Beam SF](https://codesync.global/conferences/code-beam-sf-2019/#Training) — San Francisco\\r\\n* 15 April 2019 — [Pivotal RabbitMQ Course](https://www.flane.co.uk/course-schedule/pivotal-rmq) — London"},{"id":"/2018/12/04/this-month-in-rabbitmq-dec-4-2018","metadata":{"permalink":"/rabbitmq-website/blog/2018/12/04/this-month-in-rabbitmq-dec-4-2018","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2018-12-04-this-month-in-rabbitmq-dec-4-2018/index.md","source":"@site/blog/2018-12-04-this-month-in-rabbitmq-dec-4-2018/index.md","title":"This Month in RabbitMQ, November 2018","description":"Hello RabbitMQ friends! Welcome to the first installment of This Month in RabbitMQ, inspired by the wonderful and industrious Josh Long, who publishes monthly and weekly recaps for the Spring community.","date":"2018-12-04T00:00:00.000Z","tags":[{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates"}],"readingTime":2.47,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"This Month in RabbitMQ, November 2018","tags":["Updates"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ — Jan 8, 2019","permalink":"/rabbitmq-website/blog/2019/01/08/this-month-in-rabbitmq-jan-8-2019"},"nextItem":{"title":"RabbitMQ Java Client Metrics with Micrometer and Datadog","permalink":"/rabbitmq-website/blog/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog"}},"content":"Hello RabbitMQ friends! Welcome to the first installment of This Month in RabbitMQ, inspired by the wonderful and industrious [Josh Long](https://twitter.com/starbuxman), who publishes monthly and weekly recaps for the Spring community.\\r\\nOur team was also inspired by the first ever RabbitMQ Summit that we held on November 12 in London.\\r\\nIt was awesome to see an assembly of the community and the knowledge shared. Look out for videos from that event in a future issue of This Month in RabbitMQ.\\r\\n\\r\\nWithout further ado, let\'s take a look at a roundup of what happened in RabbitMQ land last month!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Project Updates\\r\\n\\r\\n* RabbitMQ 3.7.9 [has been released](https://groups.google.com/forum/#!topic/rabbitmq-users/87A0wqH-z5s) ([release artifacts](https://github.com/rabbitmq/rabbitmq-server/releases/tag/v3.7.9), [change log](/release-information))\\r\\n* As of 3.7.9, [cipher suites](/docs/ssl#cipher-suites) now can be configured via [new style configuration format](/blog/2018/02/22/new-configuration-format-in-rabbitmq-3-7).\\r\\n* Marcial Rosales produced a set of guidelines that demonstrate [how to develop applications more resilient to failures](https://github.com/rabbitmq/workloads/tree/master/resiliency) common in messaging-based systems, whether they use RabbitMQ Java client directly or Spring AMQP\\r\\n* RabbitMQ repositories on PackageCloud have [switched to a new GPG key](https://groups.google.com/d/msg/rabbitmq-users/8Kyp265m4pE/BBM0bixZBgAJ)\\r\\n* Karl Nilsson delivered a talk on our [implementation of Raft](https://www.youtube.com/watch?v=7NNjjTrBZtw). Our team is [adopting Raft](https://www.youtube.com/watch?v=w-_1Wwymk58) in a new replicated queue implementation and more.\\r\\n* New doc guide that [covers multiple topics related to consumers](/docs/consumers) in RabbitMQ\\r\\n* New doc [guide on monitoring](/docs/monitoring)\\r\\n* Expanded [cluster formation guide](/docs/cluster-formation)\\r\\n\\r\\n## Community Writings and Resources\\r\\n\\r\\n* [RabbitMQ mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users) had threads in November\\r\\n* Dormain Drewitz published a Twitter Moment of [live tweet coverage](https://twitter.com/i/moments/1062010422944038912) from the RabbitMQ Summit\\r\\n* Elin Vinka published [RabbitMQ and Microservices](https://www.cloudamqp.com/blog/2018-11-02-rabbitmq-and-microservices.html)\\r\\n* Eko Simanjuntak explores how RabbitMQ supports microservices in a Hackernoon blog, [Messaging System—Hands On](https://hackernoon.com/messaging-system-hands-on-7dda1afded37)\\r\\n* Arnaud Lahaxe published [Symfony Messenger et RabbitMQ](https://outweb.eu/symfony-messenger-et-rabbitmq/) (in French)\\r\\n* Jack Vanlightly published [Why I Am Not A Fan Of The RabbitMQ Sharding Plugin](https://jack-vanlightly.com/blog/2018/11/14/why-i-am-not-a-fan-of-the-rabbitmq-sharding-plugin)\\r\\n* Dormain Drewitz of Pivotal published a [recap of the expert panel discussion](https://content.pivotal.io/pivotal-blog/rabbitmq-expert-opinions-rabbitmq-summit-panel-recap) at the RabbitMQ Summit\\r\\n* Dattell published Kafka vs. RabbitMQ: [How to choose an open source message broker](https://dattell.com/data-architecture-blog/kafka-vs-rabbitmq-how-to-choose-an-open-source-message-broker/)\\r\\n* Jack Vanlightly published [Quorum Queues - Making RabbitMQ More Competitive In Reliable Messaging](https://jack-vanlightly.com/blog/2018/11/20/quorum-queues-making-rabbitmq-more-competitive)\\r\\n* Leonardo Soares of Mollie published [Keeping RabbitMQ connections alive in PHP](https://blog.mollie.com/keeping-rabbitmq-connections-alive-in-php-b11cb657d5fb)\\r\\n* Stephan Bester published [AMQP with Delphi 6 and RabbitMQ](https://medium.com/@step.bester/amqp-with-delphi-6-and-rabbitmq-97da02c261d8) \\r\\n* Andreas Finger shared a presentation and demo on [A Simpler (micro)service setup with RabbitMQ](https://github.com/mediafinger/rabbitmq_presentation) \\r\\n* Tomas Vasquez shared a [library to use RabbitMQ with C#](https://github.com/Tomamais/rabbitmq_csharp)\\r\\n* Danny Kay of Sky Betting and Gaming published [Making Kafka & RabbitMQ Integration easier with Spring Cloud Stream : Part 1](https://medium.com/@danieljameskay/making-kafka-rabbitmq-integration-easier-with-spring-cloud-stream-part-1-ddbb1c6bf283)\\r\\n* Lovisa Johansson published [Is HiPE production ready?](https://www.cloudamqp.com/blog/2018-11-26-is-hipe-production-ready.html)\\r\\n* After RabbitMQ Summit @DBcodes played around with RabbitMQ and created a [small repository](https://bitbucket.org/dbcodes/rabbitmq-cluster) to play around with three nodes and understand clustering a little better.\\r\\n\\r\\n## Upcoming Events\\r\\n\\r\\nReady to learn more? Check out these upcoming opportunities to learn more about RabbitMQ:\\r\\n\\r\\n* On December 12, 2018 Pivotal hosts a webinar: [10 Things Every Developer Using RabbitMQ Should Know](https://content.pivotal.io/webinars/dec-12-10-things-every-developer-using-rabbitmq-should-know-webinar)\\r\\n* [RabbitMQ Express at Code Beam SF](https://codesync.global/conferences/code-beam-sf-2019/#Training ) in San Francisco on February 27, 2019"},{"id":"/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","metadata":{"permalink":"/rabbitmq-website/blog/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2018-04-10-rabbitmq-java-client-metrics-with-micrometer-and-datadog/index.md","source":"@site/blog/2018-04-10-rabbitmq-java-client-metrics-with-micrometer-and-datadog/index.md","title":"RabbitMQ Java Client Metrics with Micrometer and Datadog","description":"In this post we\'ll cover how the RabbitMQ Java client library gathers runtime metrics and sends them to monitoring systems like JMX and Datadog.","date":"2018-04-10T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":5.435,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"RabbitMQ Java Client Metrics with Micrometer and Datadog","tags":["Performance","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"This Month in RabbitMQ, November 2018","permalink":"/rabbitmq-website/blog/2018/12/04/this-month-in-rabbitmq-dec-4-2018"},"nextItem":{"title":"New Configuration Format in RabbitMQ 3.7","permalink":"/rabbitmq-website/blog/2018/02/22/new-configuration-format-in-rabbitmq-3-7"}},"content":"In this post we\'ll cover how the RabbitMQ Java client library gathers runtime metrics and sends them to monitoring systems like JMX and Datadog.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Micrometer in RabbitMQ Java Client\\r\\n\\r\\nThe Java client provides support for [Micrometer](http://micrometer.io/) as of 4.6.0 and 5.2.0. What does this bring to the table? Micrometer is a metrics facade: an application can use the Micrometer API for metrics collection and choose to send these metrics to different backends like JMX, Prometheus, Netflix Atlas, CloudWatch, Datadog, Graphite, Ganglia, and more.\\r\\nNext lets see how RabbitMQ Java client\'s users can benefit from Micrometer has to offer. \\r\\n\\r\\nWe can start by gathering the Java client metrics and exposing them on JMX with Micrometer:\\r\\n\\r\\n```java\\r\\nMeterRegistry jmxRegistry = new JmxMeterRegistry(JmxConfig.DEFAULT, Clock.SYSTEM);\\r\\nConnectionFactory connectionFactory = new ConnectionFactory();\\r\\nMicrometerMetricsCollector metricsCollector = new MicrometerMetricsCollector(\\r\\n    jmxRegistry, \\"rabbitmq.client\\"\\r\\n);\\r\\nconnectionFactory.setMetricsCollector(metricsCollector);\\r\\n\\r\\nConnection connection = connectionFactory.newConnection();\\r\\nChannel channel = connection.createChannel();\\r\\nString queue = channel.queueDeclare().getQueue();\\r\\nchannel.basicConsume(queue, true, (ctag, msg) -> { }, (ctag) -> { });\\r\\nexecutor.submit(() -> {\\r\\n    Random random = new Random();\\r\\n    while (true) {\\r\\n        Thread.sleep(random.nextInt(100));\\r\\n        channel.basicPublish(\\"\\", queue, null, \\"\\".getBytes());\\r\\n    }\\r\\n});\\r\\n```\\r\\n\\r\\nThen these metrics can be inspected in [VisualVM](https://visualvm.github.io/download.html):\\r\\n\\r\\n![Java Client Metrics on JMX](rabbitmq-java-client-metrics-jmx.png \\"Java Client Metrics on JMX\\")\\r\\n\\r\\nNothing much new compared to what we had done with Dropwizard Metrics [in a previous post](/blog/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0).\\r\\n\\r\\nBut Micrometer can easily bring value with metrics related to the JVM process. We simply have to bind the appropriate `MeterBinder`s to the JMX meter registry:\\r\\n\\r\\n```java\\r\\nMeterRegistry jmxRegistry = new JmxMeterRegistry(JmxConfig.DEFAULT, Clock.SYSTEM);\\r\\n// JVM and system metrics:\\r\\nnew ClassLoaderMetrics().bindTo(jmxRegistry);\\r\\nnew JvmMemoryMetrics().bindTo(jmxRegistry);\\r\\nnew JvmGcMetrics().bindTo(jmxRegistry);\\r\\nnew ProcessorMetrics().bindTo(jmxRegistry);\\r\\nnew JvmThreadMetrics().bindTo(jmxRegistry);\\r\\nConnectionFactory connectionFactory = new ConnectionFactory();\\r\\nMicrometerMetricsCollector metricsCollector = new MicrometerMetricsCollector(\\r\\n    jmxRegistry, \\"rabbitmq.client\\"\\r\\n);\\r\\nconnectionFactory.setMetricsCollector(metricsCollector);\\r\\n\\r\\nConnection connection = connectionFactory.newConnection();\\r\\nChannel channel = connection.createChannel();\\r\\nString queue = channel.queueDeclare().getQueue();\\r\\nchannel.basicConsume(queue, true, (ctag, msg) -> { }, (ctag) -> { });\\r\\nexecutor.submit(() -> {\\r\\n    Random random = new Random();\\r\\n    while (true) {\\r\\n        Thread.sleep(random.nextInt(100));\\r\\n        channel.basicPublish(\\"\\", queue, null, \\"\\".getBytes());\\r\\n    }\\r\\n});\\r\\n```\\r\\n\\r\\nThen the new metrics show up in JVisualVM, there is a bunch of them:\\r\\n\\r\\n![Java Client,JVM, and System Metrics on JMX](rabbitmq-java-client-metrics-jmx-more-metrics.png \\"Java Client, JVM, and System Metrics on JMX\\")\\r\\n\\r\\nIn practice applications often have several instances running at once, sometimes distributed across different data centers. How can we identify an instance that runs in a given datacenter and make the monitoring system aware of this information? Micrometer provides metrics _tags_: it\'s a matter of adding the datacenter information to the metric collector. We can adapt our example program and iterate over a list of data centers to simulate distributed instances. We use the `dc` tag for the data center information, and add a `host` tag as well:\\r\\n\\r\\n```java\\r\\nfor (String dc : new String[] {\\"us\\", \\"europe\\", \\"asia\\"}) {\\r\\n    Tags tags = Tags.of(\\"host\\", hostname, \\"dc\\", dc);\\r\\n    MeterRegistry jmxRegistry = new JmxMeterRegistry(JmxConfig.DEFAULT, Clock.SYSTEM);\\r\\n    new ClassLoaderMetrics(tags).bindTo(jmxRegistry);\\r\\n    new JvmMemoryMetrics(tags).bindTo(jmxRegistry);\\r\\n    new JvmGcMetrics(tags).bindTo(jmxRegistry);\\r\\n    new ProcessorMetrics(tags).bindTo(jmxRegistry);\\r\\n    new JvmThreadMetrics(tags).bindTo(jmxRegistry);\\r\\n    ConnectionFactory connectionFactory = new ConnectionFactory();\\r\\n    MicrometerMetricsCollector metricsCollector = new MicrometerMetricsCollector(\\r\\n        jmxRegistry, \\"rabbitmq.client\\", tags\\r\\n    );\\r\\n    connectionFactory.setMetricsCollector(metricsCollector);\\r\\n\\r\\n    Connection connection = connectionFactory.newConnection();\\r\\n    Channel channel = connection.createChannel();\\r\\n    String queue = channel.queueDeclare().getQueue();\\r\\n    channel.basicConsume(queue, true, (ctag, msg) -> { }, (ctag) -> { });\\r\\n    executor.submit(() -> {\\r\\n        Random random = new Random();\\r\\n        int offset = dc.length() * 10;\\r\\n        while (true) {\\r\\n            Thread.sleep(random.nextInt(100) + offset);\\r\\n            channel.basicPublish(\\"\\", queue, null, \\"\\".getBytes());\\r\\n        }\\r\\n    }); \\r\\n}\\r\\n```\\r\\n\\r\\nLet\'s see how it looks now in VisualVM:\\r\\n\\r\\n![Java Client Metrics for Different Datacenters on JMX](rabbitmq-java-client-metrics-jmx-dc.png \\"Java Client Metrics for Different Datacenters on JMX\\")\\r\\n\\r\\nThere\'s now a really long list of metrics as Micrometer flattens the set of tag/key value pairs and adds them to the name. This is because JMX is a _hierarchical_ monitoring system, it doesn\'t support _dimensions_. This makes it hard to reason about our metrics as a whole, across all our instances and datacenters. And that would be even worse in real life: here we simulate different instances of our application in the same JVM process, but in a real system, we would have a tab for each process, even harder to reason about.\\r\\n\\r\\nFortunately, Micrometer takes advantage of _dimensional_ monitoring systems. Just imagine we can see the aggregated metrics of our different instances and drill down into a specific datacenter or a given host.\\r\\n\\r\\n[Datadog](https://www.datadoghq.com/) is such a system, and Micrometer supports it out of the box. We can use a `DatadogMeterRegistry` and keep using JMX thanks to the `CompositeMeterRegistry`:\\r\\n\\r\\n```java\\r\\nfor (String dc : new String[] {\\"us\\", \\"europe\\", \\"asia\\"}) {\\r\\n    CompositeMeterRegistry compositeMeterRegistry = new CompositeMeterRegistry();\\r\\n    MeterRegistry datadogRegistry = new DatadogMeterRegistry(config, Clock.SYSTEM);\\r\\n    MeterRegistry jmxRegistry = new JmxMeterRegistry(JmxConfig.DEFAULT, Clock.SYSTEM);\\r\\n\\r\\n    Tags tags = Tags.of(\\"host\\", hostname, \\"dc\\", dc);\\r\\n    new ClassLoaderMetrics(tags).bindTo(compositeMeterRegistry);\\r\\n    new JvmMemoryMetrics(tags).bindTo(compositeMeterRegistry);\\r\\n    new JvmGcMetrics(tags).bindTo(compositeMeterRegistry);\\r\\n    new ProcessorMetrics(tags).bindTo(compositeMeterRegistry);\\r\\n    new JvmThreadMetrics(tags).bindTo(compositeMeterRegistry);\\r\\n\\r\\n    compositeMeterRegistry.add(datadogRegistry);\\r\\n    compositeMeterRegistry.add(jmxRegistry);\\r\\n\\r\\n    ConnectionFactory connectionFactory = new ConnectionFactory();\\r\\n    MicrometerMetricsCollector metricsCollector = new MicrometerMetricsCollector(\\r\\n        compositeMeterRegistry, \\"rabbitmq.client\\", tags\\r\\n    );\\r\\n    connectionFactory.setMetricsCollector(metricsCollector);\\r\\n\\r\\n    Connection connection = connectionFactory.newConnection();\\r\\n    Channel channel = connection.createChannel();\\r\\n    String queue = channel.queueDeclare().getQueue();\\r\\n    channel.basicConsume(queue, true, (ctag, msg) -> { }, (ctag) -> { });\\r\\n    executor.submit(() -> {\\r\\n        Random random = new Random();\\r\\n        int offset = dc.length() * 10;\\r\\n        while (true) {\\r\\n            Thread.sleep(random.nextInt(100) + offset);\\r\\n            channel.basicPublish(\\"\\", queue, null, \\"\\".getBytes());\\r\\n        }\\r\\n    });\\r\\n}\\r\\n```\\r\\n\\r\\nWhat happens under the hood? Micrometer gathers the metrics and send them every 10 seconds to the Datadog service through HTTPS. Note you need a Datadog API key for this to work, it is used in the Datadog registry configuration. The host and the metrics should show up in your Datadog web UI and you can easilly build a dashboard for your RabbitMQ Java client instances:\\r\\n\\r\\n![RabbitMQ Java Client Metrics Datadog Dashboard](rabbitmq-java-client-metrics-datadog-dashboard.png \\"RabbitMQ Java Client Metrics Datadog Dashboard\\")\\r\\n\\r\\nNeat isn\'t it?\\r\\n\\r\\n## Going Further\\r\\n\\r\\nCollecting metrics at a single level — say, a particular library such as the RabbitMQ Java client — is only a single step on the path\\r\\nof gaining visibility into the entire service-oriented system.\\r\\n\\r\\nDatadog also provides [support for RabbitMQ nodes and clusters](https://docs.datadoghq.com/integrations/rabbitmq/). A node needs to have the Datadog agent installed and this agent will connect to the [RabbitMQ Management Plugin](/docs/management) to gather metrics. Datadog engineers wrote a [series](https://www.datadoghq.com/blog/rabbitmq-monitoring/) of [blog posts](https://www.datadoghq.com/blog/rabbitmq-monitoring-tools) that cover [how to monitor RabbitMQ](https://www.datadoghq.com/blog/monitoring-rabbitmq-performance-with-datadog/). This is a piece of recommended reading for anyone interested in RabbitMQ operations.\\r\\n\\r\\nBack to the client level, [Spring Boot](https://projects.spring.io/spring-boot/) is a popular way to write RabbitMQ applications in Java. Micrometer is the library that backs up Spring Boot 2.0 metrics system. RabbitMQ Java client metrics collection is [configured automatically](https://docs.spring.io/spring-boot/docs/2.0.0.RELEASE/reference/htmlsingle/#production-ready-metrics-rabbitmq), the developer doesn\'t even need to register any `MetricsCollector`.\\r\\n\\r\\nIn the world of microservices and IoT workloads where application instances spring up like mushrooms, we hope this makes it easier to gain visibility\\r\\ninto operations of your Java-based apps that use RabbitMQ for messaging thanks to these metrics!\\r\\n\\r\\n[Source code](https://github.com/acogoluegnes/rabbitmq-java-client-micrometer-datadog)"},{"id":"/2018/02/22/new-configuration-format-in-rabbitmq-3-7","metadata":{"permalink":"/rabbitmq-website/blog/2018/02/22/new-configuration-format-in-rabbitmq-3-7","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2018-02-22-new-configuration-format-in-rabbitmq-3-7/index.md","source":"@site/blog/2018-02-22-new-configuration-format-in-rabbitmq-3-7/index.md","title":"New Configuration Format in RabbitMQ 3.7","description":"In this post we\'ll cover a new configuration format available","date":"2018-02-22T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":6.38,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"New Configuration Format in RabbitMQ 3.7","tags":["New Features"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Java Client Metrics with Micrometer and Datadog","permalink":"/rabbitmq-website/blog/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog"},"nextItem":{"title":"Peer Discovery Subsystem in RabbitMQ 3.7","permalink":"/rabbitmq-website/blog/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7"}},"content":"In this post we\'ll cover a new configuration format available\\r\\nin RabbitMQ 3.7.0.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Why Do We Need a New Format\\r\\n\\r\\nMany developers and operators have strong opinions about software configuration formats. Debates about the pros and cons of a particular format center on readability, whether a format\\r\\nsupports comments, and so on.\\r\\n\\r\\nThose are valid concerns indeed but configuration files are not always hand crafted by a human. In the age of rising automation expectations, the ease of generation of a particular format is rarely discussed.\\r\\n\\r\\nHistorically, RabbitMQ uses Erlang term files for configuration. Besides being the standard way of configuring Erlang-based systems, it strikes a good balance of power and safety: any Erlang data structure can be used,\\r\\nincluding arbitrary nesting, yet arbitrary code cannot be evaluated.\\r\\n\\r\\nThat format, however, also has a few downsides that became obvious once the project had accumulated a certain critical mass of users:\\r\\n\\r\\n* It\'s not familiar to those getting started with RabbitMQ\\r\\n* It has subtle aspects such as required trailing dots and commas that confuse beginners\\r\\n* Arbitrary nesting can be powerful and sometimes necessary but it also can greatly complicate config file generation\\r\\n* In some cases familiarity with different Erlang data types was necessary (e.g. lists vs. binaries) for no good reason\\r\\n\\r\\nTeam RabbitMQ wanted to address all of those concerns but particularly the last one. Provisioning tools such as Chef and BOSH manage to generate functional config files but that code is difficult to read and maintain,\\r\\nwhich in turn means that it is error-prone.\\r\\n\\r\\n## The New Format\\r\\n\\r\\nAfter evaluating all the usual suspects, we settled on an <code>ini</code>-like format used by <code>sysctl</code> and Riak. It [uses a different config extension](/docs/configure#config-file-formats), `.conf`, and looks like this:\\r\\n\\r\\n```ini\\r\\nheartbeat = 30\\r\\n```\\r\\n\\r\\nThis overrides default [heartbeat](/docs/heartbeats) value\\r\\noffered by the server to 30 seconds.\\r\\n\\r\\nMost settings use a single line, with configuration key and value separated by an\\r\\nequality sign and zero or more spaces. Such formats have been around for\\r\\ndecades and are known to be fairly readable for humans.\\r\\n\\r\\nHere\'s a slightly longer example:\\r\\n\\r\\n```ini\\r\\nheartbeat = 30\\r\\n\\r\\nlisteners.tcp.default = 5672\\r\\n```\\r\\n\\r\\nIn addition to the hearbeat setting, it also configures a TCP listener\\r\\nto use port 5672 and bind to all interfaces available.\\r\\n\\r\\nSettings can be structured (logically grouped) using dots. For example,\\r\\nall plain TCP (as opposed to TCP plus TLS) listener settings are grouped\\r\\nunder `listener.tcp.*`.\\r\\n\\r\\nHere\'s how TLS certificates and key are configured in the new format:\\r\\n\\r\\n```ini\\r\\nssl_options.cacertfile           = /path/to/testca/cacert.pem\\r\\nssl_options.certfile             = /path/to/server/cert.pem\\r\\nssl_options.keyfile              = /path/to/server/key.pem\\r\\nssl_options.verify               = verify_peer\\r\\nssl_options.fail_if_no_peer_cert = true\\r\\n```\\r\\n\\r\\nCompare this to the same settings in the classic (Erlang terms) format:\\r\\n\\r\\n```erlang\\r\\n[\\r\\n  {rabbit, [{ssl_options, [{cacertfile,           \\"/path/to/testca/cacert.pem\\"},\\r\\n                           {certfile,             \\"/path/to/server/cert.pem\\"},\\r\\n                           {keyfile,              \\"/path/to/server/key.pem\\"},\\r\\n                           {verify,               verify_peer},\\r\\n                           {fail_if_no_peer_cert, true}]}]}\\r\\n].\\r\\n```\\r\\n\\r\\nBesides being easier to read, the new version is much easier to generate.\\r\\n\\r\\nIt also has one less obvious improvement: the values are now\\r\\nvalidated with a schema. For path values such as the private key path this means\\r\\nthat should a file not be found or not be readable, the node will\\r\\nimmediately report it and refuse to start. Previously the node would\\r\\nstart but the files would fail to load at runtime, which is a great\\r\\nway to confuse deployment and monitoring tools.\\r\\n\\r\\nFields that expect numerical values will refuse to accept strings, and so on.\\r\\nThe new format offers some of the benefits of static typing, which is not\\r\\nthe case with many commonly used formats.\\r\\n\\r\\n## Collections\\r\\n\\r\\nSingle value keys are trivial to configure in this format. But what about\\r\\ncollections? For example, it\'s possible to configure more than\\r\\none TCP listener. It is also possible to [list cluster nodes](/blog/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7) for\\r\\npeer discovery purposes. How does this format account for that?\\r\\n\\r\\nThe new format supports collections that are maps (dictionaries). For values\\r\\nthat are arrays or sets, the keys are ignored. Here\'s how to specify a list of nodes\\r\\nfor peer discovery:\\r\\n\\r\\n```ini\\r\\ncluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_config\\r\\n\\r\\ncluster_formation.classic_config.nodes.1 = rabbit1@hostname\\r\\ncluster_formation.classic_config.nodes.2 = rabbit2@hostname\\r\\ncluster_formation.classic_config.nodes.3 = rabbit3@hostname\\r\\ncluster_formation.classic_config.nodes.4 = rabbit4@hostname\\r\\n```\\r\\n\\r\\nThe keys in this example are `1`, `2` and so on. Any key values can be used. Sequentially\\r\\ngrowing numbers are easy to generate, so that\'s what our documentation examples use.\\r\\n\\r\\n## Comments\\r\\n\\r\\nComments are supported in the new format, allowing us to continue providing\\r\\nan [annotated example file](https://github.com/rabbitmq/rabbitmq-server/blob/v3.7.x/docs/rabbitmq.conf.example):\\r\\n\\r\\n```ini\\r\\n## Select an authentication/authorisation backend to use.\\r\\n##\\r\\n## Alternative backends are provided by plugins, such as rabbitmq-auth-backend-ldap.\\r\\n##\\r\\n## NB: These settings require certain plugins to be enabled.\\r\\n##\\r\\n## Related doc guides:\\r\\n##\\r\\n##  * http://www.rabbitmq.com/plugins.html\\r\\n##  * http://www.rabbitmq.com/access-control.html\\r\\n##\\r\\n\\r\\nauth_backends.1   = rabbit_auth_backend_internal\\r\\n\\r\\n## uses separate backends for authentication and authorisation,\\r\\n## see below.\\r\\n# auth_backends.1.authn = rabbit_auth_backend_ldap\\r\\n# auth_backends.1.authz = rabbit_auth_backend_internal\\r\\n```\\r\\n\\r\\n## Advanced Configuration\\r\\n\\r\\nAs nice as this format is, there are certain limitations to it. Consider the following\\r\\nconfig file that demonstrates a number of features in the [LDAP plugin](/docs/ldap):\\r\\n\\r\\n```erlang\\r\\n[\\r\\n  {rabbit, [{auth_backends, [rabbit_auth_backend_ldap]}]},\\r\\n  {rabbitmq_auth_backend_ldap,\\r\\n   [ {servers,               [\\"my-ldap-server\\"]},\\r\\n     {user_dn_pattern,       \\"cn=${username},ou=People,dc=example,dc=com\\"},\\r\\n     {use_ssl,               false},\\r\\n     {port,                  389},\\r\\n     {log,                   false},\\r\\n     {vhost_access_query,    {in_group,\\r\\n                              \\"ou=${vhost}-users,ou=vhosts,dc=example,dc=com\\"}},\\r\\n     {resource_access_query,\\r\\n      {for, [{permission, configure, {in_group, \\"cn=admin,dc=example,dc=com\\"}},\\r\\n             {permission, write,\\r\\n              {for, [{resource, queue,    {in_group, \\"cn=admin,dc=example,dc=com\\"}},\\r\\n                     {resource, exchange, {constant, true}}]}},\\r\\n             {permission, read,\\r\\n              {for, [{resource, exchange, {in_group, \\"cn=admin,dc=example,dc=com\\"}},\\r\\n                     {resource, queue,    {constant, true}}]}}\\r\\n            ]\\r\\n      }},\\r\\n     {topic_access_query,\\r\\n      {for, [{permission, write, {match, {string, \\"${routing_key}\\"}, {string, \\"^a\\"}}},\\r\\n             {permission, read,  {constant, true}}\\r\\n            ]\\r\\n     }},\\r\\n     {tag_queries,           [{administrator, {constant, false}},\\r\\n                              {management,    {constant, true}}]}\\r\\n   ]\\r\\n  }\\r\\n].\\r\\n```\\r\\n\\r\\nThis example uses deeply nested data structures to express LDAP queries. Such scenarios do not\\r\\nfit the new format very well but they have to be supported.\\r\\n\\r\\nTo account for this, it is now possible to specify another config file, `advanced.config`, in the\\r\\n[classic (Erlang terms) config format](/docs/configure#config-file-formats).\\r\\n\\r\\nThe two config formats are then merged. How is this possible? The trick is in translating\\r\\nthe new format to the old one, which we will cover next.\\r\\n\\r\\nAlternatively it is possible to only use the legacy config format. It makes sense\\r\\nduring a transition period, for example.\\r\\n\\r\\n## How it Works\\r\\n\\r\\nAs mentioned above, the new format is translated into the classic one\\r\\nunder the hood since that\'s what a lot of libraries, including in Erlang/OTP, expect.\\r\\nThe translation is done by a tool called [Cuttlefish](https://github.com/Kyorai/cuttlefish),\\r\\noriginally developed by Basho Technologies. On start, RabbitMQ nodes use Cuttlefish\\r\\nto do the following:\\r\\n\\r\\n * Collect config schema files from all plugins\\r\\n * Run Cuttlefish to do the translation\\r\\n * Combines the result with the `advanced.config` file\\r\\n * Loads the final config\\r\\n\\r\\nFor both RabbitMQ core and plugins the process is entirely transparent. All the\\r\\nheavy lifting is done by a number of functions that form a [translation schema](https://github.com/rabbitmq/rabbitmq-server/blob/v3.7.x/priv/schema/rabbit.schema).\\r\\nCuttlefish does the parsing and invokes schema functions to perform validation\\r\\nand translation.\\r\\n\\r\\n## Plugin Configuration\\r\\n\\r\\nPlugins that have configurable settings now ship their own schemas that are extracted\\r\\nand incorporated into the main one on node boot.\\r\\n\\r\\nHere\'s what management plugin configuration might look like:\\r\\n\\r\\n```ini\\r\\nmanagement.listener.port = 15672\\r\\nmanagement.listener.ip   = 127.0.0.1\\r\\nmanagement.listener.ssl  = true\\r\\n\\r\\nmanagement.listener.ssl_opts.cacertfile = /path/to/cacert.pem\\r\\nmanagement.listener.ssl_opts.certfile   = /path/to/cert.pem\\r\\nmanagement.listener.ssl_opts.keyfile = /path/to/key.pem\\r\\n```\\r\\n\\r\\nThe [schema file](https://github.com/rabbitmq/rabbitmq-management/blob/v3.7.x/priv/schema/rabbitmq_management.schema) for `management.*` keys is provided by the management plugin.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nThis new format makes RabbitMQ config files be more familiar and readable\\r\\nto humans, easier to generate for tools, and introduces value validation against an extensible schema.\\r\\nPlugins can ship their own config schema files and benefit from the new format.\\r\\n\\r\\nIt still possible to use the previous format or combine the two. We believe that\\r\\nthe new format can cover the proverbial 80% of use cases, though.\\r\\n\\r\\nTake a look at the updated [configuration guide](/docs/configure),\\r\\ngive this feature a try and let us know what you think on the [RabbitMQ mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users)!"},{"id":"/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7","metadata":{"permalink":"/rabbitmq-website/blog/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2018-02-18-peer-discovery-subsystem-in-rabbitmq-3-7/index.md","source":"@site/blog/2018-02-18-peer-discovery-subsystem-in-rabbitmq-3-7/index.md","title":"Peer Discovery Subsystem in RabbitMQ 3.7","description":"In this blog post we\'re going to take a closer look at a new","date":"2018-02-18T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":8.3,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"Peer Discovery Subsystem in RabbitMQ 3.7","tags":["New Features"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"New Configuration Format in RabbitMQ 3.7","permalink":"/rabbitmq-website/blog/2018/02/22/new-configuration-format-in-rabbitmq-3-7"},"nextItem":{"title":"What\'s New in RabbitMQ 3.7","permalink":"/rabbitmq-website/blog/2018/02/05/whats-new-in-rabbitmq-3-7"}},"content":"In this blog post we\'re going to take a closer look at a new\\r\\nsubsystem introduced in [RabbitMQ 3.7.0](/release-information).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Why Do We Need Peer Discovery?\\r\\n\\r\\nUsers of open source data services such as RabbitMQ have increasing\\r\\nexpectations around operations automation. This includes so-called Day\\r\\n1 operations: initial cluster provisioning.\\r\\n\\r\\nWhen a RabbitMQ cluster is first formed, newly booting nodes need\\r\\nto have a way to discover each other. In versions up to and including 3.6.x were\\r\\ntwo ways of doing this:\\r\\n\\r\\n * CLI tools\\r\\n * A list of nodes in configuration file\\r\\n\\r\\nThe former option is used by some provisioning tools but is generally\\r\\nnot very automation friendly. The latter is more convenient but\\r\\nhas its own limitations: the set of nodes is fixed and changing it requires\\r\\na config file redeployment and node restart.\\r\\n\\r\\n## A Better Way\\r\\n\\r\\nThere is a third option and it has been around in the community for a few years:\\r\\n[rabbitmq-autocluster](https://github.com/rabbitmq/rabbitmq-autocluster), a plugin\\r\\noriginally developed by Gavin Roy.\\r\\nThat plugin modifies RabbitMQ boot process and injects a peer discovery step.\\r\\nThe list of peers in this case doesn\'t have to come from the config file:\\r\\nit can be retrieved from an AWS autoscaling group\\r\\nor an external tool such as [etcd](https://coreos.com/etcd/docs/latest/).\\r\\n\\r\\n`rabbitmq-autocluster` authors concluded that there is no one true way of\\r\\nperforming peer discovery and that different approaches made sense for different\\r\\ndeployment scenarios. As such, they introduced a pluggable interface.\\r\\nA specific implementation of this pluggable interface is called a peer\\r\\ndiscovery mechanism. Given the explosion of platforms and deployment automation\\r\\nstacks in the last few years, this turned out to be a wise decision.\\r\\n\\r\\nFor RabbitMQ 3.7.0 we took `rabbitmq-autocluster` and integrated its\\r\\nmain ideas into the core with some modifications influenced by our\\r\\nexperience supporting production RabbitMQ installations and community\\r\\nfeedback.\\r\\n\\r\\nThe result is a new [peer discovery subsystem](/docs/cluster-formation).\\r\\n\\r\\n## How Does it Work?\\r\\n\\r\\nWhen a node starts and detects it doesn\'t have a previously\\r\\ninitialised database, it will check if there\'s a peer\\r\\ndiscovery mechanism configured. If that\'s the case, it will\\r\\nthen perform the discovery and attempt to contact each\\r\\ndiscovered peer in order. Finally, it will attempt to join the\\r\\ncluster of the first reachable peer.\\r\\n\\r\\nSome mechanisms assume all cluster members are known ahead of time (for example, listed\\r\\nin the config file), others are dynamic (nodes can come and go).\\r\\n\\r\\nRabbitMQ 3.7 ships with a number of mechanisms:\\r\\n\\r\\n * AWS (EC2 instance tags or autoscaling groups)\\r\\n * Kubernetes\\r\\n * etcd\\r\\n * Consul\\r\\n * Pre-configured DNS records\\r\\n * Config file\\r\\n\\r\\nand it is easy to introduce support for more options in the future.\\r\\n\\r\\nSince the ability to list cluster nodes in the config file is not new,\\r\\nlet\'s focus on the new features.\\r\\n\\r\\n### Node Registration and Unregistration\\r\\n\\r\\nSome mechanisms use a data store to keep track of node list.\\r\\nNewly joined cluster members update the data store to indicate their presence.\\r\\n[etcd](/docs/cluster-formation#peer-discovery-etcd)\\r\\nand [Consul](/docs/cluster-formation#peer-discovery-consul) are two options supported via\\r\\nplugins that ship with RabbitMQ.\\r\\n\\r\\nWith other mechanisms cluster membership is managed out-of-band (by a mechanism that\\r\\nRabbitMQ nodes cannot control). For example, the [AWS mechanism](/docs/cluster-formation#peer-discovery-aws) uses EC2 instance\\r\\nfiltering or autoscaling group membership, both of which are managed and updated\\r\\nby AWS.\\r\\n\\r\\n## Using a Preconfigured Set\\r\\n\\r\\nBut enough theory, let\'s take a look at what it takes to configure a list of nodes\\r\\nfor peer discovery using the new config format\\r\\nthat was [introduced alongside peer discovery in 3.7](/blog/2018/02/05/whats-new-in-rabbitmq-3-7):\\r\\n\\r\\nFirst we have to tell RabbitMQ to use the classic config mechanism for peer discovery.\\r\\nThis is done using the `cluster_formation.peer_discovery_backend` key.\\r\\nThen list one or more nodes using `cluster_formation.classic_config.nodes`, which is a collection:\\r\\n\\r\\n```ini\\r\\ncluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_config\\r\\n\\r\\ncluster_formation.classic_config.nodes.1 = rabbit@hostname1.eng.example.local\\r\\ncluster_formation.classic_config.nodes.2 = rabbit@hostname2.eng.example.local\\r\\n```\\r\\n\\r\\nAnd that\'s it.\\r\\n\\r\\nThis discovery method is perhaps the easiest to get started with but it has one\\r\\nobvious issue: the list of nodes is static.\\r\\n\\r\\nNext let\'s take a look at a mechanism that uses dynamic node lists: the AWS EC2\\r\\ninstance filtering.\\r\\n\\r\\n## Using AWS Instance Filtering\\r\\n\\r\\nJust like with the earlier example, we have to tell the node to use AWS\\r\\nfor peer discovery:\\r\\n\\r\\n```ini\\r\\ncluster_formation.peer_discovery_backend = rabbit_peer_discovery_aws\\r\\n```\\r\\n\\r\\nThere are two ways to use the AWS mechanism but the backend name (module) is\\r\\nthe same for both.\\r\\n\\r\\nTo use instance filtering, the plugin requires an AWS region to be configured\\r\\nas well as a pair of credentials. Sensitive configuration file values\\r\\n[can be encrypted](/docs/configure#configuration-encryption).\\r\\n\\r\\nHere\'s a config file example that does both:\\r\\n\\r\\n```ini\\r\\ncluster_formation.peer_discovery_backend = rabbit_peer_discovery_aws\\r\\n\\r\\ncluster_formation.aws.region = us-east-1\\r\\ncluster_formation.aws.access_key_id = ANIDEXAMPLE\\r\\ncluster_formation.aws.secret_key = WjalrxuTnFEMI/K7MDENG+bPxRfiCYEXAMPLEKEY\\r\\n```\\r\\n\\r\\nThe node now has enough information to try consulting the [EC2 Instance Metadata service](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html).\\r\\n\\r\\nFinally the operator needs to provide a set of tags to filter on. The tags are key/value pairs.\\r\\nThis means it is possible to filter on more than one tag, for example, `rabbitmq` and cluster name\\r\\nor environment type (e.g. `development` or `test` or `production`).\\r\\n\\r\\nHere\'s a complete config example that uses 3 tags, `region`, `service` and `environment`:\\r\\n\\r\\n```ini\\r\\ncluster_formation.peer_discovery_backend = rabbit_peer_discovery_aws\\r\\n\\r\\ncluster_formation.aws.region = us-east-1\\r\\ncluster_formation.aws.access_key_id = ANIDEXAMPLE\\r\\ncluster_formation.aws.secret_key = WjalrxuTnFEMI/K7MDENG+bPxRfiCYEXAMPLEKEY\\r\\n\\r\\ncluster_formation.aws.instance_tags.region = us-east-1\\r\\ncluster_formation.aws.instance_tags.service = rabbitmq\\r\\ncluster_formation.aws.instance_tags.environment = staging\\r\\n```\\r\\n\\r\\nWe are all set with this example. The only thing left to discuss is how to handle a natural race\\r\\ncondition that occurs when a cluster is first formed and node listing therefore can only\\r\\nreturn an empty set. This will be covered in a separate section below.\\r\\n\\r\\n#### IAM Roles and Permissions\\r\\n\\r\\nIf an [IAM role](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html) is assigned\\r\\nto EC2 instances running RabbitMQ nodes, a policy has to be used to allow said instances use EC2 Instance\\r\\nMetadata Service. Here\'s an example of such policy:\\r\\n\\r\\n```json\\r\\n{\\r\\n    \\"Version\\": \\"2012-10-17\\",\\r\\n    \\"Statement\\": [\\r\\n        {\\r\\n            \\"Effect\\": \\"Allow\\",\\r\\n            \\"Action\\": [\\r\\n                \\"autoscaling:DescribeAutoScalingInstances\\",\\r\\n                \\"ec2:DescribeInstances\\"\\r\\n            ],\\r\\n            \\"Resource\\": [\\r\\n                \\"*\\"\\r\\n            ]\\r\\n        }\\r\\n    ]\\r\\n}\\r\\n```\\r\\n\\r\\nWithout this policy in place the AWS peer discovery plugin won\'t be able to list instances and\\r\\ndiscovery will fail. When discovery fails, the node will consider it to be a fatal condition\\r\\nand terminate.\\r\\n\\r\\n#### Node Names\\r\\n\\r\\nBy default node names with AWS peer discovery will be computed using private hostnames.\\r\\nIt is possible to switch to private IP addresses as well:\\r\\n\\r\\n```ini\\r\\ncluster_formation.aws.use_private_ip = true\\r\\n```\\r\\n\\r\\n### The Chicken and Egg Problem of Peer Discovery\\r\\n\\r\\nConsider a deployment where the entire cluster is provisioned at once\\r\\nand all nodes start in parallel. For example, they may have been just\\r\\ncreated by BOSH or an AWS Cluster Formation template. In this case\\r\\nthere\'s a natural race condition between node registration and more\\r\\nthan one node can become \\"first to register\\" (discovers no existing\\r\\npeers and thus starts as standalone).\\r\\n\\r\\nDifferent peer discovery backends use different approaches to minimize\\r\\nthe probability of such scenario. Some acquire a lock with their\\r\\ndata service (etcd, Consul) and release it after registering, retrying\\r\\nif lock acquisition fails.\\r\\n\\r\\nOthers use a technique known as randomized startup delay. With\\r\\nrandomized startup delay nodes will delay their startup for a randomly\\r\\npicked value (between 5 and 60 seconds by default).\\r\\nWhile this strategy may seem naive at first, it works quite well in practice\\r\\nwith sufficiently high max delay intervals. It is also used for leader election\\r\\nin some distributed system algorithms, for example, [Raft](http://raft.github.io).\\r\\n\\r\\nSome backends (config file, DNS) rely on a pre-configured set of peers\\r\\nand do not suffer from this issue since when a node attempts to join\\r\\nits peer, it will continue retrying for a period of time.\\r\\n\\r\\n## What Peer Discovery Does not Do\\r\\n\\r\\nPeer discovery was introduced to solve a narrow set of problems. It does not\\r\\nchange how RabbitMQ clusters operate once formed. Even though some mechanisms\\r\\nintroduce [additional features](/docs/cluster-formation#node-health-checks-and-cleanup),\\r\\nsome problems ([shared secret distribution](/docs/clustering#erlang-cookie) and [monitoring](/docs/monitoring), for example)\\r\\nshould be solved by different tools.\\r\\n\\r\\nPeer discovery is also performed by blank (uninitialised) nodes. If a\\r\\nnode previously was a cluster member, it will try to contact its \\"last\\r\\nseen\\" peer on boot for a period of time. In this case, no peer\\r\\ndiscovery will be performed. This is no different from how earlier\\r\\nRabbitMQ versions worked in this scenario.\\r\\n\\r\\n## Peer Discovery Troubleshooting\\r\\n\\r\\nReasoning about an automated cluster formation system that also\\r\\nuses a peer discovery mechanism that has external dependencies\\r\\n(e.g. AWS APIs or etcd) can be tricky. For this reason all peer\\r\\ndiscovery implementations log key decisions and most log all external\\r\\nrequests at `debug` log level. When in doubt, [enable debug logging](/docs/logging)\\r\\nand take a look at node logs!\\r\\n\\r\\nAnd keep in mind what\'s covered in the above section on when\\r\\npeer discovery is not meant to kick in.\\r\\n\\r\\n## Differences from `rabbitmq-autocluster`\\r\\n\\r\\nWhile the new peer discovery subsystem is similar to `rabbitmq-autocluster`\\r\\nin many ways, there is a couple of important differences that matter\\r\\nto operators.\\r\\n\\r\\nWith `rabbitmq-autocluster`, nodes will reset themselves before joining\\r\\nits peers. This makes sense in some environments and doesn\'t in other.\\r\\nPeer discovery in RabbitMQ core does not do this.\\r\\n\\r\\n`rabbitmq-autocluster` allows environment variables to be used\\r\\nfor mechanism-specific configuration in addition to RabbitMQ\\r\\nconfig file. While this feature was retained to simplify migration,\\r\\nit should be considered deprecated by the peer discovery subsystem\\r\\nin 3.7.0.\\r\\n\\r\\nPeer discovery in the core uses the [new configuration file format](/docs/configure)\\r\\nheavily. `rabbitmq-autocluster` does not support that format since it\\r\\nnow is effectively a 3.6.x-only plugin.\\r\\n\\r\\n## Future Work\\r\\n\\r\\nMost major aspects of the peer discovery subsystem described in this\\r\\npost have a few years of battle testing via `rabbitmq-autocluster`. However,\\r\\nas more and more users adopt this feature in more and more environments,\\r\\nnew feedback from a broader set of users and use cases accumulates.\\r\\n\\r\\nCurrently one open ended question is whether inability to contact\\r\\nan external service used by a peer discovery mechanism (e.g. an AWS API endpoint\\r\\nor etcd or DNS) should immediately be considered a fatal failure that makes\\r\\nthe node stop, or should peer discovery be retried for a period of time.\\r\\nYou feedback is welcome [on the RabbitMQ mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users)."},{"id":"/2018/02/05/whats-new-in-rabbitmq-3-7","metadata":{"permalink":"/rabbitmq-website/blog/2018/02/05/whats-new-in-rabbitmq-3-7","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2018-02-05-whats-new-in-rabbitmq-3-7/index.md","source":"@site/blog/2018-02-05-whats-new-in-rabbitmq-3-7/index.md","title":"What\'s New in RabbitMQ 3.7","description":"After over 1 year in the works, RabbitMQ 3.7.0 has quietly shipped","date":"2018-02-05T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":6.335,"hasTruncateMarker":true,"authors":[{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null}],"frontMatter":{"title":"What\'s New in RabbitMQ 3.7","tags":["New Features"],"authors":["mklishin"]},"unlisted":false,"prevItem":{"title":"Peer Discovery Subsystem in RabbitMQ 3.7","permalink":"/rabbitmq-website/blog/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7"},"nextItem":{"title":"New Reactive Client for RabbitMQ HTTP API","permalink":"/rabbitmq-website/blog/2017/10/18/new-reactive-client-for-rabbitmq-http-api"}},"content":"After over 1 year in the works, RabbitMQ 3.7.0 has quietly shipped\\r\\nright before the start of the holiday season. The release was heavily\\r\\ninspired by the community feedback on 3.6.x. In this post we\'d like to\\r\\ncover some of the highlights in this release.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nRabbitMQ 3.7.0 focuses on automation friendliness and\\r\\noperability.\\r\\n\\r\\n## New Configuration Format\\r\\n\\r\\nLet\'s start with the new configuration\\r\\nformat. Historically RabbitMQ has used Erlang term files for\\r\\nconfiguration. We will cover the pros and cons of this in a separate\\r\\nblog post. Most importantly the classic format is hard to generate,\\r\\nwhich complicates automation.\\r\\n\\r\\nThe new format is heavily inspired by sysctl and ini files. It is\\r\\neasier to read for humans and much easier to generate for provisioning\\r\\ntools.\\r\\n\\r\\nCompare the following examples from [our TLS guide](/docs/ssl).\\r\\n\\r\\nClassic (Erlang terms) format:\\r\\n\\r\\n```erlang\\r\\n[\\r\\n    {ssl, [{versions, [\'tlsv1.2\', \'tlsv1.1\']}]},\\r\\n    {rabbit, [\\r\\n            {ssl_listeners, [5671]},\\r\\n            {ssl_options, [{cacertfile,\\"/path/to/ca_certificate.pem\\"},\\r\\n                            {certfile,  \\"/path/to/server_certificate.pem\\"},\\r\\n                            {keyfile,   \\"/path/to/server_key.pem\\"},\\r\\n                            {versions, [\'tlsv1.2\', \'tlsv1.1\']}\\r\\n                            ]}\\r\\n            ]}\\r\\n].\\r\\n```\\r\\n\\r\\nversus the new format:\\r\\n\\r\\n```ini\\r\\nlisteners.ssl.1 = 5671\\r\\nssl_options.cacertfile = /path/to/ca_certificate.pem\\r\\nssl_options.certfile   = /path/to/server_certificate.pem\\r\\nssl_options.keyfile    = /path/to/server_key.pem\\r\\nssl_options.versions.1 = tlsv1.2\\r\\nssl_options.versions.2 = tlsv1.1\\r\\n```\\r\\n\\r\\nIn addition to being more friendly to humans and machines\\r\\nthis new config file includes validation for keys and certain value\\r\\ntypes such as file paths. Should a certificate or public key file\\r\\nnot exist, the node will report it and fail to start. Same for\\r\\nunknown or misspelled keys.\\r\\n\\r\\nExpect a more detailed post about the new format in the future.\\r\\n\\r\\n## Peer Discovery Subsystem\\r\\n\\r\\nWhen a RabbitMQ cluster is first formed, newly booting nodes need\\r\\nto have a way to discover each other. In versions up to and including 3.6.x were\\r\\ntwo ways of doing this:\\r\\n\\r\\n * CLI tools\\r\\n * A list of nodes in configuration file\\r\\n\\r\\nThe former option is used by some provisioning tools but is generlaly\\r\\nnot very automation friendly. The latter is more convenient but\\r\\nhas its own limitations: the set of nodes is fixed and changing it requires\\r\\na config file redeployment and node restart.\\r\\n\\r\\nThere is a third option and it has existed in the community for a few years:\\r\\n[rabbitmq-autocluster](https://github.com/rabbitmq/rabbitmq-autocluster) by Gavin Roy.\\r\\nThat plugin modifies RabbitMQ boot process and makes peer discovery more\\r\\ndynamic: for example, the list of peers can be retrieved from an AWS autoscaling group\\r\\nor an external tool such as [etcd](https://coreos.com/etcd/docs/latest/).\\r\\n\\r\\nFor RabbitMQ 3.7.0 we took `rabbitmq-autocluster` and integrated its\\r\\nmain ideas into the core with some modifications inspired by our\\r\\nexperience with production RabbitMQ installations and community\\r\\nfeedback.\\r\\n\\r\\nThe result is a new [peer discovery subsystem](/docs/cluster-formation) which will be covered\\r\\nin a separate blog post. It supports a number of mechanisms and platforms:\\r\\n\\r\\n * AWS (EC2 instance tags or autoscaling groups)\\r\\n * Kubernetes\\r\\n * etcd\\r\\n * Consul\\r\\n * Pre-configured DNS records\\r\\n * Config file\\r\\n\\r\\nand makes it easy to introduce support for more options in the future.\\r\\n\\r\\n\\r\\n## Distributed Management Plugin\\r\\n\\r\\nStatistics database overload was a major pain point in earlier\\r\\nreleases.  It had to do with the original management plugin design\\r\\nwhich delegated stats collection and aggregation for the entire cluster\\r\\nto a single dedicated node. No matter how efficient that node is, this\\r\\nhas scalability limitations.\\r\\n\\r\\nAt some point this problem accounted for a significant portion of\\r\\nthe support tickets and mailing list threads, so it was decided that\\r\\na significant and breaking management plugin redesign was warranted.\\r\\n\\r\\nIn the new design, each node hosts and aggregates its own stats, and\\r\\nrequests data from other nodes as needed when an HTTP API request\\r\\ncomes in.  We now have close to a year worth of support data and user\\r\\nfeedback and happy to report that stats DB overload is effectively no\\r\\nlonger an issue.\\r\\n\\r\\nThese changes were backported to 3.6.x releases starting with [3.6.7](https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_6_7).\\r\\n\\r\\n\\r\\n## Redesigned CLI Tools\\r\\n\\r\\nOne long standing limitation of RabbitMQ CLI was the fact\\r\\nthat plugins could not extend it. This changes with the 3.7.0 release.\\r\\nPlugins such as Shovel and Federation now can provide their own commands\\r\\nthat help operators assess the state of the system and manage it.\\r\\n\\r\\n`rabbitmq-diagnostics` is a new command for operators that include\\r\\nsome of the commands previously available in `rabbitmqctl` but also\\r\\nnew ones. The list of diagnostics commands will continue to grow\\r\\nbased on user feedback on our [mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users).\\r\\n\\r\\n\\r\\n## Proxy Protocol Support\\r\\n\\r\\nIt\'s fairly common for clients to connect to RabbitMQ nodes via a proxy\\r\\nsuch as HAproxy or AWS ELB. This created a complication for operators:\\r\\nreal client IP addresses were no longer known to the nodes and therefore\\r\\ncannot be logged, displayed in the management UI, and so on.\\r\\n\\r\\nFortunately a solution to this problem exists and is supported by\\r\\nsome of the most popular proxy tools: the [Proxy protocol](https://www.haproxy.org/download/3.1/doc/proxy-protocol.txt).\\r\\nStarting with 3.7.0, RabbitMQ supports Proxy protocol if the operator\\r\\nopts in. It requires a compatible proxy but no client library changes.\\r\\nPer Proxy protocol spec requirements, when the protocol is enabled,\\r\\ndirect client connections are no longer supported.\\r\\n\\r\\n\\r\\n## Cross-protocol Shovel\\r\\n\\r\\nThe [Shovel plugin](/docs/shovel) now supports AMQP 1.0 endpoints in both directions (as a source\\r\\nand destinations). This means that Shovel now can move messages from an AMQP 1.0 only broker to RabbitMQ or vice versa.\\r\\n\\r\\n\\r\\n## Operator Policies\\r\\n\\r\\n[Operator policies](/docs/parameters#operator-policies) work much like [regular policies](/docs/parameters) but\\r\\ncan only be managed by administrators and will override user-defined policies. Operators that\\r\\noffer RabbitMQ as a service can use them to cap e.g. [max queue length](/docs/maxlength) on specific plans.\\r\\n\\r\\n\\r\\n## Per-vhost Message Stores\\r\\n\\r\\nStarting with 3.7.0, each virtual host gets its own message store\\r\\n(actually, two stores). This was primarily done to improve resilience\\r\\nand limit potential message store failures to an individual vhost\\r\\nbut it can also improve disk I/O utilization in environments\\r\\nwhere multiple virtual hosts are used.\\r\\n\\r\\n\\r\\n## Other Noteworthy Changes\\r\\n\\r\\nThe minimum required Erlang/OTP version is now 19.3. We highly\\r\\nrecommend at least 19.3.6.5. That release contains fixes to two\\r\\nbugs that could prevent nodes with active TCP connections from shutting down,\\r\\nwhich in turn could greatly complicate automated upgrades. That version\\r\\ntogether with 20.1.7 and 20.2.x contain a fix for the recently disclosed\\r\\n[ROBOT TLS attack](https://robotattack.org/).\\r\\n\\r\\nDuring the 3.7 development cycle we introduced a new versioning scheme for clients.\\r\\nClient library releases for Java and .NET are no longer tied to those of RabbitMQ\\r\\nserver. This allows clients to evolve more rapidly and follow a versioning\\r\\nscheme that makes sense for them. Both Java and .NET clients are into\\r\\ntheir 5.x versions by now, and include important changes that warrant\\r\\na major version number bump, for example, lambda and .NET Core support.\\r\\n\\r\\n\\r\\n## Package Distribution Changes\\r\\n\\r\\nStarting with 3.7.0, RabbitMQ packages (binary artifacts) are distributed using \\r\\nthree services:\\r\\n\\r\\n * [Bintray](https://bintray.com/rabbitmq/) provides package downloads as well as a Debian and Yum (RPM) repositories\\r\\n * [Package Cloud](https://packagecloud.io/rabbitmq) provides Debian and Yum repositories\\r\\n * [GitHub releases](https://github.com/rabbitmq/rabbitmq-server/releases/) include all release notes and provide a backup package download option\\r\\n\\r\\nIf you currently consume packages from rabbitmq.com, please switch to one of options above.\\r\\n\\r\\nUnlike rabbitmq.com\'s legacy apt repository, Package Cloud and Bintray provide package versions older\\r\\nthan the most recent one. And, of course, now there are official Yum repositories for RabbitMQ itself\\r\\nas well as our [zero dependency Erlang/OTP RPM package](https://github.com/rabbitmq/erlang-rpm).\\r\\n\\r\\nJava client releases are now distributed exclusively via Maven repositories\\r\\n(most notably Maven Central). .NET client releases are only offered via NuGet.\\r\\n\\r\\n\\r\\n## Upgrading to 3.7.x\\r\\n\\r\\nWe encourage all users to [upgrade to 3.7.x](/docs/download) and let us know how it goes\\r\\non the [mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users). To simplify the transition, there is a new [documentation\\r\\nguide on upgrades](/docs/upgrade). And, of course,\\r\\nplease consult the [full change log](/release-information)\\r\\nfirst!"},{"id":"/2017/10/18/new-reactive-client-for-rabbitmq-http-api","metadata":{"permalink":"/rabbitmq-website/blog/2017/10/18/new-reactive-client-for-rabbitmq-http-api","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2017-10-18-new-reactive-client-for-rabbitmq-http-api/index.md","source":"@site/blog/2017-10-18-new-reactive-client-for-rabbitmq-http-api/index.md","title":"New Reactive Client for RabbitMQ HTTP API","description":"The RabbitMQ team is happy to announce the release of version 2.0 of HOP, RabbitMQ HTTP API client for Java and other JVM languages. This new release introduce a new reactive client based on Spring Framework 5.0 WebFlux.","date":"2017-10-18T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":1.03,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"New Reactive Client for RabbitMQ HTTP API","tags":["Performance","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"What\'s New in RabbitMQ 3.7","permalink":"/rabbitmq-website/blog/2018/02/05/whats-new-in-rabbitmq-3-7"},"nextItem":{"title":"RabbitMQ Java Client 5.0 is Released","permalink":"/rabbitmq-website/blog/2017/09/29/rabbitmq-java-client-5-0-is-released"}},"content":"The RabbitMQ team is happy to announce the release of version 2.0 of [HOP](https://github.com/rabbitmq/hop), RabbitMQ HTTP API client for Java and other JVM languages. This new release introduce a new reactive client based on [Spring Framework 5.0 WebFlux](https://docs.spring.io/spring/docs/5.0.0.RELEASE/spring-framework-reference/web-reactive.html#webflux-client).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Reactive what?\\r\\n\\r\\nAs stated in Spring Framework `WebClient` documentation:\\r\\n\\r\\n > The WebClient offers a functional and fluent API that takes full advantage of Java 8 lambdas. It supports both sync and async scenarios, including streaming, and brings the efficiency of non-blocking I/O.\\r\\n\\r\\nThis means you can easily chain HTTP requests and transform the result, e.g. to calculate the total rate for all virtual hosts in a RabbitMQ broker:\\r\\n\\r\\n```java\\r\\nReactiveClient client = new ReactiveClient(\\"http://localhost:15672/api\\", \\"guest\\", \\"guest\\");\\r\\nMono<Double> vhostsRate = client.getVhosts()\\r\\n        .map(vhostInfo -> vhostInfo.getMessagesDetails().getRate())\\r\\n        .reduce(0.0, (acc, current) -> acc + current);\\r\\n```\\r\\n\\r\\nNote HOP `ReactiveClient` uses [Reactor](http://projectreactor.io/) `Mono` and `Flux` API.\\r\\n\\r\\nThis also means you can build a fully reactive dashboard application to monitor a farm of RabbitMQ clusters. Thanks to the underlying Reactor Netty library, the dashboard application will use as less resources as possible (HTTP connection pooling, non-blocking I/O).\\r\\n\\r\\nHOP 2.0 is already available on Maven Central. For Maven:\\r\\n\\r\\n```xml\\r\\n<dependency>\\r\\n    <groupId>com.rabbitmq</groupId>\\r\\n    <artifactId>http-client</artifactId>\\r\\n    <version>2.0.0.RELEASE</version>\\r\\n</dependency>\\r\\n```\\r\\n\\r\\nFor Gradle:\\r\\n\\r\\n```groovy\\r\\ncompile \'com.rabbitmq:http-client:2.0.0.RELEASE\'\\r\\n```\\r\\n\\r\\nEnjoy!"},{"id":"/2017/09/29/rabbitmq-java-client-5-0-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2017/09/29/rabbitmq-java-client-5-0-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2017-09-29-rabbitmq-java-client-5-0-is-released/index.md","source":"@site/blog/2017-09-29-rabbitmq-java-client-5-0-is-released/index.md","title":"RabbitMQ Java Client 5.0 is Released","description":"The RabbitMQ team is happy to announce the release of version 5.0 of the RabbitMQ Java Client. This new release is now based on Java 8 and comes with a bunch of interesting new features.","date":"2017-09-29T00:00:00.000Z","tags":[{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":2.395,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"RabbitMQ Java Client 5.0 is Released","tags":["Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"New Reactive Client for RabbitMQ HTTP API","permalink":"/rabbitmq-website/blog/2017/10/18/new-reactive-client-for-rabbitmq-http-api"},"nextItem":{"title":"Brand new rabbitmqctl in 3.7.0","permalink":"/rabbitmq-website/blog/2016/12/15/brand-new-rabbitmqctl-in-3-7-0"}},"content":"The RabbitMQ team is happy to announce the release of version 5.0 of the [RabbitMQ Java Client](/client-libraries/java-api-guide). This new release is now based on Java 8 and comes with a bunch of interesting new features.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Java 8 is Now a Pre-requisite\\r\\n\\r\\nRabbitMQ Java Client has been supporting Java 6 (released in 2006!) for many years. It was time to bump the pre-requisites to benefit from modern Java features. No need to worry for those stuck on Java 6 or Java 7: we will support Java Client 4.x.x series for the next upcoming months (bug fixes and even relevant new features if possible). Note the Java Client 5.0 (as well as 4.x.x) also supports Java 9.\\r\\n\\r\\n## Spring Cleaning\\r\\n\\r\\nSome classes and interfaces showed to be less relevant these days and were marked as deprecated in the previous major versions: this is the case of `FlowListener` and `QueueingConsumer` (among others). They have been removed in 5.0.\\r\\n\\r\\n## New Lambda-oriented Methods\\r\\n\\r\\nLambda-oriented methods have been introduced for common use cases, e.g. to <a href=\\"https://github.com/rabbitmq/rabbitmq-java-client/blob/6ce40192bb426a2f24791bb58777424cc5086727/src/test/java/com/rabbitmq/client/test/LambdaCallbackTest.java#L97\\">consume a message</a>:\\r\\n\\r\\n```java\\r\\nconsumingChannel.basicConsume(queue,\\r\\n    (consumerTag, delivery) -> businessService.handle(delivery),\\r\\n    consumerTag -> LOGGER.info(\\"Consumer {} has been cancelled\\")\\r\\n);\\r\\n```\\r\\n\\r\\nOther lambda-oriented methods are also available for <a href=\\"https://github.com/rabbitmq/rabbitmq-java-client/blob/6ce40192bb426a2f24791bb58777424cc5086727/src/test/java/com/rabbitmq/client/test/LambdaCallbackTest.java#L59\\">most of the</a> <a href=\\"https://github.com/rabbitmq/rabbitmq-java-client/blob/6ce40192bb426a2f24791bb58777424cc5086727/src/test/java/com/rabbitmq/client/test/LambdaCallbackTest.java#L70\\">client</a> <a href=\\"https://github.com/rabbitmq/rabbitmq-java-client/blob/6ce40192bb426a2f24791bb58777424cc5086727/src/test/java/com/rabbitmq/client/test/LambdaCallbackTest.java#L49\\">listeners</a>. This should make relevant application code more concise and readable.\\r\\n\\r\\n## More Flexibility to Specify Client Certificate\\r\\n\\r\\nIn Java, a client certificate is presented through a `SSLContext`\'s `KeyManager`. If different client connections needed different client certificates in the RabbitMQ Java Client, they needed different instances of `ConnectionFactory`. In 5.0, we introduced the [`SslContextFactory`](https://github.com/rabbitmq/rabbitmq-java-client/blob/ce3a04c6351d89cfe7059f88378cb37d47647386/src/main/java/com/rabbitmq/client/SslContextFactory.java):\\r\\n\\r\\n```java\\r\\npublic interface SslContextFactory {\\r\\n\\r\\n    SSLContext create(String name);\\r\\n\\r\\n}\\r\\n```\\r\\n\\r\\nYou can now set your own `SslContextFactory` in the `ConnectionFactory` to provide the logic based on the connection name to create the appropriate `SslContext` for this connection. The `SslContextFactory` implementation can look up certificates from a file system directory or from any other certificate repository (database, LDAP registry, etc). Combined with NIO (added in 4.0), this is a great way to have many client connections in a single JVM process that uses only a few threads.\\r\\n\\r\\n## Breaking Changes\\r\\n\\r\\nA major release is a good time to do some cleaning as seen above and to introduce new features. Unfortunately, those new features sometimes break existing API. Cheer up, as we strived to maintain backward compatibility and most applications shouldn\'t be impacted by those changes. If in doubt, check the [dedicated section](https://github.com/rabbitmq/rabbitmq-java-client/releases/tag/v5.0.0#breaking-changes) in the release change log.\\r\\n\\r\\n## Wrapping Up\\r\\n\\r\\nThe RabbitMQ team hopes you\'ll enjoy this new version of the Java Client. Don\'t hesitate to consult the [release change log](https://github.com/rabbitmq/rabbitmq-java-client/releases/tag/v5.0.0) for all the details. The binaries are available as usual from [Maven Central](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.rabbitmq%22%20AND%20a%3A%22amqp-client%22) and from our [Bintray repository](https://bintray.com/rabbitmq/maven/com.rabbitmq%3Aamqp-client). To use RabbitMQ Java Client 5.0, add the following dependency if you\'re using Maven:\\r\\n\\r\\n```xml\\r\\n<dependency>\\r\\n    <groupId>com.rabbitmq</groupId>\\r\\n    <artifactId>amqp-client</artifactId>\\r\\n    <version>5.0.0</version>\\r\\n</dependency>\\r\\n```\\r\\n\\r\\nIf you\'re using Gradle:\\r\\n\\r\\n```groovy\\r\\ncompile \'com.rabbitmq:amqp-client:5.0.0\'\\r\\n```\\r\\n\\r\\nEnjoy!"},{"id":"/2016/12/15/brand-new-rabbitmqctl-in-3-7-0","metadata":{"permalink":"/rabbitmq-website/blog/2016/12/15/brand-new-rabbitmqctl-in-3-7-0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2016-12-15-brand-new-rabbitmqctl-in-3-7-0/index.md","source":"@site/blog/2016-12-15-brand-new-rabbitmqctl-in-3-7-0/index.md","title":"Brand new rabbitmqctl in 3.7.0","description":"As of v3.7.0 Milestone 8,","date":"2016-12-15T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":1.145,"hasTruncateMarker":true,"authors":[{"name":"Daniil Fedotov","key":"dfedotov","page":null}],"frontMatter":{"title":"Brand new rabbitmqctl in 3.7.0","tags":["New Features"],"authors":["dfedotov"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Java Client 5.0 is Released","permalink":"/rabbitmq-website/blog/2017/09/29/rabbitmq-java-client-5-0-is-released"},"nextItem":{"title":"Metrics support in RabbitMQ Java Client 4.0","permalink":"/rabbitmq-website/blog/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0"}},"content":"As of [v3.7.0 Milestone 8](https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_7_0_milestone8),\\r\\nRabbitMQ ships with a brand new set of CLI tools (`rabbitmqctl`, `rabbitmq-plugins`, and more), reworked from the ground-up. We had a few goals with this project.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nWe wanted to use a more user-friendly command line parser and produce more useful help and error messages.\\r\\n\\r\\n* CLI tools should be extensible from plugins: plugins such as management, federation, shovel, trust store all have functions that are meant to be invoked by CLI tools but the only way of doing it was `rabbitmqctl eval`, which is error prone and can be dangerous.\\r\\n* We wanted to give [Elixir](http://elixir-lang.org) a try on a real project and make it easier for developers new to Erlang to extend the CLI functionality.\\r\\n* Our CLI tools historically didn\'t have good test coverage; the new ones should (and do).\\r\\n* CLI tools should be able to produce machine-friendly formats, be it JSON, CSV or something else; there was no internal infrastructure for doing that in the original implementation.\\r\\n* CLI tools should be a separate repository just like all plugins, client libraries, and so on.\\r\\n\\r\\nNine months later the experiment was declared a success and integrated into RabbitMQ distribution.\\r\\n\\r\\nPlease give [v3.7.0 Milestone 8](https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_7_0_milestone8) a try and take a look at [how easy it is to extend the CLI](https://github.com/rabbitmq/rabbitmq-cli/blob/master/COMMAND_TUTORIAL.md).\\r\\n\\r\\nThere\'s also a [longer document](https://github.com/rabbitmq/rabbitmq-cli/blob/master/DESIGN.md) that covers new features and implementation decisions."},{"id":"/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","metadata":{"permalink":"/rabbitmq-website/blog/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2016-11-30-metrics-support-in-rabbitmq-java-client-4-0/index.md","source":"@site/blog/2016-11-30-metrics-support-in-rabbitmq-java-client-4-0/index.md","title":"Metrics support in RabbitMQ Java Client 4.0","description":"Version 4.0 of the RabbitMQ Java Client brings support for runtime metrics. This can be especially useful to know how a client application is behaving. Let\'s see how to enable metrics collection and how to monitor those metrics on JMX or even inside a Spring Boot application.","date":"2016-11-30T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.415,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"Metrics support in RabbitMQ Java Client 4.0","tags":["Performance","Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Brand new rabbitmqctl in 3.7.0","permalink":"/rabbitmq-website/blog/2016/12/15/brand-new-rabbitmqctl-in-3-7-0"},"nextItem":{"title":"RabbitMQ Java Client 4.0 is released","permalink":"/rabbitmq-website/blog/2016/11/24/rabbitmq-java-client-4-0-is-released"}},"content":"[Version 4.0 of the RabbitMQ Java Client](/blog/2016/11/24/rabbitmq-java-client-4-0-is-released) brings support for runtime metrics. This can be especially useful to know how a client application is behaving. Let\'s see how to enable metrics collection and how to monitor those metrics on JMX or even inside a Spring Boot application.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Metrics activation\\r\\n\\r\\nMetrics are collected at the `ConnectionFactory` level, through the `MetricsCollector` interface. The Java Client comes with one implementation, `StandardMetricsCollector`, which uses the [Dropwizard Metrics](http://metrics.dropwizard.io/) library. \\r\\n\\r\\nDropwizard Metrics is mature and widely used across the Java community, so we thought it\'d make sense to make it our default metrics library. Nevertheless, you can come up with your own `MetricsCollector` implementation if your application has specific needs in terms of metrics.\\r\\n\\r\\nNote metrics collection is disabled by default, so it doesn\'t impact users who don\'t want to have runtime metrics.\\r\\n\\r\\nHere is how to enable metrics collection with the default implementation and then get the total number of published messages with all the connections created from this `ConnectionFactory`:\\r\\n\\r\\n```java\\r\\nConnectionFactory connectionFactory = new ConnectionFactory();\\r\\nStandardMetricsCollector metrics = new StandardMetricsCollector();\\r\\nconnectionFactory.setMetricsCollector(metrics);    \\r\\n// later in the code\\r\\nlong publishedMessagesCount = metrics.getPublishedMessages().getCount();\\r\\n```\\r\\n\\r\\nOther available metrics are open connections and channels, consumed messages, acknowledged messages, and rejected messages.\\r\\n\\r\\nUsing metrics inside the application code usually doesn\'t make much sense: those metrics are rather meant to be sent to some monitoring backends. Fortunately, Dropwizard Metrics support many of those: JMX, Graphite, Ganglia, even CSV file export. Let\'s see how to use it with JMX, a Java standard to manage and monitor applications.\\r\\n\\r\\n## With JMX\\r\\n\\r\\nDropwizard Metrics has built-in support for JMX thanks to the `JmxReporter` class. The `MetricRegistry` just needs to be shared between the `StandardMetricsCollector` and the `JmxReporter`:\\r\\n\\r\\n```java\\r\\nMetricRegistry registry = new MetricRegistry();\\r\\nStandardMetricsCollector metrics = new StandardMetricsCollector(registry);\\r\\n\\r\\nConnectionFactory connectionFactory = new ConnectionFactory();\\r\\nconnectionFactory.setMetricsCollector(metrics);\\r\\n\\r\\nJmxReporter reporter = JmxReporter\\r\\n    .forRegistry(registry)\\r\\n    .inDomain(\\"com.rabbitmq.client.jmx\\")\\r\\n    .build();\\r\\nreporter.start();\\r\\n```\\r\\n\\r\\nPretty straightforward. You can then use any JMX-compliant client, like [Java VisualVM](https://visualvm.github.io/) (with the [appropriate plugin](https://visualvm.github.io/plugins.html)) to browse the metrics.\\r\\n\\r\\n![JMX metrics](java-visualvm-jmx.png)\\r\\n\\r\\nAs stated above, Dropwizard Metrics supports many monitoring backends, feel free to consult the library documentation to see how to send your metrics to those backends.\\r\\n\\r\\nLet\'s see now how to integrate the RabbitMQ Java Client metrics with Spring Boot.\\r\\n\\r\\n## With Spring Boot\'s metrics endpoint\\r\\n\\r\\nMany RabbitMQ users are using the Java Client through [Spring AMQP](https://projects.spring.io/spring-amqp/) and [Spring Boot](https://projects.spring.io/spring-boot/). Spring Boot also supports Dropwizard Metrics in its [`/metrics` endpoint](http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#production-ready-metrics), one of the very useful endpoints the [Spring Boot Actuator](http://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#production-ready) provides.\\r\\n\\r\\nAs soon as Spring Boot detects Dropwizard Metrics on the classpath, it creates a `MetricRegistry` bean. It doesn\'t take long to retrieve this bean and use it in our `StandardMetricsCollector`. Note Spring Boot automatically creates the necessary resources (RabbitMQ\'s `ConnectionFactory` and Spring AMQP\'s `CachingConnectionFactory`) if it detects Spring AMQP on the classpath. The glue code to add to a configuration class isn\'t obvious but it\'s at least straightforward:\\r\\n\\r\\n```java\\r\\n@Autowired CachingConnectionFactory connectionFactory;\\r\\n@Autowired MetricRegistry registry;\\r\\n\\r\\n@PostConstruct\\r\\npublic void init() {\\r\\n    ConnectionFactory rabbitConnectionFactory = connectionFactory.getRabbitConnectionFactory();\\r\\n    StandardMetricsCollector metrics = new StandardMetricsCollector(registry);\\r\\n    rabbitConnectionFactory.setMetricsCollector(metrics);\\r\\n} \\r\\n```\\r\\n\\r\\nOnce the Spring Boot web application is up, go to `http://localhost:8080/metrics` and you should see the RabbitMQ Java Client metrics:\\r\\n\\r\\n```json\\r\\n{\\r\\n    ...\\r\\n    \\"rabbitmq.acknowledged.count\\": 5445,\\r\\n    \\"rabbitmq.acknowledged.fifteenMinuteRate\\": 7.789880284345983,\\r\\n    \\"rabbitmq.acknowledged.fiveMinuteRate\\": 9.311935481093306,\\r\\n    \\"rabbitmq.acknowledged.meanRate\\": 9.930420428656602,\\r\\n    \\"rabbitmq.acknowledged.oneMinuteRate\\": 9.972266275538352,\\r\\n    \\"rabbitmq.channels\\": 2,\\r\\n    \\"rabbitmq.connections\\": 1,\\r\\n    \\"rabbitmq.consumed.count\\": 5445,\\r\\n    \\"rabbitmq.consumed.fifteenMinuteRate\\": 7.789875530041546,\\r\\n    \\"rabbitmq.consumed.fiveMinuteRate\\": 9.311910098253794,\\r\\n    \\"rabbitmq.consumed.meanRate\\": 9.930418948751754,\\r\\n    \\"rabbitmq.consumed.oneMinuteRate\\": 9.972238610447798,\\r\\n    \\"rabbitmq.published.count\\": 5445,\\r\\n    \\"rabbitmq.published.fifteenMinuteRate\\": 7.789875530041546,\\r\\n    \\"rabbitmq.published.fiveMinuteRate\\": 9.311910098253794,\\r\\n    \\"rabbitmq.published.meanRate\\": 9.930419905146142,\\r\\n    \\"rabbitmq.published.oneMinuteRate\\": 9.972238610447798,\\r\\n    \\"rabbitmq.rejected.count\\": 0,\\r\\n    \\"rabbitmq.rejected.fifteenMinuteRate\\": 0,\\r\\n    \\"rabbitmq.rejected.fiveMinuteRate\\": 0,\\r\\n    \\"rabbitmq.rejected.meanRate\\": 0,\\r\\n    \\"rabbitmq.rejected.oneMinuteRate\\": 0,\\r\\n    ...\\r\\n}\\r\\n```\\r\\n\\r\\nNeat isn\'t it? Plugging the RabbitMQ Java Client metrics on the `/metrics` endpoint is explicit right now, but this [should hopefully become automatic](https://github.com/spring-projects/spring-boot/pull/7499) (as in Spring Boot auto-configuration) as long as the appropriate conditions are met (Dropwizard Metrics and RabbitMQ Java Client version 4.0 or more on the classpath).\\r\\n\\r\\n## Wrapping up\\r\\n\\r\\nOperators and developers can now have more insights about applications using the RabbitMQ Java Client. Available metrics can tell you whether the application is operating normally or not. And thanks to Dropwizard Metrics large range of supported backends, plugging the Java Client metrics on your favorite monitoring tool should be straightforward.\\r\\n\\r\\n[Source code](https://github.com/acogoluegnes/rabbitmq-java-client-metrics-blog-post)"},{"id":"/2016/11/24/rabbitmq-java-client-4-0-is-released","metadata":{"permalink":"/rabbitmq-website/blog/2016/11/24/rabbitmq-java-client-4-0-is-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2016-11-24-rabbitmq-java-client-4-0-is-released/index.md","source":"@site/blog/2016-11-24-rabbitmq-java-client-4-0-is-released/index.md","title":"RabbitMQ Java Client 4.0 is released","description":"The RabbitMQ team is happy to announce the release of version 4.0 of the RabbitMQ Java Client. This new release does not introduce any breaking changes and comes with a bunch of interesting new features.","date":"2016-11-24T00:00:00.000Z","tags":[{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":2.58,"hasTruncateMarker":true,"authors":[{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null}],"frontMatter":{"title":"RabbitMQ Java Client 4.0 is released","tags":["Programming Languages","New Features"],"authors":["acogoluegnes"]},"unlisted":false,"prevItem":{"title":"Metrics support in RabbitMQ Java Client 4.0","permalink":"/rabbitmq-website/blog/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0"},"nextItem":{"title":"What\'s new in RabbitMQ 3.6.0","permalink":"/rabbitmq-website/blog/2015/12/28/whats-new-in-rabbitmq-3-6-0"}},"content":"The RabbitMQ team is happy to announce the release of version 4.0 of the [RabbitMQ Java Client](/client-libraries/java-api-guide). This new release does not introduce any breaking changes and comes with a bunch of interesting new features.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## New independent release process\\r\\n\\r\\nFrom now on, the Java Client will be released separately from the broker. It\'ll make it easier and faster to ship bug fixes as well as new features.\\r\\n\\r\\n## Logging support with SLF4J\\r\\n\\r\\n[SLF4J](http://www.slf4j.org/) is now used in several places of the Java Client to report logging messages. It\'s also used in the default exception handler implementation that ships with the client. This gives the application developer a large choice of logging implementations (e.g. [Logback](http://logback.qos.ch/), [Log4j](http://logging.apache.org/log4j/2.x/)) and a large choice of destinations to direct logs to (file, but also logging-specific protocols).\\r\\n\\r\\n## Metrics support\\r\\n\\r\\nThe Java Client can now gather runtime metrics such as number of sent and received messages. The metrics are collected by default through [Dropwizard Metrics](http://metrics.dropwizard.io/) library, but collection is pluggable if you have some fancy requirements. Using Dropwizard Metrics gives the opportunity to use many monitoring backends out-of-the-box: JMX, Spring Boot metrics endpoint, Ganglia, Graphite, etc.\\r\\n\\r\\nA separate blog post will cover metrics support in depth.\\r\\n\\r\\n## Support for Java NIO\\r\\n\\r\\nThe Java Client has been historically using the traditional Java blocking IO library (i.e. `Socket` and its `Input/OutputStream`s). This has been working for years, but isn\'t adapted to all kinds of workloads. Java NIO allows for a more flexible, yet more complex to implement model to handle network communication. Long story short, Java NIO allows to handle more connections with fewer threads (the blocking IO mode always needs one thread per connection).\\r\\n\\r\\nDon\'t think of Java NIO as some kind of turbo button: your client application won\'t be faster by using NIO, it\'ll likely be able to use fewer threads if you use a lot of connections, that\'s all.\\r\\n\\r\\nNote blocking IO is still the default in the Java Client, you need to explicitly enable NIO. The NIO mode uses reasonable defaults, but you may also have to tweak it for your workload through the `NioParams` class.\\r\\n\\r\\n## Automatic recovery enabled by default\\r\\n\\r\\n[Automatic recovery](/client-libraries/java-api-guide#recovery) has been there for a few years now, and we know that many users always enable it, so we\'ve decided to enable it by default. You can still choose not to use it, but you\'ll need to disable it explicitly.\\r\\n\\r\\n## Miscellaneous goodies and fixes\\r\\n\\r\\nThis new release comes also with its load of goodies and fixes. Take a look at the `AddressResolver` interface for instance: it\'s an abstraction to resolve the RabbitMQ hosts you want to connect to. Combined with automatic recovery, you end up with a robust client that can reconnect to nodes that weren\'t even up when it started in the first place.\\r\\n\\r\\nThe RabbitMQ Java Client version 4.0 is available on [Maven Central](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.rabbitmq%22%20AND%20a%3A%22amqp-client%22) (as well as on our [Bintray repository](https://bintray.com/rabbitmq/maven/com.rabbitmq%3Aamqp-client)). To use it, add the following dependency if you\'re using Maven:\\r\\n\\r\\n```xml\\r\\n<dependency>\\r\\n    <groupId>com.rabbitmq</groupId>\\r\\n    <artifactId>amqp-client</artifactId>\\r\\n    <version>4.0.0</version>\\r\\n</dependency>\\r\\n```\\r\\n\\r\\nIf you\'re using Gradle:\\r\\n\\r\\n```groovy\\r\\ncompile \'com.rabbitmq:amqp-client:4.0.0\'\\r\\n```\\r\\n\\r\\nEnjoy!\\r\\n\\r\\n[Release change](https://github.com/rabbitmq/rabbitmq-java-client/releases/tag/v4.0.0)"},{"id":"/2015/12/28/whats-new-in-rabbitmq-3-6-0","metadata":{"permalink":"/rabbitmq-website/blog/2015/12/28/whats-new-in-rabbitmq-3-6-0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2015-12-28-whats-new-in-rabbitmq-3-6-0/index.md","source":"@site/blog/2015-12-28-whats-new-in-rabbitmq-3-6-0/index.md","title":"What\'s new in RabbitMQ 3.6.0","description":"We are pleased to announce the immediate availability of RabbitMQ","date":"2015-12-28T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.83,"hasTruncateMarker":true,"authors":[{"name":"Álvaro Videla","key":"alvaro","page":null}],"frontMatter":{"title":"What\'s new in RabbitMQ 3.6.0","tags":["New Features"],"authors":["alvaro"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Java Client 4.0 is released","permalink":"/rabbitmq-website/blog/2016/11/24/rabbitmq-java-client-4-0-is-released"},"nextItem":{"title":"New Credit Flow Settings on RabbitMQ 3.5.5","permalink":"/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5"}},"content":"We are pleased to announce the immediate availability of RabbitMQ\\r\\n3.6.0, a new version of the broker that comes packed with lot of\\r\\n[new features](https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_6_0). Before\\r\\nwe go on, you can obtain it here:\\r\\n[/docs/download](/docs/download).\\r\\n\\r\\nThis release brings many improvements in broker features, development\\r\\nenvironment for our contributors, and security. Let\'s take a look at\\r\\nsome of the most significant ones.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Features\\r\\n\\r\\nThere are quite a few new features and improvements inside RabbitMQ\\r\\n3.6.0 but from my point of view the most important one are\\r\\n*lazy-queues*. Disclaimer: the author of this blog post worked on this\\r\\nfeature ;-)\\r\\n\\r\\n### Lazy Queues\\r\\n\\r\\nThis new type of queues work by sending every message that is\\r\\ndelivered to them straight to the file system, and only loading\\r\\nmessages in RAM when consumers arrive to the queues. To optimize disk\\r\\nreads messages are loaded in batches.\\r\\n\\r\\nThere are a few advantages from this approach versus the old\\r\\napproach. RabbitMQ default queues keep a cache of messages in memory\\r\\nfor fast delivery to consumers, the problem with this cache is that if\\r\\nconsumers aren\'t fast enough, or consumers go completely offline, then\\r\\nmore and more messages will be held in RAM, which at some point will\\r\\ntrigger the algorithm that makes the queue page messages to disk. Even\\r\\ntho in previous releases we have\\r\\n[improved the paging algorithm](https://github.com/rabbitmq/rabbitmq-server/issues/227),\\r\\npaging can still block the queue process, which could result in\\r\\n[credit flow](/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5)\\r\\nkicking in, which ends up blocking publishers.\\r\\n\\r\\nWith lazy queues there\'s no paging, since as stated above, all\\r\\nmessages are sent straight to disk. Our tests have shown that this has\\r\\nthe consequence of having a more even throughput for queues, even when\\r\\nconsumers are offline.\\r\\n\\r\\nAnother advantage of lazy queues is the reduced RAM usage due to the\\r\\nelimination of the message cache mentioned above.\\r\\n\\r\\nFinally, lazy queues can be enabled and disabled at runtime. You can\\r\\nuse [policies](/docs/parameters#policies) to\\r\\nconvert queues from default ones to lazy queues, and even back to the\\r\\ndefault mode if you feel the need for it.\\r\\n\\r\\nTo learn more about lazy queues please refer to their\\r\\n[documentation](/docs/lazy-queues).\\r\\n\\r\\n### Faster Mirror Queue Synchronization\\r\\n\\r\\nSynchronization between queues has been greatly improved. Before\\r\\nRabbitMQ 3.6.0 the synchronization algorithm would try to send one\\r\\nmessage at a time to those mirrors that were out of sync. This\\r\\nalgorithm has been improved by implementing batch publish operations\\r\\ninside RabbitMQ\'s queues.\\r\\n\\r\\nDuring development our tests showed that for a queue with one million\\r\\nmessages, the old algorithm would take approximately 60 seconds for a\\r\\nfull sync, while the new algorithm takes around 10 seconds for the\\r\\nsame amount of messages.\\r\\n\\r\\nRead more about mirror queue synchronization\\r\\n[here](/docs/3.13/ha#batch-sync).\\r\\n\\r\\n## Moving to Git\\r\\n\\r\\nDuring a big part of this year, our development moved completely from\\r\\nour self-hosted Mercurial repository, to a Git based workflow hosted\\r\\non Github. This has improved a lot our own productivity as a team,\\r\\nmaking it easier to work on new features, and get feedback between\\r\\ncolleagues.\\r\\n\\r\\nWhat\'s better though, is the fact that now is much easier for RabbitMQ\\r\\nusers to send their contributions back to us.\\r\\n\\r\\nThis release comes with quite a few improvements to the broker\\r\\ndirectly sent by six different external contributors. Of course we\\r\\nwant to improve that number.\\r\\n\\r\\nMoving to Github also means that now we have a public bug\\r\\ntracker. Feel free to submit issues here:\\r\\n[https://github.com/rabbitmq/rabbitmq-server/issues](https://github.com/rabbitmq/rabbitmq-server/issues).\\r\\nHere\'s our guide on how we use\\r\\n[Git and Github](/github).\\r\\n\\r\\n## Move to Erlang.mk\\r\\n\\r\\nRabbitMQ as a project predates popular build tools from the Erlang\\r\\necosystem like Rebar or [Erlang.mk](http://Erlang.mk), therefore we had our own way to\\r\\nbuild the broker and to manage Erlang dependencies. This was\\r\\nunfortunate since it made a little bit harder to integrate external\\r\\nlibraries with RabbitMQ, and at the same time, it complicated things\\r\\nfor other Erlang users to use RabbitMQ libraries. Just take a look at\\r\\nthis Github search where people are trying different ways to integrate\\r\\nour very own `gen_server2` into their projects:\\r\\n[gen_server2 search](https://github.com/search?l=erlang&amp;q=gen_server2&amp;type=Code&amp;utf8=%E2%9C%93)\\r\\n\\r\\nTo improve the situation in this area, one of our colleagues worked\\r\\nhard on a complete overhaul of our build system. We stayed with\\r\\n`make`, a tried and tested tool, but we migrated to\\r\\nErlang.mk, a make based build system for the\\r\\nErlang world.\\r\\n\\r\\nThis improved how we handle dependencies, allowed us to remove lot of\\r\\ncode that was duplicating features already provided by Erlang.mk, and\\r\\neven reduced build times!\\r\\n\\r\\nChanging things on our build system, means introducing breaking\\r\\nchanges on how we build RabbitMQ Plugins. If you are a plugin author,\\r\\nyou might want to read our new\\r\\n[plugin development guide](/plugin-development).\\r\\n\\r\\n## Security\\r\\n\\r\\nLast but not least, let\'s talk about improvements in security,\\r\\nspecifically on how passwords are handled in RabbitMQ. Before version\\r\\n3.6.0, passwords were stored in RabbitMQ as an md5 hash, which for\\r\\nthis day and age, is less than ideal. Now we have set `SHA-256` as the\\r\\ndefault password hashing function, with `SHA-512` being an option that\\r\\nwe provide out of the box.\\r\\n\\r\\nIn this regard, it\'s also possible to add other hashing algorithms to\\r\\nRabbitMQ via plugins. To add a new hashing algorithm you just need to\\r\\nimplement this Erlang behaviour\\r\\n[rabbit_password_hashing.erl](https://github.com/rabbitmq/rabbitmq-common/blob/432612a588f9741609b1318294933f6427ab2ee1/src/rabbit_password_hashing.erl)\\r\\nwhich exposes only one function: `hash/1`.\\r\\n\\r\\nIf you create a new password hashing plugin, don\'t forget to announce\\r\\nit on our mailing list:\\r\\n[rabbitmq-users](https://groups.google.com/forum/#!forum/rabbitmq-users).\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nAs you can imagine, we are really happy with this new RabbitMQ\\r\\nrelease, which has set the foundation on which we can continue to\\r\\nimprove RabbitMQ, but now even closer together with the community, by\\r\\nhaving standard tools like Erlang.mk and a collaborative platform like\\r\\nGithub.\\r\\n\\r\\nDon\'t forget to take a look at our full release notes and learn about\\r\\nall the new features and bug fixes that ship with RabbitMQ 3.6.0:\\r\\n[release notes](https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_6_0)."},{"id":"/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","metadata":{"permalink":"/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2015-10-06-new-credit-flow-settings-on-rabbitmq-3-5-5/index.md","source":"@site/blog/2015-10-06-new-credit-flow-settings-on-rabbitmq-3-5-5/index.md","title":"New Credit Flow Settings on RabbitMQ 3.5.5","description":"This blog post was written for RabbitMQ 3.5, released in 2015. While some parts still","date":"2015-10-06T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":14.58,"hasTruncateMarker":true,"authors":[{"name":"Álvaro Videla","key":"alvaro","page":null}],"frontMatter":{"title":"New Credit Flow Settings on RabbitMQ 3.5.5","tags":["Performance"],"authors":["alvaro"]},"unlisted":false,"prevItem":{"title":"What\'s new in RabbitMQ 3.6.0","permalink":"/rabbitmq-website/blog/2015/12/28/whats-new-in-rabbitmq-3-6-0"},"nextItem":{"title":"Scheduling Messages with RabbitMQ","permalink":"/rabbitmq-website/blog/2015/04/16/scheduling-messages-with-rabbitmq"}},"content":":::warning\\r\\nThis blog post was written for RabbitMQ 3.5, released in 2015. While some parts still\\r\\napply, there\'s a lot of outdated information. For example, RabbitMQ 4.0\\r\\ndoesn\'t support queue mirroring anymore and \\"paging messages to disk\\" is\\r\\nno longer something that RabbitMQ has to do, since messages are almost\\r\\nalways persisted to disk right away.\\r\\n:::\\r\\n\\r\\nIn order to prevent fast publishers from overflowing the broker with\\r\\nmore messages than it can handle at any particular moment, RabbitMQ\\r\\nimplements an internal mechanism called *credit flow* that will be\\r\\nused by the various systems inside RabbitMQ to throttle down\\r\\npublishers, while allowing the message consumers to catch up. In this\\r\\nblog post we are going to see how *credit flow* works, and what we can\\r\\ndo to tune its configuration for an optimal behaviour.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThe [latest](https://github.com/rabbitmq/rabbitmq-server/releases/tag/rabbitmq_v3_5_5) version of RabbitMQ includes a couple of new configuration\\r\\nvalues that let users fiddle with the internal credit flow\\r\\nsettings. Understanding how these work according to your particular\\r\\nworkload can help you get the most out of RabbitMQ in terms of\\r\\nperformance, but beware, increasing these values *just to see what\\r\\nhappens* can have adverse effects on how RabbitMQ is able to respond\\r\\nto message bursts, affecting the internal strategies that RabbitMQ has\\r\\nin order to deal with memory pressure. **Handle with care**.\\r\\n\\r\\nTo understand the new credit flow settings first we need to understand\\r\\nhow the internals of RabbitMQ work with regards to message publishing\\r\\nand paging messages to disk. Let\'s see first how message publishing\\r\\nworks in RabbitMQ.\\r\\n\\r\\n## Message Publishing\\r\\n\\r\\nTo see how `credit_flow` and its settings affect publishing, let\'s see\\r\\nhow internal messages flow in RabbitMQ. Keep in mind that RabbitMQ is\\r\\nimplemented in Erlang, where processes communicate by sending messages\\r\\nto each other.\\r\\n\\r\\nWhenever a RabbitMQ instance is running, there are probably hundreds\\r\\nof Erlang processes exchanging messages to communicate with each\\r\\nother. We have for example a reader process that reads AMQP frames\\r\\nfrom the network. Those frames are transformed into AMQP commands that\\r\\nare forwarded to the AMQP channel process. If this channel is handling\\r\\na publish, it needs to ask a particular exchange for the list of\\r\\nqueues where this message should end up going, which means the channel\\r\\nwill deliver the message to each of those queues. Finally if the AMQP\\r\\nmessage needs to be persisted, the msg_store process will receive it\\r\\nand write it to disk. So whenever we publish an AMQP message to\\r\\nRabbitMQ we have the following erlang message flow[^1]:\\r\\n\\r\\n```\\r\\nreader -> channel -> queue process -> message store.\\r\\n```\\r\\n\\r\\nIn order to prevent any of those processes from overflowing the next\\r\\none down the chain, we have a *credit flow* mechanism in place. Each\\r\\nprocess initially grants certain amount of credits to the process that\\r\\nit\'s sending them messages. Once a process is able to handle N of\\r\\nthose messages, it will grant more credit to the process that sent\\r\\nthem. Under default *credit flow* settings\\r\\n(`credit_flow_default_credit` under `rabbitmq.config`) these values\\r\\nare 200 messages of initial credit, and after 50 messages processed by\\r\\nthe receiving process, the process that sent the messages will be\\r\\ngranted 50 more credits.\\r\\n\\r\\nSay we are publishing messages to RabbitMQ, this means the *reader*\\r\\nwill be sending one erlang message to the channel process per AMQP\\r\\n`basic.publish` received. Each of those messages will consume one of\\r\\nthese credits from the channel. Once the channel is able to process 50\\r\\nof those messages, it will grant more credit to the reader. So far so\\r\\ngood.\\r\\n\\r\\nIn turn the channel will send the message to the queue process that\\r\\nmatched the message routing rules. This will consume one credit from\\r\\nthe credit granted by the queue process to the channel. After the\\r\\nqueue process manages to handle 50 deliveries, it will grant 50 more\\r\\ncredits to the channel.\\r\\n\\r\\nFinally if a message is deemed to be persistent (it\'s persistent and\\r\\npublished to a durable queue), it will be sent to the message store,\\r\\nwhich in this case will also consume credits from the ones granted by\\r\\nthe message store to the queue process. In this case the initial\\r\\nvalues are different and handled by the `msg_store_credit_disc_bound`\\r\\nsetting: **2000** messages of initial credit and **500** more credits\\r\\nafter 500 messages are processed by the message store.\\r\\n\\r\\nSo we know how internal messages flow inside RabbitMQ and when credit\\r\\nis granted to a process that\'s above in the msg stream. The tricky\\r\\npart comes when credit is granted between processes. Under normal\\r\\nconditions a channel will process 50 messages from the reader, and\\r\\nthen grant the reader 50 more credits, but keep in mind that a channel\\r\\nis not just handling publishes, it\'s also sending messages to\\r\\nconsumers, routing messages to queues and so on.\\r\\n\\r\\nWhat happens if the reader is sending messages to the channel at a\\r\\nhigher speed of what the channel is able to process? If we reach this\\r\\nsituation, then the channel will block the reader process, which will\\r\\nresult in producers being throttled down by RabbitMQ. Under default\\r\\nsettings, the reader will be blocked once it sends 200 messages to the\\r\\nchannel, but the channel is not able to process at least 50 of them,\\r\\nin order to grant credit back to the reader.\\r\\n\\r\\nAgain, under normal conditions, once the channel manages to go through\\r\\nthe message backlog, it will grant more credit to the reader, but\\r\\nthere\'s a catch. What if the channel process is being blocked by the\\r\\nqueue process, due to similar reasons? Then the **new credit** that\\r\\nwas supposed to go to the reader process **will be deferred**. The\\r\\nreader process **will remain blocked**.\\r\\n\\r\\nOnce the queue process manages to go through the deliveries backlog\\r\\nfrom the channel, it will grant more credit to the channel, unblocking\\r\\nit, which will result in the channel granting more credit to the\\r\\nreader, unblocking it. Once again, that\'s under normal conditions,\\r\\nbut, you guessed it, what if the message store is blocking the queue\\r\\nprocess? Then credit to the channel will be deferred, which will\\r\\nremain blocked, deferring credit to the reader, **leaving the reader\\r\\nblocked**. At some point, the message store will grant messages to the\\r\\nqueue process, which will grant messages back to the channel, and then\\r\\nthe channel will finally grant messages to the reader and **unblock\\r\\nthe reader**:\\r\\n\\r\\n```\\r\\nreader <--[grant]-- channel <--[grant]-- queue process <--[grant]-- message store.\\r\\n```\\r\\n\\r\\nHaving one channel and one queue process makes things easier to\\r\\nundertand but it might not reflect reality. It\'s common for RabbitMQ\\r\\nusers to have more than one channel publishing messages on the same\\r\\nconnection. Even more common is to have one message being routed to\\r\\nmore than one queue. What happens with the credit flow scheme we\'ve\\r\\njust explained is that **if one of those queues blocks the channel**,\\r\\nthen **the reader will be blocked as well**.\\r\\n\\r\\nThe problem is that from a reader standpoint, when we read a frame\\r\\nfrom the network, we don\'t even know to which channel it belongs\\r\\nto. Keep in mind that channels are a logical concept on top of AMQP\\r\\nconnections. So even if a new AMQP command will end up in a channel\\r\\nthat is not blocking the reader, the reader has no way of knowing\\r\\nit. Note that **we only block publishing** connections, consumers\\r\\nconnections are unaffected since we want consumers to drain messages\\r\\nfrom queues. This is a good reason why it might be better to have\\r\\nconnections dedicated to publishing messages, and connections\\r\\ndedicated for consumers only.\\r\\n\\r\\nOn a similar fashion, whenever a channel is processing message\\r\\npublishes, it doesn\'t know where messages will end up going, until it\\r\\nperforms routing. So a channel might be receiving a message that\\r\\nshould end up in a queue that is not blocking the channel. Since at\\r\\ningress time we don\'t know any of this, then the credit flow strategy\\r\\nin place is to block the reader until processes down the chain are\\r\\nable to handle new messages.\\r\\n\\r\\nOne of the new settings introduced in RabbitMQ 3.5.5 is the ability to\\r\\nmodify the values for `credit_flow_default_credit`. This setting takes\\r\\na tuple of the form `{InitialCredit, MoreCreditAfter}`. InitialCredit\\r\\nis set to **200** by default, and MoreCreditAfter is set to\\r\\n**50**. Depending on your particular workflow, you need to decide if\\r\\nit\'s worth bumping those values. Let\'s see the message flow scheme\\r\\nagain:\\r\\n\\r\\n```\\r\\nreader -> channel -> queue process -> message store.\\r\\n```\\r\\n\\r\\nBumping the values for `{InitialCredit, MoreCreditAfter}` will mean\\r\\nthat at any point in that chain we could end up with more messages\\r\\nthan those that can be handled by the broker at that particular point\\r\\nin time. More messages means more RAM usage. The same can be said\\r\\nabout `msg_store_credit_disc_bound`, but keep in mind that there\'s\\r\\nonly one message store[^2] per RabbitMQ instance, and there\\r\\ncan be **many channels** sending messages to the **same queue\\r\\nprocess**. So while a queue process has a value of 2000 as\\r\\n`InitialCredit` from the message store, that queue can be ingesting\\r\\nmany times that value from different channel/connection sources. So\\r\\n200 credits as initial `credit_flow_default_credit` value could be\\r\\nseen as too conservative, but you need to understand if according to\\r\\nyour workflow that\'s still good enough or not.\\r\\n\\r\\n## Message Paging\\r\\n\\r\\nLet\'s take a look at how RabbitMQ queues store messages. When a\\r\\nmessage enters the queue, the queue needs to determine if the message\\r\\nshould be persisted or not. If the message has to be persisted, then\\r\\nRabbitMQ will do so right away[^3]. Now even if a message was\\r\\npersisted to disk, this doesn\'t mean the message got removed from RAM,\\r\\nsince RabbitMQ keeps a cache of messages in RAM for fast access when\\r\\ndelivering messages to consumers. Whenever we are talking about\\r\\n*paging messages out to disk*, we are talking about what RabbitMQ does\\r\\nwhen it has to send messages from this cache to the file system.\\r\\n\\r\\nWhen RabbitMQ decides it needs to page messages to disk it will call\\r\\nthe function `reduce_memory_use` on the internal queue implementation\\r\\nin order to send messages to the file system. Messages are going to be\\r\\npaged out in batches; how big are those batches depends on the current\\r\\nmemory pressure status. It basically works like this:\\r\\n\\r\\nThe function `reduce_memory_use` will receive a number called `target ram count` which tells RabbitMQ that it should try to page out\\r\\nmessages until only that many remain in RAM. Keep in mind that whether\\r\\nmessages are persistent or not, they are still kept in RAM for fast\\r\\ndelivery to consumers. Only when memory pressure kicks in, is when\\r\\nmessages in memory are paged out to disk. Quoting from our code\\r\\ncomments: The question of whether a message is in RAM and whether it\\r\\nis persistent are orthogonal.\\r\\n\\r\\nThe number of messages that are accounted for during this chunk\\r\\ncalculation are those messages that are in RAM (in the aforementioned\\r\\ncache), plus the number of pending acks that are kept in RAM (i.e.:\\r\\nmessages that were delivered to consumers and are pending\\r\\nacknowledgment). If we have 20000 messages in RAM (cache + pending\\r\\nacks) and then `target ram count` is set to 8000, we will have to page\\r\\nout 12000 messages. This means paging will receive a quota of 12000\\r\\nmessages. Each message paged out to disk will consume one unit from\\r\\nthat quota, whether it\'s a pending ack, or an actual message from the\\r\\ncache.\\r\\n\\r\\nOnce we know how many messages need to be paged out, we need to decide\\r\\nfrom where we should page them first: pending acks, or the message\\r\\ncache. If pending acks is growing faster than messages the cache, ie:\\r\\nmore messages are being delivered to consumers than those being\\r\\ningested, this means the algorithm will try to page out pending acks\\r\\nfirst, and then try to push messages from the cache to the file\\r\\nsystem. If the cache is growing faster than pending acks, then\\r\\nmessages from the cache will be pushed out first.\\r\\n\\r\\nThe catch here is that paging messages from pending acks (or the cache\\r\\nif that comes first) might result in the first part of the process\\r\\nconsuming all the quota of messages that need to be pushed to disk. So\\r\\nif pending acks pushes 12000 acks to disk as in our example, this\\r\\nmeans we won\'t page out messages from the cache, and vice versa.\\r\\n\\r\\nThis first part of the paging process sent to disk certain amount of\\r\\nmessages (between acks + messages paged from the cache). The messages\\r\\nthat were paged out just had their contents paged out, but their\\r\\nposition in the queue is still in RAM. Now the queue needs to decide\\r\\nif this extra information that\'s kept in RAM needs to be paged out as\\r\\nwell, to further reduce memory usage. Here is were finally\\r\\n`msg_store_io_batch_size` enters into play (coupled with\\r\\n`msg_store_credit_disc_bound` as well). Let\'s try to understand how\\r\\nthey work.\\r\\n\\r\\nThe settings for `msg_store_credit_disc_bound` affect how internal\\r\\ncredit flow is handled when sending message to disk. The\\r\\n`rabbitmq_msg_store` module implements a database that takes care of\\r\\npersisting messages to disk. Some details about the why\'s of this\\r\\nimplementation can be found here:\\r\\n[RabbitMQ, backing stores, databases and disks](/blog/2011/01/20/rabbitmq-backing-stores-databases-and-disks).\\r\\n\\r\\nThe message store has a credit system for each of the clients that\\r\\nsend writes to it. Every RabbitMQ queue would be a read/write client\\r\\nfor this store. The message store has a credits mechanism to prevent a\\r\\nparticular writer to overflow its inbox it with messages. Assuming\\r\\ncurrent default values, when a writer starts talking to the message\\r\\nstore, it receives an initial credit of **2000** messages, and it will\\r\\nreceive more credit once **500** messages are processed. When is this\\r\\ncredit consumed then? Credit is consumed whenever we write to the\\r\\nmessage store, but that doesn\'t happen for every message. The plot\\r\\nthickens.\\r\\n\\r\\nSince version 3.5.0 it\'s possible to embed small messages into the\\r\\nqueue index, instead of having to reach the message store for\\r\\nthat. Messages that are smaller than a configurable setting (currently\\r\\n4096 bytes) will go to the queue index when persisted, so those\\r\\nmessages won\'t consume this credit. Now, let\'s see what happens with\\r\\nmessages that do need to go to the message store.\\r\\n\\r\\nWhenever we publish a message that\'s determined to be persistent\\r\\n(persistent messages published to a durable queue), then that message\\r\\nwill consume one of these credits. If a message has to paged out to\\r\\ndisk from the cache mentioned above, it will also consume one\\r\\ncredit. So if during message paging we consume more credits than those\\r\\ncurrently available for our queue, the first half of the paging\\r\\nprocess might stop, since there\'s no point in sending writes to the\\r\\nmessage store when it won\'t accept them. This means that from the\\r\\ninitial quota of 12000 that we would have had to page out, we only\\r\\nmanaged to process 2000 of them (assuming all of them need to go to\\r\\nthe message store).\\r\\n\\r\\nSo we managed to page out 2000 messages, but we still keep their\\r\\nposition in the queue in RAM. Now the paging process will determine if\\r\\nit needs to also page out any of these messages positions to disk as\\r\\nwell. RabbitMQ will calculate how many of them can stay in RAM, and\\r\\nthen it will try to page out the remaining of them to disk. For this\\r\\nsecond paging to happen, the amount of messages that has to be paged\\r\\nto disk must be greater than `msg_store_io_batch_size`. The bigger\\r\\nthis number is, the more message positions RabbitMQ will keep in RAM,\\r\\nso again, depending on your particular workload, you need to tune this\\r\\nparameter as well.\\r\\n\\r\\nAnother thing we improved significantly in 3.5.5 is the performance of\\r\\npaging queue index contents to disk. If your messages are generally\\r\\nsmaller than `queue_index_embed_msgs_below`, then you\'ll see the\\r\\nbenefit of these changes. These changes also affect how message\\r\\npositions are paged out to disk, so you should see improvements in\\r\\nthis area as well. So while having a low `msg_store_io_batch_size`\\r\\nmight mean the queue index will have more work paging to disk, keep in\\r\\nmind this process has been optimized.\\r\\n\\r\\n## Queue Mirroring\\r\\n\\r\\nTo keep the descriptions above a bit simpler, we avoided bringing queue\\r\\nmirroring into the picture. Credit flows also affects mirroring from a\\r\\nchannel point of view. When a channel delivers AMQP messages to\\r\\nqueues, it sends the message to each mirror, consuming one credit from\\r\\neach mirror process. If any of the mirrors is slow processing the\\r\\nmessage then that particular mirror might be responsible for the\\r\\nchannel being blocked. If the channel is being blocked by a mirror,\\r\\nand that queue mirror gets partitioned from the network, then the\\r\\nchannel will be unblocked only after RabbitMQ detects the mirror\\r\\ndeath.\\r\\n\\r\\nCredit flow also takes part when synchronising mirrored queues, but\\r\\nthis is something you shouldn\'t care too much about, mostly because\\r\\nthere\'s nothing you could do about it, since mirror synchronisation is\\r\\nhandled entirely by RabbitMQ.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nIn any case, we hope this blog post has been informative and helps you\\r\\nwith your RabbitMQ tuning. If you have comments or questions about the\\r\\nnew credit flow settings, don\'t hesitate to contact us at the RabbitMQ\\r\\nmailing list:\\r\\n[rabbitmq-users](https://groups.google.com/forum/#!forum/rabbitmq-users).\\r\\n\\r\\n[^1]: A message can be delivered to more than one queue process.\\r\\n[^2]: There are two message stores, one for transient messages and one for persistent messages.\\r\\n[^3]: RabbitMQ will call fsync every 200 ms."},{"id":"/2015/04/16/scheduling-messages-with-rabbitmq","metadata":{"permalink":"/rabbitmq-website/blog/2015/04/16/scheduling-messages-with-rabbitmq","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2015-04-16-scheduling-messages-with-rabbitmq/index.md","source":"@site/blog/2015-04-16-scheduling-messages-with-rabbitmq/index.md","title":"Scheduling Messages with RabbitMQ","description":"For a while people have looked for ways of implementing delayed","date":"2015-04-16T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.12,"hasTruncateMarker":true,"authors":[{"name":"Álvaro Videla","key":"alvaro","page":null}],"frontMatter":{"title":"Scheduling Messages with RabbitMQ","tags":["New Features"],"authors":["alvaro"]},"unlisted":false,"prevItem":{"title":"New Credit Flow Settings on RabbitMQ 3.5.5","permalink":"/rabbitmq-website/blog/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5"},"nextItem":{"title":"Understanding memory use with RabbitMQ 3.4","permalink":"/rabbitmq-website/blog/2014/10/30/understanding-memory-use-with-rabbitmq-3-4"}},"content":"For a while people have looked for ways of implementing delayed\\r\\nmessaging with RabbitMQ. So far the accepted solution was to use a mix\\r\\nof [message TTL](/docs/ttl#per-message-ttl-in-publishers) and\\r\\n[Dead Letter Exchanges](/docs/dlx) as implemented\\r\\nby NServiceBus\\r\\n[here](https://docs.particular.net/transports/rabbitmq/delayed-delivery). After considering an\\r\\nout-of-the-box solution for some time, we had the opportunity to implement it as a plugin. Enter\\r\\n[RabbitMQ Delayed Message Plugin](https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/).\\r\\n<!-- truncate -->\\r\\n\\r\\nThe **RabbitMQ Delayed Message Plugin** adds a new exchange type to\\r\\nRabbitMQ where messages routed by that exchange can be delayed if the\\r\\nusers choses to do so. Let\'s see how it works.\\r\\n\\r\\n## Installing the Plugin\\r\\n\\r\\nTo install the plugin go to our\\r\\n[Community Plugins page](/community-plugins)\\r\\nand download the corresponding .ez files for your RabbitMQ\\r\\ninstallation. Copy the plugin into RabbitMQ\'s plugin folder and then\\r\\nenable it by running the following command:\\r\\n\\r\\n```shell\\r\\nrabbitmq-plugins enable rabbitmq_delayed_message_exchange\\r\\n```\\r\\n\\r\\nOnce the plugin has been enabled, we are ready to start using it.\\r\\n\\r\\n## Using the Exchange\\r\\n\\r\\nTo use the Delayed Message Exchange you just need to declare an\\r\\nexchange providing the `\\"x-delayed-message\\"` exchange type as follows:\\r\\n\\r\\n```java\\r\\n// ... elided code ...\\r\\nMap<String, Object> args = new HashMap<String, Object>();\\r\\nargs.put(\\"x-delayed-type\\", \\"direct\\");\\r\\nchannel.exchangeDeclare(\\"my-exchange\\", \\"x-delayed-message\\", true, false, args);\\r\\n// ... more code ...\\r\\n```\\r\\n\\r\\nLater on we will explain the meaning of the special argument\\r\\n`\\"x-delayed-type\\"` that we provided in our exchange declaration.\\r\\n\\r\\n## Delaying Messages\\r\\n\\r\\nTo delay a message a user must publish the message with the special\\r\\nheader called `x-delay` which takes an integer representing the number\\r\\nof milliseconds the message should be delayed by RabbitMQ. It\'s worth\\r\\nnoting that here *delay* means: delay message routing to queues or to\\r\\nother exchanges.\\r\\nThe exchange has no concept of consumers. So once the delay expired,\\r\\nthe plugin will attempt to route the message to the queues matching\\r\\nthe routing rules of the exchange and the once assigned to the\\r\\nmessage. Be aware that if the message can\'t be routed to any queue,\\r\\nthen it will be discarded, as is specified by AMQP with unroutable\\r\\nmessages.\\r\\nHere\'s some sample code that adds the `x-delay` header to a message\\r\\nand publishes to our exchange.\\r\\n\\r\\n```java\\r\\n// ... elided code ...\\r\\nbyte[] messageBodyBytes = \\"delayed payload\\".getBytes();\\r\\nAMQP.BasicProperties.Builder props = new AMQP.BasicProperties.Builder();\\r\\nheaders = new HashMap<String, Object>();\\r\\nheaders.put(\\"x-delay\\", 5000);\\r\\nprops.headers(headers);\\r\\nchannel.basicPublish(\\"my-exchange\\", \\"\\", props.build(), messageBodyBytes);\\r\\n```\\r\\n\\r\\nIn the previous example, the message will be delayed for five seconds\\r\\nbefore it gets routed by the plugin. That example assumes you have\\r\\nestablished a connection to RabbitMQ and obtained a channel.\\r\\n\\r\\n## Flexible Routing\\r\\n\\r\\nWhen we declared the exchange above, we provided an `x-delayed-type`\\r\\nargument set to `direct`. What that does is to tell the exchange what\\r\\nkind of behaviour we want it to have when routing messages, creating\\r\\nbindings, and so on. In the example, our exchange will behave like the\\r\\n*direct* exchange, but we could pass there topic, fanout, or a custom\\r\\nexchange type provided by some other plugin. By doing this we don\'t\\r\\nlimit the user on what kind of routing behaviour the delayed message\\r\\nplugin offers.\\r\\n\\r\\n## Checking if a Message was Delayed\\r\\n\\r\\nOnce we receive a message on the consumer side, how can we tell if the\\r\\nmessage was delayed or not? The plugin will keep the `x-delay` message\\r\\nheader, but will negate the passed value. So if you published a\\r\\nmessage with a `5000` milliseconds delay, the consumer receiving said\\r\\nmessage will find the `x-delay` header set to `-5000`\\r\\n\\r\\n## We need feedback\\r\\n\\r\\nWe have released the plugin as experimental to gather feedback from\\r\\nthe community. Please use it and report back to us on the plugin\'s\\r\\n[issue page](https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/issues)\\r\\nor on our\\r\\n[official mailing list](https://groups.google.com/forum/#!forum/rabbitmq-users).\\r\\n\\r\\n## Learn More\\r\\n\\r\\n* Webinar: [What\'s new in RabbitMQ 3.8?](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_campaign=rabbitmq-blog-3.8-webinar-q319&utm_source=rabbitmq&utm_medium=website)\\r\\n* Webinar: [10 Things Every Developer Using RabbitMQ Should Know](https://content.pivotal.io/webinars/dec-12-10-things-every-developer-using-rabbitmq-should-know-webinar?utm_campaign=rabbitmq-blog-10-things-q319&utm_source=rabbitmq&utm_medium=website)"},{"id":"/2014/10/30/understanding-memory-use-with-rabbitmq-3-4","metadata":{"permalink":"/rabbitmq-website/blog/2014/10/30/understanding-memory-use-with-rabbitmq-3-4","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2014-10-30-understanding-memory-use-with-rabbitmq-3-4/index.md","source":"@site/blog/2014-10-30-understanding-memory-use-with-rabbitmq-3-4/index.md","title":"Understanding memory use with RabbitMQ 3.4","description":"\\"How much memory is my queue using?\\" That\'s an easy question to ask, and a somewhat more complicated one to answer. RabbitMQ 3.4 gives you a clearer view of how queues use memory. This blog post talks a bit about that, and also explains queue memory use in general.","date":"2014-10-30T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":3.96,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Understanding memory use with RabbitMQ 3.4","tags":["New Features","HowTo"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Scheduling Messages with RabbitMQ","permalink":"/rabbitmq-website/blog/2015/04/16/scheduling-messages-with-rabbitmq"},"nextItem":{"title":"Finding bottlenecks with RabbitMQ 3.3","permalink":"/rabbitmq-website/blog/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3"}},"content":"\\"How much memory is my queue using?\\" That\'s an easy question to ask, and a somewhat more complicated one to answer. RabbitMQ 3.4 gives you a clearer view of how queues use memory. This blog post talks a bit about that, and also explains queue memory use in general.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## A bit of background\\r\\n\\r\\nFirst of all we need to understand how Erlang manages memory. Erlang is a bit different from most garbage-collected languages in that it does not have a global heap. Instead, **each process has a separate heap** that\'s private to it. In RabbitMQ terms process might be queues, channels, connections and so on. This means that the entire system does not have to come to a halt every time garbage collection needs to happen; instead each process collects garbage on its own schedule.\\r\\n\\r\\nThat\'s fine, but as a message passes through RabbitMQ, it will pass through several different processes. We\'d like to avoid doing too much copying as this happens. Therefore Erlang gives us a different memory management scheme for *binaries*, which are used for a number of things inside RabbitMQ, of which the most interesting is message bodies. **Binaries are shared between processes** and reference-counted (with references being held by processes and garbage-collected along with everything else).\\r\\n\\r\\n## How this applies to RabbitMQ\\r\\n\\r\\nThis means that memory used by message bodies is shared among processes in RabbitMQ. And this sharing also happens between queues too: **if an exchange routes a message to many queues, the message body is only stored in memory once**.\\r\\n\\r\\nSo we can see that asking \\"how much memory does this queue use?\\" is a hard question to answer - we can exclude any binary memory which might be referenced by the queue, leading to under-counting, or include it, potentially leading to over-counting.\\r\\n\\r\\nEarlier versions of RabbitMQ did not attempt to do much with this quandary; they reported the \\"memory use\\" of the queue as the size of the process memory (i.e. not including any referenced binaries) and showed a monolithic lump of \\"binary memory use\\" in the global memory breakdown. There was no way to investigate further.\\r\\n\\r\\nRabbitMQ 3.4 gives us some better guidance, both from the top down and from the bottom up. First of all, let\'s look at a top-down view of memory use:\\r\\n\\r\\n![](node-memory.png)\\r\\n\\r\\nThere are a couple of differences here from what we used to have. The overall memory use breakdown now has rather more categories, and there\'s a new binary memory \\"breakdown\\".\\r\\n\\r\\nWe show the binary memory breakdown separately for a couple of reasons; one is that it can be quite expensive to calculate (we have to walk over all memory used by the server; if there are large numbers of small binaries this can take a while) and another is that we don\'t guarantee it will add up to the size shown in the overall memory breakdown (due to the way binaries are shared as mentioned above).\\r\\n\\r\\nBut we can see here that almost all binary use is due to messages in queues. This screenshot was taken from a mostly static broker, so that\'s what we\'d expect.\\r\\n\\r\\n## But what about the queues?\\r\\n\\r\\nOK, but **which** queues are using all that memory? We can investigate that by looking at the details page for each queue (this information is of course also available via `rabbitmqctl` but pictures are nicer to look at):\\r\\n\\r\\n![](queue-memory.png)\\r\\n\\r\\nHere we can see another new feature of RabbitMQ 3.4: the queue maintains a count of the total number of message body bytes it contains. So we see that this queue contains 1.2GB of message body content, of which 420MB is in memory. We can assume that the 420MB is all in the binary memory used by queues. The queue is also using 421MB of process memory (a very similar amount purely by coincidence) - this includes message properties and headers, and metadata about each message.\\r\\n\\r\\nIt would therefore be reasonable to say \\"this queue is using 841MB of memory\\" - except that the message bodies might also be shared with other queues.\\r\\n\\r\\nAs an aside, note that \\"In memory\\" and \\"Persistent\\" messages are not antonyms here: a non-persistent message can be paged out under memory pressure and a persistent message can be in memory too. See [the documentation](/docs/3.13/memory#paging) for a bit more information about paging.\\r\\n\\r\\nWe can also see this information in the queue list view:\\r\\n\\r\\n![](queues-memory.png)\\r\\n\\r\\n(Here I\'ve clicked on the \\"+/-\\" link to add columns to show memory use and remove some others for clarity.)\\r\\n\\r\\nOf course, this still doesn\'t give a perfect count of how much memory is in use by a queue; such a thing is probably impossible in a dynamic system. But it gets us much closer."},{"id":"/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3","metadata":{"permalink":"/rabbitmq-website/blog/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2014-04-14-finding-bottlenecks-with-rabbitmq-3-3/index.md","source":"@site/blog/2014-04-14-finding-bottlenecks-with-rabbitmq-3-3/index.md","title":"Finding bottlenecks with RabbitMQ 3.3","description":"One of the goals for RabbitMQ 3.3 was that you should be able to find bottlenecks in running systems more easily. Older versions of RabbitMQ let you see that you were rate-limited but didn\'t easily let you see why. In this blog post we\'ll talk through some of the new performance indicators in version 3.3.","date":"2014-04-14T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.6,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Finding bottlenecks with RabbitMQ 3.3","tags":["Performance","New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Understanding memory use with RabbitMQ 3.4","permalink":"/rabbitmq-website/blog/2014/10/30/understanding-memory-use-with-rabbitmq-3-4"},"nextItem":{"title":"Consumer Bias in RabbitMQ 3.3","permalink":"/rabbitmq-website/blog/2014/04/10/consumer-bias-in-rabbitmq-3-3"}},"content":"One of the goals for RabbitMQ 3.3 was that you should be able to find bottlenecks in running systems more easily. Older versions of RabbitMQ let you see that you were rate-limited but didn\'t easily let you see why. In this blog post we\'ll talk through some of the new performance indicators in version 3.3.\\r\\n<!-- truncate -->\\r\\n\\r\\n### Understanding flow control\\r\\n\\r\\n![](flow-q.png)\\r\\n\\r\\nSince the introduction of flow control in RabbitMQ 2.8.0, you\'ve been able to see when a connection has gone into the flow-controlled state. This (roughly) means that the client is being rate-limited; it would like to publish faster but the server can\'t keep up. Of course, the next question you\'ll want to ask is \\"why?\\".\\r\\n\\r\\nThe flow control mechanism has always extended throughout the server; not just connections but channels and queues can be in the flow-control state, meaning that they would like to publish messages faster, but something ahead of them can\'t keep up. So to make sense of the new flow control information you need to know that **a component will go into flow control if anything it is publishing to is a bottleneck - or is in flow control itself**. The order that components handle messages on their way into the server is:\\r\\n\\r\\n*Network*  \\r\\n   &#x2193;  \\r\\n**Connection process** - AMQP parsing, channel multiplexing  \\r\\n   &#x2193;  \\r\\n**Channel process** - routing, security, coordination  \\r\\n   &#x2193;  \\r\\n**Queue process** - in-memory messages, persistent queue indexing  \\r\\n   &#x2193;  \\r\\n**Message store** - message persistence  \\r\\n\\r\\nSo what possible outcomes are there?\\r\\n\\r\\n* *A connection is in flow control, but none of its channels are* - This means that one or more of the channels is the bottleneck; the server is CPU-bound on something the channel does, probably routing logic. This is most likely to be seen when publishing small transient messages.\\r\\n* *A connection is in flow control, some of its channels are, but none of the queues it is publishing to are* - This means that one or more of the queues is the bottleneck; the server is either CPU-bound on accepting messages into the queue or I/O-bound on writing queue indexes to disc. This is most likely to be seen when publishing small persistent messages.\\r\\n* *A connection is in flow control, some of its channels are, and so are some of the queues it is publishing to* - This means that the message store is the bottleneck; the server is I/O-bound on writing messages to disc. This is most likely to be seen when publishing larger persistent messages.\\r\\n\\r\\n### Consumer utilisation\\r\\n\\r\\n![](utilisation.png)\\r\\n\\r\\nSo hopefully you can now better understand the performance of the publishing side of your server. So what about the consuming side? The flow control mechanism doesn\'t extend as far as consumers, but we do have a new metric to help you tell how hard your consumers are working.\\r\\n\\r\\nThat metric is *consumer utilisation*. The definition of **consumer utilisation is the proportion of time that a queue\'s consumers could take new messages**. It\'s thus a number from 0 to 1, or 0% to 100% (or N/A if the queue has no consumers). So if a queue has a consumer utilisation of 100% then it never needs to wait for its consumers; it\'s always able to push messages out to them as fast as it can.\\r\\n\\r\\nIf its utilisation is less than 100% then this implies that its consumers are sometimes not able to take messages. Network congestion can limit the utilisation you can achieve, or low utilisation can be due to the use of too low a [prefetch limit](/blog/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3), leading to the queue needing to wait while the consumer processes messages until it can send out more.\\r\\n\\r\\nThe following table shows some approximate values for consumer utilisation I observed when consuming tiny messages over localhost with a single consumer:\\r\\n\\r\\n|Prefetch limit|Consumer utilisation|\\r\\n|--- |--- |\\r\\n|1|14%|\\r\\n|3|25%|\\r\\n|10|46%|\\r\\n|30|70%|\\r\\n|1000|74%|\\r\\n\\r\\n\\r\\nYou can see that the utilisation increases with the prefetch limit until we reach a limit of about 30. After that the network bandwidth limitation starts to dominate and increasing the limit has no further benefit. So you can see that consumer utilisation is an easy way to monitor the performance of our consumers.\\r\\n\\r\\n## Learn More\\r\\n\\r\\n* Webinar: [What\'s new in RabbitMQ 3.8?](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_campaign=rabbitmq-blog-3.8-webinar-q319&utm_source=rabbitmq&utm_medium=website)\\r\\n* Webinar: [10 Things Every Developer Using RabbitMQ Should Know](https://content.pivotal.io/webinars/dec-12-10-things-every-developer-using-rabbitmq-should-know-webinar?utm_campaign=rabbitmq-blog-10-things-q319&utm_source=rabbitmq&utm_medium=website)\\r\\n\\r\\nProcess finished with exit code 0"},{"id":"/2014/04/10/consumer-bias-in-rabbitmq-3-3","metadata":{"permalink":"/rabbitmq-website/blog/2014/04/10/consumer-bias-in-rabbitmq-3-3","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2014-04-10-consumer-bias-in-rabbitmq-3-3/index.md","source":"@site/blog/2014-04-10-consumer-bias-in-rabbitmq-3-3/index.md","title":"Consumer Bias in RabbitMQ 3.3","description":"I warn you before we start: this is another wordy blog post about performance-ish changes in RabbitMQ 3.3. Still with us? Good.","date":"2014-04-10T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":2.46,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Consumer Bias in RabbitMQ 3.3","tags":["Performance","New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Finding bottlenecks with RabbitMQ 3.3","permalink":"/rabbitmq-website/blog/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3"},"nextItem":{"title":"An end to synchrony: performance improvements in 3.3","permalink":"/rabbitmq-website/blog/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3"}},"content":"I warn you before we start: this is another wordy blog post about performance-ish changes in RabbitMQ 3.3. Still with us? Good.\\r\\n\\r\\nSo in the [previous post](/blog/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3) I mentioned \\"a new feature which I\'ll talk about in a future blog post\\". That feature is consumer bias.\\r\\n\\r\\n<!-- truncate -->\\r\\nEvery queue in RabbitMQ is an Erlang process, and like all Erlang processes it responds to messages that are sent to it. These messages might represent AMQP messages being published to the queue, or basic.get requests coming in, or messages telling the queue that a consumer\'s network connection is now no longer busy so it can receive messages again, and so on. It\'s messages all the way down.\\r\\n\\r\\nWhen the queue is not busy, it just responds to messages as they come in. But as message rates go up, and the queue starts to work harder, we get to a state where the queue is using all the CPU cycles available to it. At this point, inbound messages start to queue up to be handled by the queue! [Flow control](/blog/2012/04/16/rabbitmq-performance-measurements-part-1) prevents them from building up indefinitely - but the fact that they are building up at all can have some consequences for the queue.\\r\\n\\r\\nSome of the inbound messages help the queue shrink (\\"this consumer can take messages again\\", \\"I\'d like to perform a basic.get\\") while some make the queue grow (\\"I\'d like to publish a new message\\"). So when the queue is working flat-out, we\'d like to give preferential treatment to the messages that help the queue shrink, in order that the queue has a tendency to stay empty rather than grow forever.\\r\\n\\r\\nAnd we added such a bias in RabbitMQ 1.7.0.\\r\\n\\r\\nSo why am I talking about it now? That was five years ago!\\r\\n\\r\\nUnfortunately it turns out that just unconditionally preferring to empty the queue can have nasty side effects - in some circumstances it\'s possible for the queue to spend 100% of its time delivering messages to consumers, and indeed we had some reports from users who saw exactly that - all consumers would go offline, the queue would build up to some huge size, then the consumers would come back and the queue would refuse to accept a single publish until it became completely empty. That\'s not a very useful queue.\\r\\n\\r\\nSo we stripped out this bias in RabbitMQ 2.8.3, and went back to the situation where CPU-bound queues can tend to grow indefinitely.\\r\\n\\r\\nBut we still wanted to do better than that. And in 3.3.0 we were finally able to.\\r\\n\\r\\nNow, rather than having queues unconditionally prefer to shrink, the queues are able to continuously monitor their rate of change in size, and when busy they will prioritise messages that help them to shrink - but only until they are delivering 10% more messages than they accept. So CPU-bound queues will still always accept messages, but will tend over time to become smaller rather than larger. Phew!"},{"id":"/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3","metadata":{"permalink":"/rabbitmq-website/blog/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2014-04-03-an-end-to-synchrony-performance-improvements-in-3-3/index.md","source":"@site/blog/2014-04-03-an-end-to-synchrony-performance-improvements-in-3-3/index.md","title":"An end to synchrony: performance improvements in 3.3","description":"Well, we got the bad news out of the way yesterday, so today let\'s talk about (some of) the good news: some types of publishing and consuming are now a great deal faster, especially in clusters.","date":"2014-04-03T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.495,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"An end to synchrony: performance improvements in 3.3","tags":["Performance","New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Consumer Bias in RabbitMQ 3.3","permalink":"/rabbitmq-website/blog/2014/04/10/consumer-bias-in-rabbitmq-3-3"},"nextItem":{"title":"Breaking things with RabbitMQ 3.3","permalink":"/rabbitmq-website/blog/2014/04/02/breaking-things-with-rabbitmq-3-3"}},"content":"Well, we got the [bad news](/blog/2014/04/02/breaking-things-with-rabbitmq-3-3) out of the way yesterday, so today let\'s talk about (some of) the good news: some types of publishing and consuming are now a great deal faster, especially in clusters.\\r\\n\\r\\n<!-- truncate -->\\r\\nThe various internal parts of RabbitMQ communicate by passing messages among themselves (both within nodes and across clusters); this is how Erlang applications work. It\'s always been a design goal of RabbitMQ that operations which were asynchronous in AMQP (i.e. sending and receiving messages and acknowledgements) should be asynchronous inside the server. There\'s a good reason for that: whenever you perform a synchronous operation you are limited by latency while you wait for the reply, so asynchrony is a route to much faster messaging.\\r\\n\\r\\nUnfortunately, while that\'s always been a goal, we haven\'t always hit it. In particular there were two holdouts where asynchronous messaging in AMQP became synchronous inside the server: mandatory publishing, and consuming messages with a prefetch limit set through `basic.qos`. These holdouts have been fixed in 3.3.0.\\r\\n\\r\\nAs a refresher, mandatory publishing means **tell the publisher if its messages did not end up routed to any queues**, while consuming with a prefetch limit means **make sure you only send the consumer a maximum number of outstanding unacknowledged messages**.\\r\\n\\r\\nSo let\'s look at some numbers...\\r\\n\\r\\n### Mandatory publishing\\r\\n\\r\\n||3.2.4|3.3.0|\\r\\n|--- |--- |--- |\\r\\n|**Mandatory publish**|5.0kHz balanced|12.9kHz balanced|\\r\\n\\r\\n\\r\\n_This test involved a two node cluster on a single machine, with a publisher connected to one node and a consumer connected to the other, with the queue located on the same node as the consumer. Messages were small and non-persistent, and neither acks nor confirms were used. The machine was a Dell Precision workstation, but the point is to look at relative performance change here._\\r\\n\\r\\nHopefully you can see how badly synchrony hurts performance here. And remember that the performance penalty imposed by synchronous messaging is proportional to network latency - and these two nodes were located on the same machine, so a real cluster would have a worse drop off.\\r\\n\\r\\nNote also that in both cases the sending and receiving rates were the same; messages were not backing up in the queue.\\r\\n\\r\\n### Consuming with a prefetch limit\\r\\n\\r\\nWe would expect that a high prefetch limit would give nearly the same performance as no prefetch limit, and that as we reduce the limit we will get lower performance, since at some points the queue will have to wait until the consumer acks a message before it can send another.\\r\\n\\r\\n||3.2.4|3.3.0|\\r\\n|--- |--- |--- |\\r\\n|**No limit**|15.0kHz send / 11.0kHz receive|15.8kHz balanced|\\r\\n|**prefetch_limit=1000**|6.2kHz send / 3.6kHz receive|15.8kHz balanced|\\r\\n|**prefetch_limit=100**|6.2kHz send / 3.6kHz receive|13.5kHz balanced|\\r\\n|**prefetch_limit=10**|6.2kHz send / 3.6kHz receive|14.0kHz send / 7.0kHz receive|\\r\\n|**prefetch_limit=1**|18.0kHz send / 0.9kHz receive|18.0kHz send / 0.9kHz receive|\\r\\n\\r\\n_This test had the same characteristics as above except that the queue was on the same node as the publisher and acknowledgements were used when consuming._\\r\\n\\r\\nThere are several interesting effects visible in the numbers in this table:\\r\\n\\r\\n* Even with the prefetch limit off, 3.3.0 was slightly faster, and prevented messages backing up. This is due to a new feature which I\'ll talk about in a future blog post.\\r\\n* A sufficiently high prefetch limit (such that the queue never has to wait for the consumer) has no performance cost in 3.3.0, whereas any prefetch limit at all hurts performance in 3.2.4.\\r\\n* All of the prefetch limits between 10, 100 and 1000 had exactly the same (bad) performance in 3.2.4 - that\'s because the limiting factor turns out to be the synchronous communication between the consuming channel and the queue.\\r\\n* Finally, when we reach a prefetch limit of 1, both 3.2.4 and 3.3.0 perform equally badly - that\'s because the limiting factor has now become the amount of time we wait for the consumer to send an acknowledgement for a single message at a time.\\r\\n\\r\\nSo with these changes the messaging internals of RabbitMQ are now asynchronous under all circumstances, bringing substantial performance benefits. It\'s worth pointing out that the semantics for `basic.qos` [had to change slightly](/docs/consumer-prefetch) for this to be possible, but this seems like a small price for such a large improvement."},{"id":"/2014/04/02/breaking-things-with-rabbitmq-3-3","metadata":{"permalink":"/rabbitmq-website/blog/2014/04/02/breaking-things-with-rabbitmq-3-3","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2014-04-02-breaking-things-with-rabbitmq-3-3/index.md","source":"@site/blog/2014-04-02-breaking-things-with-rabbitmq-3-3/index.md","title":"Breaking things with RabbitMQ 3.3","description":"What? Another \\"breaking things\\" post? Well, yes, but hopefully this should be less to deal with than the previous one. But there are enough slightly incompatible changes in RabbitMQ 3.3.0 that it\'s worth listing them here.","date":"2014-04-02T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.75,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Breaking things with RabbitMQ 3.3","tags":["HowTo","New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"An end to synchrony: performance improvements in 3.3","permalink":"/rabbitmq-website/blog/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3"},"nextItem":{"title":"Distributed Semaphores with RabbitMQ","permalink":"/rabbitmq-website/blog/2014/02/19/distributed-semaphores-with-rabbitmq"}},"content":"What? Another [\\"breaking things\\"](/blog/2012/11/19/breaking-things-with-rabbitmq-3-0) post? Well, yes, but hopefully this should be less to deal with than the previous one. But there are enough *slightly* incompatible changes in RabbitMQ 3.3.0 that it\'s worth listing them here.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## \\"guest\\" user can only connect via localhost\\r\\n\\r\\n**What changed?** In previous versions, the default guest user could connect from any network location. In RabbitMQ 3.3.0 it can only connect via localhost.\\r\\n\\r\\n**Why did it change?** A default user with well known credentials that is network accessible is not the absolute safest thing in the world.\\r\\n\\r\\n**What should I do?** Create distinct users for your applications, rather than using \\"guest\\". If you can\'t easily do that, [see here](/docs/access-control) for how to re-enable \\"guest\\" access over the network.\\r\\n\\r\\n## basic.qos semantics have changed\\r\\n\\r\\n**What changed?** In the AMQP standard the `prefetch-count` field establishes a limit to be shared across all the consumers in the channel. We have decided to instead grant that limit to each consumer in the channel individually.\\r\\n\\r\\n**Why did it change?** It makes it practical for prefetch limiting to be implemented in a much more efficient way. Prefetch limiting used to have a noticable performance cost on a single node, and a quite nasty one consuming across a cluster. Now it\'s essentially free in both cases.\\r\\n\\r\\n**What should I do?** Probably you don\'t care. Most consuming applications will only have one consumer per channel, so this will make no difference. Those that have more than one consumer per channel will probably be using prefetch limiting in a fairly approximate way (i.e. \\"just don\'t swamp me\\"). Those which require exact, shared prefetch limiting can turn on the `basic.qos` `global` flag to get the old behaviour, [see here](/docs/consumer-prefetch) for details.\\r\\n\\r\\n## AMQP object names must be UTF-8\\r\\n\\r\\n**What changed?** The AMQP \'shortstr\' data type (which is used for things like exchange and queue names, routing keys and so on) is defined by the spec as being in UTF-8 format. Previous versions of RabbitMQ would accept invalid UTF-8 byte sequences.\\r\\n\\r\\n**Why did it change?** This caused nasty problems for interoperability with text-based protocols like HTTP and STOMP which can\'t just have invalid UTF-8 byte sequences dropped into them.\\r\\n\\r\\n**What should I do?** Use valid UTF-8 sequences when naming things. We expect almost everyone is doing this anyway. One symptom of using invalid UTF-8 byte sequences is that it broke the management plugin - so if that\'s not broken for you, you certainly don\'t have to do anything.\\r\\n\\r\\n## Impersonator tag removed\\r\\n\\r\\n~~**What changed?** RabbitMQ 3.0.0 introduced an \\"impersonator\\" tag which allowed you to give users the ability to forge the [validated user-id](/docs/validated-user-id) field.~~\\r\\n\\r\\n~~**Why did it change?** This was really an internal implementation detail of the federation plugin that escaped into the wild, so now that the federation plugin does not need it, it\'s going.~~\\r\\n\\r\\n~~**What should I do?** If you had a sensible use case for this feature, please tell us about it.~~\\r\\n\\r\\n**Update: the impersonator tag is back in RabbitMQ 3.3.1.**\\r\\n\\r\\n## JSON-RPC plugin removed\\r\\n\\r\\n**What changed?** The JSON-RPC plugin is no longer bundled with the server.\\r\\n\\r\\n**Why did it change?** The plugin hadn\'t been maintained for a long time. Its architecture isn\'t great.\\r\\n\\r\\n**What should I do?** If you still need the plugin it can be built from mercurial, for the time being. <del>In the future we hope to offer an easier installation experience for non-core plugins.</del> **Update: see the [community plugins](/community-plugins) page to download the JSON-RPC plugin.**\\r\\n\\r\\n## Client-sent channel.flow support removed\\r\\n\\r\\n**What changed?** In previous versions of RabbitMQ, consuming clients have been able to send `channel.flow{active=false}` to tell the server to temporarily stop sending messages. This feature has been removed.\\r\\n\\r\\n**Why did it change?** A long time ago we determined that `channel.flow` did not perform well for flow control and so stopped sending it from server to client in 2.0.0.\\r\\n\\r\\nIt doesn\'t perform well because when you want to stop receiving messages, you want to stop *now*, not send a request to the peer and hope that it processes it quickly. So we doubt anyone is really using this, and it makes the code notably more complex.\\r\\n\\r\\n**What should I do?** There are better ways to stop the server from flooding your consumer with messages. Use `basic.qos` (or just stop reading off the socket). If you do want the ability to actively say \\"stop sending me messages\\" you can still get the same effect by cancelling your consumer(s) and then re-consuming when you are ready to continue."},{"id":"/2014/02/19/distributed-semaphores-with-rabbitmq","metadata":{"permalink":"/rabbitmq-website/blog/2014/02/19/distributed-semaphores-with-rabbitmq","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2014-02-19-distributed-semaphores-with-rabbitmq/index.md","source":"@site/blog/2014-02-19-distributed-semaphores-with-rabbitmq/index.md","title":"Distributed Semaphores with RabbitMQ","description":"In this blog post we are going to address the problem of controlling the access to a particular resource in a distributed system.","date":"2014-02-19T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":6.95,"hasTruncateMarker":true,"authors":[{"name":"Álvaro Videla","key":"alvaro","page":null}],"frontMatter":{"title":"Distributed Semaphores with RabbitMQ","tags":["HowTo"],"authors":["alvaro"]},"unlisted":false,"prevItem":{"title":"Breaking things with RabbitMQ 3.3","permalink":"/rabbitmq-website/blog/2014/04/02/breaking-things-with-rabbitmq-3-3"},"nextItem":{"title":"Preventing Unbounded Buffers with RabbitMQ","permalink":"/rabbitmq-website/blog/2014/01/23/preventing-unbounded-buffers-with-rabbitmq"}},"content":"In this blog post we are going to address the problem of controlling the access to a particular resource in a distributed system. \\r\\nThe technique for solving this problem is well know in computer science, it\'s called Semaphore and it was invented by Dijkstra in 1965\\r\\nin his paper called \\"Cooperating Sequential Processes\\". We are going to see how to implement it using AMQP\'s building blocks, like consumers,\\r\\nproducers and queues. \\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## The Need for Semaphores\\r\\n\\r\\nBefore going into the actual solution, let\'s see when we might actually need something like this:\\r\\n\\r\\nLet\'s say our application has many processes taking jobs from a queue and then inserting records to a database, we might need to limit how many of them do it concurrently.\\r\\n\\r\\nSimilarly, workers are resising images that need to be stored on a remote server over the network once they are ready. We want to prevent overflowing our network link with\\r\\nimage transfers, so we also place a limit on how many of our workers can transfer images at the same time. In this way, while our workers will be resising images as fast\\r\\nas they can, they will move the images in batches to the final destination once it\'s their turn to use the network link.\\r\\n\\r\\nAnother example this time related to RabbitMQ, could be that your application might need to have only one producer from a set sending messages to an exchange, but as soon as that process \\r\\nis stopped, you want the next producer in the set to start sending messages. There are many reasons why you would like something like this, capacity control can be one of them.\\r\\n\\r\\nOn the other end, there might be the need that consumers compete for accessing a queue, but while AMQP provides a way to have exclusive queues and exclusive consumer, \\r\\nthere\'s no way for an idle consumer to know when the queue access got freed. Therefore using a similar approach as above we could have consumers taking turns\\r\\nwhen accessing a queue.\\r\\n\\r\\nIt\'s worth noting that nothing prevent us from having more than one process accessing a particular resource. Say we have ten producers but we just want\\r\\nfive of them publishing messages at the same time. Using semaphores we could implement this as well.\\r\\n\\r\\nThe previous examples all have an extra requirement in common: the processes competing for the resource shouldn\'t be polling RabbitMQ or some other\\r\\ncoordinator in order to know when they can start working. Ideally they will sit idle waiting for their turn, and as soon as the resource is freed\\r\\nthen RabbitMQ will notify the next process so it can start working automatically.\\r\\n\\r\\nLet\'s move on now onto the implementation.\\r\\n\\r\\n## Implementing Semaphores\\r\\n\\r\\nOur semaphore will be implemented using queues and messages. Surprise, surprise!.\\r\\n\\r\\nWe first declare a queue called `resource.semaphore` where `resource` will be the name of the resource our semaphore is going to control, it can be \\"images\\",\\r\\n\\"database\\", \\"file_server\\", or whatever fits our particular application.\\r\\n\\r\\nWe publish *one* message to the `resource.semaphore` queue. Then we start the processes that will seek access to that message. Each process will consume from the \\r\\n`resource.semaphore` queue; the first process to arrive will get the message and all the others will sit idle waiting for it. The trick will be that these\\r\\nprocesses will *never acknowledge* the message, but they will consume from the `resource.semaphore` queue with `ack_mode=on`. So, RabbitMQ will keep track of the\\r\\nmessage and if the processes crashes or exists, the message will go back to the queue, and it will be delivered to the next process listening from our semaphore\\r\\nqueue.\\r\\n\\r\\nWith this simple technique we will have only one process at the time having access to the resource, and we are sure the process won\'t hold the resource if it crashes.\\r\\nOf course we assume that all the processes accessing the semaphore are well behaved, i.e.: they will never acknowledge the message. If they do, RabbitMQ will delete\\r\\nthe message and all the other processes in the group will starve.\\r\\n\\r\\nWhat do we do when one process wishes to stop, how can it return the \\"token\\"? Sure the process can abruptly close the channel and RabbitMQ will take care of the message\\r\\nautomatically, but there\'s also a polite way of doing this. A process can *basic.reject* the message telling RabbitMQ to re-enqueue the message so it goes back to the\\r\\nsemaphore queue.\\r\\n\\r\\nLet\'s see this implemented in code, we assume we have obtained a connection and a channel:\\r\\n\\r\\nHere\'s the code to set up our semaphore:\\r\\n\\r\\n```java\\r\\nchannel.queueDeclare(\\"resource.semaphore\\", true, false, false, null);\\r\\nString message = \\"resource\\";\\r\\nchannel.basicPublish(\\"\\", \\"resource.semaphore\\", null, message.getBytes());\\r\\n```\\r\\n\\r\\nWe create a durable queue called `\\"resource.semaphore\\"` and then we publish a message to it using the *default* exchange.\\r\\n\\r\\nAnd here\'s the code a process would use to access the semaphore:\\r\\n\\r\\n```java\\r\\nQueueingConsumer consumer = new QueueingConsumer(channel);\\r\\nchannel.basicQos(1);\\r\\nchannel.basicConsume(\\"resource.semaphore\\", false, consumer);\\r\\n\\r\\nwhile (true) {\\r\\n  QueueingConsumer.Delivery delivery = consumer.nextDelivery();\\r\\n\\r\\n  // here we access the resource controlled by the semaphore.  \\r\\n\\r\\n  if(shouldStopProcessing()) {\\r\\n    channel.basicReject(delivery.getEnvelope().getDeliveryTag(), true);\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nThere we create a `QueueingConsumer` that\'s waiting for messages coming from the `\\"resource.semaphore\\"` queue. We make sure our process picks only \\r\\none message from the queue by setting the *prefetch-count* equal to 1 in our `basicQos` call.  Once a message arrives, the process will start using the resource. \\r\\nWhen the condition `shouldStopProcessing()` is met, the process will `basicReject` the message, telling RabbitMQ to requeue it. Keep in mind that \\r\\nthe consumer was started in ack-mode and that it will never ack the message received from the semaphore queue. If it does, then it\'s considered buggy.\\r\\n\\r\\n## Prioritising Access to the Semaphore\\r\\n\\r\\nIs it possible to prioritise access to the semaphore? Yes, since version 3.2.0 RabbitMQ supports [Consumer Priorities](/docs/consumer-priority). By using consumer\\r\\npriorities we can tell RabbitMQ which processes to favor when passing around the token message from the semaphore.\\r\\n\\r\\n## Binary vs Counting Semaphores\\r\\n\\r\\nSo far we have implemented what\'s called a *binary semaphore*, that is, a semaphore that gives access to a resource to only one process at a time. If we can allow more than one\\r\\nprocess accessing the same resource at the same time, but we still need a limit to that operation, then we can implement a *counting semaphore*. To do that, when we set up the semaphore, \\r\\ninstead of publishing one message, we can publishing as many messages as processes are allowed to be working at the same time. We need to make sure that our processes set\\r\\n*prefetch-count* value to 1 as we did before.\\r\\n\\r\\n## Altering the Count\\r\\n\\r\\nNote that the process that sets up the semaphore queue can add extra messages over time to increase processing capacity. If we wanted to decrease the number of processes that can\\r\\nsimultaneously access a resource, then we would have to stop the running ones and purge the queue. Another way would be to start an extra consumer with very\\r\\n[high priority](/docs/consumer-priority) so it would take as many messages as are needed from the semaphore queue and acknowledge them so they get removed from the system.\\r\\n\\r\\n## Some reading\\r\\n\\r\\nAs you can see it\'s quite easy to implement semaphores using AMQP basic constructs, and with RabbitMQ we can also prioritise the access to the resource.\\r\\n\\r\\nTo conclude I would like to share some articles on Semaphores as concurrency constructs. First, Dijkstra\'s seminal paper \\r\\n[Cooperating Sequential Processes](http://www.cs.utexas.edu/users/EWD/transcriptions/EWD01xx/EWD123.html). And finally Wikipedia\'s article on semaphores which explains many of the \\r\\ndefinitions: [Semaphore](https://en.wikipedia.org/wiki/Semaphore_(programming)).\\r\\n\\r\\n###  EDIT: 20.02.2014 \\r\\n\\r\\nAs discussed [here](https://twitter.com/aphyr/status/436610754083815425) and elsewhere with my colleagues as well, this setup is not resilient of [network partitions](/docs/partitions), so handle it with care. Thanks to [@aphyr](https://twitter.com/aphyr) and others for providing me feedback on the blog post. At the RabbitMQ team we always like to stay honest and tell our users what the server can, and can\'t do.\\r\\n\\r\\n###  EDIT: 10.03.2014 \\r\\n\\r\\nIt\'s worth noting that this set up is not resilient to network failures in general. For example, it could happen that a worker has a token and the connection with the server is abruptly closed. Then the server will grab the token and queue it so it can be delivered to another worker. In the meantime, the worker whose network connection was closed, will still think that it has the token, therefore, it will continue accessing a resource that it should\'t be accessing."},{"id":"/2014/01/23/preventing-unbounded-buffers-with-rabbitmq","metadata":{"permalink":"/rabbitmq-website/blog/2014/01/23/preventing-unbounded-buffers-with-rabbitmq","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2014-01-23-preventing-unbounded-buffers-with-rabbitmq/index.md","source":"@site/blog/2014-01-23-preventing-unbounded-buffers-with-rabbitmq/index.md","title":"Preventing Unbounded Buffers with RabbitMQ","description":"Different services in our architecture will require a certain amount of resources for operation, whether these resources are CPUs, RAM or disk space, we need to make sure we have enough of them. If we don\'t put limits on how many resources our servers are going to use, at some point we will be in trouble. This happens with your database if it runs out of file system space, your media storage if you fill it with images and never move them somewhere else, or your JVM if it runs out of RAM. Even your back up solution will be a problem if you don\'t have a policy for expiring/deleting old backups. Well, queues are no exception. We have to make sure that our application won\'t allow the queues to grow for ever. We need to have some strategy in place to delete/evict/migrate old messages.","date":"2014-01-23T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":8.115,"hasTruncateMarker":true,"authors":[{"name":"Álvaro Videla","key":"alvaro","page":null}],"frontMatter":{"title":"Preventing Unbounded Buffers with RabbitMQ","tags":["New Features","HowTo"],"authors":["alvaro"]},"unlisted":false,"prevItem":{"title":"Distributed Semaphores with RabbitMQ","permalink":"/rabbitmq-website/blog/2014/02/19/distributed-semaphores-with-rabbitmq"},"nextItem":{"title":"Using Consumer Priorities with RabbitMQ","permalink":"/rabbitmq-website/blog/2013/12/16/using-consumer-priorities-with-rabbitmq"}},"content":"Different services in our architecture will require a certain amount of resources for operation, whether these resources are CPUs, RAM or disk space, we need to make sure we have enough of them. If we don\'t put limits on how many resources our servers are going to use, at some point we will be in trouble. This happens with your database if it runs out of file system space, your media storage if you fill it with images and never move them somewhere else, or your JVM if it runs out of RAM. Even your back up solution will be a problem if you don\'t have a policy for expiring/deleting old backups. Well, queues are no exception. We have to make sure that our application won\'t allow the queues to grow for ever. We need to have some strategy in place to delete/evict/migrate old messages.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Why might this problem happen?\\r\\n\\r\\nThere are many reasons why our queues might be filling up with messages. Reason number one would be that our data producers are outpacing our consumers. Luckily the solution is easy: add more consumers.\\r\\n\\r\\nWhat happens if our application still can\'t handle the load? For example your consumers take too long to process each message, and you can\'t add more consumers since you ran out of servers. Then your queues will start filling up with messages. RabbitMQ has been optimized for fast message delivery with queues that have [as few messages as possible](/blog/2011/09/24/sizing-your-rabbits). While RabbitMQ comes with various **[flow control mechanisms](/docs/memory)**, of course you probably want a way to prevent to get into a situation were flow-control gets activated. Let\'s see how RabbitMQ can help us there.\\r\\n\\r\\n## Per-Queue Message TTL\\r\\n\\r\\nRabbitMQ allows to set per-queue message TTLs that will make the server not deliver messages that have lived in the queue longer than the defined per-queue TTL. Moreover, the server will attempt to expire or dead-letter those messages as soon as it can. \\r\\n\\r\\nThis works great when you have data that is only relevant to producers if it arrives on time. _If your data can\'t be dropped, but you still want the queues to remain as empty as possible, then see below, the section on \\"dead lettering\\"_.\\r\\n\\r\\nThere are two ways to setup Queue TTLs, one if by passing some extra arguments during `queue.declare` like this:\\r\\n\\r\\n```java\\r\\nMap<String, Object> args = new HashMap<String, Object>();\\r\\nargs.put(\\"x-message-ttl\\", 60000);\\r\\nchannel.queueDeclare(\\"myqueue\\", false, false, false, args);\\r\\n```\\r\\n\\r\\nThe previous code will tell RabbitMQ to expire messages on the queue `myqueue` after 60 seconds.\\r\\n\\r\\nThe same could be set up by adding a policy to our queue:\\r\\n\\r\\n```shell\\r\\nrabbitmqctl set_policy TTL \\".*\\" \'{\\"message-ttl\\":60000}\' --apply-to queues\\r\\n```\\r\\n\\r\\nThis policy will match all the queues in the the default virtual host, and will make the messages expire after 60 seconds. Note that the Windows command is a bit [different](/docs/ttl). Of course you can make that policy match only one queue. More details about it here: [Parameters and Policies](/docs/parameters).\\r\\n\\r\\nWhat if we want more fine grained control over which messages are getting expired?\\r\\n\\r\\n## Per-Message TTL\\r\\n\\r\\nRabbitMQ also supports setting per-message TTLs. We can set the TTL on a message by setting the `expiration` field on a `basic.publish` method call. As in the previous case, the value should be expressed in milliseconds. The following code will publish a message that will expire after 60 seconds:\\r\\n\\r\\n```java\\r\\nbyte[] messageBodyBytes = \\"Hello, world!\\".getBytes();\\r\\nAMQP.BasicProperties properties = new AMQP.BasicProperties();\\r\\nproperties.setExpiration(\\"60000\\");\\r\\nchannel.basicPublish(\\"my-exchange\\", \\"routing-key\\", properties, messageBodyBytes);\\r\\n```\\r\\n\\r\\nIf we combine per-message TTL with per-queue TTL, then the shortest TTL will prevail. RabbitMQ will ensure a consumer will never receive expired messages, but in the case of per-message-ttl, until those messages reach the head of the queue, they won\'t be expired.\\r\\n\\r\\n## Queue TTL\\r\\n\\r\\nWith RabbitMQ we can also let the complete queue expire, that is, get deleted by RabbitMQ after it\'s been unused for certain amount of time. Let\'s say we set up to expire our queues after one hour. If during an hour, there are no consumers on that queue, no basic.get commands have been issued or the queue hasn\'t been redeclared, then RabbitMQ will consider it unused and it will delete it.\\r\\n\\r\\nYou might want to use this feature if for example you create queues for your users when they are online, but after 15 minutes of inactivity you want to delete those queues. Think of a chat application that keeps a queue per connected user. You could have declared an `auto_delete` queue that will go away as soon as the user closes the channel, but while that might be useful for some scenarios, what happens if the user actually got disconnected because they are in a mobile network where connection quality is low? Certainly you don\'t want to delete all their messages a soon as they are disconnected. With this feature you could let those queues live a little longer.\\r\\n\\r\\nHere\'s how to set a 15 minutes queue expiration using the Java Client:\\r\\n\\r\\n```java\\r\\nMap<String, Object> args = new HashMap<String, Object>();\\r\\nargs.put(\\"x-expires\\", 900000);\\r\\nchannel.queueDeclare(\\"myqueue\\", false, false, false, args);\\r\\n```\\r\\n\\r\\nAnd via a policy:\\r\\n\\r\\n```shell\\r\\nrabbitmqctl set_policy expiry \\".*\\" \'{\\"expires\\":900000}\' --apply-to queues\\r\\n```\\r\\n\\r\\n## Queue Length Limit\\r\\n\\r\\nIf we want that our queues don\'t get more messages than certain threshold, we can configure that via the `x-max-length` argument when we declare the queue. This is rather neat and simply way to control capacity; if our queue reaches the threshold and a new message arrives, then messages that are at the front of the queue, \\"older messages\\", will be dropped, making room for the newly arrived messages. One of the reasons for this behaviour is that old messages are probably irrelevant for your application, so new ones are let into the queues.\\r\\n\\r\\nKeep in mind that queue length takes into account only the messages that are ready to be delivered. Unacked messages won\'t add to the count. Having the proper `basic.qos` settings will help your application here, since by default RabbitMQ will send as many messages as possible to the consumer, creating a situation where your queue appears to be empty, but in fact you have a lot of unacked messages that are taking up resources as well.\\r\\n\\r\\nSetting the queue length limit is quite easy, here\'s an example in Java that sets a limit on 10 messages:\\r\\n\\r\\n```java\\r\\nMap<String, Object> args = new HashMap<String, Object>();\\r\\nargs.put(\\"x-max-length\\", 10);\\r\\nchannel.queueDeclare(\\"myqueue\\", false, false, false, args);\\r\\n```\\r\\n\\r\\nAnd via a policy:\\r\\n\\r\\n```shell\\r\\nrabbitmqctl set_policy Ten \\".*\\" \'{\\"max-length\\":10}\' --apply-to queues\\r\\n```\\r\\n\\r\\n## Mixing policies\\r\\n\\r\\nKeep in mind that *at most* one policy applies to a queue at any given time. So if you run the previous `set_policy` commands in succession, then only the last one will take place. The trick to have more than one policy applying to the same resource lays in passing all the policies together on the same JSON object, for example:\\r\\n\\r\\n```shell\\r\\nrabbitmqctl set_policy capped_queues \\"^capped\\\\.\\" \\\\ \\r\\n  \'{\\"max-length\\":10, \\"expires\\":900000, \\"message-ttl\\":60000}\' --apply-to queues\\r\\n```\\r\\n\\r\\n## No Queueing at all\\r\\n\\r\\nWait, did I read that right? Yes. No queueing.\\r\\n\\r\\nImagine you are on a very busy day, and you arrive to the post office just to see that every counter is busy. Since you don\'t have time to waste waiting in line, you just go back and continue doing what you were doing before. In other words: you have a request that has to be served *right now*, that is: without queueing. Well, RabbitMQ can do something similar to that with your application messages and queues.\\r\\n\\r\\nThe trick consists on setting a `per-queue-TTL` of `0` (zero). If messages can\'t be delivered immediately to consumers, then they will be expired right away. If you set up a dead-letter exchange, then you could get messages to be dead-lettered to a separate queue.\\r\\n\\r\\n## Dead Lettering\\r\\n\\r\\nWe\'ve been mentioning [dead-lettering](/docs/dlx) a couple of times already. What this feature does is that you could set up a *dead letter exchange (DLX)* for one of your queues, and then when a message on that queue expires, or the queue limit has been exceeded, the message will be published to the DLX. It\'s up to you to bind a separate queue to that exchange and then later process the messages sent there.\\r\\n\\r\\nHere\'s a `queue.declare` example for setting a DLX:\\r\\n\\r\\n```java\\r\\nchannel.exchangeDeclare(\\"some.exchange.name\\", \\"direct\\");\\r\\n\\r\\nMap<String, Object> args = new HashMap<String, Object>();\\r\\nargs.put(\\"x-dead-letter-exchange\\", \\"some.exchange.name\\");\\r\\nchannel.queueDeclare(\\"myqueue\\", false, false, false, args);\\r\\n```\\r\\n\\r\\nDead-lettering messages will keep your queues with the right sizes and expected amount of messages, but this won\'t prevent you from filling up the node with messages. If these messages are being queued in a different queue on the same node, then at some point this new dead-letter queue could present a problem. What you could do in this case is to use [exchange federation](/docs/federation) to send those messages to a separate node, and process them separately from the main flow of your application.\\r\\n\\r\\n## Conclusion\\r\\n\\r\\nOne of the basic questions of queueing theory with regard to requests arriving to our system can be stated as follows[^1]:\\r\\n\\r\\n> λ = mean arrival time  \\r\\nµ = mean service rate  \\r\\nif λ > µ what happens?  \\r\\nQueue length goes to infinity over time.\\r\\n\\r\\nWe know that if we encounter this problem at any point in our architecture, sooner or later our application will be in trouble. Luckily for us RabbitMQ offers many features like queues and messages TTLs, queue expiration and queue length, tailored to avoid this issue. What\'s more interesting, is that we don\'t need to lose messages just because we use these features. The dead-letter exchange can help us to re-route messages to more appropriate places. It\'s time we make these techniques part of our queueing and messaging arsenal.\\r\\n\\r\\n[^1]: [Performance Modeling and Design of Computer Systems: Queueing Theory in Action](https://www.amazon.com/Performance-Modeling-Design-Computer-Systems/dp/1107027500)"},{"id":"/2013/12/16/using-consumer-priorities-with-rabbitmq","metadata":{"permalink":"/rabbitmq-website/blog/2013/12/16/using-consumer-priorities-with-rabbitmq","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2013-12-16-using-consumer-priorities-with-rabbitmq/index.md","source":"@site/blog/2013-12-16-using-consumer-priorities-with-rabbitmq/index.md","title":"Using Consumer Priorities with RabbitMQ","description":"With RabbitMQ 3.2.0 we introduced Consumer Priorities which not surprisingly allows us to set priorities for our consumers. This provides us with a bit of control over how RabbitMQ will deliver messages to consumers in order to obtain a different kind of scheduling that might be beneficial for our application.","date":"2013-12-16T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":3.1,"hasTruncateMarker":true,"authors":[{"name":"Álvaro Videla","key":"alvaro","page":null}],"frontMatter":{"title":"Using Consumer Priorities with RabbitMQ","tags":["New Features","HowTo"],"authors":["alvaro"]},"unlisted":false,"prevItem":{"title":"Preventing Unbounded Buffers with RabbitMQ","permalink":"/rabbitmq-website/blog/2014/01/23/preventing-unbounded-buffers-with-rabbitmq"},"nextItem":{"title":"Federated queues in 3.2.0","permalink":"/rabbitmq-website/blog/2013/10/23/federated-queues-in-3-2-0"}},"content":"With RabbitMQ 3.2.0 we introduced [Consumer Priorities](/docs/consumer-priority) which not surprisingly allows us to set priorities for our consumers. This provides us with a bit of control over how RabbitMQ will deliver messages to consumers in order to obtain a different kind of scheduling that might be beneficial for our application.\\r\\n\\r\\nWhen would you want to use Consumer Priorities in your code?\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Heterogeneous Cluster\\r\\n\\r\\nLet\'s say our cluster of workers doesn\'t run in exactly the same hardware. Some machines have some hardware features that give them an advantage over the others in the cluster based on the type of task we are running. For example some machines have SSDs and our tasks require a lot of I/O; or perhaps the tasks need faster CPUs to perform calculations; or more RAM in order to cache results for future computations. In any case it would be interesting that if we have two consumers ready to get more messages, and one is in a better machine, then RabbitMQ should pick the consumer in the better machine and deliver the message to it, instead of the other one in the lesser machine. Keep in mind that consumer priorities *only* take effect for consumers that are ready to receive a message. So if one consumer in our lesser machines is ready, and there are no ready consumers in the better machines, then RabbitMQ will directly send a message to that particular consumer without waiting for a faster consumer to become available.\\r\\n\\r\\n## Data Locality\\r\\n\\r\\nAnother use for consumer priorities is to benefit from data locality. In RabbitMQ queue contents live in the node where the queue was originally declared, and in case of [mirrored queues](/docs/3.13/ha) there will be a master node that will coordinate the queue, so while consumers can connect to various nodes in the cluster, and get messages from the mirror, at the end of the day the information about who consumed what messages will travel back to the master. In this case we can use a consumer priority to tell RabbitMQ to first deliver messages to consumers connected to the master node. To do that the consumer that connects to the master node, will set a higher priority for itself when issuing a `basic.consume` command (provided it has a way of knowing it is connected to the master node).\\r\\n\\r\\n## Declaring consumer priorities\\r\\n\\r\\nBelow you can find sample code that shows how to declare consumer priorities using the [RabbitMQ Java Client](/client-libraries/java-client):\\r\\n\\r\\n```java {linenos=inline,hl_lines=[\\"25-27\\"],linenostart=1}\\r\\nimport java.util.*;\\r\\nimport com.rabbitmq.client.ConnectionFactory;\\r\\nimport com.rabbitmq.client.Connection;\\r\\nimport com.rabbitmq.client.Channel;\\r\\nimport com.rabbitmq.client.QueueingConsumer;\\r\\n\\r\\npublic class Consumer {\\r\\n\\r\\n    private final static String EXCHANGE_NAME = \\"my_exchange\\";\\r\\n    private final static String QUEUE_NAME = \\"my_queue\\";\\r\\n\\r\\n    public static void main(String[] argv) throws Exception {\\r\\n      ConnectionFactory factory = new ConnectionFactory();\\r\\n      factory.setHost(\\"localhost\\");\\r\\n      Connection connection = factory.newConnection();\\r\\n      Channel channel = connection.createChannel();\\r\\n\\r\\n      channel.queueDeclare(QUEUE_NAME, true, false, false, null);\\r\\n      channel.exchangeDeclare(EXCHANGE_NAME, \\"direct\\", true);\\r\\n      channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \\"\\");\\r\\n      System.out.println(\\"Waiting for messages. To exit press CTRL+C\\");\\r\\n\\r\\n      QueueingConsumer consumer = new QueueingConsumer(channel);\\r\\n\\r\\n      Map<String, Object> args = new HashMap<String, Object>();\\r\\n      args.put(\\"x-priority\\", 10);\\r\\n      channel.basicConsume(QUEUE_NAME, false, \\"\\", false, false, args, consumer);\\r\\n\\r\\n      while (true) {\\r\\n        QueueingConsumer.Delivery delivery = consumer.nextDelivery();\\r\\n        String message = new String(delivery.getBody());\\r\\n        System.out.println(\\"Received \'\\" + message + \\"\'\\");\\r\\n        channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);\\r\\n      }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nThis code implements a very simple consumer based on the example from [tutorial 1](/tutorials/tutorial-one-java). The interesting parts are from lines 25 to 27 where first we create a `HashMap` to hold our arguments to `basicConsume`. We create an argument named `x-priority` with value `10` (the higher the value, the higher the priority). When we call `basicConsume` we pass those arguments to RabbitMQ, and that\'s it! A very powerful feature that is rather simple to use. As usual, it\'s wise to run performance tests to decide what\'s the best priority strategy for our consumers."},{"id":"/2013/10/23/federated-queues-in-3-2-0","metadata":{"permalink":"/rabbitmq-website/blog/2013/10/23/federated-queues-in-3-2-0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2013-10-23-federated-queues-in-3-2-0/index.md","source":"@site/blog/2013-10-23-federated-queues-in-3-2-0/index.md","title":"Federated queues in 3.2.0","description":"So we added support for federated queues in RabbitMQ 3.2.0. This blog post explains what they\'re for and how to use them.","date":"2013-10-23T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":2.64,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Federated queues in 3.2.0","tags":["New Features","HowTo"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Using Consumer Priorities with RabbitMQ","permalink":"/rabbitmq-website/blog/2013/12/16/using-consumer-priorities-with-rabbitmq"},"nextItem":{"title":"Using Elixir to write RabbitMQ Plugins","permalink":"/rabbitmq-website/blog/2013/06/03/using-elixir-to-write-rabbitmq-plugins"}},"content":"So we added support for federated queues in RabbitMQ 3.2.0. This blog post explains what they\'re for and how to use them.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n(And apologies if this looks like a wall of text by the way, my drawing skills are not great. More artistically-inclined members of the RabbitMQ team are working on some beautiful diagrams...)\\r\\n\\r\\n**What are they for?**\\r\\n\\r\\nThe idea behind queue federation is to deal with load-balancing messages across queues on different brokers. If you have a set of queues that federate with each other, then producers can publish into them and consumers can consume from them without (much) regard to location.\\r\\n\\r\\nSo whereas federated exchanges are really motivated by pub-sub scenarios (consumers everywhere will be able to see messages that were published anywhere), federated queues are useful for work-queuing scenarios (a consumer somewhere will be able to see messages that were published anywhere). Publishers can publish anywhere, and the federation mechanism will automatically move messages to where they can be consumed, but a message should only be in one place at any given time.\\r\\n\\r\\nThis is a different approach to load-balancing from how people normally talk about the term by the way. Normally we think of load-balancing \\"before the fact\\" - imagine a publisher picking one of many queues at random to publish to, with each queue having some local consumers. The trouble with this approach is that if one queue\'s consumers fall behind or stop working altogether then there is nothing to smooth things out. Queue federation load-balances \\"after the fact\\", moving messages around to where they can be handled.\\r\\n\\r\\nFederation links have improved in performance since 3.1.x (roughly twice as fast in `no-ack` [mode](/docs/federation-reference), and 50% faster in `on-confirm` mode). But we still want to avoid moving messages if we can avoid it, so queue federation only moves messages from queue A to queue B when B has consumers but no messages and when A has more messages than its consumers can (immediately) deal with. An ideal user of queue federation would balance publishing and consuming at each individual queue, and thus leave federation with nothing to do :smiley: Until some consumer falls behind, at least...\\r\\n\\r\\n**And what are they not for?**\\r\\n\\r\\nNow that both exchanges and queues can be federated, it\'s tempting to think \\"well, I can just federate everything and then I\'ll have a big virtual broker, like a cluster but with partition tolerance\\". Of course, as our old friend the CAP theorem suggests, it\'s not as simple as that; if you gain (P)artition-tolerance you have to lose something else, and in federation\'s case that\'s (C)onsistency. Federated queues will only ever contain a given message in one location; there\'s no mirroring. Think RAID-0 rather than [HA](/docs/3.13/ha)\'s RAID-1.\\r\\n\\r\\nOf course you can connect clusters together with federation if you want RAID-10...\\r\\n\\r\\n**So how do you federate a queue?**\\r\\n\\r\\nThat\'s simple! Define one or more upstreams, just as you would to federate an exchange, then define a policy that matches your queue, and defines a `federation-upstream-set` or `federation-upstream`, again just as you would for an exchange. See [the documentation](/docs/federation) for more details, but really it works just like federating an exchange."},{"id":"/2013/06/03/using-elixir-to-write-rabbitmq-plugins","metadata":{"permalink":"/rabbitmq-website/blog/2013/06/03/using-elixir-to-write-rabbitmq-plugins","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2013-06-03-using-elixir-to-write-rabbitmq-plugins/index.md","source":"@site/blog/2013-06-03-using-elixir-to-write-rabbitmq-plugins/index.md","title":"Using Elixir to write RabbitMQ Plugins","description":"RabbitMQ is a very extensible message broker, allowing users to extend the server\'s functionality by writing plugins. Many of the broker features are even shipped as plugins that come by default with the broker installation: the Management Plugin, or STOMP support, to name just a couple. While that\'s pretty cool, the fact that plugins must be written in Erlang is sometimes a challenge. I decided to see if it was possible to write plugins in another language that targeted the Erlang Virtual Machine (EVM), and in this post I\'ll share my progress.","date":"2013-06-03T00:00:00.000Z","tags":[{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":7.57,"hasTruncateMarker":true,"authors":[{"name":"Álvaro Videla","key":"alvaro","page":null}],"frontMatter":{"title":"Using Elixir to write RabbitMQ Plugins","tags":["Programming Languages","HowTo"],"authors":["alvaro"]},"unlisted":false,"prevItem":{"title":"Federated queues in 3.2.0","permalink":"/rabbitmq-website/blog/2013/10/23/federated-queues-in-3-2-0"},"nextItem":{"title":"RabbitMQ 3.1... in images","permalink":"/rabbitmq-website/blog/2013/05/01/rabbitmq-3-1-0-in-images"}},"content":"RabbitMQ is a very extensible message broker, allowing users to extend the server\'s functionality by writing plugins. Many of the broker features are even shipped as plugins that come by default with the broker installation: the [Management Plugin](/docs/management), or [STOMP](/docs/stomp) support, to name just a couple. While that\'s pretty cool, the fact that plugins must be written in Erlang is sometimes a challenge. I decided to see if it was possible to write plugins in another language that targeted the Erlang Virtual Machine (EVM), and in this post I\'ll share my progress.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Elixir\\r\\n\\r\\nIn the last couple of months I\'ve been paying attention to a new programming language called [*Elixir*](http://elixir-lang.org) that targets the EVM, and in the last week it became immensely popular inside the Erlang community (and other circles) since [Joe Armstrong](https://twitter.com/joeerl), the father of Erlang, [tried the language](https://joearms.github.io/#2013-05-31%20A%20week%20with%20Elixir), and liked it very much. So I said, OK, let\'s give it a try.\\r\\n\\r\\nI don\'t want to spend much time describing what Elixir is - it\'s better if you read the website or Joe Armstrong\'s blog post about it. For me, it brings ideas from the Ruby language to the Erlang platform. We can essentially write Erlang programs with an arguably better syntax (for some definitions of *better syntax*).\\r\\n\\r\\nCompare this Erlang Hello World program, taken from the Elixir website:\\r\\n\\r\\n```erlang\\r\\n-module(module_name).\\r\\n-compile(export_all).\\r\\n\\r\\nhello() ->\\r\\n  io:format(\\"~s~n\\", [\\"Hello world!\\"]).\\r\\n```\\r\\n\\r\\nWith this one in Elixir, also from their website:\\r\\n\\r\\n```elixir\\r\\n# module_name.ex\\r\\n\\r\\ndefmodule ModuleName do\\r\\n  def hello do\\r\\n    IO.puts \\"Hello World\\"\\r\\n  end\\r\\nend\\r\\n```\\r\\n\\r\\nWhile this example is quite trivial, I think for someone that has never seen Erlang syntax, the Elixir version is easier to read. From my point of view, I always liked Erlang\'s syntax, since it makes the semantics of Erlang concepts stand out and is very clear what\'s going on, but again, that\'s my own point of view.\\r\\n\\r\\nConsidering that people might prefer to write RabbitMQ plugins with Elixir, let\'s see how that could be done.\\r\\n\\r\\n## Writing RabbitMQ Plugins\\r\\n\\r\\nTo write plugins for RabbitMQ you will need to setup your development environment to use the tools, Makefiles and libraries provided by the *rabbitmq public umbrella*. You can follow the setup instructions from [here](/plugin-development). Once you have cloned the `http://hg.rabbitmq.com/rabbitmq-public-umbrella` project and have all the dependencies installed, we can start writing our own plugin. To do it with Elixir, you first need to install the language on your machine, so you can use the Elixir compiler (`mix`) and the language libraries.\\r\\n\\r\\nWhen you write RabbitMQ plugins you may want to use some Erlang libraries with your plugin, to do that you need to *wrap them* as a plugin as well, so they can be picked up by the build environment when you declare a library as a dependency of your project. In this case our new plugins will depend on Elixir, so we need to wrap the language libraries as a plugin. I\'ve done that already and you can just clone the [elixir_wrapper](https://github.com/videlalvaro/elixir_wrapper) from Github and follow the instructions on its README to get it installed.\\r\\n\\r\\nNow is time to create our own plugin. As an example I\'ve ported a plugin called *recent-history-exchange* to Elixir. As the name implies, it adds a new exchange type to RabbitMQ. Exchanges are routing algorithms that RabbitMQ uses to decide where your messages are going to end up. If you want to read more about exchanges go [here](/tutorials/amqp-concepts).\\r\\n\\r\\nThe code for the new exchange can be found on Github: [RabbitMQ Recent History Exchange](https://github.com/videlalvaro/rabbitmq-recent-history-exchange-elixir).\\r\\n\\r\\nThe code for the new exchange type lives inside the file `lib/rabbit_exchange_type_recent_history.ex`, where we implement the `rabbit_exchange_type` behaviour. The overridden methods are: `route/2`, `delete/3` and `add_binding`. What this exchange does is to cache the last 20 messages while they are routed to queues. Whenever a new queue is bound to the exchange, we deliver those last 20 messages to it. Finally, when the exchange is deleted we remove those entries from the database. When is this useful? Say you implement a chat room with RabbitMQ, and you want people that join the room to get the last messages sent to the room - this is a simple way to accomplish that.\\r\\n\\r\\nWhile you could understand most of the code if you looked at an [Elixir Tutorial](https://elixir-lang.org/getting_started/1.html) first, there are some points worth noting, since for me it was not so clear on how to port them into Elixir. If you want to take a look at the original project I was porting from Erlang go look [here](https://github.com/videlalvaro/rabbitmq-recent-history-exchange).\\r\\n\\r\\n### Module Attributes\\r\\n\\r\\nRabbitMQ uses a concept of *boot steps* in order to start the broker. Those boot steps are scanned when the broker starts, and from there plugins are automatically picked up by the server. They are declared as module attributes, so my first blocker was how to add a module attribute to Elixir. Assuming we have the following module:\\r\\n\\r\\n```elixir\\r\\ndefmodule RabbitExchangeTypeRecentHistory do\\r\\nend\\r\\n```\\r\\n\\r\\nTo add an attribute to it like the ones expected by RabbitMQ we have to do so like this:\\r\\n\\r\\n```elixir\\r\\ndefmodule RabbitExchangeTypeRecentHistory do\\r\\n\\r\\n  Module.register_attribute __MODULE__,\\r\\n       :rabbit_boot_step,\\r\\n       accumulate: true, persist: true\\r\\n\\r\\n  @rabbit_boot_step { __MODULE__,\\r\\n                     [{:description, \\"exchange type x-recent-history\\"},\\r\\n                      {:mfa, {:rabbit_registry, :register,\\r\\n                              [:exchange, <<\\"x-recent-history\\">>, __MODULE__]}},\\r\\n                      {:requires, :rabbit_registry},\\r\\n                      {:enables, :kernel_ready}]\\r\\nend\\r\\n```\\r\\n\\r\\nFirst we have to register our attribute by calling `Module.register_attribute` and then we can use it in our code as in this example.\\r\\n\\r\\n### Behaviours\\r\\n\\r\\nDeclaring behaviours in our modules is quite easy. We just need to add a behaviour attribute to our module like this:\\r\\n\\r\\n```elixir\\r\\n@behaviour :rabbit_exchange_type\\r\\n```\\r\\n\\r\\n### Erlang Records\\r\\n\\r\\nWhen you develop RabbitMQ plugins (and probably whenever you interop with Erlang libraries) you will need to use the records defined in the library. This isn\'t as straightforward as I was expecting. We have to import the record definitions into Elixir. For example, to have the `#exchange` record from RabbitMQ we have to do this:\\r\\n\\r\\n```elixir\\r\\ndefmodule RabbitExchangeTypeRecentHistory do  \\r\\n  defrecord :exchange, Record.extract(:exchange, from_lib: \\"rabbit_common/include/rabbit.hrl\\")\\r\\nend\\r\\n```\\r\\n\\r\\nKeep in mind here that  I\'m just showing snippets of the code. You don\'t need to define the `RabbitExchangeTypeRecentHistory` module every time.\\r\\n\\r\\n## Building the Plugin\\r\\n\\r\\nOnce we finish implementing our plugin we might want to build it, after all there\'s a reason why we spent all this time on it! To do so we need to add two `Makefiles` into our project folder in order to integrate with RabbitMQ\'s build system.\\r\\n\\r\\nThe first is called `Makefile` and it includes just one line:\\r\\n\\r\\n```makefile\\r\\ninclude ../umbrella.mk\\r\\n```\\r\\n\\r\\nThe second one is a bit more involved. Here we specify the dependencies of our project and we tell the RabbitMQ build system how to compile our Elixir code.\\r\\n\\r\\n```makefile\\r\\nDEPS:=rabbitmq-server rabbitmq-erlang-client elixir_wrapper\\r\\nRETAIN_ORIGINAL_VERSION:=true\\r\\nORIGINAL_VERSION:=0.1\\r\\nDO_NOT_GENERATE_APP_FILE:=\\r\\n\\r\\nCONSTRUCT_APP_PREREQS:=mix-compile\\r\\ndefine construct_app_commands\\r\\n\\tmkdir -p $(APP_DIR)/ebin\\r\\n\\tcp $(PACKAGE_DIR)/ebin/* $(APP_DIR)/ebin\\r\\nendef\\r\\n\\r\\ndefine package_rules\\r\\n\\r\\n$(PACKAGE_DIR)/deps/.done:\\r\\n\\trm -rf $$(@D)\\r\\n\\tmkdir -p $$(@D)\\r\\n\\t@echo [elided] unzip ezs\\r\\n\\t@cd $$(@D) &amp;&amp; $$(foreach EZ,$$(wildcard $(PACKAGE_DIR)/build/dep-ezs/*.ez),unzip -q $$(abspath $$(EZ)) &amp;&amp;) :\\r\\n\\ttouch $$@\\r\\n\\r\\nmix-compile: $(PACKAGE_DIR)/deps/.done\\r\\n\\tmix clean\\r\\n\\tERL_LIBS=$(PACKAGE_DIR)/deps mix compile\\r\\n\\r\\nendef\\r\\n```\\r\\n\\r\\nI won\'t explain this code line-by-line, just the interesting bits. On the first line we declare our plugin\'s dependencies. In this case we depend on the `rabbitmq server` and the `rabbitmq-erlang-client` in order to have access to all the behaviours and records required by our plugin. Of course, we also depend on the Elixir libraries that will be shipped with our plugin.\\r\\n\\r\\nNext, we define some make targets to compile our plugin and package it inside an `.ez` file (RabbitMQ plugins are shipped as .ez files). The `mix-compile` target will build our Elixir code. As you might have noticed it sets the `ERL_LIBS` variable to our plugin\'s `./deps` folder. For that to work we first need to have the dependencies unpacked there, so the make rule `$(PACKAGE_DIR)/deps/.done` unpacks the previously built dependencies into that folder.\\r\\n\\r\\nFinally our `define construct_app_commands` will copy our `.beam` files into the destination folder so the RabbitMQ build system will be able to find them and ship them inside our plugin `.ez` file.\\r\\n\\r\\nOnce we have everything in place it\'s time to actually build our plugin. We can do so by simply calling `make` inside the plugin folder.\\r\\n\\r\\nOnce the build process has finished, we can find the `.ez` files inside the `dist` folder\\r\\n\\r\\n```shell\\r\\nls dist/\\r\\namqp_client-3.3.1.ez\\r\\nelixir-0.9.2.dev-rmq3.3.1-git7c379aa.ez\\r\\nrabbit_common-3.3.1.ez\\r\\nrabbitmq_recent_history_exchange_elixir-0.1-rmq3.3.1.ez\\r\\n```\\r\\n\\r\\nFrom that list of files we only need to distribute `rabbitmq_recent_history_exchange_elixir-0.1-rmq3.3.1.ez` and `elixir-0.9.2.dev-rmq3.3.1-git7c379aa.ez` as part of our plugin.\\r\\n\\r\\n## Installing the Plugin\\r\\n\\r\\nCopy the files `rabbitmq_recent_history_exchange_elixir-0.1-rmq3.3.1.ez` and `elixir-0.9.2.dev-rmq3.3.1-git7c379aa.ez` into the `plugins` folder of your RabbitMQ installation and then activate the plugin by running: \\r\\n\\r\\n```shell\\r\\n./sbin/rabbitmq-plugins enable rabbitmq_recent_history_exchange_elixir\\r\\n```\\r\\n\\r\\nOnce we start the broker we can see in the management interface that we can now add exchanges of the type `x-recent-history`.\\r\\n\\r\\n![](rh_exchange.png)\\r\\n\\r\\n## Coda\\r\\n\\r\\nAnd that\'s that. We can build RabbitMQ plugins using Elixir! Most of the *yak shaving* is done already, and we just need to use the `elixir_wrapper` and create the proper `package.mk` file for our plugin. From there it\'s just a matter of invoking `make`. Please share your thoughts in the comments section and if you build a RabbitMQ plugin using Elixir please share it and let me know."},{"id":"/2013/05/01/rabbitmq-3-1-0-in-images","metadata":{"permalink":"/rabbitmq-website/blog/2013/05/01/rabbitmq-3-1-0-in-images","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2013-05-01-rabbitmq-3-1-0-in-images/index.md","source":"@site/blog/2013-05-01-rabbitmq-3-1-0-in-images/index.md","title":"RabbitMQ 3.1... in images","description":"Charts","date":"2013-05-01T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":0.19,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"RabbitMQ 3.1... in images","tags":["New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Using Elixir to write RabbitMQ Plugins","permalink":"/rabbitmq-website/blog/2013/06/03/using-elixir-to-write-rabbitmq-plugins"},"nextItem":{"title":"What\'s new in RabbitMQ 3.0?","permalink":"/rabbitmq-website/blog/2012/11/20/whats-new-in-rabbitmq-3-0"}},"content":"## Charts\\r\\n\\r\\n![](chart.png)\\r\\n<!-- truncate -->\\r\\n\\r\\n## Syncing\\r\\n\\r\\n![](syncing.png)\\r\\n\\r\\n## Limited-length queues\\r\\n\\r\\n![](limited.png)\\r\\n\\r\\n## Filters\\r\\n\\r\\n![](filter.png)\\r\\n\\r\\n## Less scrolling\\r\\n\\r\\n![](banner.png)\\r\\n\\r\\n## AMQP 1.0 support\\r\\n\\r\\n![](amqp1.0.png)\\r\\n\\r\\n## autoheal\\r\\n\\r\\n![](autoheal.png)\\r\\n\\r\\n(OK that last one was a bit of a stretch...)"},{"id":"/2012/11/20/whats-new-in-rabbitmq-3-0","metadata":{"permalink":"/rabbitmq-website/blog/2012/11/20/whats-new-in-rabbitmq-3-0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-11-20-whats-new-in-rabbitmq-3-0/index.md","source":"@site/blog/2012-11-20-whats-new-in-rabbitmq-3-0/index.md","title":"What\'s new in RabbitMQ 3.0?","description":"So we\'ve talked about how RabbitMQ 3.0 can break things, but that\'s not very positive. Let\'s have a look at some of the new features! Just some of them - quite a lot changed in 3.0, and we don\'t have all day...","date":"2012-11-20T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":2.29,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"What\'s new in RabbitMQ 3.0?","tags":["New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 3.1... in images","permalink":"/rabbitmq-website/blog/2013/05/01/rabbitmq-3-1-0-in-images"},"nextItem":{"title":"Breaking things with RabbitMQ 3.0","permalink":"/rabbitmq-website/blog/2012/11/19/breaking-things-with-rabbitmq-3-0"}},"content":"So we\'ve talked about how [RabbitMQ 3.0 can break things](/blog/2012/11/19/breaking-things-with-rabbitmq-3-0), but that\'s not very positive. Let\'s have a look at some of the new features! Just some of them - [quite a lot changed in 3.0](https://www.rabbitmq.com/release-notes/README-3.0.0.txt), and we don\'t have all day...\\r\\n<!-- truncate -->\\r\\n\\r\\n## Policy-based mirroring\\r\\n\\r\\n![](policy-ha.png)\\r\\n\\r\\nYou can now [define queue mirroring](/docs/3.13/ha) in a much simpler and more flexible way. Your applications no longer need to know about it, and can work the same way in development and production. You can take an existing unmirrored queue and make it become mirrored with no downtime (and vice versa of course). Furthermore you can now mirror queues on to a set number of nodes in a cluster.\\r\\n\\r\\n## Faster mirroring\\r\\n\\r\\nMirrored queues have also become much faster - while the improvement in performance depends on a variety of factors, it is not unknown to see mirrored queues running an order of magnitude faster, or even more.\\r\\n\\r\\n## Dynamic federation\\r\\n\\r\\n![](federation.png)\\r\\n\\r\\nFederation has also become [more flexible, transparent to applications, and dynamic](/docs/federation). You can federate or unfederate exchanges at any time; and add, remove and reconfigure upstreams without changing anything.\\r\\n\\r\\n## New clustering commands\\r\\n\\r\\nClustering is now easier to [set up](/docs/clustering), and more checks for cluster consistency are performed at each step in the process. It\'s also now possible to remove a dead node from a cluster without its cooperation.\\r\\n\\r\\n## Partition detection\\r\\n\\r\\n![](partition.png)\\r\\n\\r\\n[Network partitions](/docs/partitions) in clusters are a bad thing - so RabbitMQ will now display a large warning in the management plugin when one has occurred (this is also available in `rabbitmqctl cluster\\\\_status`).\\r\\n\\r\\n## Per-message TTL\\r\\n\\r\\nAs well as being able to specify a TTL for messages on a per-queue basis, individual messages can also [have a TTL set](/docs/ttl#per-message-ttl-in-publishers) when they are published.\\r\\n\\r\\n## Enabling heartbeats by default\\r\\n\\r\\nSince so many people have experienced problems with long-running idle connections being interrupted by network infrastructure, the server now proposes AMQP heartbeats every 10 minutes by default during connection negotiation. This value can be [configured here](/docs/configure#configuration-files).\\r\\n\\r\\n## Memory use statistics\\r\\n\\r\\n![](memory.png)\\r\\n\\r\\nIt\'s now possible to get a simple overview of [where the memory used by your broker is going](/docs/memory-use).\\r\\n\\r\\n## Background GC\\r\\n\\r\\nCertain long-running processes have ended up consuming a lot of memory while waiting for garbage collection. RabbitMQ now forcibly GCs idle processes in the background, cutting down on excess memory use.\\r\\n\\r\\n## Reverse DNS lookups\\r\\n\\r\\n![](rdns.png)\\r\\n\\r\\nJust a small thing - but you can now have RabbitMQ perform reverse DNS lookups on connecting clients to give clearer names in management and rabbitmqctl. Just set `{reverse\\\\_dns\\\\_lookups, true}` in your [rabbitmq.config](/docs/configure#configuration-files).\\r\\n\\r\\n## Web-STOMP and MQTT\\r\\n\\r\\nWe\'ve added plugins to support [STOMP-over-websockets](/blog/2012/05/14/introducing-rabbitmq-web-stomp) (with SockJS support for non-websocket browsers) and [MQTT 3.1](https://www.ibm.com/developerworks/webservices/library/ws-mqtt/). We\'ve also added support for [STOMP 1.2](http://stomp.github.com/stomp-specification-1.2.html)."},{"id":"/2012/11/19/breaking-things-with-rabbitmq-3-0","metadata":{"permalink":"/rabbitmq-website/blog/2012/11/19/breaking-things-with-rabbitmq-3-0","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-11-19-breaking-things-with-rabbitmq-3-0/index.md","source":"@site/blog/2012-11-19-breaking-things-with-rabbitmq-3-0/index.md","title":"Breaking things with RabbitMQ 3.0","description":"RabbitMQ includes a bunch of cool new features. But in order to implement some of them we needed to change some things. So in this blog post I\'m going to list some of those things in case you need to do anything about them.","date":"2012-11-19T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":5.35,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Breaking things with RabbitMQ 3.0","tags":["New Features","HowTo"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"What\'s new in RabbitMQ 3.0?","permalink":"/rabbitmq-website/blog/2012/11/20/whats-new-in-rabbitmq-3-0"},"nextItem":{"title":"MQTT Adapter","permalink":"/rabbitmq-website/blog/2012/09/12/mqtt-adapter"}},"content":"RabbitMQ includes a bunch of cool new features. But in order to implement some of them we needed to change some things. So in this blog post I\'m going to list some of those things in case you need to do anything about them.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Mirror queue policies\\r\\n\\r\\n**What changed?** In RabbitMQ 3.0, queue mirroring is no longer controlled by the `x-ha-policy` argument when declaring a queue. Your applications can continue to declare this argument, but it won\'t cause queues to be mirrored. Instead you can declare one or more [policies](/docs/parameters) which control which queues are mirrored, and how.\\r\\n\\r\\n**Why did it change?** As anyone who\'s used mirrored queues will tell you, requiring applications to know which queues are mirrored is a pain. The new approach puts configuration in the broker, where it belongs, and also supports changing mirroring policy at any time.\\r\\n\\r\\n**What should I do?** You need to make sure your queues are still mirrored. For the full documentation [see here](/docs/3.13/ha), but if you just want to make sure that all queues (except those with auto-generated names) are mirrored across all nodes, run:\\r\\n\\r\\n```shell\\r\\nrabbitmqctl set_policy HA \'^(?!amq\\\\\\\\.).*\' \'{\\"ha-mode\\": \\"all\\"}\'\\r\\n```\\r\\n\\r\\n## New federation\\r\\n\\r\\n**What changed?** Federation is configured quite differently in RabbitMQ 3.0. The `x-federation` exchange type no longer exists; instead normal exchanges are made federated by policy in the same way that HA queues are. Furthermore, upstreams are defined dynamically as well.\\r\\n\\r\\n**Why did it change?** Again, your applications should not need to know about federation. Federation configuration in `rabbitmq.config` was complicated and confused many people. And needing to restart the broker to add a new upstream was not fun.\\r\\n\\r\\n**But I have a working federation setup! You broke it.** Migrating to the [new way of doing federation](/docs/federation) will take a bit of work. In the mean time you can use the `rabbitmq_old_federation` plugin. This is a backport of the 2.8.7 federation plugin for RabbitMQ 3.0. To use it:\\r\\n\\r\\n```shell\\r\\nrabbitmq-plugins disable rabbitmq_federation\\r\\n\\r\\nrabbitmq-plugins enable rabbitmq_old_federation\\r\\n```\\r\\n\\r\\nand then edit your `rabbitmq.config` file so that the `rabbitmq_federation` section is renamed to `rabbitmq_old_federation`.\\r\\n\\r\\n## New clustering\\r\\n\\r\\n**What changed?** The clustering-setup commands in rabbitmqctl have changed.\\r\\n\\r\\n**Why did it change?** The old ones were not very user friendly.\\r\\n\\r\\n**What do I need to do?** If you have an existing cluster, nothing. If you write scripts to create clusters, you will need to edit them. In particular, `rabbitmqctl cluster` should be replaced with `rabbitmqctl join_cluster`, but:\\r\\n\\r\\n* You don\'t need to invoke `rabbitmqctl reset` first\\r\\n* You don\'t need to list all the nodes on the command line; if you give more than one node then they will be taken as a list of nodes to try to cluster with\\r\\n* Whether the new node is a disc or RAM node is determined by the --disc and --ram flags. The default is to be a disc node.\\r\\n\\r\\nFor more details, see [the documentation](/docs/man/rabbitmqctl.8#join_cluster).\\r\\n\\r\\n## Removal of \\"immediate\\" flag\\r\\n\\r\\n**What changed?** We removed support for the rarely-used \\"immediate\\" flag on AMQP\'s basic.publish.\\r\\n\\r\\n**Why on earth did you do that?** Support for \\"immediate\\" made many parts of the codebase more complex, particularly around mirrored queues. It also stood in the way of our being able to deliver substantial performance improvements in mirrored queues.\\r\\n\\r\\n**What do I need to do?** \\r\\nIf you just want to be able to publish messages that will be dropped if they are not consumed immediately, you can publish to a queue [with a TTL of 0](/docs/ttl).\\r\\n\\r\\nIf you also need your publisher to be able to determine that this has happened, you can also use the [DLX](/docs/dlx) feature to route such messages to another queue, from which the publisher can consume them.\\r\\n\\r\\n## frame_max\\r\\n\\r\\n**What changed?** The RabbitMQ server now disconnects clients which send frames larger than the negotiated `frame_max` setting for the connection.\\r\\n\\r\\n**Why did it change?** Malicious (or badly written) clients could send arbitrarily large frames and cause the server to run out of memory.\\r\\n\\r\\n**Why do I care?** Unfortunately some clients don\'t implement AMQP framing correctly. RabbitMQ 3.0 will allow clients to exceed `frame_max` by a fudge factor of a few bytes (to allow for off by one errors and incorrectly excluding the frame header) but if your client has broken framing you will be disconnected after trying to send a message larger than `frame_max` (which by default comes out to 128kb; see the [documentation](/docs/configure#config-items) on how to raise this).\\r\\n\\r\\n## Management and JSON-RPC channel port changes\\r\\n\\r\\n**What changed?** The management plugin now listens on port 15672, not 55672. JSON-RPC channel now listens on 15670, not 55670.\\r\\n\\r\\n**Why did it change?** The old ports were in the ephemeral port range on many operating systems, meaning that web browsers and other client applications might use these ports arbitrarily. You\'re not supposed to listen on these ports.\\r\\n\\r\\nIn particular we noticed that the management plugin web UI could, when pointed at a stopped broker on localhost, end up getting the browser to connect to itself on port 55672. This prevented the broker from starting again.\\r\\n\\r\\n**What do I have to do?** Hopefully nothing. RabbitMQ will attempt to open the old port and send HTTP redirects to the new one. But if you\'re using an application other than a web browser to talk to the HTTP API, it might not support HTTP redirects. If it doesn\'t, you\'ll need to point it at the new port.\\r\\n\\r\\nNote that `rabbitmqadmin` prior to version 3.0 was such an application. Oops.\\r\\n\\r\\nAlso note that the STOMP plugin still listens on port 61313. Although this is in the ephemeral range, it\'s the closest thing STOMP has to a standard port, so we have to stick with it.\\r\\n\\r\\n## expiration property\\r\\n\\r\\n**What changed?** We now expect the expiration field in message properties to be parseable as an integer if it\'s set at all.\\r\\n\\r\\n**Why did it change?** In order to support [per-message TTL](/docs/ttl#per-message-ttl-in-publishers) we need a place to get the TTL of the message from, and this is the obvious place. Unfortunately the AMQP standard defines it as a string, so we try to parse it as an integer and will throw a channel exception if it is not.\\r\\n\\r\\n**What do I have to do?** Make sure that if you\'re using that property then you\'re using it because you expect RabbitMQ to expire the message, and make sure it\'s set to a string which can be parsed as an integer."},{"id":"/2012/09/12/mqtt-adapter","metadata":{"permalink":"/rabbitmq-website/blog/2012/09/12/mqtt-adapter","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-09-12-mqtt-adapter/index.md","source":"@site/blog/2012-09-12-mqtt-adapter/index.md","title":"MQTT Adapter","description":"I\'ve written a plugin for RabbitMQ that adds support for the MQTT 3.1 protocol. MQ Telemetry Transport is a light-weight PUB/SUB protocol designed for resource-constrained devices and limited bandwidth situations, making it ideally suited to sensors and mobile devices. The implementation is a protocol adapter plugin, allowing MQTT clients to connect to a RabbitMQ broker simultaneously with clients implementing other protocols. We encourage projects that demand the combination of a low-overhead protocol on a robust, scalable broker with high reliability and enterprise features to consider this option.","date":"2012-09-12T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.05,"hasTruncateMarker":true,"authors":[{"name":"Emile Joubert","key":"emile","page":null}],"frontMatter":{"title":"MQTT Adapter","tags":["New Features"],"authors":["emile"]},"unlisted":false,"prevItem":{"title":"Breaking things with RabbitMQ 3.0","permalink":"/rabbitmq-website/blog/2012/11/19/breaking-things-with-rabbitmq-3-0"},"nextItem":{"title":"Jason and Alvaro\'s excellent Rabbit book","permalink":"/rabbitmq-website/blog/2012/05/29/jason-and-alvaros-excellent-rabbit-book"}},"content":"I\'ve written a plugin for RabbitMQ that adds support for the [MQTT 3.1](https://www.ibm.com/developerworks/webservices/library/ws-mqtt/) protocol. MQ Telemetry Transport is a light-weight PUB/SUB protocol designed for resource-constrained devices and limited bandwidth situations, making it ideally suited to sensors and mobile devices. The implementation is a protocol adapter plugin, allowing MQTT clients to connect to a RabbitMQ broker simultaneously with clients implementing other protocols. We encourage projects that demand the combination of a low-overhead protocol on a robust, scalable broker with high reliability and enterprise features to consider this option.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Supported features\\r\\n\\r\\n### QoS 0 and QoS 1\\r\\n\\r\\nThe MQTT adapter supports QoS 0 (at most once) and QoS 1 (at least once) semantics. In MQTT QoS relates to transport assurance as well as persistence - the plugin honours both. While clients are permitted to request QoS 2 subscriptions, the adapter will only grant subscriptions up to QoS 1.\\r\\n\\r\\n### Last Will and Testament (LWT)\\r\\n\\r\\nClients can provide a LWT message during connection that will only be published if the client disconnects unexpectedly, e.g. due to a network failure.\\r\\n\\r\\n### Sticky sessions\\r\\n\\r\\nClients can make use of sticky (or non-clean) sessions to ensure they receive messages that were published whilst they were disconnected.\\r\\n\\r\\n### Default logins\\r\\n\\r\\nDefault authentication details can be optionally be configured so that the MQTT adapter authenticates to the RabbitMQ broker as a default user in case a connecting MQTT client provides no login details.\\r\\n\\r\\n## Extended features\\r\\n\\r\\nWhile not explicitly enumerated, all core broker features are available to MQTT clients.\\r\\n\\r\\nMQTT subscription wildcards are limited in that they may only appear as a suffix. AMQP topics are not limited in this way, so wildcards can appear in any position. The MQTT adapter implements the more flexible AMQP patterns, but with MQTT syntax.\\r\\n\\r\\nThe MQTT specification does not mention SSL or any interaction between SSL and authentication. The MQTT adapter includes SSL capability now, with the possibility of integrating certificates with authentication on the future.\\r\\n\\r\\nThe MQTT concept of \\"bridging\\" can be realised with RabbitMQ\'s [federation](/docs/federation) by federating the exchanges that the MQTT adapter publishes to.\\r\\n\\r\\n## Future features\\r\\n\\r\\nAMQP 0-9-1 does not define \\"exactly once\\" semantics for message delivery. For this reason the MQTT adapter does not support publishing messages at the QoS 2 (exactly once) level, or exchanging PUBREC, PUBREL or PUBCOMP messages with clients.\\r\\n\\r\\n\\"Retained messages\\" is an MQTT feature where the broker retains flagged messages and delivers them to future subscribing clients. E.g. in a topic for sensor readings, a retained message allows a client to receive the last reading without needing to wait for the next reading. By default AMQP 0-9-1 exchanges do not retain any message state. Therefore the MQTT adapter makes no attempt to honour the \\"Retained\\" flag, which will be silently ignored.\\r\\n\\r\\nThese are areas where we are especially interested in obtaining feedback from the community. There is scope to enhance the core broker with these features not only for MQTT clients, but potentially for (extended) AMQP and other clients as well - provided there is sufficient demand.\\r\\n\\r\\n## Interoperability with other MQTT implementations\\r\\n\\r\\nThe MQTT adapter has been successfully tested with the MQTT clients of the following products, when restricting operation to the supported features:\\r\\n\\r\\n* Really Small Message Broker\\r\\n* Mosquitto\\r\\n* Paho\\r\\n* WebSphere MQ\\r\\n\\r\\n## Interoperability with other protocols\\r\\n\\r\\nThe MQTT adapter uses one configurable exchange for publishing, and subscriptions are implemented as AMQP bindings. In combination these allow interoperability with any clients that know the name of the exchange or the topics used by MQTT clients.\\r\\n\\r\\n## Installation\\r\\n\\r\\nFirst make sure you have [rabbitmq-server 2.8.6](/docs/download) installed. (The plugin should also be compatible with other v2.8.x releases.)\\r\\n\\r\\nThe MQTT adapter is currently available as a preview release. You must download and install the plugin manually until it is included as a regular plugin in a future release. The plugin can be downloaded from the [preview release downloads](https://www.rabbitmq.com/releases/plugins/v2.8.6-mqtt-preview/rabbitmq_mqtt-2.8.6.ez), e.g.\\r\\n\\r\\n```shell\\r\\nwget https://www.rabbitmq.com/releases/plugins/v2.8.6-mqtt-preview/rabbitmq_mqtt-2.8.6.ez\\r\\n```\\r\\n\\r\\nThe *.ez file must be copied to the [plugins directory](/docs/plugins#plugin-directories). On my Debian-based workstation this is in ` /usr/lib/rabbitmq/lib/rabbitmq_server-2.8.6/plugins`:\\r\\n\\r\\n```shell\\r\\nsudo cp rabbitmq_mqtt-2.8.6.ez /usr/lib/rabbitmq/lib/rabbitmq_server-2.8.6/plugins\\r\\n```\\r\\n\\r\\nEnable the plugin using [rabbitmq-plugins](/docs/plugins):\\r\\n\\r\\n```shell\\r\\nsudo rabbitmq-plugins enable rabbitmq_mqtt\\r\\n```\\r\\n\\r\\nRestart the rabbitmq server\\r\\n\\r\\n```shell\\r\\nsudo /etc/init.d/rabbitmq-server restart \\r\\n```\\r\\n\\r\\nThe broker logfile should now include a new line indicating that it is ready to accept MQTT connections:\\r\\n\\r\\n```\\r\\n=INFO REPORT==== 12-Sep-2012::14:21:26 ===\\r\\n  started MQTT TCP Listener on [::]:1883\\r\\n```\\r\\n\\r\\nThe default configuration options should work fine in most cases. A description of all configuration options is included in the [readme](http://hg.rabbitmq.com/rabbitmq-mqtt/file/default/README.md). You will need to provide further configuration if you wish to set up SSL, or define a different exchange in order to facilitate [federation](/docs/federation).\\r\\n\\r\\nYou can now try to execute the [included tests](http://hg.rabbitmq.com/rabbitmq-mqtt/file/default/test/src/com/rabbitmq/mqtt/test/MqttTest.java) (based on the Java Paho client library), or your own MQTT application.\\r\\n\\r\\nSee the [contact](/contact) page for details on how to provide feedback."},{"id":"/2012/05/29/jason-and-alvaros-excellent-rabbit-book","metadata":{"permalink":"/rabbitmq-website/blog/2012/05/29/jason-and-alvaros-excellent-rabbit-book","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-05-29-jason-and-alvaros-excellent-rabbit-book/index.md","source":"@site/blog/2012-05-29-jason-and-alvaros-excellent-rabbit-book/index.md","title":"Jason and Alvaro\'s excellent Rabbit book","description":"Here at Rabbit HQ we\'ve been enjoying \\"RabbitMQ in Action\\", the introduction to RabbitMQ and messaging.  Part of the Manning series, the book is written by Jason Williams and Alvaro Videla, both well known for their many contributions to the Rabbit community.","date":"2012-05-29T00:00:00.000Z","tags":[],"readingTime":2.875,"hasTruncateMarker":true,"authors":[{"name":"Alexis Richardson","key":"alexis","page":null}],"frontMatter":{"title":"Jason and Alvaro\'s excellent Rabbit book","tags":[],"authors":["alexis"]},"unlisted":false,"prevItem":{"title":"MQTT Adapter","permalink":"/rabbitmq-website/blog/2012/09/12/mqtt-adapter"},"nextItem":{"title":"Introducing RabbitMQ-Web-Stomp","permalink":"/rabbitmq-website/blog/2012/05/14/introducing-rabbitmq-web-stomp"}},"content":"Here at Rabbit HQ we\'ve been enjoying \\"[RabbitMQ in Action](http://manning.com/videla/)\\", the introduction to RabbitMQ and messaging.  Part of the [Manning series](http://www.manning.com/), the book is written by [Jason Williams](http://blogs.digitar.com/jjww/) and [Alvaro Videla](http://videlalvaro.github.com/), both well known for their many contributions to the Rabbit community.\\r\\n\\r\\nToday we\'d like to say thank-you to Jason and Alvaro.  Thank-you Jason and Alvaro!  You did an amazing job and infinite beers are on us.\\r\\n\\r\\nBut there\'s more...  Manning have kindly offered a promotional discount of 37% to readers of this blog.  All is revealed below, in a guest post by Jason Williams himself...\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## RabbitMQ in Action is here\\r\\n\\r\\nWell, it\'s finally here. After 18 months of writing, re-writing and updating, RabbitMQ in Action is finished and in the flesh. It\'s hard to believe that when we started, RabbitMQ was at version 1.8.0 and now we\'re at 2.8.2. So much has changed in Rabbit that required rewrites of whole sections along the way, that it feels like we\'re really at 5 or 6.0. It\'s a testament to the Rabbit team members that helped us that the book kept pace with it all. So now that it\'s out why should you read it (besides the 37% discount code below)?\\r\\n\\r\\nIf you feel like you want a deeper understanding than the [online tutorials](/tutorials) offer, we wrote this for you. Whether it\'s figuring out [clustering](/docs/clustering) and [mirrored queues](/docs/3.13/ha), or just getting a better understanding of messaging fabrics ([queues, bindings and routing exchanges](/tutorials/amqp-concepts), [relays and federations](/docs/distributed).), our goal was to write the book we wished had existed when we started, and that we hope will help you. From the [management console and API](/docs/management) to building real world applications and [plugins](/docs/plugins), we\'ve tried to cover everything you need to get a good foundation of Rabbit under your belt and hopefully that you can use as a desk reference too.\\r\\n\\r\\n## Lots of example code on Github to get you started\\r\\n\\r\\nOne thing we tried to focus on was using RabbitMQ to link together different applications written in completely different languages.  That\'s one of the main reasons we wrote the examples in Python and PHP. However, we had two other reasons also:\\r\\n\\r\\n1.) Python reads almost like pseudo-code and produces incredibly readable programs which makes it an excellent teaching language. You can focus on what the example program\'s doing, without a lot of class declarations and boiler plate clouding up the works.\\r\\n\\r\\n2.) There are a ton of books on messaging targeted at Java and the old-line enterprise brokers. We wanted to write something different... something that was easier to read and more accessible to people without any background in messaging. RabbitMQ in Action is very\\r\\nmuch a book for people of all languages and backgrounds. Writing in Python and PHP helped us do that (there\'s appendices on using Rabbit with Java and .NET too).\\r\\n\\r\\nWith that last one in mind, we\'ve done something a little different than other Manning books all of our examples are in a [public repo on Github](https://github.com/rabbitinaction/sourcecode).\\r\\n\\r\\nWe did this so that if you feel like converting the examples into the language of your choice to help those like you, you can. As long as the license on your contribution is [BSD](http://en.wikipedia.org/wiki/BSD_licenses), we\'ll merge in your pull requests and hopefully build a huge library of RabbitMQ examples that can help everyone. There are already Ruby versions of the examples merged in!\\r\\n\\r\\nSo if those aren\'t reasons enough to give RabbitMQ in Action a shot how about a 37% discount just because you read this blog? :)\\r\\n\\r\\nSave 37% on RabbitMQ in Action with Promotional Discount Code *12rmqb* when you checkout at [the Manning web site](http://manning.com/videla)."},{"id":"/2012/05/14/introducing-rabbitmq-web-stomp","metadata":{"permalink":"/rabbitmq-website/blog/2012/05/14/introducing-rabbitmq-web-stomp","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-05-14-introducing-rabbitmq-web-stomp/index.md","source":"@site/blog/2012-05-14-introducing-rabbitmq-web-stomp/index.md","title":"Introducing RabbitMQ-Web-Stomp","description":"For quite a while here, at RabbitMQ headquarters, we were struggling to","date":"2012-05-14T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.085,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"Introducing RabbitMQ-Web-Stomp","tags":["Web Messaging","New Features"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"Jason and Alvaro\'s excellent Rabbit book","permalink":"/rabbitmq-website/blog/2012/05/29/jason-and-alvaros-excellent-rabbit-book"},"nextItem":{"title":"Some queuing theory: throughput, latency and bandwidth","permalink":"/rabbitmq-website/blog/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth"}},"content":"![](web-stomp.png)\\r\\n\\r\\nFor quite a while here, at RabbitMQ headquarters, we were struggling to\\r\\nfind a good way to expose messaging in a web browser. In the past we tried many\\r\\nthings ranging from the old-and-famous JsonRPC plugin (which basically\\r\\nexposes AMQP via AJAX), to Rabbit-Socks (an attempt to create a generic\\r\\nprotocol hub), to the management plugin (which can be used for basic\\r\\nthings like sending and receiving messages from the browser).\\r\\n\\r\\nOver time we\'ve learned that the messaging on the web is very different\\r\\nto what we\'re used to. None of our attempts really addressed\\r\\nthat, and it is likely that messaging on the web will not be a fully\\r\\nsolved problem for some time yet.\\r\\n\\r\\nThat said, there is a simple thing RabbitMQ users keep on asking\\r\\nabout, and although not perfect, it\'s far from the worst way do messaging\\r\\nin the browser: exposing STOMP through Websockets.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## STOMP + Websockets\\r\\n\\r\\nWe\'re delighted to introduce a new plugin for RabbitMQ:\\r\\n\\r\\n* [RabbitMQ-Web-Stomp](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_web_stomp)\\r\\n\\r\\nIt is basically a bridge between [RabbitMQ-STOMP](https://github.com/rabbitmq/rabbitmq-stomp)\\r\\nplugin and a Websockets server ([SockJS](http://sockjs.org)). Hopefully, it is a decent solution\\r\\nfor a set of rabbit-on-the-web use cases.\\r\\n\\r\\n## What it actually does\\r\\n\\r\\n### Within RabbitMQ \\r\\n\\r\\nRabbitMQ-Web-Stomp is a simple beast. It takes the STOMP\\r\\nprotocol as provided by the RabbitMQ-STOMP plugin and exposes it using\\r\\nthe SockJS server.\\r\\n\\r\\n### Wire protocol\\r\\n\\r\\nOne can connect to the SockJS endpoint from any browser using the reliable\\r\\nSockJS protocol. This will work even in browsers that don\'t support\\r\\nnative websockets or in environments behind broken proxies that block non-http\\r\\ntransports.\\r\\n\\r\\nAlternatively, for users that don\'t need this level of sophistication,\\r\\nSockJS exposes a raw websockets url that can be accessed directly from\\r\\na recent, websocket-capable browser.\\r\\n\\r\\n### In the browser\\r\\n\\r\\nWithin the browser, the connection to SockJS endpoint is basically\\r\\na raw STOMP connection. You can send and receive normal STOMP frames.\\r\\n\\r\\nAny decent javascript STOMP library should be able to handle that.\\r\\nFor our examples we\'re using the [stomp-websocket](https://github.com/jmesnil/stomp-websocket/) library by [Jeff Mesnil](https://github.com/jmesnil) and [Jeff Lindsay](https://github.com/progrium).\\r\\n\\r\\nWe use this code in the examples:\\r\\n\\r\\n```html\\r\\n<script src=\\"http://cdn.sockjs.org/sockjs-0.3.min.js\\"></script>\\r\\n<script src=\\"stomp.js\\"></script>\\r\\n<script>\\r\\n   WebSocketStompMock = SockJS;\\r\\n\\r\\n    var client = Stomp.client(\'http://127.0.0.1:55674/stomp\');\\r\\n    [...]\\r\\n\\r\\n```\\r\\n\\r\\n## Installation\\r\\n\\r\\n[Rabbitmq-Web-Stomp](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_web_stomp) is an experimental plugin.\\r\\nIt\'s not distributed with vanilla RabbitMQ releases; you need to install it manually.\\r\\n\\r\\n1. You need at least Erlang R14 ([more info](/docs/which-erlang)).\\r\\n2. You need [Rabbitmq-server 2.8.2](/docs/download) installed\\r\\n3. Grab the needed erlang plugin .ez files:\\r\\n\\r\\n```shell\\r\\nwget \\\\\\r\\n  https://www.rabbitmq.com/releases/plugins/v2.8.2-web-stomp-preview/cowboy-0.5.0-rmq2.8.2-git4b93c2d.ez \\\\\\r\\n  https://www.rabbitmq.com/releases/plugins/v2.8.2-web-stomp-preview/sockjs-0.2.1-rmq2.8.2-gitfa1db96.ez \\\\\\r\\n  https://www.rabbitmq.com/releases/plugins/v2.8.2-web-stomp-preview/rabbitmq_web_stomp-2.8.2.ez \\\\\\r\\n  https://www.rabbitmq.com/releases/plugins/v2.8.2-web-stomp-preview/rabbitmq_web_stomp_examples-2.8.2.ez\\r\\n```\\r\\n\\r\\n4. Next, copy them to the [plugins directory](/docs/plugins#plugin-directories). For example, on my Ubuntu box this will be:\\r\\n\\r\\n```shell\\r\\nsudo cp *.ez /usr/lib/rabbitmq/lib/rabbitmq_server-2.8.2/plugins\\r\\n```\\r\\n\\r\\n5. Now, you\'re ready to enable them using [rabbitmq-plugins](/docs/plugins):\\r\\n\\r\\n```shell\\r\\nsudo rabbitmq-plugins enable rabbitmq_web_stomp\\r\\nsudo rabbitmq-plugins enable rabbitmq_web_stomp_examples\\r\\n```\\r\\n\\r\\n6. Restart the rabbitmq server. On ubuntu:\\r\\n\\r\\n```shell\\r\\nsudo /etc/init.d/rabbitmq-server restart\\r\\n```\\r\\n\\r\\nAs you may have noticed, we enabled two plugins:\\r\\n\\r\\n* First, [RabbitMQ-web-stomp](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_web_stomp), which is the main\\r\\nplugin. It exposes SockJS endpoint on port 55674, like: [http://127.0.0.1:55674/stomp](http://127.0.0.1:55674/stomp).\\r\\n* Second,\\r\\n[RabbitMQ-web-stomp-examples](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_web_stomp_examples), which\\r\\nonly hosts a few javascript and html files with examples. This is accessible under:\\r\\n[http://127.0.0.1:55670/](http://127.0.0.1:55670/).\\r\\n\\r\\nKeep in mind, that RabbitMQ-web-stomp depends on [RabbitMQ-STOMP](/docs/stomp) which by default will bind to port 61613.\\r\\n\\r\\n## The usage\\r\\n\\r\\nIf you enabled RabbitMQ-web-stomp-examples plugin, you should be able\\r\\nto instantly run two examples prepared by us. Just open a web\\r\\nbrowser at [http://127.0.0.1:55670/](http://127.0.0.1:55670/).\\r\\n\\r\\n* [\\"echo\\"](http://127.0.0.1:55670/web-stomp-examples/echo.html) - shows how to use STOMP to do\\r\\nsimple message broadcasting ([source](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_web_stomp_examples/blob/master/priv/echo.html))\\r\\n\\r\\n![](web-stomp-echo.png)\\r\\n\\r\\n* [\\"bunny\\"](http://127.0.0.1:55670/web-stomp-examples/bunny.html) - example of a simple\\r\\ncollaboration canvas painting app ([source](https://github.com/rabbitmq/rabbitmq-server/tree/main/deps/rabbitmq_web_stomp_examples/blob/master/priv/bunny.html))\\r\\n\\r\\n![](web-stomp-bunny1.png)\\r\\n\\r\\n## Summary\\r\\n\\r\\nRabbitMQ-web-stomp is quite a simple plugin, but opens wide possibilities,\\r\\nexposing the STOMP protocol to the browser.\\r\\n\\r\\nLike always, feedback welcome. We\'re also looking for inspiration for\\r\\nmore examples!"},{"id":"/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","metadata":{"permalink":"/rabbitmq-website/blog/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md","source":"@site/blog/2012-05-11-some-queuing-theory-throughput-latency-and-bandwidth/index.md","title":"Some queuing theory: throughput, latency and bandwidth","description":"You have a queue in Rabbit. You have some clients consuming from that","date":"2012-05-11T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":11.775,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"Some queuing theory: throughput, latency and bandwidth","tags":["HowTo","New Features"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"Introducing RabbitMQ-Web-Stomp","permalink":"/rabbitmq-website/blog/2012/05/14/introducing-rabbitmq-web-stomp"},"nextItem":{"title":"RabbitMQ Performance Measurements, part 2","permalink":"/rabbitmq-website/blog/2012/04/25/rabbitmq-performance-measurements-part-2"}},"content":"You have a queue in Rabbit. You have some clients consuming from that\\r\\nqueue. If you don\'t set a QoS setting at all (`basic.qos`), then\\r\\nRabbit will push all the queue\'s messages to the clients as fast as\\r\\nthe network and the clients will allow. The consumers will balloon in\\r\\nmemory as they buffer all the messages in their own RAM. The queue may\\r\\nappear empty if you ask Rabbit, but there may be millions of messages\\r\\nunacknowledged as they sit in the clients, ready for processing by the\\r\\nclient application. If you add a new consumer, there are no messages\\r\\nleft in the queue to be sent to the new consumer. Messages are just\\r\\nbeing buffered in the existing clients, and may be there for a long\\r\\ntime, even if there are other consumers that become available to\\r\\nprocess such messages sooner. This is rather sub optimal.\\r\\n\\r\\nSo, the default QoS `prefetch` setting gives clients an _unlimited_\\r\\nbuffer, and that can result in poor behaviour and performance. But\\r\\nwhat should you set the QoS `prefetch` buffer size to? The goal is to\\r\\nkeep the consumers saturated with work, but to minimise the client\'s\\r\\nbuffer size so that more messages stay in Rabbit\'s queue and are thus\\r\\navailable for new consumers or to just be sent out to consumers as\\r\\nthey become free.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nLet\'s say it takes 50ms for Rabbit to take a message from this queue,\\r\\nput it on the network and for it to arrive at the consumer. It takes\\r\\n4ms for the client to process the message. Once the consumer has\\r\\nprocessed the message, it sends an `ack` back to Rabbit, which takes a\\r\\nfurther 50ms to be sent to and processed by Rabbit. So we have a total\\r\\nround trip time of 104ms. If we have a QoS `prefetch` setting of 1\\r\\nmessage then Rabbit won\'t sent out the next message until after this\\r\\nround trip completes. Thus the client will be busy for only 4ms of\\r\\nevery 104ms, or 3.8% of the time. We want it to be busy 100% of the\\r\\ntime.\\r\\n\\r\\n![](qos.svg)\\r\\n\\r\\nIf we do _total round trip time_ / _processing time on the client for\\r\\neach message_, we get `104 / 4 = 26`. If we have a QoS `prefetch` of\\r\\n26 messages this solves our problem: assume that the client has 26\\r\\nmessages buffered, ready and waiting for processing. (This is a\\r\\nsensible assumption: once you set `basic.qos` and then `consume` from\\r\\na queue, Rabbit will send as many messages as it can from the queue\\r\\nyou\'ve subscribed to to the client, up to the QoS limit. If you assume\\r\\nmessages aren\'t very big and bandwidth is high, it\'s likely Rabbit\\r\\nwill be able to send messages to your consuming client faster than\\r\\nyour client can process them. Thus it\'s reasonable (and simpler) to do\\r\\nall the maths from the assumption of a full client-side buffer.) If\\r\\neach message takes 4ms of processing to deal with then it\'ll take a\\r\\ntotal of `26 * 4 = 104ms` to deal with the entire buffer. The first\\r\\n4ms is the client processing of the first message. The client then\\r\\nissues an `ack` and goes on to process the next message from the\\r\\nbuffer. That ack takes 50ms to get to the broker. The broker than\\r\\nissues a new message to the client, which takes 50ms to get there, so\\r\\nby the time 104ms has passed and the client has finished processing\\r\\nits buffer, the next message from the broker has already arrived and\\r\\nis ready and waiting for the client to process it. Thus the client\\r\\nremains busy all the time: having a bigger QoS `prefetch` will not\\r\\nmake it go faster; but we minimise the buffer size and thus latency of\\r\\nmessages in the client: messages are buffered by the client for no\\r\\nlonger than they need to be in order to keep the client saturated with\\r\\nwork. In fact, the client is able to fully drain the buffer before the\\r\\nnext message arrives, thus the buffer actually stays empty.\\r\\n\\r\\nThis solution is absolutely fine, provided processing time and network\\r\\nbehaviour remains the same. But consider what happens if suddenly the\\r\\nnetwork halves in speed: your `prefetch` buffer is no longer big\\r\\nenough and now the client will sit idle, waiting for new messages to\\r\\narrive as the client is able to process messages faster than Rabbit\\r\\ncan supply fresh messages.\\r\\n\\r\\nTo address this problem, we might just decide to double (or nearly\\r\\ndouble) the QoS `prefetch` size. If we push it to 51 from 26, then if\\r\\nthe client processing remains at 4ms per message, we now have `51 * 4\\r\\n= 204ms` of messages in the buffer, of which 4ms will be spent\\r\\nprocessing a message, leaving 200ms for the sending an ack back to\\r\\nRabbit and receiving the next message. Thus we can now cope with the\\r\\nnetwork halving in speed.\\r\\n\\r\\nBut if the network\'s performing normally, doubling our QoS `prefetch`\\r\\nnow means each message will sit in the client side buffer for a while,\\r\\ninstead of being processed immediately upon arrival at the\\r\\nclient. Again, starting from a full buffer of now 51 messages we know\\r\\nthat new messages will start appearing at the client 100ms after the\\r\\nclient finishes processing the first message. But in those 100ms, the\\r\\nclient will have processed `100 / 4 = 25` messages out of the 50\\r\\navailable. Which means as a new message arrives at the client, it\'ll\\r\\nbe added to the end of the buffer as the client removes from the head\\r\\nof the buffer. The buffer will thus always stay `50 - 25 = 25`\\r\\nmessages long and every message will thus sit in the buffer for `25 *\\r\\n4 = 100ms`, increasing the latency between Rabbit sending it to the\\r\\nclient and the client starting to process it from 50ms to 150ms.\\r\\n\\r\\nThus we see that increasing the `prefetch` buffer so that the client\\r\\ncan cope with deteriorated network performance whilst keeping the\\r\\nclient busy, substantially increases the latency when the network is\\r\\nperforming normally.\\r\\n\\r\\nEqually, rather than the network\'s performance deteriorating, what\\r\\nhappens if the client starts taking 40ms to process each message\\r\\nrather than 4ms? If the queue in Rabbit was previously at a steady\\r\\nlength (i.e. ingress and egress rates were the same), it\'ll now start\\r\\ngrowing rapidly, as the egress rate has dropped to a tenth of what it\\r\\nwas. You might decide to try and work through this growing backlog by\\r\\nadding more consumers, but there are messages now being buffered by\\r\\nthe existing clients. Assuming the original buffer size of 26\\r\\nmessages, the client will spend 40ms processing the first message,\\r\\nwill then send the ack back to Rabbit and move onto the next\\r\\nmessage. The ack still takes 50ms to get to Rabbit and a further 50ms\\r\\nfor Rabbit to send out a new message, but in that 100ms, the client\\r\\nhas only worked through `100 / 40 = 2.5` further messages rather than\\r\\nthe remaining 25 messages. Thus the buffer is at this point `25 - 3 =\\r\\n22` messages long. The new message arriving from Rabbit, rather than\\r\\nbeing processed immediately, now sits in 23rd place, behind 22 other\\r\\nmessages still waiting to be processed, and will not be touched by the\\r\\nclient for a further `22 * 40 = 880ms`. Given the network delay from\\r\\nRabbit to the client is only 50ms, this additional 880ms delay is now\\r\\n95% of the latency (`880 / (880 + 50) = 0.946`).\\r\\n\\r\\nEven worse, what happens if we doubled the buffer size to 51 messages\\r\\nin order to cope with network performance degradation? After the first\\r\\nmessage has been processed, there will be 50 further messages buffered\\r\\nin the client. 100ms later (assuming the network is running normally),\\r\\na new message will arrive from Rabbit, and the client will be half way\\r\\nthrough processing the 3rd of those 50 messages (the buffer will now\\r\\nbe 47 messages long), thus the new message will be 48th in the buffer,\\r\\nand will not be touched for a further `47 * 40 = 1880ms`. Again, given\\r\\nthe network delay of getting the message to the client is only 50ms,\\r\\nthis further 1880ms delay now means client side buffering is\\r\\nresponsible for over 97% of the latency (`1880 / (1880 + 50) =\\r\\n0.974`). This may very well be unacceptable: the data may only be\\r\\nvalid and useful if it\'s processed promptly, not some 2 seconds after\\r\\nthe client received it! If other consuming clients are idle, there\'s\\r\\nnothing they can do: once Rabbit has sent a message to a client, the\\r\\nmessage is the client\'s responsibility until it acks or rejects the\\r\\nmessage. Clients can\'t steal messages from each other once the message\\r\\nhas been sent to a client. What you want is for clients to be kept\\r\\nbusy, but for clients to buffer as few messages as possible so that\\r\\nmessages are not delayed by client-side buffers and thus new consuming\\r\\nclients can be quickly fed with messages from Rabbit\'s queue.\\r\\n\\r\\nSo, too small a buffer results in clients going idle if the network\\r\\ngets slower, but too big a buffer results in lots of extra latency if\\r\\nthe network performs normally, and huge amounts of extra latency if\\r\\nthe client suddenly starts taking longer to process each message than\\r\\nnormal. It\'s clear that what you really want is a varying buffer\\r\\nsize. These problems are common across network devices and have been\\r\\nthe subject of much study. _Active Queue Management_ algorithms seek\\r\\nto try and drop or reject messages so that you avoid messages sitting\\r\\nin buffers for long periods of time. The lowest latency is achieved\\r\\nwhen the buffer is kept empty (each message suffers network latency\\r\\nonly and does not sit around in a buffer at all) and buffers are there\\r\\nto absorb spikes. [Jim Gettys](http://gettys.wordpress.com/) has been\\r\\nworking on this problem from the point of view of network routers:\\r\\ndifferences between performance of the LAN and the WAN suffer exactly\\r\\nthe same sorts of problems. Indeed whenever you have a buffer between\\r\\na producer (in our case Rabbit) and a consumer (the client-side\\r\\napplication logic) where the performance of both sides can vary\\r\\ndynamically, you will suffer these sorts of problems. Recently a new\\r\\nalgorithm called\\r\\n[Controlled Delay](https://queue.acm.org/detail.cfm?id=2209336) has\\r\\nbeen published which\\r\\n[appears to work well](http://arstechnica.com/information-technology/2012/05/codel-buffer-management-could-solve-the-internets-bufferbloat-jams/)\\r\\nin solving these problems.\\r\\n\\r\\nThe authors claim that their _CoDel_ (\\"coddle\\") algorithm is a \\"knob\\r\\nfree\\" algorithm. This is a bit of a lie really: there are two knobs\\r\\nand they do need setting appropriately. But they don\'t need changing\\r\\nevery time performance changes, which is a massive benefit. I have\\r\\n[implemented this algorithm](https://gist.github.com/2658712) for our\\r\\nAMQP Java Client as a variant of the QueueingConsumer. Whilst the\\r\\noriginal algorithm is aimed at the TCP layer, where it\'s valid to just\\r\\ndrop packets (TCP itself will take care\\r\\nof re-transmission of lost packets), in AMQP that\'s not so polite! As a result,\\r\\nmy implementation uses Rabbit\'s `basic.nack` extension to explicitly\\r\\nreturn messages to the queue so they can be processed by others.\\r\\n\\r\\n[Using it is pretty much the same](https://gist.github.com/2658727) as\\r\\nthe normal QueueingConsumer except that you should provide three extra\\r\\nparameters to the constructor to get the best performance.\\r\\n\\r\\n1. The first is `requeue` which says whether, when messages are\\r\\n   nacked, should they be requeued or discarded. If false, they will\\r\\n   be discarded which may trigger the dead letter exchange mechanisms\\r\\n   if they\'re set up.\\r\\n1. The second is the `targetDelay` which is the acceptable time in\\r\\n   milliseconds for messages to wait in the client-side QoS `prefetch`\\r\\n   buffer.\\r\\n1. The third is the `interval` and is the expected worst case\\r\\n   processing time of one message in milliseconds. This doesn\'t have\\r\\n   to be spot on, but within an order of magnitude certainly helps.\\r\\n\\r\\nYou should still set a QoS `prefetch` size appropriately. If you do\\r\\nnot, what is likely is that the client will be sent a lot of messages,\\r\\nand the algorithm will then have to return them to Rabbit if they sit\\r\\nin the buffer for too long. It\'s easy to end up with a lot of extra\\r\\nnetwork traffic as messages are returned to Rabbit. The CoDel\\r\\nalgorithm is meant to only start dropping (or rejecting) messages once\\r\\nperformance diverges from the norm, thus a worked example might help.\\r\\n\\r\\nAgain, assume network traversal time in each direction of 50ms, and we\\r\\nexpect the client to spend 4ms on average processing each message, but\\r\\nthis can spike to 20ms. We thus set the `interval` parameter of CoDel\\r\\nto 20. Sometimes the network halves in speed, so the traversal time\\r\\ncan be 100ms in each direction. To cater for that, we set the\\r\\n`basic.qos prefetch` to `204 / 4 = 51`. Yes, this means that the\\r\\nbuffer will remain 25 messages long most of the time when the network\\r\\nis running normally (see workings earlier), but we decide that\'s\\r\\nOK. Each message will thus sit in the buffer for an expected `25 * 4 =\\r\\n100ms`, so we set the `targetDelay` of CoDel to 100.\\r\\n\\r\\nWhen things are running normally, CoDel should not get in the way, and\\r\\nfew if any messages should be being nacked. But should the client\\r\\nstart processing messages more slowly than normal, CoDel will spot\\r\\nthat messages have been buffered by the client for too long, and will\\r\\nreturn those messages to the queue. If those messages are requeued\\r\\nthen they will become available for delivery to other clients.\\r\\n\\r\\nThis is very much experimental at the moment, and it\'s possible to see\\r\\nreasons why CoDel isn\'t as appropriate for dealing with AMQP messages\\r\\nas it is for plain IP. It\'s also worth remembering that requeuing\\r\\nmessages via nacks is a fairly expensive operation, so it\'s a good\\r\\nidea to set the parameters of CoDel to ensure in normal operation very\\r\\nfew if any messages are being nacked. The management plugin is an easy\\r\\nway to inspect how many messages are being nacked. As ever, comments,\\r\\nfeedback and improvements are most welcome!"},{"id":"/2012/04/25/rabbitmq-performance-measurements-part-2","metadata":{"permalink":"/rabbitmq-website/blog/2012/04/25/rabbitmq-performance-measurements-part-2","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-04-25-rabbitmq-performance-measurements-part-2/index.md","source":"@site/blog/2012-04-25-rabbitmq-performance-measurements-part-2/index.md","title":"RabbitMQ Performance Measurements, part 2","description":"Welcome back! Last time we talked about flow control and","date":"2012-04-25T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"}],"readingTime":6.135,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"RabbitMQ Performance Measurements, part 2","tags":["Performance"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Some queuing theory: throughput, latency and bandwidth","permalink":"/rabbitmq-website/blog/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth"},"nextItem":{"title":"London Realtime hackweekend","permalink":"/rabbitmq-website/blog/2012/04/17/london-realtime-hackweekend"}},"content":"Welcome back! [Last time](/blog/2012/04/16/rabbitmq-performance-measurements-part-1) we talked about flow control and\\r\\nlatency; today let\'s talk about how different features affect\\r\\nthe performance we see. Here are some simple scenarios. As\\r\\nbefore, they\'re all variations on the theme of one publisher and\\r\\none consumer publishing as fast as they can.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Some Simple Scenarios\\r\\n\\r\\n![](performance-01.png)\\r\\n\\r\\nThis first scenario is the simplest - just one producer and\\r\\none consumer. So we have a baseline.\\r\\n\\r\\n![](performance-02.png)\\r\\n\\r\\nOf course we want to produce impressive figures. So we can go\\r\\na bit faster than that - if we don\'t consume anything then we\\r\\ncan publish faster.\\r\\n\\r\\n![](performance-03.png)\\r\\n\\r\\nThis uses a couple of the cores on our server - but not all of\\r\\nthem. So for the best headline-grabbing rate, we start a\\r\\nnumber of parallel producers, all publishing into nothing.\\r\\n\\r\\n![](performance-04.png)\\r\\n\\r\\nOf course, consuming is rather important! So for the headline\\r\\nconsuming rate, we publish to a large number of consumers in\\r\\nparallel.\\r\\n\\r\\nOf course to some extent this quest for large numbers is a bit\\r\\nsilly, we\'re more interested in relative performance. So let\'s\\r\\nrevert to one producer and one consumer.\\r\\n\\r\\n![](performance-05.png)\\r\\n\\r\\nNow let\'s try publishing with the mandatory flag set. We drop\\r\\nto about 40% of the non-mandatory rate. The reason for this is\\r\\nthat the channel we\'re publishing to can\'t just asynchronously\\r\\nstream messages at queues any more; it synchronously checks\\r\\nwith the queues to make sure they\'re still there. (Yes, we\\r\\ncould probably make mandatory publishing faster, but it\'s not\\r\\nvery heavily used.)\\r\\n\\r\\n![](performance-06.png)\\r\\n\\r\\nThe immediate flag gives us almost exactly the same drop in\\r\\nperformance. This isn\'t hugely surprising - it has to make the\\r\\nsame synchronous check with the queue.\\r\\n\\r\\n![](performance-07.png)\\r\\n\\r\\nScrapping the rarely-used mandatory and immediate flags, let\'s\\r\\ntry turning on acknowledgements for delivered messages. We still\\r\\nsee a performance drop compared to delivering without\\r\\nacknowledgements (the server has to do more bookkeeping after\\r\\nall) but it\'s less noticeable.\\r\\n\\r\\n![](performance-08.png)\\r\\n\\r\\nNow we turn on publish confirms as well. Performance drops a\\r\\nlittle more but we\'re still at over 60% the speed of neither\\r\\nacks nor confirms.\\r\\n\\r\\n![](performance-09.png)\\r\\n\\r\\nFinally, we enable message persistence. The rate becomes much\\r\\nlower, since we\'re throwing all those messages at the disk as\\r\\nwell.\\r\\n\\r\\n## Message Sizes\\r\\n\\r\\nNotably, all the messages we\'ve been sending until now have only\\r\\nbeen a few bytes long. There are a couple of reasons for this:\\r\\n\\r\\n* Quite a lot of the work done by RabbitMQ is per-message, not\\r\\n    per-byte-of-message.\\r\\n* It\'s always nice to look at big numbers.\\r\\n\\r\\nBut in the real world we will often want to send bigger\\r\\nmessages. So let\'s look at the next chart:\\r\\n\\r\\n### 1 -> 1 sending rate message sizes\\r\\n\\r\\n![](performance-10.png)\\r\\n\\r\\nHere (again) we\'re sending unacked / unconfirmed messages as\\r\\nfast as possible, but this time we vary the message size. We\\r\\ncan see that (of course) the message rate drops further as the\\r\\nsize increases, but the actual number of bytes sent increases as\\r\\nwe have less and less routing overhead.\\r\\n\\r\\nSo how does the message size affect horizontal scaling? Let\'s\\r\\nvary the number of producers with different message sizes. Just\\r\\nfor a change, in this test we\'re not going to have any consumers\\r\\nar all.\\r\\n\\r\\n### n -> 0 sending msg rate vs number of producers, for various message sizes\\r\\n\\r\\n![](performance-11.png)\\r\\n\\r\\n### n -> 0 sending bytes rate vs number of producers, for various message sizes\\r\\n\\r\\n![](performance-12.png)\\r\\n\\r\\nIn these tests we can see that for small messages it only takes\\r\\na couple of producers to reach an upper bound on how many\\r\\nmessages we can publish, but that for larger messages we need\\r\\nmore producers to use the available bandwidth.\\r\\n\\r\\nAnother frequently confusing issue is performance around\\r\\nconsumers with a prefetch count. RabbitMQ (well, AMQP) defaults\\r\\nto sending all the messages it can to any consumer that looks\\r\\nready to accept them. The maximum number of these unacknowledged\\r\\nmessages per channel can be limited by setting the prefetch\\r\\ncount. However, small prefetch counts can hurt performance\\r\\n(since we can be waiting for acks to arrive before sending out\\r\\nmore messages).\\r\\n\\r\\nSo let\'s have a look at prefetch count and, while we\'re there,\\r\\nalso consider the number of consumers consuming from a single\\r\\nqueue. This chart contains some deliberately absurd extremes.\\r\\n\\r\\n### 1 -> n receiving rate vs consumer count / prefetch count\\r\\n\\r\\n![](performance-13.png)\\r\\n\\r\\nThe first thing to notice is that tiny prefetch counts really\\r\\nhurt performance. Note the large difference in performance\\r\\nbetween prefetch = 1 and prefetch = 2! But we also get into\\r\\ndiminishing returns - notice that the difference between\\r\\nprefetch = 20 and prefetch = 50 is hard to see, and the\\r\\ndifference between prefetch = 50 and prefetch = 10000 is almost\\r\\ninvisible. Of course, this is because for our particular network\\r\\nlink prefetch = 50 already ensures that we never starve the\\r\\nconsumer while waiting for acks. Of course, this test was run\\r\\nover a low latency link - more latent links will benefit from a\\r\\nhigher prefetch count.\\r\\n\\r\\nThe second thing to notice is that when we have a small number\\r\\nof consumers, adding one more will increase performance (we get\\r\\nmore parallellism). And with a tiny prefetch count, increasing\\r\\nconsumers even up to a large number has benefits (since each\\r\\nindividual consumer spends much of its time starved). But when\\r\\nwe have a larger prefetch count, increasing the number of\\r\\nconsumers is not so helpful, since even a small number can kept\\r\\nbusy enough to max out our queue, but the more consumers we have\\r\\nthe more work RabbitMQ has to do to keep track of all of them.\\r\\n\\r\\n## Large queues\\r\\n\\r\\nAll the examples we\'ve looked at so far have one thing in\\r\\ncommon: very few messages actually get queued. In general we\'ve\\r\\nlooked at scenarios where messages get consumed as quickly as\\r\\nthey get produced, and thus each queue has an average length of\\r\\n0.\\r\\n\\r\\nSo what happens whe queues get big? When queues are small(ish)\\r\\nthey will reside entirely within memory. Persistent messages\\r\\nwill also get written to disc, but they will only get read again\\r\\nif the broker restarts.\\r\\n\\r\\nBut when queues get larger, they will get paged to disc,\\r\\npersistent or not. In this case performance can take a hit as\\r\\nsuddenly we need to access the disc to send messages to\\r\\nconsumers. So let\'s run a test: publish a lot of non-persistent\\r\\nmessages to a queue, and then consume them all.\\r\\n\\r\\n### Queue load / drain 500k messages\\r\\n\\r\\n![](performance-14.png)\\r\\n\\r\\nIn this small case we can see fairly consistent performance:\\r\\nthe messages go into the queue fairly quickly and then come out\\r\\neven more quickly.\\r\\n\\r\\n### Queue load / drain 10M messages\\r\\n\\r\\n![](performance-15.png)\\r\\n\\r\\nBut when we have a larger queue we see that the performance\\r\\nvaries a lot more. We see that when loading the queue we\\r\\ninitially get a very high throughput, then a pause while some of\\r\\nthe queue is paged out to disc, then a more consistent lower\\r\\nthroughput. Similarly when draining the queue we see a much\\r\\nlower rate when pulling the messages from disc.\\r\\n\\r\\nPerformance of disc-bound queues is a complex topic -\\r\\nsee [Matthew\'s\\r\\nblog post on the subject](/blog/2011/10/27/performance-of-queues-when-less-is-more) for some more talk on the subject.\\r\\n\\r\\n## Learn More\\r\\n\\r\\n* Webinar: [What\'s new in RabbitMQ 3.8?](https://content.pivotal.io/webinars/may-23-what-s-new-in-rabbitmq-3-8-webinar?utm_campaign=rabbitmq-blog-3.8-webinar-q319&utm_source=rabbitmq&utm_medium=website)\\r\\n* Webinar: [10 Things Every Developer Using RabbitMQ Should Know](https://content.pivotal.io/webinars/dec-12-10-things-every-developer-using-rabbitmq-should-know-webinar?utm_campaign=rabbitmq-blog-10-things-q319&utm_source=rabbitmq&utm_medium=website)"},{"id":"/2012/04/17/london-realtime-hackweekend","metadata":{"permalink":"/rabbitmq-website/blog/2012/04/17/london-realtime-hackweekend","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-04-17-london-realtime-hackweekend/index.md","source":"@site/blog/2012-04-17-london-realtime-hackweekend/index.md","title":"London Realtime hackweekend","description":"Over the weekend, RabbitMQ co-sponsored London Realtime, two nights and two days of unadulterated hackery. It was all put on by the apparently indefatigable* crew at GoSquared, a very impressive debut effort.","date":"2012-04-17T00:00:00.000Z","tags":[],"readingTime":1.175,"hasTruncateMarker":true,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"London Realtime hackweekend","tags":[],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Performance Measurements, part 2","permalink":"/rabbitmq-website/blog/2012/04/25/rabbitmq-performance-measurements-part-2"},"nextItem":{"title":"RabbitMQ Performance Measurements, part 1","permalink":"/rabbitmq-website/blog/2012/04/16/rabbitmq-performance-measurements-part-1"}},"content":"Over the weekend, RabbitMQ co-sponsored [London Realtime](http://londonrealtime.co.uk), two nights and two days of unadulterated hackery. It was all put on by the apparently indefatigable<sup>[*](http://www.youtube.com/watch?v=p2EE7acJv1o&feature=player_embedded#t=120s)</sup> crew at [GoSquared](http://www.gosquared.com/), a very impressive debut effort.\\r\\n\\r\\n![](sockjs-rabbit-cf.png)\\r\\n\\r\\nAs a co-sponsor we had one of the iPad prizes to award. We decided to allow hacks that used one or more of [RabbitMQ](/), [SockJS](http://www.sockjs.org/), or [Cloud Foundry](http://www.cloudfoundry.com). This meant that about half of the twenty-seven hacks were eligible when it came to judging, making the choice rather difficult.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nIn the end we chose **[YouChoose](http://youchoose.cloudfoundry.com)**, which uses **SockJS** and is hosted on **CloudFoundry**. The idea was nifty, and the hack complete and well-executed; and it let one of the judges, who shall remain unnamed, subject the audience to the Titanic theme (until they worked out how to collectively vote it off). Empowering stuff.\\r\\n\\r\\nAll the hacks were imaginative and almost all made it to a working demo stage -- which was pretty amazing (or perhaps explained by) considering the lack of sleep some people were suffering on Sunday.\\r\\n\\r\\nAmong our favourites were: **Err**, microgames with location-based matchmaking (one of the games is \\"run away as fast as you can\\"); **The Worm**, a live popularity chart with optional rageface meter; and **Support Net**, a site and mobile app for people quitting smoking.\\r\\n\\r\\nFull coverage of the event is over on [GoSquared\'s blog](http://www.gosquared.com/liquidicity/archives/2873), including video footage and interviews.\\r\\n\\r\\n![Pusher.com are diversifying](pusherlondondry.jpg)"},{"id":"/2012/04/16/rabbitmq-performance-measurements-part-1","metadata":{"permalink":"/rabbitmq-website/blog/2012/04/16/rabbitmq-performance-measurements-part-1","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-04-16-rabbitmq-performance-measurements-part-1/index.md","source":"@site/blog/2012-04-16-rabbitmq-performance-measurements-part-1/index.md","title":"RabbitMQ Performance Measurements, part 1","description":"So today I would like to talk about some aspects of RabbitMQ\'s","date":"2012-04-16T00:00:00.000Z","tags":[{"inline":true,"label":"Performance","permalink":"/rabbitmq-website/blog/tags/performance"},{"inline":true,"label":"Introductory","permalink":"/rabbitmq-website/blog/tags/introductory"}],"readingTime":5.85,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"RabbitMQ Performance Measurements, part 1","tags":["Performance","Introductory"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"London Realtime hackweekend","permalink":"/rabbitmq-website/blog/2012/04/17/london-realtime-hackweekend"},"nextItem":{"title":"How to compose apps using WebSockets","permalink":"/rabbitmq-website/blog/2012/02/23/how-to-compose-apps-using-websockets"}},"content":"So today I would like to talk about some aspects of RabbitMQ\'s\\r\\nperformance. There are a huge number of variables that feed into\\r\\nthe overall level of performance you can get from a RabbitMQ\\r\\nserver, and today we\'re going to try tweaking some of them and\\r\\nseeing what we can see.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThe aim of this piece is not to try to convince you that\\r\\nRabbitMQ is the fastest message broker in the world - it often\\r\\nisn\'t (although we like to think we\'re still pretty decent) -\\r\\nbut to give you some ideas about what sort of performance you\\r\\ncan expect in different situations.\\r\\n\\r\\nAll the charts and statistics shown were measured on a PowerEdge\\r\\nR610 with dual Xeon E5530s and 40GB RAM. Largely because it was\\r\\nthe fastest machine we had lying around. One major thing that\'s\\r\\nnot ideal is we ran the clients on the same machine as the\\r\\nserver - just due to the limited hardware we had available. We used\\r\\nRabbitMQ 2.8.1 (in most cases) and Erlang R15B with HiPE compilation\\r\\nenabled.\\r\\n\\r\\nBy the way, the code to produce all these statistics\\r\\nis available in branch bug24527 of rabbitmq-java-client\\r\\n(although it\'s currently rather rough) Eventually it will get\\r\\nmerged to default, and also become easier to work with. We hope.\\r\\n\\r\\n## Flow control in RabbitMQ 2.8.0+\\r\\n\\r\\nBut first of all I need to introduce a new feature in RabbitMQ\\r\\n2.8.0+ - internal flow control. RabbitMQ is internally made up of\\r\\na number of Erlang processes which pass messages to each\\r\\nother. Each process has a *mailbox* which contains\\r\\nmessages it has received and not yet handled. And these\\r\\nmailboxes can grow to an unbounded size.\\r\\n\\r\\nWhat this means is that unless the first process to receive data\\r\\noff a network socket is the slowest in the chain, (it\'s not)\\r\\nthen when you have a heavily-loaded RabbitMQ server messages can\\r\\nbuild up in process mailboxes forever. Or rather, until we run\\r\\nout of memory. Or rather, until the memory alarm goes off. At\\r\\nwhich point the server will stop accepting new messages while it\\r\\nsorts itself out.\\r\\n\\r\\nThe trouble is, this can take some time. The following chart\\r\\n(the only one in this post made against RabbitMQ 2.7.1) shows a\\r\\nsimple process that publishes small messages into the broker as\\r\\nfast as possible, and also consumes them as fast as possible,\\r\\nwith acknowledgement, confirms, persistence and so on all\\r\\nswitched off. We plot the sending rate, the receiving rate, and\\r\\nthe latency (time taken for a sent message to be received), over\\r\\ntime. Note that the latency is a logarithmic scale.\\r\\n\\r\\n### Simple 1 -> 1 autoack (2.7.1)\\r\\n\\r\\n![](performance-01-01.png)\\r\\n\\r\\nOuch! That\'s rather unpleasant. Several things should be obvious:\\r\\n\\r\\n* The send rate and receive rate fluctuate quite a lot.\\r\\n* The send rate drops to zero for two minutes (this is the\\r\\nfirst time the memory alarm went off). In fact the memory alarm\\r\\ngoes off again at the end.\\r\\n* The latency increases steadily (and look at the scale - we\\r\\nshow microseconds, but we could just as easily measure it in\\r\\nminutes).\\r\\n\\r\\n(The small drop in latency around 440s is due to all the\\r\\nmessages published before 200s being consumed, and the long gap\\r\\nafterwards.)\\r\\n\\r\\nOf course, this is only the sort of behaviour you would expect\\r\\nwhen stressing a server to the limit. But we\'re benchmarking -\\r\\nwe want to do that. And anyway, servers get stressed in\\r\\nproduction too.\\r\\n\\r\\nSo now let\'s look at the same experiment conducted against a\\r\\nRabbitMQ 2.8.1 server:\\r\\n\\r\\n### Simple 1 -> 1 autoack (2.8.1)\\r\\n\\r\\n![](performance-01-02.png)\\r\\n\\r\\nThat looks like a much calmer experience! The send rate, receive\\r\\nrate and latency are all near-constant. The reason is internal\\r\\nflow control. The latency is around 400ms (which is still quite\\r\\nhigh compared to a less loaded server for reasons I\'ll discuss\\r\\nin a minute).\\r\\n\\r\\nThese charts don\'t show memory consumption, but the story is the\\r\\nsame - in this circumstance 2.7.1 will eat lots of memory and\\r\\nbounce off the memory alarm threshold, and 2.8.1 will use a\\r\\nfairly constant, fairly low quantity of memory.\\r\\n\\r\\nEach process in the chain issues *credit* to the\\r\\nprocesses that can send messages to it. Processes consume credit\\r\\nas they send messages, and issue more credit as they receive\\r\\nthem. When a process runs out of credit it will stop issuing\\r\\nmore to its upstream processes. Eventually we reach the process\\r\\nwhich is reading bytes off a network\\r\\nsocket. When **that** process runs out of credit,\\r\\nit stops reading until it gets more. This is the same as when\\r\\nthe memory alarm goes off for the 2.7.1 broker, except that it\\r\\nhappens many times per second rather than taking minutes, and we\\r\\ncontrol memory use a lot more.\\r\\n\\r\\nSo where does that 400ms latency come from? Well, there are\\r\\nstill messages queueing up at each stage in the pipeline, so it\\r\\ntakes a while for a message to get from the beginning to the\\r\\nend. That accounts for some of the latency. However, most of it\\r\\ncomes from an invisible \\"mailbox\\" in front of the entire server\\r\\n- the TCP buffers provided by the operating system. On Linux\\r\\nthe OS will allow up to 8MB of messages to back up in the TCP\\r\\nstack. 8MB doesn\'t sound like a lot of course, but we\'re dealing\\r\\nwith tiny messages (and each one needs routing decisions,\\r\\npermissions check and so on to be made).\\r\\n\\r\\nBut it\'s important to remember that we tend to see the worst\\r\\nlatency when running at the limit of what we can do. So here\'s\\r\\none final chart for this week:\\r\\n\\r\\n### 1 -> 1 sending rate attempted vs latency\\r\\n\\r\\n![](performance-01-03.png)\\r\\n\\r\\nNote that the horizontal axis is no longer time. We\'re now\\r\\nshowing the results of many runs like the ones above, with each\\r\\npoint representing one run.\\r\\n\\r\\nIn the charts above we were running as fast as we can, but here\\r\\nwe limit the rate at varying points up to the maximum rate we\\r\\ncan achieve. So the yellow line shows rate attempted vs rate\\r\\nachieved - see that it goes most of the way purely 1:1 linearly\\r\\n(when we have spare capacity and so if we try to publish faster\\r\\nwe will succeed) and then stops growing as we reach the limit of\\r\\nwhat we can do.\\r\\n\\r\\nBut look at the latency! With low publishing rates we have\\r\\nlatency of considerably less than a millisecond. But this drifts\\r\\nup as the server gets busier. As we stop being able to publish\\r\\nany faster, we hit a wall of latency - the TCP buffers start to\\r\\nfill up and soon messages are taking hundreds of milliseconds to\\r\\nget through them.\\r\\n\\r\\nSo hopefully we\'ve shown how RabbitMQ 2.8.1 offers much more\\r\\nreliable performance when heavily loaded than previous versions,\\r\\nand shown how latency can reach for the skies when your message\\r\\nbroker is overloaded. Tune in next time to see how some\\r\\ndifferent ways of using messaging affect performance!"},{"id":"/2012/02/23/how-to-compose-apps-using-websockets","metadata":{"permalink":"/rabbitmq-website/blog/2012/02/23/how-to-compose-apps-using-websockets","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-02-23-how-to-compose-apps-using-websockets/index.md","source":"@site/blog/2012-02-23-how-to-compose-apps-using-websockets/index.md","title":"How to compose apps using WebSockets","description":"Or: How to properly do multiplexing on WebSockets or on SockJS","date":"2012-02-23T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"}],"readingTime":3.6,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"How to compose apps using WebSockets","tags":["Web Messaging"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"RabbitMQ Performance Measurements, part 1","permalink":"/rabbitmq-website/blog/2012/04/16/rabbitmq-performance-measurements-part-1"},"nextItem":{"title":"AtomizeJS: Distributed Software Transactional Memory","permalink":"/rabbitmq-website/blog/2012/02/21/atomizejs-distributed-software-transactional-memory"}},"content":"*Or: How to properly do multiplexing on WebSockets or on SockJS*\\r\\n\\r\\n![](HTML5_Logo_256.png)\\r\\n\\r\\nAs you may know, WebSockets are a cool new HTML5 technology which\\r\\nallows you to asynchronously send and receive messages. Our\\r\\ncompatibility layer - [SockJS](http://sockjs.org) - emulates it and\\r\\nwill work even on old browsers or behind proxies.\\r\\nWebSockets conceptually are very simple. The API is basically:\\r\\nconnect, send and receive. But what if your web-app has many modules\\r\\nand every one wants to be able to send and receive data?\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nIn theory you could open multiple WebSocket connections, one for every\\r\\nmodule. Although suboptimal (due to the need to handle multiple TCP/IP\\r\\nconnections), this approach will work for native WebSockets. But,\\r\\nunfortunately it won\'t for SockJS due to a technical limitation of\\r\\nHTTP: for some fallbacks transports it is not possible to open more\\r\\nthan one connection at a time to a single server.\\r\\nThis problem is real and worth solving. Let me rephrase it:\\r\\n\\r\\n> Assuming you can have only a single connection to a given host, and multiple modules wanting to send and receive data, what do you do?\\r\\n\\r\\nYou need [multiplexing](http://en.wikipedia.org/wiki/Multiplexing):\\r\\ncombining data from multiple sources into a single connection. The\\r\\nnext question is what API do you use; how do you expose multiplexing\\r\\nin the code?\\r\\n\\r\\n## The Socket.io way\\r\\n\\r\\nSocket.io has an API that attempts to solve this problem, it calls\\r\\nthis \'namespaces\'. Here\'s some example client (browser) code:\\r\\n\\r\\n```javascript\\r\\nvar chat = io.connect(\'http://localhost/chat\');\\r\\nchat.on(\'connect\', function () {\\r\\n  chat.emit(\'hi!\');\\r\\n});\\r\\n\\r\\nvar news = io.connect(\'http://localhost/news\');\\r\\nnews.on(\'news\', function () {\\r\\n  news.emit(\'woot\');\\r\\n});\\r\\n```\\r\\n\\r\\nI think this API is quite confusing - under the hood Socket.io is\\r\\nopening only a single connection, but reading the code gives us a\\r\\ndifferent story.\\r\\n\\r\\n## The SockJS way\\r\\n\\r\\nAs opposed to Socket.io, SockJS doesn\'t have any magical API. It looks\\r\\nlike a WebSocket object, it behaves like one. Nothing surprising.\\r\\n\\r\\nSo how to solve the multiplexing problem?\\r\\n\\r\\nIt\'s usually a good idea to avoid inventing new APIs if possible, by\\r\\nusing already established ones. Why not present each multiplexed\\r\\nchannel as a WebSocket object?\\r\\n\\r\\nWhat I\'m suggesting is quite simple - you take a real SockJS (or\\r\\nWebSocket) connection, wrap it in a multiplexing layer, and extract\\r\\nany number of fake WebSocket objects out of it. They will be\\r\\nmultiplexed internally, but from a module point of view - it will be\\r\\ncompletely transparent. The module speaks to a WebSocket object as far as\\r\\nit is concerned.\\r\\n\\r\\nThat\'s it. It\'s a bit like a magician\'s hat. You put one WebSocket\\r\\nconnection in, you can take any number of fake WebSocket connections\\r\\nout.\\r\\n\\r\\nThis approach is better than what Socket.io proposes - you can create\\r\\ncode that just relies on a native WebSocket API. Later on, when the\\r\\nneed arises, you can just pass a fake WebSocket object instead of real\\r\\none. In other words: it composes. Problem solved.\\r\\n\\r\\n## Implementation\\r\\n\\r\\nIf previously in the browser you were using a single SockJS\\r\\nconnection, like this:\\r\\n\\r\\n```javascript\\r\\nvar sockjs = new SockJS(\'/echo\');\\r\\n```\\r\\n\\r\\nYou can modify the client code to:\\r\\n\\r\\n```javascript\\r\\nvar real_sockjs = new SockJS(\'/echo\');\\r\\n\\r\\nvar multiplexer = new WebSocketMultiplex(real_sockjs);\\r\\nvar fake_sockjs_1 = multiplexer.channel(\'ann\');\\r\\nvar fake_sockjs_2 = multiplexer.channel(\'bob\');\\r\\n```\\r\\n\\r\\nAt this point \'fake\' objects will behave identically to a normal\\r\\nSockJS object. You can expect to hear \'open\', \'message\' and \'close\'\\r\\nevents.\\r\\n(The underlying code is\\r\\n[about 60 lines of javascript](https://github.com/sockjs/websocket-multiplex/blob/master/multiplex_client.js))\\r\\nSimilarly the server side - it normally uses the usual \\"net.Server\\" and\\r\\n\\"Stream\\" node APIs:\\r\\n\\r\\n```javascript\\r\\nvar service = sockjs.createServer();\\r\\n```\\r\\n\\r\\nAfter a change:\\r\\n\\r\\n```javascript\\r\\nvar real_service = sockjs.createServer();\\r\\n\\r\\nvar multiplexer = new multiplex_server.MultiplexServer(real_service);\\r\\nvar fake_service_1 = multiplexer.registerChannel(\'ann\');\\r\\nvar fake_service_2 = multiplexer.registerChannel(\'bob\');\\r\\n```\\r\\n\\r\\nAgain \'fake\' objects will do the usual thing, they will emit a\\r\\n\'connected\' event when a user subscribed to this particular channel\\r\\narrives.\\r\\n(The underlying multiplexer code\\r\\n[is not very complex either](https://github.com/sockjs/websocket-multiplex/blob/master/multiplex_server.js))\\r\\n\\r\\nIf you want to see the multiplexer code in action:\\r\\n\\r\\n* [Server snippet](https://github.com/sockjs/websocket-multiplex/blob/master/examples/sockjs/server.js#L13-36)\\r\\n* [Client snippet](https://github.com/sockjs/websocket-multiplex/blob/master/examples/sockjs/index.html#L85-92)\\r\\n* Live code: [http://sockjs-multiplex.cloudfoundry.com/](http://sockjs-multiplex.cloudfoundry.com/)\\r\\n\\r\\n## Final thoughts\\r\\n\\r\\nIt\'s worth emphasising that this approach really does compose. Any module\\r\\ncan take a fake WebSocket object and repeat the trick to get more\\r\\nsecond-layer fake WebSockets objects.\\r\\nInstead of inventing new API\'s, just create code that relies on a\\r\\nWebSocket instance passed to the constructor. That\'ll all you really\\r\\nneed to create composable code using WebSockets!"},{"id":"/2012/02/21/atomizejs-distributed-software-transactional-memory","metadata":{"permalink":"/rabbitmq-website/blog/2012/02/21/atomizejs-distributed-software-transactional-memory","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-02-21-atomizejs-distributed-software-transactional-memory/index.md","source":"@site/blog/2012-02-21-atomizejs-distributed-software-transactional-memory/index.md","title":"AtomizeJS: Distributed Software Transactional Memory","description":"AtomizeJS is a JavaScript library for writing distributed programs, that run in the browser, without having to write any application specific logic on the server.","date":"2012-02-21T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"},{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"}],"readingTime":2.38,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"AtomizeJS: Distributed Software Transactional Memory","tags":["Web Messaging","Programming Languages"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"How to compose apps using WebSockets","permalink":"/rabbitmq-website/blog/2012/02/23/how-to-compose-apps-using-websockets"},"nextItem":{"title":"SockJS 0.2 released!","permalink":"/rabbitmq-website/blog/2012/01/24/sockjs-0-2-released"}},"content":"**[AtomizeJS](http://atomizejs.github.com/) is a JavaScript library for writing distributed programs, that run in the browser, without having to write any application specific logic on the server.**\\r\\n\\r\\nHere at RabbitMQ HQ we spend quite a lot of time arguing. Occasionally, it\'s about important things, like what *messaging* really means, and the range of different APIs that can be used to achieve *messaging*. RabbitMQ and AMQP present a very explicit interface to messaging: you very much have verbs *send* and *receive* and you need to think about what your messaging patterns are. There\'s a lot (of often quite clever stuff) going on under the bonnet but nevertheless, the interface is quite low-level and explicit, which gives a good degree of flexibility. Sometimes though, that style of API is not the most natural fit for the problem you\'re trying to solve - do you really reach an impasse and think \\"What I need here is an AMQP-message broker\\", or do you, from pre-existing knowledge, realise that you could choose to use an AMQP-message broker to solve your current problem?\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n[AtomizeJS](http://atomizejs.github.com/getting_started.html) exists at the opposite end of the spectrum. There is lots of messaging involved, but you almost never get to see any of it. Instead, you write transactions in JavaScript that modify objects, and those objects are shared between all clients that are connected to the same AtomizeJS server. The [API](http://atomizejs.github.com/api.html) that you\'re given lets you do slightly more powerful things than you\'re used to from database transactions, in particular, `retry` allows you to abort a transaction but then restart it automatically once someone else has changed one of the variables you read. This means you have the observer-pattern, and from that you can then build any explicit messaging patterns you want. In most cases, I doubt you\'ll be building APIs that say *send* or *receive*, instead you\'ll be building richer data-structures - work queues, shared dictionaries etc. The question to pose then is: is it easier to build these things based on top of a transaction-like API such as offered by AtomizeJS, or on top of an explicit messaging API such as offered by RabbitMQ and AMQP brokers. There is no one solution and horses-for-courses etc, but please leave your thoughts below.\\r\\n\\r\\nThe gain that AtomizeJS provides is not so much in the use of STM from the browser, but the use of STM against a distributed object. This allows you to trivially share state between browsers, modify it safely in intuitive terms, and thus build your applications with little or no application-specific server-side code. Currently, it\'s a little clunky to use with browsers that don\'t support bleeding-edge JavaScript features (though I\'ve provided some tooling to try and mitigate this), and everything does work with the latest versions of Chrome, Firefox, IE, Safari, and Opera. Please [have a go](http://atomizejs.github.com/getting_started.html) and [let us know](http://atomizejs.github.com/contact.html) what you think!"},{"id":"/2012/01/24/sockjs-0-2-released","metadata":{"permalink":"/rabbitmq-website/blog/2012/01/24/sockjs-0-2-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2012-01-24-sockjs-0-2-released/index.md","source":"@site/blog/2012-01-24-sockjs-0-2-released/index.md","title":"SockJS 0.2 released!","description":"SockJS version 0.2 has been released:","date":"2012-01-24T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"}],"readingTime":0.59,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"SockJS 0.2 released!","tags":["Web Messaging"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"AtomizeJS: Distributed Software Transactional Memory","permalink":"/rabbitmq-website/blog/2012/02/21/atomizejs-distributed-software-transactional-memory"},"nextItem":{"title":"RabbitMQ 2.7.0 and 2.7.1 are released","permalink":"/rabbitmq-website/blog/2011/12/20/rabbitmq-2-7-0-and-2-7-1-are-released"}},"content":"![](sockjs-logo.png)\\r\\n\\r\\nSockJS version 0.2 has been released:\\r\\n\\r\\n* [https://groups.google.com/group/sockjs/browse_thread/thread/79893c8545c49f06](https://groups.google.com/group/sockjs/browse_thread/thread/79893c8545c49f06)\\r\\n\\r\\nYou can test it in the usual playground:\\r\\n\\r\\n* [http://sockjs.popcnt.org/example-cursors.html](http://sockjs.popcnt.org/example-cursors.html)\\r\\n* [http://sockjs.cloudfoundry.com/tests-qunit.html](http://sockjs.cloudfoundry.com/tests-qunit.html)\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nApart from ton of general updates and few API tweaks, SockJS 0.2\\r\\ncontains two major features:\\r\\n\\r\\n* Faster connection times - due to a better fallback-detection algorithm.\\r\\n* Raw websocket api - should make it easier to write command line clients for SockJS.\\r\\n\\r\\nThat means two out of three updates to SockJS protocol [I proposed\\r\\nabout a month ago are done](https://groups.google.com/group/sockjs/browse_thread/thread/cd2b468d312bd5e1). The last major feature remaining is\\r\\nbinary data support.\\r\\nUnfortunately [the releases rarely go smoothly](https://groups.google.com/group/sockjs/browse_thread/thread/4b0f3d426223ac0d), but thanks to\\r\\nalert SockJS users the problem was quickly spotted and fixed.\\r\\nSo, happy playing with [SockJS](http://sockjs.org)!"},{"id":"/2011/12/20/rabbitmq-2-7-0-and-2-7-1-are-released","metadata":{"permalink":"/rabbitmq-website/blog/2011/12/20/rabbitmq-2-7-0-and-2-7-1-are-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-12-20-rabbitmq-2-7-0-and-2-7-1-are-released/index.md","source":"@site/blog/2011-12-20-rabbitmq-2-7-0-and-2-7-1-are-released/index.md","title":"RabbitMQ 2.7.0 and 2.7.1 are released","description":"The previous release of RabbitMQ (2.7.0) brought with it a better way of managing plugins, one-stop URI connecting by clients, thread-safe consumers in the Java client, and a number of performance improvements and bug-fixes. The latest release (2.7.1) is essentially a bug-fix release; though it also makes RabbitMQ compatible with Erlang R15B and enhances some of the management interface. The previous release didn\'t get a blog post, so I\'ve combined both releases in this one.  (These are my own personal remarks and are NOT binding; errors of commission or omission are entirely my own -- Steve Powell.)","date":"2011-12-20T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":8.665,"hasTruncateMarker":true,"authors":[{"name":"Steve Powell","key":"Zteve","page":null}],"frontMatter":{"title":"RabbitMQ 2.7.0 and 2.7.1 are released","tags":["New Features"],"authors":["Zteve"]},"unlisted":false,"prevItem":{"title":"SockJS 0.2 released!","permalink":"/rabbitmq-website/blog/2012/01/24/sockjs-0-2-released"},"nextItem":{"title":"Ponies, Dragons and Socks","permalink":"/rabbitmq-website/blog/2011/11/30/ponies-dragons-and-socks"}},"content":"The [previous release of RabbitMQ](http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2011-November/016069.html) (2.7.0) brought with it a better way of managing plugins, one-stop URI connecting by clients, thread-safe consumers in the Java client, and a number of performance improvements and bug-fixes. The [latest release](http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2011-December/016941.html) (2.7.1) is essentially a bug-fix release; though it also makes RabbitMQ compatible with Erlang R15B and enhances some of the management interface. The previous release didn\'t get a blog post, so I\'ve combined both releases in this one.  (These are my own personal remarks and are NOT binding; errors of commission or omission are entirely my own -- Steve Powell.)\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## plugins\\r\\n\\r\\nPrior to 2.7.0 if you wanted to use a plugin then a `.ez` file was placed in the `plugins` directory, and the broker restarted. Any plugin found in this directory was installed on startup.  This meant two things: plugins weren\'t supplied with the server (even our supported ones), and installing or uninstalling a plugin involved moving files about *and* ensuring other plugin dependencies were installed. Administration of plugins was unnecessarily messy.\\r\\n\\r\\nIn 2.7.0, we introduced a command `rabbitmq-plugins`, to enable or disable any plugin in the `plugins` directory. Simply issue the command `rabbitmq-plugins list` to see what plugin files are there, and `rabbitmq-plugins enable <plugin-name>` to use one the next time the broker starts. No files need to be moved around -- they can stay in the plugins directory all the time -- and all the rabbit plugins are now supplied with the server, disabled by default.  The command also understands which plugins depend upon which others, and enables dependencies automatically. Using and managing plugins is now much easier. See [the plugins page](/docs/plugins) for more.\\r\\n\\r\\nIn 2.7.1 there is a fix to the `consistent-hash-exchange` plugin which mis-routed messages when handling multiple exchanges.\\r\\n\\r\\n## connect by URI\\r\\n\\r\\nAll of the rabbit clients (.NET, Java and Erlang) clients accept an `amqp` URI scheme for connections. This is a convenient *one-stop shop* allowing the username and password, hostname and port, and virtual host, to be supplied by a single URI or String parameter. For example:\\r\\n\\r\\n```plaintext\\r\\namqp://guest:ghost@rabbit01.coderus.moc:5672/vhost01\\r\\n```\\r\\n\\r\\nSee the individual client APIs for details.\\r\\n\\r\\n## Java threads\\r\\n\\r\\nIn Release 2.7.0 the threading structure of the Java client has been significantly redesigned. Before this release there were restrictions in what could be done in the Java client\'s `Consumer` callback methods, and also on which application threads can call `Channel` methods. These have been due to the underlying threading structure of the Java client which shared the channel thread with the callbacks. Locks on the channel and connection objects meant that calling `Channel` methods directly from the `Consumer` resulted in deadlocks (with a few exceptions, like acknowledgements). The `QueueingConsumer` helper class was made available to isolate applications from some of these issues, at the cost of introducing another queue (in the Java client).\\r\\n\\r\\nWith the new threading structure, there are far fewer restrictions upon which application threads can call channel operations, because all `Consumer` callbacks are executed on threads which are separate from the channel. In fact, it is now possible to configure the connection to manage a pool of threads used specifically for callbacks  preserving the order of execution of these within each channel. Simple client applications can take the default which provides a small pool of callback threads and sophisticated clients can provide their own `ExecutorService` object, which allows them to create and manage the size and behaviour of the thread pool themselves. `QueueingConsumer` is now no longer necessary, for everything one would want to do as a result of a `Consumer` callback can be done in the `Consumer` method directly, without deadlocks.  See the [Java API Guide](/client-libraries/java-api-guide) for more.\\r\\n\\r\\n2.7.1 fixed a few irritations in the Java Client adjustments in 2.7.0: we inadvertently hid some of the API, and this has now been restored. There were also some potential resource leaks which we have now fixed.\\r\\n\\r\\n## performance\\r\\n\\r\\nA number of small performance improvements have been made to the server in both 2.7.0 and 2.7.1. These have been quite varied in scope, and I can only touch on some of them here.\\r\\n\\r\\n* In the first place, basic file I/O has been improved by the simple expedient of using lower-level basic file operations. This has allowed certain operations to occur in parallel that were previously serialised through an Erlang process. This results in removing some bottlenecks, and slightly speeds up several areas, including server shutdown.\\r\\n* An area of intense I/O, interestingly unaffected by the tweak above, is what is known as the \'message store\'. This is, unsurprisingly, where messages are stored (stored for various reasons, not only message persistence). Rather than using a conventional database, RabbitMQ manages its own file storage for messages.  (A conventional database has almost the entirely wrong performance profile for queueing -- the most recently used items are likely to be the ones accessed last.)  The messages store is one of the most sophisticated parts of the server because it needs to respond very quickly without gating the rest of the system by the relatively slow I/O operations it performs. It behaves something like a paging system cache, in that while messages are waiting to be written they can potentially be \'stolen\' from the write list if they are subsequently read, rewritten or even deleted. The \'overtaking\' rules are quite different from those of a paging system, however, and in this release, the organisation was changed to allow some deletes to \'cancel\' store requests which hadn\'t yet occurred. This results in reducing unnecessary writes and therefore higher overall throughput for every queue. Extensive tests have shown an improvement in performance with preserved reliability, even under load.\\r\\n* There was sub-optimal treatment of a connection with a large number of consumers, especially if they were of low utilisation. There appeared to be an overhead for consumers that were relatively inactive. In 2.7.0 this has been improved, which means that having lots of low-use consumers has far less of an impact on overall performance.\\r\\n* Deletion of queues with a large number of bindings and exchanges with a large number of bindings took rather longer than we would have liked. This has been speeded up in 2.7.1.\\r\\n\\r\\n## HiPE option\\r\\n\\r\\nErlang offers a High Performance compiler (HiPE) for some platforms whereby Erlang modules can be compiled to native code. This compilation does not always produce a faster system, however, and is not supported by all Erlang environments and versions. In 2.7.0 we introduced a [configuration option](/docs/configure) to use HiPE, and a re-compilation is performed automatically at server startup. Not every rabbit module is re-compiled only those that we have determined may benefit from this treatment. Although this option delays startup by some tens of seconds, it produces significant performance improvements at runtime which may be crucial for some larger rabbit installations.\\r\\n\\r\\nThis option is *disabled* by default, since it may actually affect behaviour (not that we have detected this), and the performance improvements are not tested on all the environments our users employ. However, if it works for you, go for it. If your Erlang environment does not support HiPE, there is a brief diagnostic message and the option is ignored.\\r\\n\\r\\nWe would be very interested in your experiences with this feature.\\r\\n\\r\\n## re-queued messages\\r\\n\\r\\nRabbitMQ deals with FIFO queues. If all goes well, the order the messages are put on a queue is the same as the order they are consumed. When a consumer fails, however, some of the messages it received may not have been acknowledged, and in this case these messages are re-queued so that they may be delivered again. In this way messages may appear to be re-ordered. Before this release, there was no guarantee of the order of re-queued messages.\\r\\n\\r\\nFrom 2.7.0 the relative order *of re-queued messages from a single consumer* is preserved. Therefore, if another consumer receives them later, they will be consumed in the same order they originally appeared. Of course, if two or more consumers on the same queue fail, there is no guarantee that messages re-queued by *distinct* consumers will retain their relative order. But in the majority of cases where order matters, this guarantee should be enough.\\r\\n\\r\\n## high availability problems\\r\\n\\r\\nA number of fixes for high availability features (mostly introduced in 2.7.0) were included in 2.7.1. These relate to some memory leaks; recovery of master queues; frequent restarting causing HA queues to fail; and promotion of slaves (to master) failing under some circumstances.  The general quality of this code area is high, but the complex nature of the failure scenarios (which this feature is specifically designed to protect against) makes it a fruitful one for bugs to lurk. Nearly all the bugs fixed in 2.7.1 are due to rare or obscure combinations of recovery or restart events, and we confidently expect there to be few surprises left. Of course, High Availability doesn\'t mean Guaranteed Availability, so there are going to be situations from which we cannot recover.\\r\\n\\r\\n## other small improvements and bug fixes\\r\\n\\r\\n* If you ran a broker for a very long time it was possible to wrap one of the internal GUIDs (Globally Unique IDentifiers). Clearly this was not intended, and in any case it can\'t cause a problem in practice can it?  Well it did!  (Wouldn\'t you know it -- some people run brokers for a very long time!) We\'ve fixed it in 2.7.1.\\r\\n* The management plugin interface now displays a bit more information about queue lengths and shovel information is presented a little more nicely, plus there were a number of small problems with statistics and HA slave information that are now fixed.\\r\\n* `rabbitmqctl eval <expr>` is new (in 2.7.1) to evaluate an arbitrary Erlang expression in the broker node.\\r\\n* .net client session autoclose could sometimes return an AlreadyClosed exception (it is supposed not to do this).\\r\\n* The STOMP adapter didn\'t support reply-to queues properly (they weren\'t re-usable), and could supply multiple message-id headers on a MESSAGE frame if the SEND frame supplied one. We now check for this latter condition and reject the SEND.\\r\\n* Some functions used which are no longer in Erlang R15B have been removed (and the code rewritten), so that RabbitMQ should now build and run under the latest Erlang Release. Let us know if not!\\r\\n\\r\\n## thank you for listening\\r\\n\\r\\nAs usual, the rabbit team welcome feedback of your experiences, good or bad. We encourage you to use the [rabbitmq-discuss](https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss) mailing list."},{"id":"/2011/11/30/ponies-dragons-and-socks","metadata":{"permalink":"/rabbitmq-website/blog/2011/11/30/ponies-dragons-and-socks","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-11-30-ponies-dragons-and-socks/index.md","source":"@site/blog/2011-11-30-ponies-dragons-and-socks/index.md","title":"Ponies, Dragons and Socks","description":"We were wondering how to present SockJS and its possibilities to a","date":"2011-11-30T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"}],"readingTime":1.47,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"Ponies, Dragons and Socks","tags":["Web Messaging"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 2.7.0 and 2.7.1 are released","permalink":"/rabbitmq-website/blog/2011/12/20/rabbitmq-2-7-0-and-2-7-1-are-released"},"nextItem":{"title":"Performance of Queues: when less is more","permalink":"/rabbitmq-website/blog/2011/10/27/performance-of-queues-when-less-is-more"}},"content":"We were wondering how to present SockJS and its possibilities to a\\r\\nwider audience. Having a working demo is worth much more than\\r\\nexplaining [dry theory](/blog/2011/09/13/sockjs-websocket-emulation),\\r\\nbut what can you present if you are just a boring technologist, with\\r\\nno design skills whatsoever?\\r\\n\\r\\nWith questions like that it\'s always good to open a history book\\r\\nand review previous generation of computer geeks with no artistic\\r\\nskills. What were they doing? On consoles with green letters\\r\\nthey were playing geeky computer games,\\r\\n[MUDs (Multi User Dungeons)](http://en.wikipedia.org/wiki/MUD) were\\r\\nespecially popular.\\r\\n\\r\\nHey, we can do that!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n![](squirrel_tales.png)\\r\\n\\r\\nSo here it is, a rough and dirty, hacked together in an afternoon MUD!\\r\\nBut it aint a normal MUD, it\'s a unique one:\\r\\n\\r\\n* The world isn\'t exactly large, with five locations and 6 commands\\r\\n   in total.\\r\\n* But it\'s an in-browser game, using [SockJS](http://sockjs.org) underneath.\\r\\n* It\'s built using Django, and the state is handled using Django ORM.\\r\\n\\r\\nSo, forget the 21st century and dive into an ancient world of dragons,\\r\\nat least for a few minutes:\\r\\n\\r\\n* [http://mud.sockjs.org](http://mud.sockjs.org)\\r\\n\\r\\nIf you\'re interested in technology feel free\\r\\n[to take a look at the sources](https://github.com/sockjs/sockjs-mud). Also,\\r\\nas the project is using Django ORM you can add new locations using\\r\\n[Django Admin](http://mud.sockjs.org/admin) (user: guest, pass:\\r\\nguest). Unleash your creativity! Unfortunately there isn\'t a simple\\r\\nway of restricting Django Admin users, so you can\'t see what you\\r\\nadded. You may also want to take a look at the\\r\\n[initial database fixture](https://github.com/sockjs/sockjs-mud/blob/master/mud/initial_data.json).\\r\\n\\r\\nHere\'s a diagram illustrating the architecture of this demo:\\r\\n\\r\\n![](sockjs-mud-architecture.png)\\r\\n\\r\\nAs you can see it\'s quite simple, and it follows one of the\\r\\nrecommended SockJS deployment models. It should be possible to\\r\\nscale it horizontally, although this game is only a toy and we haven\'t\\r\\nreally tested that."},{"id":"/2011/10/27/performance-of-queues-when-less-is-more","metadata":{"permalink":"/rabbitmq-website/blog/2011/10/27/performance-of-queues-when-less-is-more","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-10-27-performance-of-queues-when-less-is-more/index.md","source":"@site/blog/2011-10-27-performance-of-queues-when-less-is-more/index.md","title":"Performance of Queues: when less is more","description":"Since the new persister arrived in RabbitMQ 2.0.0 (yes, it\'s not so","date":"2011-10-27T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":8.085,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"Performance of Queues: when less is more","tags":["New Features"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"Ponies, Dragons and Socks","permalink":"/rabbitmq-website/blog/2011/11/30/ponies-dragons-and-socks"},"nextItem":{"title":"High Availability in RabbitMQ: solving part of the puzzle","permalink":"/rabbitmq-website/blog/2011/10/25/high-availability-in-rabbitmq-solving-part-of-the-puzzle"}},"content":"Since the *new persister* arrived in RabbitMQ 2.0.0 (yes, it\'s not so\\r\\n*new* anymore), Rabbit has had a relatively good story to tell about\\r\\ncoping with queues that grow and grow and grow and reach sizes that\\r\\npreclude them from being able to be held in RAM. Rabbit starts writing\\r\\nout messages to disk fairly early on, and continues to do so at a\\r\\ngentle rate so that by the time RAM gets really tight, we\'ve done most\\r\\nof the hard work already and thus avoid sudden bursts of\\r\\nwrites. Provided your message rates aren\'t too high or too bursty,\\r\\nthis should all happen without any real impact on any connected\\r\\nclients.\\r\\n\\r\\nSome recent discussion with a client made us return to what we\'d\\r\\nthought was a fairly solved problem and has prompted us to make some\\r\\nchanges.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nFirst, we\\r\\n[took some time to understand better how CPU use per message varies as queues get longer and go to disk](/blog/2011/09/24/sizing-your-rabbits),\\r\\nand what the effect of that is. The conclusions are not necessarily\\r\\nobvious. Then we started thinking about the justifications behind some\\r\\nof the decisions queues take in the process of going from a\\r\\npurely-in-RAM queue to a purely-on-disk queue.\\r\\n\\r\\nAn AMQP queue in Rabbit is not simple functional FIFO queue. There are\\r\\nin fact at least four \\"queues\\" used internally by each AMQP queue,\\r\\neach of which are allowed to hold messages in various different\\r\\nstates. These states are things like: Is the message held in RAM\\r\\n(regardless of whether it has *additionally* been written to disk)?;\\r\\nIs the message itself on disk, but its location within the queue still\\r\\nonly held in RAM? That sort of thing. Each message in the AMQP queue\\r\\nwill only appear at any one time in one of these internal queues, but\\r\\nthey can move from queue to queue if and when their state changes\\r\\n(though the movement between these internal queues respects the\\r\\noverall order of messages within the AMQP queue). There is then a\\r\\nfifth \\"queue\\" which is not really a queue at all. It is more a couple\\r\\nof numbers that indicate the range of messages that are held solely on\\r\\ndisk (if you like, these are pointers to the head and tail of the\\r\\n\\"queue\\" which is solely on disk). Messages in this form have, in\\r\\ntheory, zero RAM-cost (depending on how you count (numbers cost RAM\\r\\ntoo you know!), and elsewhere in Rabbit you can be fairly sure the\\r\\nbest you can get down to is a few bytes per message). The full gory\\r\\ndetails can be gleaned from the essay at the top of the\\r\\n[variable_queue](http://hg.rabbitmq.com/rabbitmq-server/file/default/src/rabbit_variable_queue.erl)\\r\\nmodule. It\'s not really that terrifying, but it isn\'t exactly noddy\\r\\nstuff either. The tricky bits are working out how you decide which\\r\\nmessages should be in which states, and when, and I\'m not going to\\r\\ncover those decisions in this post.\\r\\n\\r\\nA message that is captured by this fifth \\"queue\\" will potentially take\\r\\ntwo reads to go from that purely-on-disk form right back to a\\r\\nfully-in-RAM message. This is because every message has a message ID\\r\\n(which is random, unordered, and allocated to each message before it\\r\\narrives at any queue, so is useless for determining relative position\\r\\nwithin an AMQP queue), and within each AMQP queue each message is known by its\\r\\nper-queue sequence ID, which enforces the relative order of messages\\r\\nwithin an AMQP queue. This fifth \\"queue\\" can be thought of as a\\r\\nmapping from sequence ID to message ID (plus some\\r\\nper-message-per-queue state), and then you can use a different\\r\\nsubsystem to transform that message ID to the actual message.\\r\\n\\r\\nAs a result of these two reads (though the way we structure it, one of\\r\\nthe reads is shared between 16k messages, so it\'s probably closer to\\r\\n1+(1/16384) reads per message, at least by default), we\'ve previously\\r\\ntried to prevent the use of this fifth \\"queue\\": in the past, even when\\r\\nmemory is running very low, we\'ll write messages out to disk fully,\\r\\nbut then still hold onto a record in RAM (though by this point it\'s a\\r\\nfairly small record per message), assuming that this will give us an\\r\\nadvantage later on: yes, it costs more RAM, but if some other big AMQP\\r\\nqueue suddenly gets deleted and frees up lots of RAM then by holding\\r\\nonto this smallish record per message, we avoid having to do the two\\r\\nreads to go from the fifth \\"queue\\" back to a full message, and will\\r\\nonly have to do a single read instead. Only when RAM runs out\\r\\ncompletely will we suddenly dump (almost) everything into this fifth\\r\\n\\"queue\\" (though by this point, everything will be on disk by now\\r\\nanyway so it\'s more or less a no-op -- we\'re just freeing up RAM in\\r\\nthis transition).\\r\\n\\r\\nHowever, because of the effective amortisation of at least one of\\r\\nthese reads, using the fifth \\"queue\\" isn\'t as expensive as we\\r\\nfeared. Plus, if you start to use it earlier then the queue grows in\\r\\nRAM at a slower rate: messages have the lowest per-message RAM cost when\\r\\nthey\'re in this fifth \\"queue\\", and thus the greater your use of this\\r\\n\\"queue\\", the lower the rate at which your queue will consume RAM. This\\r\\non its own helps Rabbit smooth out the transition to purely on disk\\r\\noperation (given the same growth rate in messages, a lower growth rate in RAM will result in a lower rate of disk ops).\\r\\n\\r\\nSo we\'ve changed the behaviour of Rabbit\'s AMQP queues to use this\\r\\nfifth \\"queue\\" more eagerly. Benchmarks suggest that this seems to\\r\\nresult in an AMQP queue\'s memory use flat-lining earlier on in its\\r\\ngrowth, and actually seems to make Rabbit able to deliver messages\\r\\nfrom large AMQP queues out to consumers faster (probably because by\\r\\nlimiting the size of the other four internal queues, some operations\\r\\nwhich were found to be very inefficient (such as joining two\\r\\nfunctional queues together (Erlang\'s default queue module does a plain\\r\\nappend (`++`) here, which is expensive)) are avoided, thus more CPU is\\r\\navailable for driving consumers). The downside is that queues now\\r\\nspend more time doing reads, but that seems to have been more than\\r\\noffset by the lower user jiffies per message.\\r\\n\\r\\nBelow is a graph. This is very exciting -- not just because of the\\r\\nfact that most of my blog posts are endless words. It shows three runs\\r\\nof the same test program. This test program does the following:\\r\\n\\r\\n1. It creates 3 queues.\\r\\n1. It binds those 3 queues to a fanout exchange.\\r\\n1. It then starts publishing 200-byte messages to that exchange at 600\\r\\n   messages / second.\\r\\n1. For the first 120 seconds, it has 20 consumers per queue consuming\\r\\n   without auto-ack, one ack per message, and a QoS pre-fetch of 1. This is known to be a very expensive way of consuming\\r\\n   messages. Further, the ack is deliberately delayed so that,\\r\\n   ignoring network latency, the maximum aggregate consuming rate will\\r\\n   be 1200 messages / second.\\r\\n1. After 120 seconds, the consumers are stopped, and not started again\\r\\n   until there is a total backlog of 500,000 messages (i.e. each of\\r\\n   the 3 queues will have around 166,000 messages).\\r\\n1. After that, the consumers resume as before, and you hope that the\\r\\n   queues can cope with the continuing publishes and drive their\\r\\n   backlog out to the consumers. Hopefully, all the queues will\\r\\n   eventually become empty again.\\r\\n\\r\\nNow depending on your CPU, RAM, network latency, and *high_watermark*\\r\\nsettings, this backlog can be purely in RAM only, and so no disk\\r\\noperations ever take place; or it could be purely on disk; or anywhere\\r\\nin between. Our desktops in the office here tend to be too powerful\\r\\nfor this test to cause any problems (the backlog always drains), but\\r\\non some EC2 hosts, with older versions of Erlang and older versions of\\r\\nRabbit, it was possible to reach a point where this backlog would\\r\\nnever drain, and instead grow.\\r\\n\\r\\nIn the following graph, we have three successful runs of this test,\\r\\nboth on *m1.large* EC2 instances, with the test being run on a\\r\\nseparate EC2 instance (i.e. we really were going across the\\r\\nnetwork). These are running Ubuntu images, but with a locally compiled\\r\\nErlang R14B04 installation. The three runs are: 1) what was on our\\r\\ndefault branch prior to this work being merged; 2) our default branch\\r\\nafter this work was merged; 3) the 2.6.1 release.\\r\\n\\r\\n![](graph.svg)\\r\\n\\r\\nSince 2.6.1 was released, a fairly large number of performance tweaks\\r\\nhave been made, and this is shown by the faster rate at which the\\r\\nbacklog disappears. But the \\"default prior to change\\" and \\"2.6.1\\"\\r\\nmemory usages are fairly similar, whereas, on average, the \\"default\\r\\npost change\\" has a lower memory usage. The memory measurements are not\\r\\nespecially compelling however as, owing to Erlang being an\\r\\nauto-garbage-collected language, it is not always the case that\\r\\nimproving memory efficiency internally results in the VM requesting\\r\\nless RAM or returning RAM to the OS faster. What is more compelling is\\r\\nthe faster rate at which the backlog is eliminated and the lower\\r\\ncumulative jiffies: even though \\"default post change\\" is doing more\\r\\nmessages per second than either of the other runs, it still uses fewer\\r\\njiffies per second than the other runs.\\r\\n\\r\\nHopefully this change will make improvements to many users across many\\r\\nscenarios. It\'s possible there may be some use cases where it performs\\r\\nworse -- we certainly can\'t rule that out. No problem in software\\r\\nengineering that\'s worth solving has a single correct solution. This\\r\\ncase shows that sometimes, using less memory and doing apparently more disk ops\\r\\ncan actually make things go faster overall."},{"id":"/2011/10/25/high-availability-in-rabbitmq-solving-part-of-the-puzzle","metadata":{"permalink":"/rabbitmq-website/blog/2011/10/25/high-availability-in-rabbitmq-solving-part-of-the-puzzle","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-10-25-high-availability-in-rabbitmq-solving-part-of-the-puzzle/index.md","source":"@site/blog/2011-10-25-high-availability-in-rabbitmq-solving-part-of-the-puzzle/index.md","title":"High Availability in RabbitMQ: solving part of the puzzle","description":"In","date":"2011-10-25T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.93,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"High Availability in RabbitMQ: solving part of the puzzle","tags":["New Features"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"Performance of Queues: when less is more","permalink":"/rabbitmq-website/blog/2011/10/27/performance-of-queues-when-less-is-more"},"nextItem":{"title":"Keeping It Realtime Conference (Portland, OR)","permalink":"/rabbitmq-website/blog/2011/10/19/keeping-it-realtime-conference-portland-or"}},"content":"In\\r\\nRabbitMQ 2.6.0\\r\\nwe introduced [Highly Available](/docs/3.13/ha)\\r\\nqueues. These necessitated a\\r\\n[new extension](/docs/consumer-cancel)\\r\\nto AMQP, and a fair amount of\\r\\n[documentation](/docs/3.13/ha), but to date, little has\\r\\nbeen written on how they work.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n*High Availability* (HA) is a typically over-used term and means\\r\\ndifferent things to different people. In the context of RabbitMQ,\\r\\nthere are a number of aspects of *high availability*, some of which\\r\\nthis work does solve and some of which it does not. The things it does\\r\\nnot solve include:\\r\\n\\r\\n1. Maintaining connections to a RabbitMQ broker or node: using some\\r\\nsort of TCP load-balancer or proxy is the best route here, though other\\r\\nsolutions such as dynamically updating DNS entries or just pre-loading\\r\\nyour clients with a list of addresses to connect to may work just as\\r\\nwell.\\r\\n\\r\\n1. Recovery from failure: in the event that a client is disconnected\\r\\nfrom the broker owing to failure of the node to which the client was\\r\\nconnected, if the client was a publishing client, it\'s possible for\\r\\nthe broker to have accepted and passed on messages from the client\\r\\nwithout the client having received confirmation for them; and likewise\\r\\non the consuming side it\'s possible for the client to have issued\\r\\nacknowledgements for messages and have no idea whether or not those\\r\\nacknowledgements made it to the broker and were processed before the\\r\\nfailure occurred. In short, you still need to make sure your consuming\\r\\nclients can identify and deal with duplicate messages.\\r\\n\\r\\n1. Auto-healing from network partitions or splits. RabbitMQ makes use\\r\\nof the Erlang distributed database Mnesia. This database itself does\\r\\nnot cope with network partitions: it very much chooses *Consistency*\\r\\nand *Availability* and not *Partitions* from the *CAP* triangle. As\\r\\nRabbitMQ depends on Mnesia, RabbitMQ itself has the same\\r\\nproperties. Thus the HA work in RabbitMQ can prevent queues from\\r\\ndisappearing in the event of a node failure, but does not have\\r\\nanything to say about automatically rejoining the failed node when it\\r\\nis repaired: this still requires manual intervention.\\r\\n\\r\\nThese are not new problems at all; and RabbitMQ\'s HA work does not\\r\\nattempt to address these problems. Instead, it focuses solely on\\r\\npreventing queues from being bound to a single node in a cluster.\\r\\n\\r\\n\\r\\nThe previous situation was that a queue exists only on one node. If\\r\\nthat node fails, the queue becomes unavailable. The HA work solves\\r\\nthis by mirroring a queue on other nodes: all actions that occur on\\r\\nthe queue\'s master are intercepted and applied in the same order to\\r\\neach of the slaves within the mirror.\\r\\n\\r\\nThis requires:\\r\\n\\r\\n1. The ability to intercept all actions being performed on a\\r\\nqueue. Fortunately, the code abstractions we already have makes this\\r\\nfairly easy.\\r\\n\\r\\n1. The ability for those actions to be communicated reliably,\\r\\nconsistently and in order to all the slaves within the mirror. For\\r\\nthis we have written a new\\r\\n[guaranteed multicast](http://hg.rabbitmq.com/rabbitmq-server/file/default/src/gm.erl)\\r\\nmodule (also known as atomic broadcast).\\r\\n\\r\\n1. The ability to reliably detect the loss of a node in such a way\\r\\nthat no messages sent from that node reach a subset of the slaves: to\\r\\nensure the members of the mirrored queue stay in sync with each other,\\r\\nit\'s crucial that in the event of the failure of the master, any\\r\\nmessages that the master was in the process of sending to the slaves\\r\\neither fail completely or succeed completely (this is really the\\r\\n*atomic* in *atomic broadcast*).\\r\\n\\r\\n\\r\\nIn addition, all this communication between the members of the mirror\\r\\noccurs in an asynchronous fashion. This has advantages such as it\\r\\nprevents the master from being slowed down if one of the slaves starts\\r\\nstruggling; but it also has disadvantages such as the complexity of\\r\\ninterleavings of actions in the event of failure of the master and\\r\\npromotion of a slave.\\r\\n\\r\\nOnce the master does fail, a slave is chosen for promotion. The slave\\r\\nchosen is the eldest slave, in the belief that it\'s the most likely to\\r\\nhave contents that match the contents of the failed master queue. This\\r\\nis important because currently there is no eager synchronisation of\\r\\nmirrored queues. Thus if you create a mirrored queue, send messages\\r\\ninto it, and then add another node which then mirrors that queue, the\\r\\nslave on the new node will not receive the existing messages. Only new\\r\\nmessages published to the queue will be sent to all current members of\\r\\nthe mirrored queue. Thus by consuming from the queue and thus\\r\\nprocessing the messages at the head of the queue, the\\r\\nnon-fully-mirrored messages will be eliminated. Consequently, by\\r\\npromoting the eldest slave, you minimise the number of messages at the\\r\\nhead of the queue that may have only been known to the failed master."},{"id":"/2011/10/19/keeping-it-realtime-conference-portland-or","metadata":{"permalink":"/rabbitmq-website/blog/2011/10/19/keeping-it-realtime-conference-portland-or","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-10-19-keeping-it-realtime-conference-portland-or/index.md","source":"@site/blog/2011-10-19-keeping-it-realtime-conference-portland-or/index.md","title":"Keeping It Realtime Conference (Portland, OR)","description":"There\'s a lot of hot stuff happening in the web technology lately.","date":"2011-10-19T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"},{"inline":true,"label":"Talks and Conferences","permalink":"/rabbitmq-website/blog/tags/talks-and-conferences"}],"readingTime":0.965,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"Keeping It Realtime Conference (Portland, OR)","tags":["Web Messaging","Talks and Conferences"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"High Availability in RabbitMQ: solving part of the puzzle","permalink":"/rabbitmq-website/blog/2011/10/25/high-availability-in-rabbitmq-solving-part-of-the-puzzle"},"nextItem":{"title":"PubSubHuddle \'Realtime Web\' talk","permalink":"/rabbitmq-website/blog/2011/09/26/pubsubhuddle-realtime-web-talk"}},"content":"There\'s a lot of hot stuff happening in the web technology lately.\\r\\nJavaScript seems to be bearing the torch, both\\r\\nbrowser-side and server-side.\\r\\nAt the RabbitMQ HQ we\'re interested in developments in the wide world of\\r\\nmessaging, and we\'re particularly excited about the JavaScript angle on\\r\\nmessaging - namely WebSockets and related technologies.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n![](krt.png)\\r\\n\\r\\nThe good news is - there will be a conference dedicated to these topics:\\r\\n\\r\\n* [Keeping It Realtime Conference](http://krtconf.com/)\\r\\n\\r\\nThe conference will take two days on Nov 7 and 8 in Portland, OR.\\r\\nI\'m delighted to announce that I\'ll be giving a talk there. I\'ll speak\\r\\nabout our view on messaging in the web environment, our attempt (and\\r\\nfailure) to build a generic web-messaging service, and finally I\'ll\\r\\ndescribe what we came up after all this - the [SockJS project](http://sockjs.org). (Which is a simple WebSocket emulation layer, but it took us a while to understand why this is the best approach to do web-messaging.)\\r\\nI\'ll be hanging around there for the two days - feel free to talk to me\\r\\nabout SockJS, RabbitMQ, AMQP or just messaging in general in any flavour.\\r\\nSee you in Portland!"},{"id":"/2011/09/26/pubsubhuddle-realtime-web-talk","metadata":{"permalink":"/rabbitmq-website/blog/2011/09/26/pubsubhuddle-realtime-web-talk","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-09-26-pubsubhuddle-realtime-web-talk/index.md","source":"@site/blog/2011-09-26-pubsubhuddle-realtime-web-talk/index.md","title":"PubSubHuddle \'Realtime Web\' talk","description":"I was asked to do a short presentation during the","date":"2011-09-26T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"},{"inline":true,"label":"Talks and Conferences","permalink":"/rabbitmq-website/blog/tags/talks-and-conferences"}],"readingTime":0.75,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"PubSubHuddle \'Realtime Web\' talk","tags":["Web Messaging","Talks and Conferences"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"Keeping It Realtime Conference (Portland, OR)","permalink":"/rabbitmq-website/blog/2011/10/19/keeping-it-realtime-conference-portland-or"},"nextItem":{"title":"Sizing your Rabbits","permalink":"/rabbitmq-website/blog/2011/09/24/sizing-your-rabbits"}},"content":"I was asked to do a short presentation during the\\r\\n[PubSubHuddle meetup](http://www.pubsubhuddle.com/). The talk was\\r\\nabout current development of WebSockets, its issues and building web\\r\\napplications using them.\\r\\n\\r\\n![](huddle4.png)\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nIn the presentation I present the evolution of simple shared-nothing architecture and I\\r\\ntry to explain why, in order to use web messaging, the website\\r\\narchitecture should be truly asynchronous on every stage.\\r\\nAll that is an attempt to express a rationale for the\\r\\n[SockJS project](https://github.com/sockjs/sockjs-client).  Actually,\\r\\nthe full story behind SockJS is much deeper, but probably nobody cares\\r\\nabout every detail, I am guessing.\\r\\nThe presentation is available here:\\r\\n\\r\\n* [PubSubHuddle - Realtime Web PDF](https://github.com/sockjs/sockjs-client/wiki/pubsubhuddle-realtime-web.pdf) (5MiB) [(Scribd)](http://www.scribd.com/doc/66379391) \\r\\n\\r\\nThe slides are rather terse, in order to understand them you may\\r\\nwant to listen to the talk:\\r\\n\\r\\n* [Skills Matter recording](http://skillsmatter.com/podcast/nosql/marek-majkowski-talk)\\r\\n\\r\\nFor more details about the reasons behind SockJS, read on:\\r\\n\\r\\n* [Web messaging ain\'t easy](https://github.com/sockjs/sockjs-client/wiki/%5BArticle%5D-SockJS:-web-messaging-ain%E2%80%99t-easy)\\r\\n* [WebSocket emulation](https://github.com/sockjs/sockjs-client/wiki/%5BArticle%5D-SockJS:-WebSocket-emulation-done-right)"},{"id":"/2011/09/24/sizing-your-rabbits","metadata":{"permalink":"/rabbitmq-website/blog/2011/09/24/sizing-your-rabbits","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-09-24-sizing-your-rabbits/index.md","source":"@site/blog/2011-09-24-sizing-your-rabbits/index.md","title":"Sizing your Rabbits","description":"One of the problems we face at the RabbitMQ HQ is that whilst we may","date":"2011-09-24T00:00:00.000Z","tags":[{"inline":true,"label":"Introductory","permalink":"/rabbitmq-website/blog/tags/introductory"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":10.105,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"Sizing your Rabbits","tags":["Introductory","HowTo"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"PubSubHuddle \'Realtime Web\' talk","permalink":"/rabbitmq-website/blog/2011/09/26/pubsubhuddle-realtime-web-talk"},"nextItem":{"title":"PubSub huddle","permalink":"/rabbitmq-website/blog/2011/09/16/pubsub-huddle"}},"content":"One of the problems we face at the RabbitMQ HQ is that whilst we may\\r\\nknow lots about how the broker works, we don\'t tend to have a large\\r\\npool of experience of designing applications that use RabbitMQ and\\r\\nwhich need to work reliably, unattended, for long periods of time. We\\r\\nspend a lot of time answering questions on the mailing list, and we do\\r\\nconsultancy work here and there, but in some cases it\'s as a result of\\r\\nbeing contacted by users building applications that we\'re really made\\r\\nto think about long-term behaviour of RabbitMQ. Recently, we\'ve been\\r\\nprompted to think long and hard about the basic performance of queues,\\r\\nand this has lead to some realisations about provisioning Rabbits.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nRabbitMQ\'s queues are fastest when they\'re empty. When a queue is\\r\\nempty, and it has consumers ready to receive messages, then as soon as\\r\\na message is received by the queue, it goes straight out to the\\r\\nconsumer. In the case of a persistent message in a durable queue, yes,\\r\\nit will also go to disk, but that\'s done in an asynchronous manner and\\r\\nis buffered heavily. The main point is that very little book-keeping\\r\\nneeds to be done, very few data structures are modified, and very\\r\\nlittle additional memory needs allocating. Consequently, the CPU load\\r\\nof a message going through an empty queue is very small.\\r\\n\\r\\nIf the queue is not empty then a bit more work has to be done: the\\r\\nmessages have to actually be queued up. Initially, this too is fast\\r\\nand cheap as the underlying functional data structures are very\\r\\nfast. Nevertheless, by holding on to messages, the overall memory\\r\\nusage of the queue will be higher, and we are doing more work than\\r\\nbefore per message (each message is being both enqueued and dequeued\\r\\nnow, whereas before each message was just going straight out to a\\r\\nconsumer), so the CPU cost per message is higher. Consequently, the\\r\\ntop speed you\'ll be able to achieve with an empty queue will be higher\\r\\nthan the top speed of a queue with a fixed N messages in it, even if N\\r\\nis very small.\\r\\n\\r\\nIf the queue receives messages at a faster rate than it can pump out\\r\\nto consumers then things get slower. As the queue grows, it will\\r\\nrequire more memory. Additionally, if a queue receives a spike of\\r\\npublications, then the queue must spend time dealing with those\\r\\npublications, which takes CPU time away from sending existing messages\\r\\nout to consumers: a queue of a million messages will be able to be\\r\\ndrained out to ready consumers at a much higher rate if there are no\\r\\npublications arriving at the queue to distract it. Not exactly rocket\\r\\nscience, but worth remembering that publications arriving at a queue\\r\\ncan reduce the rate at which the queue drives its consumers.\\r\\n\\r\\nEventually, as a queue grows, it\'ll become so big that we have to\\r\\nstart writing messages out to disk and forgetting about them from RAM\\r\\nin order to free up RAM. At this point, the CPU cost per message is\\r\\nmuch higher than had the message been dealt with by an empty queue.\\r\\n\\r\\nNone of this seems particularly profound, but keeping these points in\\r\\nmind when building your application turns out to be very important.\\r\\n\\r\\nLet\'s say you design and build your application, using RabbitMQ. There\\r\\nwill be some set of publishers, and some set of consumers. You test\\r\\nthis, and let\'s say that in total, in one part of the system, you find\\r\\nthat the maximum rate that\'ll ensure your queues stay empty or very\\r\\nnear empty is 2000 msgs/second. You then choose a machine on which to\\r\\nrun RabbitMQ, which might be on some sort of virtual server. When\\r\\ntesting at 2000 msgs/second you found the CPU load of the box running\\r\\nRabbitMQ was not very high: the bottleneck was elsewhere in the\\r\\napplication -- most likely in the consumers of your queues (you were\\r\\nmeasuring the maximum stable end-to-end performance) -- so RabbitMQ\\r\\nitself wasn\'t being overly stressed and so wasn\'t eating up much\\r\\nCPU. Consequently, you choose a virtual server which isn\'t enormously\\r\\npowerful. You then launch the application and sure enough, everything\\r\\nlooks OK.\\r\\n\\r\\nOver time, your application becomes more popular, and so your rates\\r\\nincrease.\\r\\n\\r\\nEventually, you get to a point where your consumers are running flat\\r\\nout, and your queues are staying nearly empty. But then, at the most\\r\\npopular time of the day for your application, your publishers push a\\r\\nfew more messages into your queues than before. This is just normal\\r\\ngrowth -- you have more users now and so it\'s not surprising messages\\r\\nare being published a bit faster than before. What you hope will\\r\\nhappen is that RabbitMQ will just happily buffer up the messages and\\r\\nwill eventually feed them to your consumers who will be able to work\\r\\nthrough the back-log during quieter times of the day.\\r\\n\\r\\nThe problem is that this might not be able to happen. Because your\\r\\nqueues are now (albeit briefly) receiving more messages than your\\r\\nconsumers can cope with, the queues spend more CPU time dealing with\\r\\neach message than they used to when the queue was empty (the messages\\r\\nnow have to be queued up). That takes away CPU time from driving the\\r\\nconsumers and unfortunately, as you chose a machine for RabbitMQ which\\r\\ndidn\'t have a great deal of spare CPU capacity, you start maxing out\\r\\nthe CPU. Thus your queues can\'t drive your consumers quite as hard as\\r\\nbefore, which in turn makes the rate of growth of the queues\\r\\nincrease. This in turn starts to push the queues to sizes where they\\r\\nhave to start pushing messages to disk in order to free up RAM which\\r\\nagain takes up more CPU which you don\'t have, and by this point,\\r\\nyou\'re likely in deep trouble.\\r\\n\\r\\nWhat can you do?\\r\\n\\r\\nAt this immediate point, you need to get your queues drained. Because\\r\\nyour queues are spending more time dealing with new messages arriving\\r\\nthan with pushing messages out to consumers, it\'s unlikely that\\r\\nthrowing more consumers at the queues is going to significantly\\r\\nhelp. You really need to get the publishers to stop.\\r\\n\\r\\nIf you have the luxury of just turning off the publishers then do\\r\\nthat, and turn them back on when the queues become empty again. If you\\r\\ncan\'t do that, then you need to divert their load somewhere else, but\\r\\ngiven that your Rabbit is writing out to disk to avoid running out of\\r\\nmemory, and is maxing out the CPU, adding new queues to your current\\r\\nRabbit is not going to help -- you need a new Rabbit on a different\\r\\nmachine. If you\'ve set up a cluster, then you could provision new\\r\\nqueues on a node of your RabbitMQ cluster that is not so heavily\\r\\nloaded, then attach lots of new consumers to that, and divert the\\r\\npublishers into there. At this point, you\'ll realise the value of not\\r\\nusing the default nameless exchange and addressing queues directly,\\r\\nand instead will be very glad that you had your publishers publish to\\r\\nan exchange you created, thus allowing you to add a new binding to\\r\\nyour fresh new queue, and deleting the binding to your old queue,\\r\\ndiverting the load, and not having to interrupt your publishers at\\r\\nall. The old queues will then be able to drive their consumers (which\\r\\nyou\'ve not removed!) as fast as possible, and the queues will\\r\\ndrain. Now in this situation, you have the prospect of messages being\\r\\nprocessed out of order (new messages arriving in the fresh new queues\\r\\nmay be processed by your new consumers before the old messages in the\\r\\nold queues are processed), but if you have multiple consumers off a\\r\\nsingle queue then you\'re probably already dealing with that problem\\r\\nanyway.\\r\\n\\r\\nPrevention, we are often told, is preferable to cure. So how could you\\r\\ndesign your application to be able to help RabbitMQ cope with these\\r\\npotentially catastrophic situations?\\r\\n\\r\\nFirstly, don\'t use a very low `basic.qos` prefetch value in\\r\\nyour consumers. If you use a value of 1 then it\'ll mean that a queue\\r\\nsends out one message to a consumer, and then can\'t send anything more\\r\\nto that consumer until it receives the acknowledgement back. Only when\\r\\nit\'s done that can it send out the next message. If it takes a while\\r\\nfor the acknowledgement to make its way back to the queue (for\\r\\nexample, high latency on the network, or the load that your Rabbit is\\r\\nunder may mean it takes a while for that acknowledgement to get all\\r\\nthe way through to the queue) then in the meantime, that consumer is\\r\\nsitting there idle. If you use a `basic.qos` prefetch value\\r\\nof 20, for example, then the broker will ensure that 20 messages are\\r\\nsent to the consumer, and then even as the acknowledgement for the\\r\\nfirst message is (maybe slowly) making its way back to the queue, the\\r\\nconsumer still has work to be getting on with (i.e. the next 19\\r\\nmessages). Essentially, the higher the prefetch value, the greater\\r\\ninsulation the consumer has from spikes in the round trip time back to\\r\\nthe queue.\\r\\n\\r\\nSecondly, consider not acknowledging every message, but instead\\r\\nacknowledging every N messages and setting the `multiple`\\r\\nflag on the acknowledgement. When the queue is overloaded, it\'s\\r\\nbecause it has too much work to do (profound, I know). As a consumer,\\r\\nyou can reduce the amount of work it has to do by ensuring you don\'t\\r\\nflood it with acknowledgements.  Thus, for example, you set the\\r\\n`basic.qos` prefetch to 20, but you only send an\\r\\nacknowledgement after you\'ve processed every 10 messages and you set\\r\\nthe `multiple` flag to true on the acknowledgement. The\\r\\nqueue will now receive one-tenth of the acknowledgements it would have\\r\\npreviously received. It will still internally acknowledge all ten\\r\\nmessages, but it can do it in a more efficient way if it receives one\\r\\nacknowledgement that accounts for several messages, rather than lots\\r\\nof individual acknowledgements. However, if you\'re only acknowledging\\r\\nevery N messages, be sure that your `basic.qos` prefetch\\r\\nvalue is higher than N. Probably at least 2*N. If your prefetch value\\r\\nis the same as N, then your consumer will once again be left idle\\r\\nwhilst the acknowledgement makes its way back to the queue and the\\r\\nqueue sends out a fresh batch of messages.\\r\\n\\r\\nThirdly, have a strategy to pivot the load to other queues on others\\r\\nmachines if the worst comes to the worst. Yes, it is a good idea to\\r\\nuse RabbitMQ as a buffer which insulates publishers from consumers and\\r\\ncan absorb spikes. But equally, you need to remember that RabbitMQ\'s\\r\\nqueues go fastest when they\'re empty, and we always say that you\\r\\nshould design your application so that the queues are normally\\r\\nempty. Or to put it another way, the performance of a queue is lowest\\r\\nwhen you likely need more than ever for it to absorb a large\\r\\nspike. The upshot of that is that unless you test to makes sure you\\r\\nknow it will recover, you might be in for a surprise should a\\r\\nnon-trivial spike occur which substantially increases the length of\\r\\nyour queues. You may not have factored into your thinking that in such\\r\\na situation, your existing consumers may end up being driven more\\r\\nslowly than before, simply because your queues are busy doing other\\r\\nthings (enqueuing messages), and that this can cause a vicious cycle\\r\\nthat eventually results in a catastrophic loss of performance of the\\r\\nqueue.\\r\\n\\r\\nThe nub of the issue is that a queue is a single-threaded resource. If\\r\\nyou\'ve designed your routing topology in such a way that it already\\r\\ndoes, or at least can, spread messages across multiple queues rather\\r\\nthan just hammering all messages into a single queue, then you\'re far\\r\\nmore likely to be able to respond to such problems occurring quickly\\r\\nand easily, by diverting load and being able to take advantage of\\r\\nadditional CPU resources which ensure that you can minimise the\\r\\nCPU-hit per message."},{"id":"/2011/09/16/pubsub-huddle","metadata":{"permalink":"/rabbitmq-website/blog/2011/09/16/pubsub-huddle","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-09-16-pubsub-huddle/index.md","source":"@site/blog/2011-09-16-pubsub-huddle/index.md","title":"PubSub huddle","description":"All of a sudden there\'s just one week to go until the PubSub huddle. It\'s a one day conference, in London, about messaging. Not just RabbitMQ, but ZeroMQ, MQTT, XMPP and PuSH.","date":"2011-09-16T00:00:00.000Z","tags":[{"inline":true,"label":"Talks and Conferences","permalink":"/rabbitmq-website/blog/tags/talks-and-conferences"}],"readingTime":1.735,"hasTruncateMarker":true,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"PubSub huddle","tags":["Talks and Conferences"],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"Sizing your Rabbits","permalink":"/rabbitmq-website/blog/2011/09/24/sizing-your-rabbits"},"nextItem":{"title":"SockJS - WebSocket emulation","permalink":"/rabbitmq-website/blog/2011/09/13/sockjs-websocket-emulation"}},"content":"All of a sudden there\'s just one week to go until the [PubSub huddle](http://www.pubsubhuddle.com/). It\'s a one day conference, in London, about messaging. Not just RabbitMQ, but ZeroMQ, MQTT, XMPP and PuSH.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n**It\'s free as in beer**. *There\'s free beer*. And, at last count, there\'s [spaces left](http://skillsmatter.com/event/nosql/pubsub).\\r\\n\\r\\n### We have some neat talks lined up\\r\\n\\r\\n* Martin Sustrik -- **The Future of Messaging**\\r\\n* Andy Piper -- **Introducing MQTT**\\r\\n* Marek Majkowski -- **Realtime web: Not there yet!**\\r\\n* Julien Genestoux -- **PubSub for the web : PubSubHubbub, XMPP and Superfeedr**\\r\\n\\r\\n([full descriptions](http://pubsubhuddle.com/node/1))\\r\\n\\r\\nIf you can\'t come along, do not fret. The talks will all be taped.\\r\\n\\r\\nIf you can come along, here\'s the important bit: **we want you to bring along your own projects** (and laptops). Because in the afternoon, we\'ll be asking for people to stand up and give a quick talk about what they are doing with messaging, then we\'ll all break out into huddles. This is your chance to win people to your cause -- or to find a great project to get involved in.\\r\\n\\r\\nWe\'ll have the speakers and various RabbitMQ and ZeroMQ folk floating around, so it\'s also your chance to put them on the spot.\\r\\n\\r\\n### pubsubwhatnow?\\r\\n\\r\\nGoing back a few years, James Governor suggested there was an emerging community\\r\\nof people who cared about messaging and that we should all meet up.  Thus\\r\\nwas born an occasional series of events called \\"PubSub - putting the pub back into\\r\\npubsub\\". Many people you\'ll see at the huddle went to those pubs.\\r\\n\\r\\nThe idea of a conference came during the ZeroMQ meetup in Brussels,\\r\\nwhen someone said \\"wouldn\'t it be great to bring *messaging* folks together for a day?\\" -- RabbitMQ or ZeroMQ, we think messaging is fundamental.\\r\\n\\r\\nTo make it happen, we partnered with [Skills Matter](http://www.skillsmatter.com/), who know a thing or two about running this kind of event.\\r\\n\\r\\n### You said free beer?\\r\\n\\r\\nYes. We\'re providing coffee and tea, lunch, and later on beer and pizza, courtesy of VMware. [Register for your free beer and conference here](http://skillsmatter.com/event/nosql/pubsub)."},{"id":"/2011/09/13/sockjs-websocket-emulation","metadata":{"permalink":"/rabbitmq-website/blog/2011/09/13/sockjs-websocket-emulation","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-09-13-sockjs-websocket-emulation/index.md","source":"@site/blog/2011-09-13-sockjs-websocket-emulation/index.md","title":"SockJS - WebSocket emulation","description":"WebSocket technology is catching up, but it will take a while before","date":"2011-09-13T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"}],"readingTime":6.55,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"SockJS - WebSocket emulation","tags":["Web Messaging"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"PubSub huddle","permalink":"/rabbitmq-website/blog/2011/09/16/pubsub-huddle"},"nextItem":{"title":"rabbitmq-tracing - a UI for the firehose","permalink":"/rabbitmq-website/blog/2011/09/09/rabbitmq-tracing-a-ui-for-the-firehose"}},"content":"WebSocket technology is catching up, but it will take a while before\\r\\nall browsers support it.\\r\\nIn the meantime there are loads of projects that aim to substitute for\\r\\nWebSockets and enable \'realtime\' capabilities for web apps. But all\\r\\nattempts solve only a part of the general problem, and there isn\'t any\\r\\nsingle solution that works, is scalable and doesn\'t require special\\r\\ndeployment tricks.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n![](sockjs-logo-128.png)\\r\\n\\r\\nThat\'s why a new project\\r\\n[was born](https://github.com/sockjs/sockjs-client/wiki/%5BBlog%5D-SockJS:-web-messaging-ain%E2%80%99t-easy):\\r\\n[SockJS](https://github.com/sockjs/sockjs-client) - yet another\\r\\nWebSocket emulation library, but this time done right.\\r\\nSockJS has ambitious goals:\\r\\n\\r\\n* Simple browser-side and server-side APIs, as close to WebSocket API\\r\\n   as possible.\\r\\n* Well documented scaling and load balancing techniques.\\r\\n* Transports must fully support cross-domain communication.\\r\\n* Transports must fall back gracefully in case of restrictive proxies.\\r\\n* Connection establishment should be fast.\\r\\n* No Flash on the client side, Javascript only.\\r\\n* Client-side Javascript must be reasonably well tested.\\r\\n* Additionally the server side code should be simple, in order to\\r\\n   lower the cost of writing servers for different languages.\\r\\n\\r\\n## Simple APIs\\r\\n\\r\\nIt may sound obvious, but the\\r\\n[WebSocket API](http://dev.w3.org/html5/websockets/) is actually quite\\r\\ngood. It\'s an effect of a tremendous effort led by Ian Hickson and\\r\\nothers. It\'s shouldn\'t be forgotten that there were earlier, less\\r\\nsuccessful attempts to\\r\\n[achieve a similar thing](http://dev.w3.org/html5/eventsource/) -\\r\\nthe WebSockets API wasn\'t developed in the void.\\r\\n\\r\\nYet, I haven\'t seen any Javascript library that tries to emulate this\\r\\nAPI closely. Early\\r\\n[Socket.io](https://github.com/learnboost/socket.io) attempted that,\\r\\nbut it has evolved quite far away by now.\\r\\n\\r\\nWebSocket doesn\'t define a server side API, but it\'s easy to come up\\r\\nwith a scheme with similar ideology and abstractions as the client\\r\\nside.\\r\\n\\r\\n## Deployment story\\r\\n\\r\\nSockJS does support cross-domain communication out of the box. You\\r\\ncan, and should, isolate SockJS server and host it on a different\\r\\ndomain than your main web site. There are multiple advantages of this\\r\\napproach and, frankly speaking, it\'s just the only sane deployment\\r\\nstrategy.\\r\\n\\r\\n## Load balancing story\\r\\n\\r\\nSingle SockJS server capacity is finite. If you are anticipating that\\r\\na single server will not be enough for your needs - take a look at the\\r\\nscaling scenarios below.\\r\\n\\r\\n### Use multiple domains for SockJS servers\\r\\n\\r\\nThe simplest solution is just to put every SockJS server under a\\r\\ndifferent domain name, for example `sockjs1.example.com` and\\r\\n`sockjs2.example.com`, and allow clients to pick a server randomly.\\r\\n\\r\\n### Use a WebSocket-capable load balancer\\r\\n\\r\\nYou can choose to host all the SockJS traffic under one domain and use\\r\\na decent WebSocket-capable load balancer to split the traffic. There\\r\\nis\\r\\n[a sample HAProxy configuration file](https://github.com/sockjs/sockjs-node/blob/master/examples/haproxy.cfg)\\r\\nwhich can be a good starting point.\\r\\n\\r\\n### Use almost any load balancer\\r\\n\\r\\nThis is not a preferred solution, but it\'s possible to run scalable\\r\\nSockJS even in environments where the load balancer doesn\'t support\\r\\nWebSockets. Shared hosting providers are like that - for example\\r\\n[CloudFoundry](http://cloudfoundry.com). In order to make connection\\r\\nestablishment faster you can disable WebSocket protocol both on the\\r\\nclient and server side.\\r\\nIn such an environment load balancer must forward all requests for a\\r\\nsingle SockJS session to a single SockJS server - the load balancer\\r\\nmust support sticky sessions (session affinity) in one of two\\r\\nvariants:\\r\\n\\r\\n* Prefix-based sticky sessions. All requests to SockJS are prefixed\\r\\n   with a session id. Good loadbalancers may use that as a clue for\\r\\n   session-affinity algorithms (for example HAProxy can do it).\\r\\n* `JSESSIONID` cookie sticky sessions. By default SockJS server sets\\r\\n   this cookie. Some load balancers understand that cookie and\\r\\n   enable session stickyness (for example this is the case for\\r\\n   CloudFoundry).\\r\\n\\r\\n## Robust transport protocols\\r\\n\\r\\n![](sockjs-transport.png)\\r\\n\\r\\nApart from native WebSockets, SockJS comes with the support for few\\r\\ncarefully chosen transport protocols, and all of them support\\r\\ncross-domain communication.\\r\\nThe basic idea is that there should be a decent streaming and polling\\r\\nprotocol for every browser. The polling ones must work work in\\r\\nenvironments with restrictive proxies and support old browsers. There\\r\\nare three ways every browser can establish connection:\\r\\n\\r\\n### Native WebSocket\\r\\n\\r\\nWebSocket is the fastest and best transport protocol, it supports\\r\\ncross-domain connections out of the box. Unfortunately it is not yet\\r\\nwidely supported by browsers. Also, some browsers may have problems\\r\\nwith proxies (for example, Firefox WebSocket implementation won\'t work\\r\\nthrough the majority of the proxies). It\'s going to take some time\\r\\nbefore the browser vendors agree on the protocol and proxy handling.\\r\\n\\r\\n### Streaming protocol\\r\\n\\r\\nStreaming protocols supported by SockJS are based on http 1.1 chunking - it \\r\\nallows browser to receive a single http response in many parts.\\r\\nA great example of streaming protocol is\\r\\n[EventSource](http://dev.w3.org/html5/eventsource/) or streaming over\\r\\nXHR (ajax). Messages sent from the browser are posted using another\\r\\nXHR request.\\r\\n\\r\\nEvery browser supports a different set of streaming protocols and they\\r\\nusually can\'t do cross-domain communication. Fortunately SockJS is\\r\\nable to work around that limitation by using an Iframe and\\r\\ncommunicating with it using an Html5 PostMessage API. This is quite\\r\\ncomplex, but fortunately it is supported by the majority of the\\r\\nbrowsers (with the exception of IE7).\\r\\n\\r\\n### Polling transport\\r\\n\\r\\nSockJS supports few good-old polling protocols for ancient browsers\\r\\n(including IE7). Unfortunately these techniques are quite slow, but\\r\\nthere is not much that can done about it.\\r\\n\\r\\nPolling transports can also be used in situations where proxy on the\\r\\nclient side doesn\'t support WebSockets nor http chunking- it is required for the streaming protocols.\\r\\n\\r\\n## Connection establishment should be fast\\r\\n\\r\\nOpening SockJS connection should be fast, in some deployments it may\\r\\nbe necessary to establish a SockJS connection on every http page the\\r\\nuser visits.\\r\\n\\r\\nIf the browser supports it SockJS first tries to open a native WebSocket\\r\\nconnection. Depending on a network and server setup it may work or\\r\\nfail. The failure should happen quite fast, unless the client is\\r\\nbehind a badly misbehaving proxy - in such case it can take up to 5\\r\\nseconds to timeout.\\r\\n\\r\\nAfter WebSocket transport is ruled out, SockJS opens XHR request that\\r\\nintends to check if chunking is supported by the proxy. It\'s not that\\r\\nunusual to meet proxies that don\'t support http chunking. Running\\r\\nstreaming protocol in such environment will fail with a timeout.\\r\\nIf chunking is working fine, SockJS chooses the best streaming\\r\\nprotocol supported by the browser. In the other case, polling\\r\\ntransports are used.\\r\\n\\r\\nAll that, depending on the browser, can take between 3 or 4 round trip\\r\\ntimes from the browser to the server, plus a DNS request. Unless\\r\\nyou\'re behind a broken proxy or live in Antarctica it should be quite\\r\\nfast.\\r\\n\\r\\nThis is one of the reasons why SockJS avoids using Flash transports -\\r\\nFlash connection can take\\r\\n[at least to 3 seconds](http://www.adobe.com/devnet/flashplayer/articles/fplayer9_security.html)\\r\\nif port 843 is blocked.\\r\\n\\r\\n## Client-side Javascript must be reasonably tested\\r\\n\\r\\nSockJS is quite young and testing is not yet done properly. That said,\\r\\nwe have multiple end-to-end QUnit tests. At the moment are deployed in\\r\\nfew places:\\r\\n\\r\\n* [http://sockjs.popcnt.org/](http://sockjs.popcnt.org/) (hosted in Europe)\\r\\n* [http://sockjs.cloudfoundry.com/](http://sockjs.cloudfoundry.com/) (CloudFoundry, websockets disabled, loadbalanced)\\r\\n* [https://sockjs.cloudfoundry.com/](http://sockjs.cloudfoundry.com/) (CloudFoundry SSL, websockets disabled, loadbalanced)\\r\\n* [http://sockjs.herokuapp.com/](http://sockjs.herokuapp.com/) (Heroku, websockets disabled)\\r\\n\\r\\n## Server side code should be simple\\r\\n\\r\\nAt that point SockJS-node implementation is using about 1200 lines of\\r\\ncode in CoffeeScript. About 340 are used by WebSocket protocol, 220 by\\r\\na simple http abstractions and only around 230 are used by core SockJS\\r\\nlogic.\\r\\n\\r\\nThe SockJS protocol used between the browser and the server is already\\r\\nquite simple and we\'re working on making it even more obvious.\\r\\n\\r\\nWe do intend to support at least Node and Erlang servers and we would\\r\\nbe pleased to see Python and Ruby implementations as well. SockJS is\\r\\nintended to be polyglot.\\r\\n\\r\\n## Summary\\r\\n\\r\\nSockJS is quite young and there is loads of work remaining to be done,\\r\\nbut we believe it is stable enough for real applications. If you\'re\\r\\nplanning on doing realtime web apps, give it a try!\\r\\n(Article also published on [github pages](https://github.com/sockjs/sockjs-client/wiki/%5BArticle%5D-SockJS:-WebSocket-emulation-done-right))"},{"id":"/2011/09/09/rabbitmq-tracing-a-ui-for-the-firehose","metadata":{"permalink":"/rabbitmq-website/blog/2011/09/09/rabbitmq-tracing-a-ui-for-the-firehose","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-09-09-rabbitmq-tracing-a-ui-for-the-firehose/index.md","source":"@site/blog/2011-09-09-rabbitmq-tracing-a-ui-for-the-firehose/index.md","title":"rabbitmq-tracing - a UI for the firehose","description":"While the firehose is quite a cool feature, I always thought that it was a shame we didn\'t have a simple GUI to go on top and make it accessible to system administrators. So I wrote one. You can download it here.","date":"2011-09-09T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":1.95,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"rabbitmq-tracing - a UI for the firehose","tags":["New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"SockJS - WebSocket emulation","permalink":"/rabbitmq-website/blog/2011/09/13/sockjs-websocket-emulation"},"nextItem":{"title":"RabbitMQ on Heroku","permalink":"/rabbitmq-website/blog/2011/09/01/rabbitmq-on-heroku"}},"content":"While the [firehose](/docs/firehose) is quite a cool feature, I always thought that it was a shame we didn\'t have a simple GUI to go on top and make it accessible to system administrators. So I wrote one. You can download it [here](https://www.rabbitmq.com/releases/plugins/v2.6.1-tracing-preview/rabbitmq_tracing-2.6.1.ez).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n![](tracing.png)\\r\\n\\r\\nIt\'s an extension to the management plugin, and requires 2.6.0 / 2.6.1. Once you\'ve installed it and restarted Rabbit, you should see another tab labelled \\"Tracing\\" in management. (**Edit:** as of RabbitMQ 3.0.0, \\"Tracing\\" is under the \\"Admin\\" tab.) From here you can start and stop tracing, and download or delete log files. Hopefully the interface is fairly obvious.\\r\\n\\r\\nCurrently rabbitmq-tracing supports two log formats: **text** and **json**. **text** is designed to be human-readable, and looks like this:\\r\\n\\r\\n```\\r\\n================================================================================\\r\\n2011-9-9 10:57:24: Message published\\r\\n\\r\\nNode:         rabbit@smacmullen\\r\\nExchange:     direct\\r\\nRouting keys: [<<\\"5d07bff4-1708-4a5d-87f9-a14177d6681b\\">>]\\r\\nProperties:   []\\r\\nPayload: \\r\\nHello world\\r\\n\\r\\n================================================================================\\r\\n2011-9-9 10:57:24: Message received\\r\\n\\r\\nNode:         rabbit@smacmullen\\r\\nExchange:     direct\\r\\nQueue:        amq.gen-PJfnaKdg7AmsWmYTUeuApw==\\r\\nRouting keys: [<<\\"5d07bff4-1708-4a5d-87f9-a14177d6681b\\">>]\\r\\nProperties:   []\\r\\nPayload: \\r\\nHello world\\r\\n\\r\\n================================================================================\\r\\n```\\r\\n\\r\\n**json** is designed to be machine readable and consists of a file with one JSON structure per line. Note that this means the entire file is *not* itself a JSON structure, you need to split it by line first. (The reason for this is so that we can treat it like a normal log file and just append to it.)\\r\\n\\r\\nThere are two configuration options:\\r\\n\\r\\n* \\"directory\\". This controls where the log files go. It defaults to \\"/var/tmp/rabbitmq-tracing\\".\\r\\n* \\"username\\". The name of a user as which to create the tracing queues and bindings.\\r\\n\\r\\nA complete configuration might look like:\\r\\n\\r\\n```erlang\\r\\n[{rabbitmq_tracing, [{directory, \\"/my/log/file/location\\"},\\r\\n                     {username,  \\"guest\\"}]}].\\r\\n```\\r\\n\\r\\nAs with any new plugin there are of course a couple of caveats. On my workstation, rabbitmq-tracing can write about 2000 msg/s to a log file. You should be careful using rabbitmq-tracing if you think you\'re going to capture more messages than this. Of course, any messages that can\'t be logged are queued until they can be.\\r\\n\\r\\nAlso, the code to serve up the log files over HTTP is pretty dumb: it loads the whole log into memory (unfortunately webmachine doesn\'t really let us stream files). If you have large log files you may wish to transfer them off the server in some other way.\\r\\n\\r\\nSo, what do you think? Is this useful to you? How could it be extended?"},{"id":"/2011/09/01/rabbitmq-on-heroku","metadata":{"permalink":"/rabbitmq-website/blog/2011/09/01/rabbitmq-on-heroku","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-09-01-rabbitmq-on-heroku/index.md","source":"@site/blog/2011-09-01-rabbitmq-on-heroku/index.md","title":"RabbitMQ on Heroku","description":"We are very pleased to announce the availability in beta","date":"2011-09-01T00:00:00.000Z","tags":[{"inline":true,"label":"Cloud","permalink":"/rabbitmq-website/blog/tags/cloud"}],"readingTime":2.95,"hasTruncateMarker":true,"authors":[{"name":"Alexis Richardson","key":"alexis","page":null}],"frontMatter":{"title":"RabbitMQ on Heroku","tags":["Cloud"],"authors":["alexis"]},"unlisted":false,"prevItem":{"title":"rabbitmq-tracing - a UI for the firehose","permalink":"/rabbitmq-website/blog/2011/09/09/rabbitmq-tracing-a-ui-for-the-firehose"},"nextItem":{"title":"SockJS - web messaging ain\'t easy","permalink":"/rabbitmq-website/blog/2011/08/22/sockjs-web-messaging-aint-easy"}},"content":"We are very pleased to announce the availability in beta\\r\\nof [RabbitMQ as a Heroku\\r\\nadd-on](https://heroku.srs.rabbitmq.com/). With\\r\\nour [RabbitMQ\\r\\nservice on CloudFoundry](http://blog.cloudfoundry.com/post/8713844574/rabbitmq-cloud-foundry-cloud-messaging-that-just-works), this extends our commitment to\\r\\nsupporting the community of cloud application developers.\\r\\n\\r\\nWe believe that cloud messaging is fundamental in two senses. First\\r\\nas a core capability to build applications that scale to cloud use\\r\\ncases  as explained in\\r\\nour [blog\\r\\npost](http://blog.cloudfoundry.com/post/8713844574/rabbitmq-cloud-foundry-cloud-messaging-that-just-works) launching RabbitMQ on CloudFoundry. And second, because\\r\\nmessaging can be extended to solve common problems like integration\\r\\nand data push. For example: to connect traditional on-premise\\r\\napplications with virtualized and cloud deployments.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Why offer RabbitMQ as a service\\r\\n\\r\\nAs we talked to more and more customers about this, what stood out\\r\\nwas that people want more than \\"it just works\\". They\\r\\nalso want \\"it\'s just there\\". In other words people want\\r\\nubiquity, and convenience.\\r\\n\\r\\nThus it made sense for us to move beyond offering RabbitMQ as a\\r\\nproduct that you install and manage for every application\\r\\ninstance. RabbitMQ is now also a platform service. That means it is\\r\\ninstalled and operated by us to save you the overhead and worry of\\r\\nmanaging all your Rabbits yourself.\\r\\n\\r\\n## A big thank-you to Rapportive\\r\\n\\r\\nWe would like to take this opportunity to\\r\\nthank [the excellent Rapportive\\r\\nteam](http://rapportive.com/), who have helped us roadtest RabbitMQ on Heroku.\\r\\n\\r\\n[Sam Stokes](http://twitter.com/#!/samstokes), CTO of\\r\\nRapportive, has kindly provided us with the following testimonial:\\r\\n\\"RabbitMQ has been instrumental in scaling Rapportive. We now\\r\\nserve our users 65 million contact profiles per month.\\"\\r\\n\\r\\nHe goes on to say: \\"RabbitMQ holds Rapportive together: it\\r\\ndelivers requests to our highly concurrent web-crawling engine,\\r\\nroutes log entries for analytics, and lets us perform long-running\\r\\noperations without tying up our web servers. We ask it to juggle\\r\\nbillions of messages every month and it hasn\'t broken a sweat.  The\\r\\nRabbitMQ Heroku addon has saved us the weeks of effort we\'d have had\\r\\nto spend maintaining a RabbitMQ instance. We\'ve come to depend on\\r\\ntheir responsive support and domain expertise; they\'ve even given us\\r\\ntips to improve our application code!\\"\\r\\n\\r\\nWe look forward to seeing Rapportive go from strength to strength.\\r\\n\\r\\n## The first open cloud messaging service\\r\\n\\r\\nRabbitMQ and the Rabbit service demonstrate the power of \\"open\\r\\nPaaS\\" as described by VMware\'s CTO Steve Herrod in\\r\\na [blog\\r\\npost](http://blogs.vmware.com/console/2010/05/google-and-vmwares-open-paas-strategy.html) last year. In the open PaaS, platform services, eg queues\\r\\nand notifications, do not limit developers to just one cloud.\\r\\n\\r\\nBy offering the same RabbitMQ service on instances of CloudFoundry\\r\\nas well as on Heroku, we provide developers with convenience via a\\r\\nfamiliar programming model on multiple clouds. That delivers choice\\r\\nbecause messaging is available in the same place a developer chooses\\r\\nto deploy their application.\\r\\n\\r\\nAnd because RabbitMQ is open source, developers can set up their own\\r\\nmessaging capability for testing, or on their own servers behind the\\r\\nfirewall. This delivers a complete, consistent and portable\\r\\ndeployment model.\\r\\n\\r\\n## Getting started\\r\\n\\r\\nHeroku applications that use RabbitMQ may be built on any language\\r\\nsupported on the Heroku\\r\\ncloud. In [this\\r\\nblog post](http://blog.heroku.com/archives/2011/8/31/rabbitmq_add_on_now_available_on_heroku/), Morten Bagai introduces the steps required to build a\\r\\nfirst application. If you would like to try the add-on and are not\\r\\non the Heroku beta tester program please contact us.\\r\\n\\r\\nAnd: if you are at Dreamforce this week, please go and talk to Jerry\\r\\nKuch in the Developer Zone, who can show you the service.\\r\\n\\r\\nIf you write a cool application, please tell us about it. We\'ll\\r\\nmaintain a list of examples to show case the service, [as we are\\r\\ndoing with CloudFoundry](http://rabbitmq.cloudfoundry.com/)."},{"id":"/2011/08/22/sockjs-web-messaging-aint-easy","metadata":{"permalink":"/rabbitmq-website/blog/2011/08/22/sockjs-web-messaging-aint-easy","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-08-22-sockjs-web-messaging-aint-easy/index.md","source":"@site/blog/2011-08-22-sockjs-web-messaging-aint-easy/index.md","title":"SockJS - web messaging ain\'t easy","description":"The idea of \'realtime web\' or messaging using web browsers has been","date":"2011-08-22T00:00:00.000Z","tags":[{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging"}],"readingTime":4.595,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"SockJS - web messaging ain\'t easy","tags":["Web Messaging"],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"RabbitMQ on Heroku","permalink":"/rabbitmq-website/blog/2011/09/01/rabbitmq-on-heroku"},"nextItem":{"title":"Using the RabbitMQ service on Cloud Foundry with Node.JS","permalink":"/rabbitmq-website/blog/2011/08/16/using-the-rabbitmq-service-on-cloud-foundry-with-nodejs"}},"content":"The idea of \'realtime web\' or messaging using web browsers has been\\r\\naround for quite some time. First it was called \'long-polling\', then\\r\\n\'Comet\', the latest incarnation is named \'WebSockets\'.\\r\\nWithout doubt it\'s going in a good direction, WebSockets is a neat\\r\\ntechnology.\\r\\n\\r\\nBut during the fight for realtime capabilities we\'ve lost focus on\\r\\nwhat is really important  how to actually use messaging. In the web\\r\\ncontext everything is request-response driven and marrying a typical\\r\\nweb stack to asynchronous messaging isn\'t easy.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## The landscape\\r\\n\\r\\nThere were many attempts to create a generic component that could join\\r\\nthe web stack and just deal with \'messaging\' in a similar way to a\\r\\ndatabase dealing with data.\\r\\n\\r\\nThere is a problem though, the asynchronous nature of messaging and\\r\\nbrowser cross-domain restrictions mean that in order to get \'Comet\'\\r\\nworking, you need to use a particular web stack. A classic case of\\r\\nvendor lock-in.\\r\\n\\r\\n## The new approach\\r\\n\\r\\nAt least that\'s how it was in the past. You could have a web-messaging\\r\\nframework, but you were pretty much tied to it.\\r\\n\\r\\nUntil, not long ago, the [Socket.io](http://socket.io/) project emerged.\\r\\nIt\'s build on [Node.js](http://nodejs.org/), which gives it a unique\\r\\nposition  not only everything in Node.js is already fully\\r\\nasynchronous (there\'s almost no way to screw it up) but also it used a\\r\\ncommon language already used in the web environment.\\r\\n\\r\\nEarly Socket.io development focused on message delivery  in other\\r\\nwords how to get the messages to and from web browsers. The contract\\r\\nwith web developers was simple: here\'s an asynchronous transport\\r\\nlayer, you build your application logic in JavaScript on top of that.\\r\\n\\r\\nA developer needed to write a thin JavaScript layer that joined\\r\\nSocket.io connections with the application  the implementation\\r\\ndetails were left to developer. The application could be Node or using\\r\\nany other stack. It could be connected using just about any method,\\r\\nfor example Redis, RabbitMQ or HTTP callbacks.\\r\\n\\r\\nBut recently Socket.io changed focus, it\'s not a simple transport any\\r\\nmore  it starts to be a full messaging stack, featuring:\\r\\n\\r\\n* message acknowledgments\\r\\n* broadcasts / \\"rooms\\"\\r\\n* multiplexing\\r\\n* volatile messages\\r\\n\\r\\n## No silver bullet\\r\\n\\r\\nBut here\'s a catch: if you build messaging semantics the messaging\\r\\nlibrary starts to be a framework and quickly becomes tied to a\\r\\nplatform.\\r\\n\\r\\nThink about it, even if you try to build a simple \'broadcast\'\\r\\nabstraction, you inevitably need to answer many nonobvious questions:\\r\\n\\r\\n* How the application is going to be deployed?\\r\\n    (Limited to one server or scaling using an underlying message bus?\\r\\n     What message bus? How does it play with an HTTP load balancer?)\\r\\n* Who is authorized to \'subscribe\' to that broadcast data? Is it public?\\r\\n    How can you set permissions?\\r\\n* Who can publish messages? How can a subscriber reliably identify\\r\\n    the author of the message?\\r\\n\\r\\nBear in mind that \'broadcast\' is a very simple abstraction, in\\r\\npractice everyone uses messaging differently and it\'s very hard to\\r\\ncreate a generic messaging framework.\\r\\nMost of the decisions made by messaging framework are in fact\\r\\napplication specific:\\r\\n\\r\\n* Authorization (who can hear what and publish where)\\r\\n* Understanding of data (how do you do value + updates? What is the\\r\\n   diff algorithm?)\\r\\n* Presence (all applications need a slightly different meaning of that)\\r\\n\\r\\nI\'m glad Socket.io development is going well and I keep my fingers\\r\\ncrossed for it. But in my opinion it focuses on the wrong problem: I\\r\\ndon\'t need another opinionated messaging framework which is tied to a\\r\\nparticular platform.\\r\\n\\r\\nInstead, I only need a stable transport layer.\\r\\n\\r\\n## The next steps\\r\\n\\r\\nSocket.io showed the way - there is a room for a simple and stable\\r\\nlibrary that would solve the message-delivery problem, that would\\r\\nenable WebSockets-like API\'s until a native implementation is widely\\r\\ndeployed. All that without defining the messaging model, please.\\r\\n\\r\\nHere is my reply: [SockJS](https://github.com/sockjs/sockjs-client#readme) - a library\\r\\nwith WebSockets-like API that focuses only on the transport\\r\\nlayer. Although project is young, in my opinion it\'s already better\\r\\nthan other libraries like that.\\r\\n\\r\\nThe project is split in two parts:\\r\\n\\r\\n* Browser JavaScript library:\\r\\n   [SockJS-client](https://github.com/sockjs/sockjs-client#readme)\\r\\n* Server-side component for node:\\r\\n   [SockJS-node](https://github.com/sockjs/sockjs-node#readme)\\r\\n\\r\\nIf you want to see it running, here are a few live deployments hosting\\r\\nQUnit tests:\\r\\n\\r\\n* [http://sockjs.popcnt.org/](http://sockjs.popcnt.org/) (hosted in Europe)\\r\\n* [http://sockjs.cloudfoundry.com/](http://sockjs.cloudfoundry.com/) (CloudFoundry, websockets disabled)\\r\\n* [https://sockjs.cloudfoundry.com/](https://sockjs.cloudfoundry.com/) (CloudFoundry SSL, websockets disabled)\\r\\n* [http://sockjs.herokuapp.com/](http://sockjs.herokuapp.com/) (Heroku, websockets disabled)\\r\\n\\r\\nThere main assumptions behind SockJS are:\\r\\n\\r\\n* The API should be modeled as close to WebSocket API as possible.\\r\\n* The server side part should be simple, all the complexity should be\\r\\n   handled by the browser library. (With the assumption that there is\\r\\n   only a single browser library and there will be many server-side\\r\\n   implementations. We have a SockJS Node server and we\'d like to do\\r\\n   at least an Erlang one.)\\r\\n* No Flash inside, only JavaScript.\\r\\n* Fallback to slow and dumb polling transports, useful when the\\r\\n   clients are behind corporate firewalls and proxies.\\r\\n* All transports must be cross-domain - developers must be able to\\r\\n   host SockJS server as a separate part of their infrastructure.\\r\\n* Supports common load-balancing strategies: using sticky sessions\\r\\n   based on JSESSIONID cookie or prefix-based balancing.\\r\\n\\r\\n## The future\\r\\n\\r\\nSolving message delivery problem is just a first step. The ultimate\\r\\ngoal is to create a generic messaging framework for web apps, but it\'s\\r\\nnot going to be easy. It\'ll take a lot of work and many failed\\r\\nattempts. That\'s why it\'s so important to have a stable, well\\r\\ndesigned, reusable transport layer handy.\\r\\n\\r\\n(Article also available on [github pages](https://github.com/sockjs/sockjs-client/wiki/%5BArticle%5D-SockJS:-web-messaging-ain%E2%80%99t-easy))"},{"id":"/2011/08/16/using-the-rabbitmq-service-on-cloud-foundry-with-nodejs","metadata":{"permalink":"/rabbitmq-website/blog/2011/08/16/using-the-rabbitmq-service-on-cloud-foundry-with-nodejs","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-08-16-using-the-rabbitmq-service-on-cloud-foundry-with-nodejs/index.md","source":"@site/blog/2011-08-16-using-the-rabbitmq-service-on-cloud-foundry-with-nodejs/index.md","title":"Using the RabbitMQ service on Cloud Foundry with Node.JS","description":"Recently we launched a RabbitMQ service for Cloud Foundry, making it simple to spin up a message broker to use with your apps on Cloud Foundry. There are tutorials online for using it with Ruby on Rails and with Java apps using Spring. Here we are going to look at using the RabbitMQ service with Node.JS apps.","date":"2011-08-16T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":4.05,"hasTruncateMarker":true,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"Using the RabbitMQ service on Cloud Foundry with Node.JS","tags":["HowTo"],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"SockJS - web messaging ain\'t easy","permalink":"/rabbitmq-website/blog/2011/08/22/sockjs-web-messaging-aint-easy"},"nextItem":{"title":"RabbitMQ + Cloud Foundry: Cloud Messaging that Just Works","permalink":"/rabbitmq-website/blog/2011/08/10/rabbitmq-cloud-foundry-cloud-messaging-that-just-works"}},"content":"Recently we launched a [RabbitMQ service for Cloud Foundry](http://blog.cloudfoundry.com/post/8713844574/rabbitmq-cloud-foundry-cloud-messaging-that-just-works), making it simple to spin up a message broker to use with your apps on Cloud Foundry. There are tutorials online for using it with Ruby on Rails and with Java apps using Spring. Here we are going to look at using the RabbitMQ service with Node.JS apps.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nI\'m not assuming too much prior knowledge of Node.JS, npm or RabbitMQ; but, you\'ll get more out of this if you\'re acquainted with them all. The [man page for npm](https://github.com/isaacs/npm/blob/master/doc/npm.md), and its accompanying [information for developers](https://github.com/isaacs/npm/blob/master/doc/developers.md#readme) are the best guide, barring actual use, to understanding npm. For RabbitMQ, I recommend Michael Klishin\'s [primer on the AMQP messaging model](http://rubydoc.info/github/ruby-amqp/amqp/master/file/docs/AMQP091ModelExplained.textile).\\r\\n\\r\\n[This repository on github](https://github.com/rabbitmq/rabbitmq-cloudfoundry-samples/tree/master/nodejs) has the source code for our Node.JS example. Let\'s walk through it first the `package.json`:\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\"name\\":\\"node-srs-demo\\",\\r\\n  \\"author\\": \\"Michael Bridgen\\",\\r\\n  \\"version\\":\\"0.0.2\\",\\r\\n  \\"dependencies\\":{\\r\\n    \\"amqp\\":\\">= 0.1.0\\",\\r\\n    \\"sanitizer\\": \\"*\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nThe item of interest in there is the dependency on \\"amqp\\"; version 0.1.0 supports the URL syntax that Cloud Foundry will supply, and there\'s no reason not to use the latest and greatest.\\r\\n\\r\\nHere\'s the first bit of application code. Note that we call the file `app.js` so Cloud Foundry will recognise it as the main module and run it.\\r\\n\\r\\n```javascript\\r\\nrequire.paths.unshift(\'./node_modules\');\\r\\n\\r\\nvar http = require(\'http\');\\r\\nvar amqp = require(\'amqp\');\\r\\nvar URL = require(\'url\');\\r\\nvar htmlEscape = require(\'sanitizer/sanitizer\').escape;\\r\\n\\r\\nfunction rabbitUrl() {\\r\\n  if (process.env.VCAP_SERVICES) {\\r\\n    conf = JSON.parse(process.env.VCAP_SERVICES);\\r\\n    return conf[\'rabbitmq-2.4\'][0].credentials.url;\\r\\n  }\\r\\n  else {\\r\\n    return \\"amqp://localhost\\";\\r\\n  }\\r\\n}\\r\\n\\r\\nvar port = process.env.VCAP_APP_PORT || 3000;\\r\\n```\\r\\n\\r\\nFirst of all we\'re making sure Node.JS knows where our libraries are.  Using `npm install` in the working directory will install them in a subdirectory called `node_modules`, and when we push to Cloud Foundry they\'ll be copied across with `app.js`.\\r\\n\\r\\nOur service connection details come as a JSON object in the environment; the procedure `rabbitUrl` parses that and extracts the URL for the RabbitMQ service. In principle we could have more than one RabbitMQ service instance bound to the application -- we\'re assuming here we just want the first (and probably only) such instance. That\'s the `[0]` bit.\\r\\n\\r\\n```javascript\\r\\nvar messages = [];\\r\\n\\r\\nfunction setup() {\\r\\n\\r\\n  var exchange = conn.exchange(\'cf-demo\', {\'type\': \'fanout\', durable: false}, function() {\\r\\n\\r\\n    var queue = conn.queue(\'\', {durable: false, exclusive: true},\\r\\n    function() {\\r\\n      queue.subscribe(function(msg) {\\r\\n        messages.push(htmlEscape(msg.body));\\r\\n        if (messages.length > 10) {\\r\\n          messages.shift();\\r\\n        }\\r\\n      });\\r\\n      queue.bind(exchange.name, \'\');\\r\\n    });\\r\\n    queue.on(\'queueBindOk\', function() { httpServer(exchange); });\\r\\n  });\\r\\n}\\r\\n```\\r\\n\\r\\nThis is a procedure we\'re going to invoke later to creates all the things we need in our RabbitMQ instance.\\r\\n\\r\\nSince everything in the client is an asynchronous operation there\'s a lot of callbacks. The nesting is determined by when we need the results; specifically, we need the queue in order to subscribe, and we need the queue *and* the exchange in order to bind the queue. Note the empty name given for the queue -- this indicates that the queue is to be anonymous, in other words given a randomly generated name by RabbitMQ.\\r\\n\\r\\nWe can skip right back out the scopes for the last callback (the one that starts the HTTP server) since we know everything has been done by then.\\r\\n\\r\\nThe next part of the code is where we\'re responding to HTTP requests:\\r\\n\\r\\n```javascript\\r\\nfunction httpServer(exchange) {\\r\\n  var serv = http.createServer(function(req, res) {\\r\\n    var url = URL.parse(req.url);\\r\\n    if (req.method == \'GET\' &amp;&amp; url.pathname == \'/env\') {\\r\\n      printEnv(res);\\r\\n    }\\r\\n    else if (req.method == \'GET\' &amp;&amp; url.pathname == \'/\') {\\r\\n      res.statusCode = 200;\\r\\n      openHtml(res);\\r\\n      writeForm(res);\\r\\n      writeMessages(res);\\r\\n      closeHtml(res);\\r\\n    }\\r\\n    else if (req.method == \'POST\' &amp;&amp; url.pathname == \'/\') {\\r\\n      chunks = \'\';\\r\\n      req.on(\'data\', function(chunk) { chunks += chunk; });\\r\\n      req.on(\'end\', function() {\\r\\n        msg = unescapeFormData(chunks.split(\'=\')[1]);\\r\\n        exchange.publish(\'\', {body: msg});\\r\\n        res.statusCode = 303;\\r\\n        res.setHeader(\'Location\', \'/\');\\r\\n        res.end();\\r\\n      });\\r\\n    }\\r\\n    else {\\r\\n      res.statusCode = 404;\\r\\n      res.end(\\"This is not the page you were looking for.\\");\\r\\n    }\\r\\n  });\\r\\n  serv.listen(port);\\r\\n}\\r\\n```\\r\\n\\r\\nThe RabbitMQ bit is right in the middle, where we publish a message to our exchange from earlier. The Node.JS AMQP library will happily publish an object, serialising it as a JSON value; the subscribe method we used earlier assumes a JSON payload and parses it to an object.\\r\\n\\r\\nThe rest of app.js is just helpers, except for the line that kicks the whole thing off (so far we\'ve only written callbacks!):\\r\\n\\r\\n```javascript\\r\\nvar conn = amqp.createConnection({url: rabbitUrl()});\\r\\nconn.on(\'ready\', setup);\\r\\n```\\r\\n\\r\\nYou can see the overall control flow is simply\\r\\n\\r\\n1. Open a connection to RabbitMQ; when that\'s done,\\r\\n1. Construct an exchange and a queue, bind the queue to the exchange and subscribe to the queue; then\\r\\n1. Start the HTTP listener.\\r\\n\\r\\nWith this code, I have erred on the side of spelling things out. There is of course plenty of room for abstraction, for example in the exchange-queue-bind-subscribe pattern which I\'d expect to recur often in apps.\\r\\n\\r\\nFor help with RabbitMQ on Cloud Foundry, join in the forum at [support.cloudfoundry.com](http://support.cloudfoundry.com/forums/373011-community-q-a)."},{"id":"/2011/08/10/rabbitmq-cloud-foundry-cloud-messaging-that-just-works","metadata":{"permalink":"/rabbitmq-website/blog/2011/08/10/rabbitmq-cloud-foundry-cloud-messaging-that-just-works","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-08-10-rabbitmq-cloud-foundry-cloud-messaging-that-just-works/index.md","source":"@site/blog/2011-08-10-rabbitmq-cloud-foundry-cloud-messaging-that-just-works/index.md","title":"RabbitMQ + Cloud Foundry: Cloud Messaging that Just Works","description":"Today we launched a RabbitMQ service on CloudFoundry.com. This service brings the messaging functionality  of RabbitMQ to developers building applications on Cloud Foundry. You can read the main announcement over on the Cloud Foundry blog. There\'s also an FAQ with more details on the Cloud Foundry knowledge base.  CloudFoundry.com is a free beta service.  So please register there (if you haven\'t already), then take a look at the RabbitMQ service, try out the sample apps, and write your own.  And tell us how to make it better.","date":"2011-08-10T00:00:00.000Z","tags":[{"inline":true,"label":"Cloud","permalink":"/rabbitmq-website/blog/tags/cloud"}],"readingTime":0.435,"hasTruncateMarker":false,"authors":[{"name":"David Wragg","key":"david","page":null}],"frontMatter":{"title":"RabbitMQ + Cloud Foundry: Cloud Messaging that Just Works","tags":["Cloud"],"authors":["david"]},"unlisted":false,"prevItem":{"title":"Using the RabbitMQ service on Cloud Foundry with Node.JS","permalink":"/rabbitmq-website/blog/2011/08/16/using-the-rabbitmq-service-on-cloud-foundry-with-nodejs"},"nextItem":{"title":"Puka - rethinking AMQP clients","permalink":"/rabbitmq-website/blog/2011/07/08/puka-rethinking-amqp-clients"}},"content":"Today we launched a RabbitMQ service on [CloudFoundry.com](http://cloudfoundry.com/). This service brings the messaging functionality  of RabbitMQ to developers building applications on Cloud Foundry. You can read [the main announcement](http://blog.cloudfoundry.com/post/8713844574/rabbitmq-cloud-foundry-cloud-messaging-that-just-works) over on the Cloud Foundry blog. There\'s also [an FAQ with more details](http://support.cloudfoundry.com/entries/20334618-rabbitmq-service-faq) on the Cloud Foundry knowledge base.  CloudFoundry.com is a free beta service.  So please register there (if you haven\'t already), then take a look at the RabbitMQ service, try out the sample apps, and write your own.  And tell us how to make it better."},{"id":"/2011/07/08/puka-rethinking-amqp-clients","metadata":{"permalink":"/rabbitmq-website/blog/2011/07/08/puka-rethinking-amqp-clients","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-07-08-puka-rethinking-amqp-clients/index.md","source":"@site/blog/2011-07-08-puka-rethinking-amqp-clients/index.md","title":"Puka - rethinking AMQP clients","description":"I fundamentally disagree with the APIs exposed by our current AMQP client libraries.","date":"2011-07-08T00:00:00.000Z","tags":[],"readingTime":4.425,"hasTruncateMarker":true,"authors":[{"name":"Marek Majkowski","key":"marek","page":null}],"frontMatter":{"title":"Puka - rethinking AMQP clients","tags":[],"authors":["marek"]},"unlisted":false,"prevItem":{"title":"RabbitMQ + Cloud Foundry: Cloud Messaging that Just Works","permalink":"/rabbitmq-website/blog/2011/08/10/rabbitmq-cloud-foundry-cloud-messaging-that-just-works"},"nextItem":{"title":"ZeroMQ =/= Erlang","permalink":"/rabbitmq-website/blog/2011/06/30/zeromq-erlang"}},"content":"I fundamentally disagree with the APIs exposed by our current AMQP client libraries.\\r\\n\\r\\nThere is a reason why they\'re imperfect: we intentionally avoided innovation in APIs since the beginning. The purpose of our client libraries is to expose generic AMQP, not any one view of messaging. But, in my opinion, trying to map AMQP directly to client libraries APIs is just wrong and results in over-complication and abstractions hard to use.\\r\\n\\r\\nThere is no common ground: the client libraries blindly following AMQP model will be complex; easy to use client libraries must to be opinionated.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## 1. Channels\\r\\n\\r\\nThe main problem with client libraries following the protocol is caused by the nature of AMQP channels. Channels are often explained as an abstraction matching an operating system thread - you may have many of those, and each one is synchronous.\\r\\n\\r\\nThat\'s all good, but an AMQP channel is not limited to being a thread - It\'s so much more than that: error scope, transaction scope, ordering guarantee and scope for acks.\\r\\n\\r\\nThe programmer may decide to use many channels within a single thread, or the opposite: many threads may need to work on a single channel.\\r\\n\\r\\nThe example of the first situation: forwarding messages between two queues (one channel for publishing, one for consuming). Second situation: splitting work from one channel between multiple worker threads (in order to share basic.qos quota between workers).\\r\\n\\r\\nInevitably, an author of a client library must make a decision on the relationship between a channel and a thread. It may sound boring if you\'re from .NET/Java background - these frameworks are opinionated about threading. But assuming anything about threading model in a third party library is a very bad practice in some languages, for example C and Python.\\r\\n\\r\\nWe can repeat almost the same discussion for the problem of handling multiple connections. For example a single thread may need to speak to two connections.\\r\\n\\r\\nEvery client library author must answer the following two questions:\\r\\n* Is it possible to run multiple synchronous methods, on multiple channels, at the same time?\\r\\n* Is it possible to run multiple connections, from a single thread?\\r\\n\\r\\nTwo questions - four possible choices:\\r\\n\\r\\n|Blocking on multiple channels|Handling multiple connections from a single thread||\\r\\n|--- |--- |--- |\\r\\n|no|no|simple blocking client (pyamqplib)|\\r\\n|no|yes|semi-asynchronous client (pika 0.5.2)|\\r\\n|yes|no|threaded clients (rabbitmq-java, rabbitmq-dotnet)|\\r\\n|yes|yes|fully asynchronous client (puka)|\\r\\n\\r\\n## 2. Error handling\\r\\n\\r\\nThe next problem is error handling. Using some of the client libraries it\'s virtually impossible to catch a AMQP error and recover from it without having to restart the whole program. This is often caused by users not understanding the nature of channels as error scope. But the libraries don\'t make dealing with errors easy: you get a channel error, now what? For example, doing basic.publish may kill your channel, in theory at any time.\\r\\n\\r\\n## 3. Synchronous publish\\r\\n\\r\\nThe last broken thing is the lack of support for synchronous publish. It wasn\'t practically possible to make sure a message got delivered to the broker before RabbitMQ extended AMQP to support \'confirms\'. The only solution was to use transactions, which slowed publishing radically. Now, with \'confirms\' it\'s possible but rather hard - as well as writing a callback a user needs to maintain a lock between a library thread and user thread, which requires understanding of the library threading model.\\r\\n\\r\\n## The birth\\r\\n\\r\\nOut of this frustration a new experimental Python client was born: [Puka](https://github.com/majek/puka#readme).\\r\\n\\r\\nPuka tries to provide simple APIs to the underlying AMQP protocol and reasonable error handling. The major features of Puka:\\r\\n\\r\\n* Single threaded. It doesn\'t make any assumptions about underlying threading model; the user may write a thin threaded layer on top of Puka if required.\\r\\n* It\'s possible to mix synchronous and asynchronous programming styles.\\r\\n* AMQP Errors are predictable and recoverable.\\r\\n* Basic.publish can be synchronous or asynchronous, as you wish.\\r\\n\\r\\nThe anti-features of Puka:\\r\\n* AMQP Channels are not exposed to the user.\\r\\n* Removed support for some AMQP features, most notably heartbeats.\\r\\n\\r\\n## Code snippets\\r\\n\\r\\nAs a teaser, here are a few code snippets. \\r\\n\\r\\nDeclare 1000 queues, one by one:\\r\\n\\r\\n```python\\r\\nfor i in range(1000):\\r\\n    promise = client.queue_declare(queue=\'a%04i\' % i)\\r\\n    client.wait(promise)\\r\\n```\\r\\n\\r\\nDeclare 1000 queues in parallel:\\r\\n\\r\\n```python\\r\\npromises = [client.queue_declare(queue=\'a%04i\' % i) for i in range(1000)]\\r\\nfor promise in promises:\\r\\n    client.wait(promise)\\r\\n```\\r\\n\\r\\nAsynchronous publish:\\r\\n\\r\\n```python\\r\\nclient.basic_publish(exchange=\'\', routing_key=\'test\',\\r\\n                     body=\\"Hello world!\\")\\r\\n```\\r\\n\\r\\nSynchronous publish:\\r\\n\\r\\n```python\\r\\npromise = client.basic_publish(exchange=\'\', routing_key=\'test\',\\r\\n                              body=\\"Hello world!\\")\\r\\nclient.wait(promise)\\r\\n```\\r\\n\\r\\nAMQP errors don\'t affect other parts of your program (publishes, consumes, etc). For example if a \'test\' queue was already declared as \'durable\', and you try to redeclare it without a proper flag you\'ll get an error:\\r\\n\\r\\n```python\\r\\n> promise = client.queue_declare(queue=\'test\')\\r\\n> client.wait(promise)\\r\\nTraceback (most recent call last):\\r\\n[...]\\r\\npuka.spec_exceptions.PreconditionFailed: {\'class_id\': 50, \'method_id\': 10,\\r\\n    \'reply_code\': 406, \'reply_text\': \\"PRECONDITION_FAILED - parameters for queue\\r\\n    \'test\' in vhost \'/\' not equivalent\\"}\\r\\n```\\r\\n\\r\\nIn Puka you may simply catch this exception and continue:\\r\\n\\r\\n```python\\r\\ntry:\\r\\n   promise = client.queue_declare(queue=\'test\')\\r\\n   client.wait(promise)\\r\\nexcept puka.PreconditionFailed:\\r\\n    # Oh, sorry. Forgot it was durable.\\r\\n   promise = client.queue_declare(queue=\'test\', durable=True)\\r\\n   client.wait(promise)\\r\\n```\\r\\n\\r\\nYou may take a look at [Puka code for RabbitMQ tutorials](https://github.com/rabbitmq/rabbitmq-tutorials/tree/master/python-puka) and Puka [examples](https://github.com/majek/puka/tree/master/examples) and [tests](https://github.com/majek/puka/tree/master/tests).\\r\\n\\r\\n## Summary\\r\\n\\r\\nIn summary, Puka provides a simpler APIs, flexible programming model, proper error handling and doesn\'t make any decisions on threading. It makes using AMQP fun again."},{"id":"/2011/06/30/zeromq-erlang","metadata":{"permalink":"/rabbitmq-website/blog/2011/06/30/zeromq-erlang","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-06-30-zeromq-erlang/index.md","source":"@site/blog/2011-06-30-zeromq-erlang/index.md","title":"ZeroMQ =/= Erlang","description":"Recently I saw a tweet saying \\"ZeroMQ Erlangizes everything!\\" or some such. While I realise that not everything posted on the web is meant seriously, it does seem there is a stream of similar claims lately that ought to be dammed.","date":"2011-06-30T00:00:00.000Z","tags":[{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"}],"readingTime":2.36,"hasTruncateMarker":true,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"ZeroMQ =/= Erlang","tags":["Programming Languages"],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"Puka - rethinking AMQP clients","permalink":"/rabbitmq-website/blog/2011/07/08/puka-rethinking-amqp-clients"},"nextItem":{"title":"Federation plugin preview release","permalink":"/rabbitmq-website/blog/2011/06/22/federation-plugin-preview-release"}},"content":"Recently I saw a tweet saying \\"ZeroMQ Erlangizes everything!\\" or some such. While I realise that not everything posted on the web is meant seriously, it does seem there is a stream of similar claims lately that ought to be dammed.\\r\\n\\r\\nIn the article Multi-threading Magic[^1], Pieter Hintjens and Martin Sustrik persuasively explain why concurrency is better served by message-passing than by locks and shared memory. And they are fair, I think, in their analysis -- except for the insinuation that using ZeroMQ transforms your chosen programming language into a domestic Erlang.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nMid-way through there is a sleight-of-hand. After mentioning the ingredients of Erlang, the article chooses just one of them -- message passing -- to be the key ingredient, and ignores the rest. But the others are at least as important! Let\'s look at all of them:\\r\\n\\r\\n* Fast process creation/destruction\\r\\n* Ability to support » 10 000 concurrent processes with largely unchanged characteristics.\\r\\n\\r\\nA programming model where processes are lightweight values -- and a good scheduler -- make concurrent programming much easier, in a similar way to garbage collection. It frees you from resource micro-management so you can spend more time reasoning about other things.\\r\\n\\r\\n* Fast asynchronous message passing.\\r\\n\\r\\nThis is what ZeroMQ gives you. But it gives you it in a form different to that of Erlang: in Erlang, processes are values and message-passing channels are anonymous; in ZeroMQ, channels are values and processes are anonymous. ZeroMQ is more like Go than Erlang. If you want the actor model (that Erlang is based on), you have to encode it in your language of choice, yourself.\\r\\n\\r\\n* Copying message-passing semantics (share-nothing concurrency).\\r\\n\\r\\nNotably, Erlang enforces this. In other languages, shared memory and the trap of using it (usually unwittingly) doesn\'t go away.\\r\\n\\r\\n* Process monitoring.\\r\\n\\r\\nErlang comes with a substantial library, battle-tested over decades, for building highly concurrent, distributed, and fault-tolerant systems. Crucial to this is process monitoring -- notification of process termination. This allows sophisticated process management strategies; in particular, using supervisor hierarchies to firewall core parts of the system from more failure-prone parts of the system.\\r\\n\\r\\n* Selective message reception.\\r\\n\\r\\nYou can use poll with ZeroMQ to efficiently use many channels in a single process at once; however, you don\'t get to block on particular kinds of message, meaning you have to buffer messages you don\'t want to deal with yet, or keep complex state around.\\r\\n\\r\\nZeroMQ is a lovely bit of kit, I would not argue otherwise. My point is that it does not magically give you fool-proof concurrent programming; neither does Erlang, but it\'s an awful lot further ahead than you may have been led to believe. With ZeroMQ there are still a number of things you have to invent, mimicking Erlang or otherwise.\\r\\n\\r\\n[^1]: [Multi-threading Magic](http://www.zeromq.org/whitepapers:multithreading-magic). It\'s well worth a read."},{"id":"/2011/06/22/federation-plugin-preview-release","metadata":{"permalink":"/rabbitmq-website/blog/2011/06/22/federation-plugin-preview-release","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-06-22-federation-plugin-preview-release/index.md","source":"@site/blog/2011-06-22-federation-plugin-preview-release/index.md","title":"Federation plugin preview release","description":"Note: this blog post talks about the federation plugin preview that was released for RabbitMQ 2.5.0. If you\'re using 2.6.0 or later, federation is part of the main release; get it the same way you would any other plugin.","date":"2011-06-22T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.815,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Federation plugin preview release","tags":["HowTo","New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"ZeroMQ =/= Erlang","permalink":"/rabbitmq-website/blog/2011/06/30/zeromq-erlang"},"nextItem":{"title":"RabbitMQ 2.5.0 released","permalink":"/rabbitmq-website/blog/2011/06/16/rabbitmq-250-released"}},"content":"**Note: this blog post talks about the federation plugin preview that was released for RabbitMQ 2.5.0. If you\'re using 2.6.0 or later, federation is part of the main release; get it the same way you would any other plugin.**\\r\\n\\r\\nAnother day, another new plugin release :smiley: Today it\'s **federation**. If you want to skip this post and just download the plugin, go [here](https://www.rabbitmq.com/releases/plugins/v2.5.0-federation-preview/). The detailed instructions are [here](http://hg.rabbitmq.com/rabbitmq-federation/file/rabbitmq_v2_5_0_preview/README).\\r\\n\\r\\nThe high level goal of federation is to scale out publish / subscribe messaging across WANs and administrative domains.\\r\\n\\r\\nTo do this we introduce the concept of the **federation exchange**. A federation exchange acts like a normal exchange of a given type (it can emulate the routing logic of any installed exchange type), but also knows how to connect to **upstream** exchanges (which might in turn themselves be federation exchanges).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nQueues that bind to a federation exchange receive messages that were published to the upstream exchanges (or the upstreams\' upstreams) as well as messages that are published locally. In the event of the network going down, messages will be queued upstream.\\r\\n\\r\\nSo how does this differ from clustering?\\r\\n\\r\\n|Federation|Clustering|\\r\\n|--- |--- |\\r\\n|Brokers are logically separate and may have different owners.|A cluster forms a single logical broker.|\\r\\n|Brokers can run different versions of RabbitMQ and Erlang.|Nodes must run the same version of RabbitMQ, and frequently Erlang.|\\r\\n|Brokers can be connected via unreliable WAN links. Communication is via AMQP (optionally secured by SSL).|Brokers must be connected via reliable LAN links. Communication is via Erlang internode messaging.|\\r\\n|Brokers can be connected in whatever topology you arrange. Links can be one- or two-way.|All nodes connect to all other nodes in both directions.|\\r\\n|Chooses Availability and Partition Tolerance from the [CAP theorem](http://en.wikipedia.org/wiki/CAP_theorem).|Chooses Consistency and Availability from the CAP theorem.|\\r\\n|Some exchanges in a broker may be federated while some may be local.|Clustering is all-or-nothing.|\\r\\n|A client connecting to any broker can only see queues in that broker.|A client connecting to any node can see queues on all nodes.|\\r\\n\\r\\nThe [README](http://hg.rabbitmq.com/rabbitmq-federation/file/rabbitmq_v2_5_0_preview/README) contains detailed instructions for getting things working, but let\'s look at a simple example.\\r\\n\\r\\nSuppose we have three brokers, `london`, `paris` and `newyork`. We want a federated `topic` exchange called `stocks` (sorry for the predictable example...). We\'ll look at how the `london` broker is configured to federate with `paris` and `newyork`.\\r\\n\\r\\nThis is what a simple `rabbitmq.config` file would look like for `london`:\\r\\n```erlang\\r\\n[\\r\\n  {rabbitmq_federation,\\r\\n   [{exchanges, [[{exchange,     \\"stocks\\"},\\r\\n                  {virtual_host, \\"/\\"},\\r\\n                  {type,         \\"topic\\"},\\r\\n                  {durable,      true},\\r\\n                  {auto_delete,  false},\\r\\n                  {internal,     false},\\r\\n                  {upstream_set, \\"common-upstreams\\"}]]},\\r\\n    {upstream_sets, [{\\"common-upstreams\\", [[{connection, \\"newyork\\"}],\\r\\n                                           [{connection, \\"paris\\"}]]}\\r\\n                    ]},\\r\\n    {connections, [{\\"newyork\\", [{host, \\"newyork.mycompany.com\\"}]},\\r\\n                   {\\"paris\\",   [{host, \\"paris.mycompany.com\\"}, {protocol, \\"amqps\\"},\\r\\n                                {username, \\"my-user\\"}, {password, \\"secret\\"}]}\\r\\n                  ]},\\r\\n    {local_username, \\"my-user\\"}\\r\\n   ]}\\r\\n].\\r\\n```\\r\\n\\r\\nThe rabbitmq_federation application has several options configured.\\r\\n\\r\\nFirstly we configure an exchange to declare. (You can declare federation exchanges via AMQP - see the [README](http://hg.rabbitmq.com/rabbitmq-federation/file/rabbitmq_v2_5_0_preview/README) - but since they can require some coordination to set up it is often more convenient to declare them in the configuration file).\\r\\n\\r\\nEach federated exchange needs the name of an \\"upstream set\\" to work with - a set of upstream machines to connect to - so we set one of those up.\\r\\n\\r\\nThen we list how to make each connection. There are quite a few options here; see the [README](http://hg.rabbitmq.com/rabbitmq-federation/file/rabbitmq_v2_5_0_preview/README).\\r\\n\\r\\nFinally we specify the name of the local user that should be considered to be injecting messages from the upstream brokers.\\r\\n\\r\\nWhen we bring the `london` broker up, we should see messages in the log like:\\r\\n```\\r\\n=INFO REPORT==== 22-Jun-2011::12:16:42 ===\\r\\nFederation exchange \'stocks\' in vhost \'/\' connected to newyork.mycompany.com:5672:/:stocks\\r\\n\\r\\n=INFO REPORT==== 22-Jun-2011::12:16:43 ===\\r\\nFederation exchange \'stocks\' in vhost \'/\' connected to paris.mycompany.com:5671:/:stocks\\r\\n```\\r\\n\\r\\nand the exchange will now receive messages published remotely.\\r\\n\\r\\nIn this case we would probably also configure the other brokers to federate with `london`, but this is not the only way you can do things - for example you can connect brokers in a unidirectional ring, or do massive fanout with brokers in a tree structure.\\r\\n\\r\\nThere are of course limitations, since this is a preview release. The worst is that **federation is not compatible with clustering**. You shouldn\'t use the federation plugin in a cluster. This is the first thing we\'re going to fix.\\r\\n\\r\\nThere are other limitations too: You can\'t federate headers exchanges. You can\'t change which machines you federate with unless you restart the broker. There\'s no status reporting (except for the messages written to the log). Again these will get fixed.\\r\\n\\r\\nSo - is this useful to you? What do you think? (Reminder: download it [here](https://www.rabbitmq.com/releases/plugins/v2.5.0-federation-preview/)). Let us know in comments here, or on the [rabbitmq-discuss](https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss) mailing list."},{"id":"/2011/06/16/rabbitmq-250-released","metadata":{"permalink":"/rabbitmq-website/blog/2011/06/16/rabbitmq-250-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-06-16-rabbitmq-250-released/index.md","source":"@site/blog/2011-06-16-rabbitmq-250-released/index.md","title":"RabbitMQ 2.5.0 released","description":"The RabbitMQ team is delighted to announce the release of RabbitMQ 2.5.0.","date":"2011-06-16T00:00:00.000Z","tags":[],"readingTime":0.71,"hasTruncateMarker":true,"authors":[{"name":"Jerry Kuch","key":"jerry","page":null}],"frontMatter":{"title":"RabbitMQ 2.5.0 released","tags":[],"authors":["jerry"]},"unlisted":false,"prevItem":{"title":"Federation plugin preview release","permalink":"/rabbitmq-website/blog/2011/06/22/federation-plugin-preview-release"},"nextItem":{"title":"Can you hear the drums, Erlando?","permalink":"/rabbitmq-website/blog/2011/05/17/can-you-hear-the-drums-erlando"}},"content":"The RabbitMQ team is delighted to announce the release of RabbitMQ 2.5.0.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThis release fixes a number of bugs. In particular:\\r\\n\\r\\n* recovery has been simplified, improving startup times when many exchanges or bindings exist\\r\\n* bindings are recovered between durable queues and non-durable exchanges on restart of individual cluster nodes\\r\\n* better performance under high load and memory pressure\\r\\n* source compatibility with the new Erlang R14B03 release\\r\\n\\r\\nNew features include:\\r\\n\\r\\n* tracing facility for debugging incoming and outgoing messages, (see [firehose](/docs/firehose))\\r\\n* improved inbound network performance\\r\\n* improved routing performance\\r\\n* new rabbitmqctl commands (\'report\', \'environment\', and \'cluster_status\')\\r\\n\\r\\nFor details see the [release notes](http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2011-June/013249.html).\\r\\n\\r\\nAs always, we welcome any questions, bug reports, and other feedback on this release, as well as general suggestions for features and enhancements in future releases. Mail us via the RabbitMQ [discussion list](https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss), or directly at [info@rabbitmq.com](mailto:info@rabbitmq.com)."},{"id":"/2011/05/17/can-you-hear-the-drums-erlando","metadata":{"permalink":"/rabbitmq-website/blog/2011/05/17/can-you-hear-the-drums-erlando","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-05-17-can-you-hear-the-drums-erlando/index.md","source":"@site/blog/2011-05-17-can-you-hear-the-drums-erlando/index.md","title":"Can you hear the drums, Erlando?","description":"Most of us at RabbitMQ HQ have spend time working in a number of functional languages in addition to Erlang, such as Haskell, Scheme, Lisp, OCaml or others. Whilst there is lots to like about Erlang, such as its VM/Emulator, there are inevitably features that we all miss from other languages. In my case, having spent a couple of years working in Haskell before returning to the RabbitMQ fold, all sorts of features are \\"missing\\", such as laziness, type classes, additional infix operators, the ability to specify precedence of functions, fewer parenthesis, partial application, more consistent standard libraries and do-notation. That\'s a fair list, and it\'ll take me a while to get around to implementing them all in Erlang, but here are two for starters.","date":"2011-05-17T00:00:00.000Z","tags":[{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages"}],"readingTime":15.1,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"Can you hear the drums, Erlando?","tags":["Programming Languages"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"RabbitMQ 2.5.0 released","permalink":"/rabbitmq-website/blog/2011/06/16/rabbitmq-250-released"},"nextItem":{"title":"Very fast and scalable topic routing - part 2","permalink":"/rabbitmq-website/blog/2011/03/28/very-fast-and-scalable-topic-routing-part-2"}},"content":"Most of us at RabbitMQ HQ have spend time working in a number of functional languages in addition to Erlang, such as Haskell, Scheme, Lisp, OCaml or others. Whilst there is lots to like about Erlang, such as its VM/Emulator, there are inevitably features that we all miss from other languages. In my case, having spent a couple of years working in Haskell before returning to the RabbitMQ fold, all sorts of features are \\"missing\\", such as laziness, type classes, additional infix operators, the ability to specify precedence of functions, fewer parenthesis, partial application, more consistent standard libraries and do-notation. That\'s a fair list, and it\'ll take me a while to get around to implementing them all in Erlang, but here are two for starters.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Introduction\\r\\n\\r\\n[Erlando](http://hg.rabbitmq.com/erlando/) is a set of syntax extensions for Erlang. Currently it\\r\\nconsists of two syntax extensions, both of which take the form of\\r\\n[parse transformers](http://www.erlang.org/doc/man/erl_id_trans.html).\\r\\n\\r\\n* **Cut**: This adds support for cuts to Erlang. These are\\r\\n  inspired by the\\r\\n  [Scheme form of cuts](http://srfi.schemers.org/srfi-26/srfi-26.html). Cuts\\r\\n  can be thought of as a light-weight form of abstraction, with\\r\\n  similarities to partial application (or currying).\\r\\n* **Do**: This adds support for do-syntax and monads to\\r\\n  Erlang. These are heavily inspired by [Haskell](http://haskell.org),\\r\\n  and the monads and libraries are near-mechanical translations from\\r\\n  the Haskell GHC libraries.\\r\\n\\r\\n## Use\\r\\n\\r\\nTo use any of these parse transformers, you must add the necessary\\r\\n`-compile` attributes to your Erlang source files. For example:\\r\\n\\r\\n```erlang\\r\\n-module(test).\\r\\n-compile({parse_transform, cut}).\\r\\n-compile({parse_transform, do}).\\r\\n```\\r\\n\\r\\nThen, when compiling `test.erl`, you must ensure `erlc` can locate\\r\\n`cut.beam` and/or `do.beam` by passing the suitable path to `erlc` with a\\r\\n`-pa` or `-pz` argument. For example:\\r\\n\\r\\n```shell\\r\\nerlc -Wall +debug_info -I ./include -pa ebin -o ebin  src/cut.erl\\r\\nerlc -Wall +debug_info -I ./include -pa ebin -o ebin  src/do.erl\\r\\nerlc -Wall +debug_info -I ./include -pa test/ebin -pa ./ebin -o test/ebin test/src/test.erl\\r\\n```\\r\\n\\r\\nNote, if you\'re using QLC, you may find you need to be careful as to\\r\\nthe order of the parse transforms: I\'ve found that the\\r\\n`-compile({parse_transform, cut}).` must occur before the\\r\\n`-include_lib(\\"stdlib/include/qlc.hrl\\").`\\r\\n\\r\\n## Cut\\r\\n\\r\\n### Motivation\\r\\n\\r\\nCut is motivated by the frequency with which simple abstractions (in a\\r\\nlambda-calculus sense) are used in Erlang, and the relatively noisy\\r\\nnature of declaring `fun`s. For example, it\'s quite common to see code\\r\\nlike:\\r\\n\\r\\n```erlang\\r\\nwith_resource(Resource, Fun) ->\\r\\n    case lookup_resource(Resource) of\\r\\n        {ok, R}          -> Fun(R);\\r\\n        {error, _} = Err -> Err\\r\\n    end.\\r\\n\\r\\nmy_fun(A, B, C) ->\\r\\n    with_resource(A, fun (Resource) ->\\r\\n                            my_resource_modification(Resource, B, C)\\r\\n                        end).\\r\\n```\\r\\n\\r\\nI.e. a fun is very simply created in order to perform variable capture\\r\\nfrom the its surrounding scope but to leave holes for further\\r\\narguments to be provided. Using a cut, the function `my_fun` can be\\r\\nrewritten as:\\r\\n\\r\\n```erlang\\r\\nmy_fun(A, B, C) ->\\r\\n    with_resource(A, my_resource_modification(_, B, C)).\\r\\n```\\r\\n\\r\\n### Definition\\r\\n\\r\\nNormally, the variable `_` can only occur in patterns: i.e. where\\r\\nmatch occurs. This can be in assignment, in cases, and in function\\r\\nheads. For example:\\r\\n\\r\\n```erlang\\r\\n{_, bar} = {foo, bar}.\\r\\n```\\r\\n\\r\\nCut uses `_` in expressions to indicate where abstraction should\\r\\noccur. Abstraction from cuts is **always** performed on the\\r\\n*shallowest* enclosing expression. For example:\\r\\n\\r\\n```erlang\\r\\nlist_to_binary([1, 2, math:pow(2, _)]).\\r\\n```\\r\\n\\r\\nwill create the expression\\r\\n\\r\\n```erlang\\r\\nlist_to_binary([1, 2, fun (X) -> math:pow(2, X) end]).\\r\\n```\\r\\n\\r\\nand not\\r\\n\\r\\n```erlang\\r\\nfun (X) -> list_to_binary([1, 2, math:pow(2, X)]) end.\\r\\n```\\r\\n\\r\\nIt is fine to use multiple cuts in the same expression, and the\\r\\narguments to the created abstraction will match the order in which the\\r\\n`_` var is found in the expression. For example:\\r\\n\\r\\n```erlang\\r\\nassert_sum_3(X, Y, Z, Sum) when X + Y + Z == Sum -> ok;\\r\\nassert_sum_3(_X, _Y, _Z, _Sum) -> {error, not_sum}.\\r\\n\\r\\ntest() ->\\r\\n    Equals12 = assert_sum_3(_, _, _, 12),\\r\\n    ok = Equals12(9, 2, 1).\\r\\n```\\r\\n\\r\\nIt is perfectly legal to take cuts of cuts as the abstraction created\\r\\nby the cut is a normal `fun` expression and thus can be re-cut as\\r\\nnecessary:\\r\\n\\r\\n```erlang\\r\\ntest() ->\\r\\n    Equals12 = assert_sum_3(_, _, _, 12),\\r\\n    Equals5 = Equals12(_, _, 7),\\r\\n    ok = Equals5(2, 3).\\r\\n```\\r\\n\\r\\nNote that because a simple `fun` is being constructed by the cut, the\\r\\narguments are evaluated prior to the cut function. For example:\\r\\n\\r\\n```erlang\\r\\nf1(_, _) -> io:format(\\"in f1~n\\").\\r\\n\\r\\ntest() ->\\r\\n    F = f1(io:format(\\"test line 1~n\\"), _),\\r\\n    F(io:format(\\"test line 2~n\\")).\\r\\n```\\r\\n\\r\\nwill print out\\r\\n\\r\\n```shell\\r\\ntest line 2\\r\\ntest line 1\\r\\nin f1\\r\\n```\\r\\n\\r\\nThis is because the cut creates `fun (X) -> f1(io:format(\\"test line\\r\\n1~n\\"), X) end`. Thus it is clear that `X` must be evaluated first,\\r\\nbefore the `fun` can be invoked.\\r\\n\\r\\nOf course, no one would be crazy enough to have side-effects in\\r\\nfunction argument expressions, so this will never cause any issues!\\r\\n\\r\\nCuts are not limited to function calls. They can be used in any\\r\\nexpression where they make sense:\\r\\n\\r\\n#### Tuples\\r\\n\\r\\n```erlang\\r\\nF = {_, 3},\\r\\n{a, 3} = F(a).\\r\\n```\\r\\n\\r\\n#### Lists\\r\\n\\r\\n```erlang\\r\\ndbl_cons(List) -> [_, _ | List].\\r\\n\\r\\ntest() ->\\r\\n    F = dbl_cons([33]),\\r\\n    [7, 8, 33] = F(7, 8).\\r\\n```\\r\\n\\r\\nNote that if you nest a list as a list tail in Erlang, it\'s still\\r\\ntreated as one expression. For example:\\r\\n\\r\\n```erlang\\r\\nA = [a, b | [c, d | [e]]]\\r\\n```\\r\\n\\r\\nis exactly the same (right from the Erlang parser onwards) as:\\r\\n\\r\\n```\\r\\nA = [a, b, c, d, e]\\r\\n```\\r\\n\\r\\nI.e. those sub-lists, when they\'re in the tail position **do not**\\r\\nform sub-expressions. Thus:\\r\\n\\r\\n```erlang\\r\\nF = [1, _, _, [_], 5 | [6, [_] | [_]]],\\r\\n%% This is the same as:\\r\\n%%  [1, _, _, [_], 5, 6, [_], _]\\r\\n[1, 2, 3, G, 5, 6, H, 8] = F(2, 3, 8),\\r\\n[4] = G(4),\\r\\n[7] = H(7).\\r\\n```\\r\\n\\r\\nHowever, be very clear about the difference between `,` and `|`: the\\r\\ntail of a list is **only** defined following a `|`. Following a `,`,\\r\\nyou\'re just defining another list element.\\r\\n\\r\\n```erlang\\r\\nF = [_, [_]],\\r\\n%% This is **not** the same as [_, _] or its synonym: [_ | [_]]\\r\\n[a, G] = F(a),\\r\\n[b] = G(b).\\r\\n```\\r\\n\\r\\n#### Records\\r\\n\\r\\n```erlang\\r\\n-record(vector, { x, y, z }).\\r\\n\\r\\ntest() ->\\r\\n    GetZ = _#vector.z,\\r\\n    7 = GetZ(#vector { z = 7 }),\\r\\n    SetX = _#vector{x = _},\\r\\n    V = #vector{ x = 5, y = 4 } = SetX(#vector{ y = 4 }, 5).\\r\\n```\\r\\n\\r\\n#### Case\\r\\n\\r\\n```erlang\\r\\nF = case _ of\\r\\n        N when is_integer(N) -> N + N;\\r\\n        N                    -> N\\r\\n    end,\\r\\n10 = F(5),\\r\\nok = F(ok).\\r\\n```\\r\\n\\r\\nSee\\r\\n[test_cut.erl](http://hg.rabbitmq.com/erlando/file/default/test/src/test_cut.erl)\\r\\nfor more examples, including use of cuts in list comprehensions and\\r\\nbinary construction.\\r\\n\\r\\nNote that cuts are not allowed where the result of the cut can only be\\r\\nuseful by interacting with the evaluation scope. For example:\\r\\n\\r\\n```erlang\\r\\nF = begin _, _, _ end.\\r\\n```\\r\\n\\r\\nThis is not allowed, because the arguments to `F` would have to be\\r\\nevaluated before the invocation of its body, which would then have no\\r\\neffect, as they\'re already fully evaluated by that point.\\r\\n\\r\\n## Do\\r\\n\\r\\nThe Do parse transformer permits Haskell-style *do-notation* in\\r\\nErlang, which makes using monads, and monad transformers possible and\\r\\neasy. Without *do-notation*, monads tend to look like a lot of line\\r\\nnoise.\\r\\n\\r\\n### The Inevitable Monad Tutorial\\r\\n\\r\\n#### The Mechanics of a Comma\\r\\n\\r\\nWhat follows is a brief and mechanical introduction to monads. It\\r\\ndiffers from a lot of the Haskell monad tutorials, because they tend\\r\\nto view monads as a means of achieving sequencing of operations in\\r\\nHaskell, which is challenging because Haskell is a lazy\\r\\nlanguage. Erlang is not a lazy language, but the powerful abstractions\\r\\npossible from using monads are still very worthwhile. Whilst this is a\\r\\nvery mechanical tutorial, it should be possible to see the more\\r\\nadvanced abstractions possible.\\r\\n\\r\\nLet\'s say we have the three lines of code:\\r\\n\\r\\n```erlang\\r\\nA = foo(),\\r\\nB = bar(A, dog),\\r\\nok.\\r\\n```\\r\\n\\r\\nThey are three, simple statements, which are evaluated\\r\\nconsecutively. What a monad gives you is control over what happens\\r\\nbetween the statements: in Erlang, it is a programmatic comma.\\r\\n\\r\\nIf you wanted to implement a programmatic comma, how would you do it?\\r\\nYou might start with something like:\\r\\n\\r\\n```erlang\\r\\nA = foo(),\\r\\ncomma(),\\r\\nB = bar(A, dog),\\r\\ncomma(),\\r\\nok.\\r\\n```\\r\\n\\r\\nBut that\'s not quite powerful enough, because unless `comma/0` throws\\r\\nsome sort of exception, it can\'t actually stop the subsequent\\r\\nexpression from being evaluated. Most of the time we\'d probably like\\r\\nthe `comma/0` function to be able to act on some variables which are\\r\\ncurrently in scope, and that\'s not possible here either. So we should\\r\\nextend the function `comma/0` so that it takes the result of the\\r\\npreceding expression, and can choose whether or not the subsequent\\r\\nexpressions should be evaluated:\\r\\n\\r\\n```erlang\\r\\ncomma(foo(),\\r\\n        fun (A) -> comma(bar(A, dog),\\r\\n                        fun (B) -> ok end)).\\r\\n```\\r\\n\\r\\nThus the function `comma/2` takes all results from the previous\\r\\nexpression, and controls how and whether they are passed to the next\\r\\nexpression.\\r\\n\\r\\nAs defined, the `comma/2` function is the monadic function `>>=/2`.\\r\\n\\r\\nNow it\'s pretty difficult to read the program with the `comma/2`\\r\\nfunction (especially as Erlang annoyingly doesn\'t allow us to define\\r\\nnew infix functions), which is why some special syntax is\\r\\nnecessary. Haskell has it\'s *do-notation*, and so we\'ve borrowed from\\r\\nthat and abused Erlang\'s list comprehensions. Haskell also has lovely\\r\\ntype-classes, which we\'ve sort of faked specifically for monads. So,\\r\\nwith the Do parse transformer, you can write in Erlang:\\r\\n\\r\\n```erlang\\r\\ndo([Monad ||\\r\\n    A <- foo(),\\r\\n    B <- bar(A, dog),\\r\\n    ok]).\\r\\n```\\r\\n\\r\\nwhich is readable and straightforward, but is transformed into:\\r\\n\\r\\n```erlang\\r\\nMonad:\'>>=\'(foo(),\\r\\n            fun (A) -> Monad:\'>>=\'(bar(A, dog),\\r\\n                                    fun (B) -> ok end)).\\r\\n```\\r\\n\\r\\nThere is no intention that this latter form is any more readable than\\r\\nthe `comma/2` form - it is not. However, it should be clear that the\\r\\nfunction `Monad:\'>>=\'/2` now has complete control over what happens:\\r\\ndoes the fun on the right hand side ever get invoked? If so, with what\\r\\nvalue?\\r\\n\\r\\n#### Lots of different types of Monads\\r\\n\\r\\nSo now that we have some relatively nice syntax for using monads, what\\r\\ncan we do with them? Also, in the code\\r\\n\\r\\n```erlang\\r\\ndo([Monad ||\\r\\n    A <- foo(),\\r\\n    B <- bar(A, dog),\\r\\n    ok]).\\r\\n```\\r\\n\\r\\nwhat are the possible values of `Monad`?\\r\\n\\r\\nThe answer to the first question is *almost anything*; and to the\\r\\nlater question, is *any module name that implements the monad\\r\\nbehaviour*.\\r\\n\\r\\nAbove, we covered one of the three monadic operators, `>>=/2`. The\\r\\nothers are:\\r\\n\\r\\n* `return/1`: This *lifts* a value into the monad. We\'ll see examples\\r\\n  of this shortly.\\r\\n\\r\\n* `fail/1`: This takes a term describing the error encountered, and\\r\\n  informs whichever monad currently in use that some sort of error has\\r\\n  occurred.\\r\\n\\r\\nNote that within *do-notation*, any function call to functions named\\r\\n`return` or `fail`, are automatically rewritten to invoke `return` or\\r\\n`fail` within the current monad.\\r\\n\\r\\nSome people familiar with Haskell\'s monads may be expecting to see a\\r\\nfourth operator, `>>/2`. Interestingly, it turns out that you can\'t\\r\\nimplement `>>/2` in a strict language unless all your monad types are\\r\\nbuilt on top a function. This is because in a strict language,\\r\\narguments to functions are evaluated before the function is\\r\\ninvoked. For `>>=/2`, the 2nd argument is only reduced to a function\\r\\nprior to invocation of `>>=/2`. But the 2nd argument to `>>/2` is not\\r\\na function, and so in strict languages, will be fully reduced prior to\\r\\n`>>/2` being invoked. This is problematic because the `>>/2` operator\\r\\nis meant to be in control of whether or not subsequent expressions are\\r\\nevaluated. The only solution here would be to make the basic monad\\r\\ntype a function, which would then mean that the 2nd argument to\\r\\n`>>=/2` would become a function to a function to a result! However, it\\r\\nis required that `\'>>\'(A, B)` behaves identically to `\'>>=\'(A, fun (_)\\r\\n-> B end)`, and so that is what we do: whenever we come to a\\r\\n`do([Monad || A, B ])`, we rewrite it to `\'>>=\'(A, fun (_) -> B end)`\\r\\nrather than `\'>>\'(A, B)`. The effect of this is that the `>>/2`\\r\\noperator does not exist.\\r\\n\\r\\nThe simplest monad possible is the Identity-monad:\\r\\n\\r\\n```erlang\\r\\n-module(identity_m).\\r\\n-behaviour(monad).\\r\\n-export([\'>>=\'/2, return/1, fail/1]).\\r\\n\\r\\n\'>>=\'(X, Fun) -> Fun(X).\\r\\nreturn(X)     -> X.\\r\\nfail(X)       -> throw({error, X}).\\r\\n```\\r\\n\\r\\nThis makes our programmatic comma behave just like Erlang\'s comma\\r\\nnormally does. The **bind** operator (`>>=/2`) does not inspect the\\r\\nvalues passed to it, and always invokes the subsequent expression fun.\\r\\n\\r\\nWhat could we do if we did inspect the values passed to the sequencing\\r\\ncombinators? One possibility results in the Maybe-monad:\\r\\n\\r\\n```erlang\\r\\n-module(maybe_m).\\r\\n-behaviour(monad).\\r\\n-export([\'>>=\'/2, return/1, fail/1]).\\r\\n\\r\\n\'>>=\'({just, X}, Fun) -> Fun(X);\\r\\n\'>>=\'(nothing,  _Fun) -> nothing.\\r\\n\\r\\nreturn(X) -> {just, X}.\\r\\nfail(_X)  -> nothing.\\r\\n```\\r\\n\\r\\nThus if the result of the preceding expression is `nothing`, then the\\r\\nsubsequent expressions are not evaluated. This means that we can write\\r\\nvery neat looking code which immediately stops should any failure be\\r\\nencountered.\\r\\n\\r\\n```erlang\\r\\nif_safe_div_zero(X, Y, Fun) ->\\r\\n    do([maybe_m ||\\r\\n        Result <- case Y == 0 of\\r\\n                        true  -> fail(\\"Cannot divide by zero\\");\\r\\n                        false -> return(X / Y)\\r\\n                    end,\\r\\n        return(Fun(Result))]).\\r\\n```\\r\\n\\r\\nIf `Y` is equal to 0, then `Fun` will not be invoked, and the result\\r\\nof the `if_safe_div_zero` function call will be `nothing`. If `Y` is\\r\\nnot equal to 0, then the result of the `if_safe_div_zero` function\\r\\ncall will be `{just, Fun(X / Y)}`.\\r\\n\\r\\nWe see here that within the do-block, there is no mention of `nothing`\\r\\nor `just`: they are abstracted away by the Maybe-monad. As a result,\\r\\nit is possible to change the monad in use, without having to rewrite\\r\\nany further code.\\r\\n\\r\\nOne common place to use a monad like the Maybe-monad is where you\'d\\r\\notherwise have a lot of nested case statements in order to detect\\r\\nerrors. For example:\\r\\n\\r\\n```erlang\\r\\nwrite_file(Path, Data, Modes) ->\\r\\n    Modes1 = [binary, write | (Modes -- [binary, write])],\\r\\n    case make_binary(Data) of\\r\\n        Bin when is_binary(Bin) ->\\r\\n            case file:open(Path, Modes1) of\\r\\n                {ok, Hdl} ->\\r\\n                    case file:write(Hdl, Bin) of\\r\\n                        ok ->\\r\\n                            case file:sync(Hdl) of\\r\\n                                ok ->\\r\\n                                    file:close(Hdl);\\r\\n                                {error, _} = E ->\\r\\n                                    file:close(Hdl),\\r\\n                                    E\\r\\n                            end;\\r\\n                        {error, _} = E ->\\r\\n                            file:close(Hdl),\\r\\n                            E\\r\\n                    end;\\r\\n                {error, _} = E -> E\\r\\n            end;\\r\\n        {error, _} = E -> E\\r\\n    end.\\r\\n\\r\\nmake_binary(Bin) when is_binary(Bin) ->\\r\\n    Bin;\\r\\nmake_binary(List) ->\\r\\n    try\\r\\n        iolist_to_binary(List)\\r\\n    catch error:Reason ->\\r\\n            {error, Reason}\\r\\n    end.\\r\\n```\\r\\n\\r\\ncan be transformed into the much shorter\\r\\n\\r\\n```erlang\\r\\nwrite_file(Path, Data, Modes) ->\\r\\n    Modes1 = [binary, write | (Modes -- [binary, write])],\\r\\n    do([error_m ||\\r\\n        Bin <- make_binary(Data),\\r\\n        {ok, Hdl} <- file:open(Path, Modes1),\\r\\n        {ok, Result} <- return(do([error_m ||\\r\\n                                    ok <- file:write(Hdl, Bin),\\r\\n                                    file:sync(Hdl)])),\\r\\n        file:close(Hdl),\\r\\n        Result]).\\r\\n```\\r\\n\\r\\nNote that we have a nested do-block so that, as with the non-monadic\\r\\ncode, we ensure that once the file is opened, we always call\\r\\n`file:close/1` even if an error occurs in a subsequent operation. This\\r\\nis achieved by wrapping the nested do-block with a `return/1` call:\\r\\neven if the inner do-block errors, the error is *lifted* to a\\r\\nnon-error value in the outer do-block, and thus execution continues to\\r\\nthe subsequent `file:close/1` call.\\r\\n\\r\\nHere we are using an Error-monad which is remarkably similar to the\\r\\nMaybe-monad, but matches the typical Erlang practice of indicating\\r\\nerrors by an `{error, Reason}` tuple:\\r\\n\\r\\n```erlang\\r\\n-module(error_m).\\r\\n-behaviour(monad).\\r\\n-export([\'>>=\'/2, return/1, fail/1]).\\r\\n\\r\\n\'>>=\'({error, _Err} = Error, _Fun) -> Error;\\r\\n\'>>=\'(Result,                 Fun) -> Fun(Result).\\r\\n\\r\\nreturn(X) -> {ok,    X}.\\r\\nfail(X)   -> {error, X}.\\r\\n```\\r\\n\\r\\n#### Monad Transformers\\r\\n\\r\\nMonads can be *nested* by having do-blocks inside do-blocks, and\\r\\n*parameterized* by defining a monad as a transformation of another, inner,\\r\\nmonad. The State Transform is a very commonly used monad transformer,\\r\\nand is especially relevant for Erlang. Because Erlang is a\\r\\nsingle-assignment language, it\'s very common to end up with a lot of\\r\\ncode that incrementally numbers variables:\\r\\n\\r\\n```erlang\\r\\nState1 = init(Dimensions),\\r\\nState2 = plant_seeds(SeedCount, State1),\\r\\n{DidFlood, State3} = pour_on_water(WaterVolume, State2),\\r\\nState4 = apply_sunlight(Time, State3),\\r\\n{DidFlood2, State5} = pour_on_water(WaterVolume, State4),\\r\\n{Crop, State6} = harvest(State5),\\r\\n    ...\\r\\n```\\r\\n\\r\\nThis is doubly annoying, not only because it looks awful, but also\\r\\nbecause you have to re-number many variables and references whenever a\\r\\nline is added or removed. Wouldn\'t it be nice if we could abstract out the\\r\\n`State`? We could then have a monad encapsulate the state and provide\\r\\nit to (and collect it from) the functions we wish to run.\\r\\n\\r\\nOur implementation of monad-transformers (like State) uses a \\"hidden feature\\"\\r\\nof the Erlang distribution called *parameterized modules*. These are\\r\\ndescribed in [Parameterized Modules in Erlang](http://ftp.sunet.se/pub/lang/erlang/workshop/2003/paper/p29-carlsson.pdf).\\r\\n\\r\\nThe State-transform can be applied to any monad. If we apply it to the\\r\\nIdentity-monad then we get what we\'re looking for. The key extra\\r\\nfunctionality that the State transformer provides us with is the\\r\\nability to `get` and `set` (or just plain `modify`) state from within\\r\\nthe inner monad. If we use both the Do and Cut parse transformers, we\\r\\ncan write:\\r\\n\\r\\n```erlang\\r\\nStateT = state_t:new(identity_m),\\r\\nSM = StateT:modify(_),\\r\\nSMR = StateT:modify_and_return(_),\\r\\nStateT:exec(\\r\\n    do([StateT ||\\r\\n\\r\\n        StateT:put(init(Dimensions)),\\r\\n        SM(plant_seeds(SeedCount, _)),\\r\\n        DidFlood <- SMR(pour_on_water(WaterVolume, _)),\\r\\n        SM(apply_sunlight(Time, _)),\\r\\n        DidFlood2 <- SMR(pour_on_water(WaterVolume, _)),\\r\\n        Crop <- SMR(harvest(_)),\\r\\n        ...\\r\\n\\r\\n        ]), undefined).\\r\\n```\\r\\n\\r\\nWe start by creating a State-transform over the Identity-monad.\\r\\n\\r\\nThis is the syntax for *instantiating* parameterized modules. `StateT` is a\\r\\nvariable referencing a module instance which, in this case, is a monad.\\r\\n\\r\\nWe set up two shorthands for running functions that either just\\r\\nmodify the state, or modify the state *and* return a result. Whilst\\r\\nthere\'s a bit of bookkeeping to do, we achieve our goal: there are no\\r\\nstate variables now to renumber whenever we make a change: we use cut\\r\\nto leave holes in the functions where State should be fed in, and we\\r\\nobey the protocol that if functions return both a result and state, it\\r\\nshould be in the form of a `{Result, State}` tuple. The\\r\\nState-transform does the rest.\\r\\n\\r\\n### Beyond Monads\\r\\n\\r\\nThere are some standard monad functions such as `join/2` and\\r\\n`sequence/2` available in the `monad` module. We have also implemented\\r\\n`monad_plus` which works for monads where there\'s an obvious sense of\\r\\n*zero*  and *plus* (currently Maybe-monad, List-monad, and Omega-monad).\\r\\nThe associated functions `guard`, `msum` and `mfilter` are available\\r\\nin the `monad_plus` module.\\r\\n\\r\\nIn many cases, a fairly mechanical translation from Haskell to Erlang\\r\\nis possible, so in many cases converting other monads or combinators should\\r\\nbe straightforward. However, the lack of type classes in Erlang is limiting."},{"id":"/2011/03/28/very-fast-and-scalable-topic-routing-part-2","metadata":{"permalink":"/rabbitmq-website/blog/2011/03/28/very-fast-and-scalable-topic-routing-part-2","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-03-28-very-fast-and-scalable-topic-routing-part-2/index.md","source":"@site/blog/2011-03-28-very-fast-and-scalable-topic-routing-part-2/index.md","title":"Very fast and scalable topic routing - part 2","description":"In our previous blog post we talked about a few approaches to topic routing optimization and described the two more important of these in brief. In this post, we will talk about a few things we tried when implementing the DFA, as well as some performance benchmarking we have done on the trie and the DFA.","date":"2011-03-28T00:00:00.000Z","tags":[],"readingTime":8.155,"hasTruncateMarker":true,"authors":[{"name":"Vlad Alexandru Ionescu","key":"vlad","page":null}],"frontMatter":{"title":"Very fast and scalable topic routing - part 2","tags":[],"authors":["vlad"]},"unlisted":false,"prevItem":{"title":"Can you hear the drums, Erlando?","permalink":"/rabbitmq-website/blog/2011/05/17/can-you-hear-the-drums-erlando"},"nextItem":{"title":"Sender-selected distribution","permalink":"/rabbitmq-website/blog/2011/03/23/sender-selected-distribution"}},"content":"In our [previous blog post](/blog/2010/09/14/very-fast-and-scalable-topic-routing-part-1) we talked about a few approaches to topic routing optimization and described the two more important of these in brief. In this post, we will talk about a few things we tried when implementing the DFA, as well as some performance benchmarking we have done on the trie and the DFA.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Implementing the DFA\\r\\n\\r\\nIn order to be able to build the DFA, we first need to build the NFA from the patterns. The main difference between the DFA and the NFA is that, in the DFA, at any point, you don\'t have to choose (backtrack); you only get one precise route that you follow down the graph. For example, here is how we would turn patterns \\"a.b\\" and \\"*.b\\" into a DFA:\\r\\n\\r\\n![](nfa-to-dfa-example.png)\\r\\n\\r\\nWe can see that in the NFA, state 0 has a choice, if the topic starts with \\"a\\". It can either go through 1 or through 3. This causes backtracking. In the DFA, the two branches got merged together for the case when the topic starts with \\"a\\" and turned the \\"any\\" into \\"other\\", leaving only one, clear choice for each case.\\r\\n\\r\\nThere are a few options to turn to when converting an NFA into a DFA:\\r\\n\\r\\n* **Using the powerset construction algorithm**. This is approach is generally used to construct the entire DFA from the start.\\r\\n* **Using the NFA algorithm**. This is the same complexity as backtracking, but it is modelled with set operations.\\r\\n* **Pure backtracking**. Basically the same thing as the trie approach mentioned in the previous article.\\r\\n\\r\\nThe main problems of the conversion are the size of the DFA and the complexity of the algorithms. Although not obvious, in the example above, the DFA can get significantly bigger than the NFA, when using \\"#\\" in patterns. In some cases, a \\"#\\" can cause a node to link to all other nodes in the graph. For this reason, it would be useless to try to build the whole DFA from the start, and then rebuild it entirely whenever a new binding is added.\\r\\n\\r\\nTo overcome this problem we thought of a way of patching the DFA with a new pattern when a new binding is created. How? Construct the NFA for the new pattern and link it to the existing DFA like this:\\r\\n\\r\\n![](patch-dfa.png)\\r\\n\\r\\nwhere 0 is the start node of the existing DFA and X is the start node of the new pattern to be added.\\r\\n\\r\\nThe result would be a new NFA. Then, we would use the powerset construction method to rebuild the DFA, but when encountering a node which contains a singleton set, whose element belonged to the previous DFA, we can stop and link it as it was previously in the DFA.\\r\\n\\r\\nFor patterns that do not contain \\"#\\"\', in most cases you would barely touch the existing DFA and keep it entirely, while attaching the new pattern. In these cases, the cost of adding a new binding would be very low.\\r\\n\\r\\nThe problem is... the \\"#\\". If the new pattern contains a \\"#\\" at the beginning, you end up traversing the whole DFA again and renewing all nodes to reconstruct it. For this reason and because the DFA has a big size complexity anyway, we decided that building the whole DFA and then patching it was not such a good idea after all.\\r\\n\\r\\nGood regex compilers nowadays don\'t store the DFA entirely, because it can get huge. Instead they build it on the fly, as needed, with the NFA algorithm, and cache it. You can think of it as having it in a lazy evaluation form - new nodes are only produces when needed. When the cache gets too big, they drop it entirely and start over. We ended up using this approach in our problem.\\r\\n\\r\\n## Testing the trie and the DFA and attempts to improve the DFA\\r\\n\\r\\nWe wrote a benchmarking test for the purpose of comparing the performances of the two. We tried to make the tests mimic as much as possible the way a topic exchange is commonly used. In the following, \\"x times faster\\" refers to the benchmark test times, in general compared with the naive implementation, which does not do the unnecessary splitting mentioned in the previous post. The benchmark consists of matching 1M topics against 2000 patterns. We ran it on a 2.3 GHz machine. The patterns contain a concentration of 0.1 of \\"*\\"\'s and 0.01 of \\"#\\"\'s.\\r\\n\\r\\nThe trie finished our benchmark in *11.7 seconds*, which made it *15 times* faster than the naÃ¯ve implementation.\\r\\n\\r\\nWe then benchmarked the NFA algorithm, but without the caching of the DFA, using Erlang\'s digraph module for graphs. Its complexity is about the same as the trie\'s, so we expected a similar time. The result? It was very very slow! It was of the order of hundreds of seconds.\\r\\n\\r\\nWe needed to write our own graph implementation, since digraph gave really poor performance. So we wrote a specialized finite automata graph, based on Erlang dicts. We got *37 seconds* for just NFA (without caching DFA). Four times slower than the trie. Still not as fast. But it is probably due to the cost of walking a graph rather than a tree and doing some extra set operations.\\r\\n\\r\\nWe then implemented the caching of the DFA. Result? *Slower* than the trie! We got *26.7 seconds* in our benchmark. We tried it for even more messages (perhaps the DFA wasn\'t build entirely). Still... slower.\\r\\n\\r\\nHere is a graph of the tests, when varying the number of messages (2000 patterns, millions of messages vs time microseconds - lower is better):\\r\\n\\r\\n![](msgs-vs-time.png)\\r\\n\\r\\nThat was quite unexpected. We should have seen the DFA grow in a logarithmic manner at some point. What\'s wrong? Maybe we need a faster graph. It is known that the dict implementation in Erlang is not very quick. Our graph implementation was based on Erlang\'s dict. We needed a way to optimize that.\\r\\n\\r\\nWe came up with the idea of generating source code for the dictionaries, on the fly. For example, if you have a dictionary with the entries `[{k1, v1}, {k2, v2}, {k3, v3}]` we would generate a function\\r\\n\\r\\n```\\r\\nmydict(k1) -> {ok, v1};\\r\\n\\r\\nmydict(k2) -> {ok, v2};\\r\\n\\r\\nmydict(k3) -> {ok, v3};\\r\\n\\r\\nmydict(_) -> error.\\r\\n```\\r\\n\\r\\nIt would thus behave like the dict:find/2 function, except it only takes one parameter. We used Yariv Sadan\'s [smerl](http://code.google.com/p/erlyweb/source/browse/trunk/src/smerl/smerl.erl) module for the job.\\r\\n\\r\\nWe first tested the new graph with just NFA, without caching the DFA. We got *21.9 seconds* on our benchmark test. That\'s great! Almost twice as fast that the previous 37 seconds result.\\r\\n\\r\\nLet\'s now try to cache the DFA and compile the dictionaries to functions every 5 seconds. Complete failure! The generated function has hundreds of thousands of clauses, because of the high number of edges in the graph. Compiling such a thing takes ages! It\'s useless.\\r\\n\\r\\nUsing compiled dict only for the NFA and not for the cached DFA, we got *15.2 seconds* in our benchmark - our fastest DFA attempt.\\r\\n\\r\\n## Further testing\\r\\n\\r\\nLet us have a closer look at the complexities of the trie and the DFA. Maybe we get a clue of what\'s wrong with the DFA. Here is a graph of the tests if varying the number of patterns (3M messages, number of patterns vs time in microseconds):\\r\\n\\r\\n![](patterns-vs-time.png)\\r\\n\\r\\nSurprise! The DFA has a rather exponential/quadratic complexity, while the trie keeps pretty linear or rather logarithmic.\\r\\n\\r\\nWhat could the explanation be? The DFA uses a lot of memory. The reason the DFA is much slower could only be because the processor needs to grab bits of the DFA from the memory very often, instead of being able to keep the DFA in the processor\'s cache. The trie uses significantly less memory and probably fits better in the cache.\\r\\n\\r\\nLet\'s see the memory usage, when varying the number of messages (2000 patterns, millions of messages vs words used):\\r\\n\\r\\n![](msgs-vs-mem.png)\\r\\n\\r\\nObviously, the trie does not vary in size while the messages flow. We can see that the DFA uses up *40 times* more memory than the trie, in this scenario. Indeed the theory that the DFA does not fit in the cache is confirmed. The trie uses 1-2MB, while the DFA uses almost 50MB.\\r\\n\\r\\nNow let us vary the number of patterns and keep the number of messages constant (3M messages, number of patterns vs words used):\\r\\n\\r\\n![](patterns-vs-mem.png)\\r\\n\\r\\nWe can see here that the DFA has an exponential space complexity.\\r\\n\\r\\n## So...\\r\\n\\r\\nCaching messages\' topics and indexing the patterns on a per-level basis are clearly inferior to the trie and DFA approaches.\\r\\n\\r\\nThe DFA uses a lot more memory and optimizing it is limited by a number of obstacles. Even with a specialized graph implementation, the DFA fails to achieve linear time complexity due to the high usage of memory, falling towards an exponential space and time complexity. It is significantly worse than the trie approach, even though it is the trie backtracks and would have had an exponential complexity if the number of words per pattern would have been greater in common use.\\r\\n\\r\\nThe trie approach is simpler and thus easier to implement and maintain than the DFA; it uses many times less memory, thus being able to fit in the processor\'s cache; and exhibits a linear-logarithmic complexity in both space and time, making it the fittest approach.\\r\\n\\r\\nWe implemented the trie approach in the new RabbitMQ version 2.4.0. Here is what we got, when we tested Rabbit itself, with the new implementation (number of bindings vs time in microseconds):\\r\\n\\r\\n![](rabbitmq-240-performance-std.png)\\r\\n\\r\\nAnd finally, here is a performance comparison between version 2.3.1 and version 2.4.0 (number of bindings vs time in microseconds) - the performance improvement in this graph varies from 25 to 145 times faster:\\r\\n\\r\\n![](comparison-performance.png)"},{"id":"/2011/03/23/sender-selected-distribution","metadata":{"permalink":"/rabbitmq-website/blog/2011/03/23/sender-selected-distribution","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-03-23-sender-selected-distribution/index.md","source":"@site/blog/2011-03-23-sender-selected-distribution/index.md","title":"Sender-selected distribution","description":"RabbitMQ 2.4.0 introduced an extension that allows publishers to specify multiple routing keys in the CC and BCC message headers. The BCC header is removed from the message prior to delivery. Direct and topic exchanges are the only standard exchange types that make use of routing keys, therefore the routing logic of this feature only works with these exchange types.","date":"2011-03-23T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.71,"hasTruncateMarker":true,"authors":[{"name":"Emile Joubert","key":"emile","page":null}],"frontMatter":{"title":"Sender-selected distribution","tags":["New Features"],"authors":["emile"]},"unlisted":false,"prevItem":{"title":"Very fast and scalable topic routing - part 2","permalink":"/rabbitmq-website/blog/2011/03/28/very-fast-and-scalable-topic-routing-part-2"},"nextItem":{"title":"Ruby AMQP Benchmarks","permalink":"/rabbitmq-website/blog/2011/03/01/ruby-amqp-benchmarks"}},"content":"RabbitMQ 2.4.0 introduced an extension that allows publishers to specify multiple routing keys in the CC and BCC message headers. The BCC header is removed from the message prior to delivery. Direct and topic exchanges are the only standard exchange types that make use of routing keys, therefore the routing logic of this feature only works with these exchange types.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Why would I want this?\\r\\n\\r\\n### 1. Custom routing logic\\r\\n\\r\\nYou would normally resort to an external or custom exchange when routing rules are too complex to be expressed with standard exchanges. CC/BCC headers allow a peer to implement potentially complex routing rules by populating these headers with the matching routes.\\r\\n\\r\\nImagine a RabbitMQ broker receiving Java Log4J messages and that we are interested in messages at level SEVERE that arrive outside office-hours. This assumes an AMQP Log4J handler that forwards log messages to a RabbitMQ exchange and a client (perhaps connected to a pager) that retrieves them from a queue. Let us assume that the queue is titled \\"out-of-hours-emergencies\\" and declared by the pager client.\\r\\n\\r\\nThe problem is how to selectively route messages satisfying these criteria (severity and time). The Java logging API has sufficient sophistication to perform some selective processing and filtering in the log handler before the messages reach the broker, so the problem could potentially be solved upstream from the broker in simple cases. For the purposes of this example we\'ll want to manage the routing across all log producers centrally in the  broker.\\r\\n\\r\\nThe log handler could decorate the AMQP messages with information about the log events by placing information in the headers. Messages could then be routed according to those headers with the built-in amq.headers exchange. So the first constraint could potentially be met without resorting to additional features, provided that the event severity appears in a message header. The second constraint of our requirement (only messages received outside office-hours) cannot be satisfied with a built-in exchange in the same way. The built-in exchange types can only perform routing based on the contents of a message, not when it arrives. Even if the messages contained a timestamp, built-in exchanges have no way of matching by inequality.\\r\\n\\r\\nWe can solve this problem by relying on a smart consumer that populates the BCC headers before republishing received messages. The relevant criteria in our example would be \\"out-of-hours-emergencies\\", so the smart consumer adds this to the BCC header before republishing severe log messages that arrive out of hours. It could use any information at its disposal to make that determination, including date, time, message contents or information from other sources. Any number of criteria can selectively be added to the BCC header in the same way. A queue with the same name will receive all messages from our smart  consumer that republished messages with this string in the BCC header. At this point the pager client retrieves messages from the \\"out-of-hours-emergencies\\" queue and pages an operator.\\r\\n\\r\\nThis technique can route messages that are encoded in a domain-specific format. A smart peer with knowledge of the format could unpack the message, populate the BCC header with a relevant field and republish. The smart peer is acting in a similar way as an [external exchange](http://hg.rabbitmq.com/rabbitmq-external-exchange/).\\r\\n\\r\\n### 2. Confidential routing\\r\\n\\r\\nThis is useful in cases where the routing key is a secure token which producers and consumers agree beforehand. Wild-cards make topic exchanges useless in this scenario. Messages published with a routing key set to \\"topsecret.eyesonly\\" can be obtained by any consumer that binds with a wild-card \\"#\\".\\r\\n\\r\\nProducers can send messages to arbitrary subsets of consumers by populating the BCC header with the routing keys of the selected recipients. The recipients will have no way of learning the identities of other recipients, because the BCC header is removed from the message prior to delivery.\\r\\n\\r\\nRouting information may still leak in other ways, such as the Management &amp; Monitoring plugin or the rabbitmqctl administration utility. These will need appropriate protection.\\r\\n\\r\\n## Can\'t AMQP do this already?\\r\\n\\r\\nWhile it\'s not possible to remove headers, it is possible to obtain some comparable effects using only standard AMQP features.\\r\\n\\r\\n*  Producers can send multiple messages, each with a different routing key. This wastes network bandwidth and broker resources, because the broker cannot optimise the storage of the duplicate messages.\\r\\n*  Producers can declare a temporary exchange, with a temporary binding for each intended recipient. This a great deal of effort that needs to be repeated each time the set of recipients changes.\\r\\n\\r\\n## How do I use this?\\r\\n\\r\\nBe sure to use RabbitMQ version 2.4.0 or later. Any AMQP client can be used. Set the CC or BCC headers to the list of routing keys. The header value must be an AMQP array type, even if it only contains a single value. The message will be routed to all destinations according to the combined routings keys in the CC and BCC headers, as well as the basic.publish method (\\"routingkey1\\", \\"routingkey2\\" and \\"routingkey3\\" in this example).\\r\\n\\r\\nJava sample code:\\r\\n\\r\\n```java\\r\\nBasicProperties props  = new BasicProperties();\\r\\nMap<String, Object> headers = new HashMap<String, Object>();\\r\\nList<String> ccList = new ArrayList<String>();\\r\\nccList.add(\\"routingkey2\\");\\r\\nccList.add(\\"routingkey3\\");\\r\\nheaders.put(\\"CC\\", ccList);\\r\\nprops.setHeaders(headers);\\r\\nchannel.basicPublish(exchange, \\"routingkey1\\", props, payload);\\r\\n```\\r\\n\\r\\n## What are the interoperability implications?\\r\\n\\r\\nAny AMQP client can make use of this feature. Producers require nothing more than the ability to set headers in messages.\\r\\n\\r\\nThe use of any RabbitMQ-specific extensions makes it harder to swap RabbitMQ for a different AMQP broker - sender-selected distribution is no exception.\\r\\n\\r\\nIf your application already makes use of headers named CC or BCC then you should use different keys or contact the RabbitMQ team for assistance."},{"id":"/2011/03/01/ruby-amqp-benchmarks","metadata":{"permalink":"/rabbitmq-website/blog/2011/03/01/ruby-amqp-benchmarks","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-03-01-ruby-amqp-benchmarks/index.md","source":"@site/blog/2011-03-01-ruby-amqp-benchmarks/index.md","title":"Ruby AMQP Benchmarks","description":"I decided to run some benchmarks of my AMQP encoder/decoder (AMQ Protocol gem) against the old one in the AMQP gem to see whether it performs better or not. So far I did only the most basic optimisations like storing reusable values in constants, nothing special (yet).","date":"2011-03-01T00:00:00.000Z","tags":[],"readingTime":1.88,"hasTruncateMarker":true,"authors":[{"name":"Jakub Stastny","key":"botanicus","page":null}],"frontMatter":{"title":"Ruby AMQP Benchmarks","tags":[],"authors":["botanicus"]},"unlisted":false,"prevItem":{"title":"Sender-selected distribution","permalink":"/rabbitmq-website/blog/2011/03/23/sender-selected-distribution"},"nextItem":{"title":"Introducing Publisher Confirms","permalink":"/rabbitmq-website/blog/2011/02/10/introducing-publisher-confirms"}},"content":"I decided to run some [benchmarks](https://github.com/ruby-amqp/amqp-benchmarks) of my AMQP encoder/decoder ([AMQ Protocol](https://github.com/ruby-amqp/amq-protocol) gem) against the old one in the [AMQP](https://github.com/ruby-amqp/amqp) gem to see whether it performs better or not. So far I did only the most basic optimisations like storing reusable values in constants, nothing special (yet).\\r\\n\\r\\nI did two sets of benchmarks: CPU time benchmarking using [my fork of RBench](https://github.com/botanicus/rbench) with support for custom formatters (like writing results into a YAML file) and memory benchmarking using `Object.count_objects` (Ruby 1.9).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nI\'m not going to write about technical details of these benchmarks, get [the sources](https://github.com/ruby-amqp/amqp-benchmarks) and take a look yourself. I run every example 50,000 times, except of the example for the AMQP preamble which I run 200,000 times.\\r\\n\\r\\nHere are the results from CPU time benchmarking (tmm1 means the old encoder/decoder, amqp the new one, the first graph is for decoding, the second one for encoding):\\r\\n\\r\\n![](cpu-decode.png)\\r\\n\\r\\n![](cpu-encode.png)\\r\\n\\r\\nAs you can see, the results are very cheerful, **the new encoder/decoder is always significantly faster, on average it\'s 4.875x faster then the old one**. (Obviously not all the metrics have the same relevance: regardless how fast is decoding of `Connection.Open`, you call it only once per connection, which in most cases means once per one run of the client.)\\r\\n\\r\\nAnd that\'s not all, I have actually even better results for the memory consumption: **the new encoder/decoder needs 5.417x less objects**! This definitely can influence the performance as well, because the Ruby GC is fairly weak.\\r\\n\\r\\n![](mem-decode.png)\\r\\n\\r\\n![](mem-encode.png)\\r\\n\\r\\nOn average **decoding works only 3.449x faster and needs 2.083x less memory whereas encoding works 6.300x faster and needs 8.75x less memory**.\\r\\n\\r\\nActually these benchmarks aren\'t really fair, because AMQ Protocol encoder/decoder do much more than the one in the AMQP gem: it\'s way more granular and it always takes care about errors, whereas the old one quite often just silently fails. This flexibility and extra functionality obviously has some overhead (and yet it\'s significantly faster!).\\r\\n\\r\\nWhat\'s next? Well, the next big thing on my TODO list is to **integrate AMQ Protocol to the AMQP gem, so you can benefit from these new changes in the next 0.8 release**! Then, if I\'ll have some time (my contract\'s running out), I\'d love to do some further optimisation for the methods which matters in performance impact."},{"id":"/2011/02/10/introducing-publisher-confirms","metadata":{"permalink":"/rabbitmq-website/blog/2011/02/10/introducing-publisher-confirms","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-02-10-introducing-publisher-confirms/index.md","source":"@site/blog/2011-02-10-introducing-publisher-confirms/index.md","title":"Introducing Publisher Confirms","description":"In many messaging scenarios, you must not lose messages.  Since AMQP gives few guarantees regarding message persistence/handling, the traditional way to do this is with transactions, which can be unacceptably slow.  To remedy this problem, we introduce an extension to AMQP in the form of Lightweight Publisher Confirms.","date":"2011-02-10T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":4.985,"hasTruncateMarker":true,"authors":[{"name":"Alexandru Scvortov","key":"alexandru","page":null}],"frontMatter":{"title":"Introducing Publisher Confirms","tags":["New Features"],"authors":["alexandru"]},"unlisted":false,"prevItem":{"title":"Ruby AMQP Benchmarks","permalink":"/rabbitmq-website/blog/2011/03/01/ruby-amqp-benchmarks"},"nextItem":{"title":"Who are you? Authentication and authorisation in RabbitMQ 2.3.1","permalink":"/rabbitmq-website/blog/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231"}},"content":"In many messaging scenarios, you must not lose messages.  Since AMQP gives few guarantees regarding message persistence/handling, the traditional way to do this is with transactions, which can be unacceptably slow.  To remedy this problem, we introduce an extension to AMQP in the form of Lightweight Publisher Confirms.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Guaranteed Delivery with Tx\\r\\n\\r\\nIn RabbitMQ, a persistent message is one that *should* survive a broker restart.  The operative word here is *should*, since the message can still be lost if broker goes down before it\'s had a chance to write the message to disk.  In some cases, this is not enough and the publisher needs to know whether a message was handled correctly or not.  The straightforward solution is to use transactions, i.e. to commit every message.\\r\\n\\r\\nThe publisher would use something like:\\r\\n\\r\\n```java\\r\\nch.txSelect();\\r\\nfor (int i = 0; i < MSG_COUNT; ++i) {\\r\\n        ch.basicPublish(\\"\\", QUEUE_NAME,\\r\\n                            MessageProperties.PERSISTENT_BASIC,\\r\\n                            \\"nop\\".getBytes());\\r\\n        ch.txCommit();\\r\\n}\\r\\n```\\r\\n\\r\\nAnd the consumer would do something like:\\r\\n\\r\\n```java\\r\\nQueueingConsumer qc = new QueueingConsumer(ch);\\r\\nch.basicConsume(QUEUE_NAME, true, qc);\\r\\nfor (int i = 0; i < MSG_COUNT; ++i) {\\r\\n        qc.nextDelivery();\\r\\n        System.out.printf(\\"Consumed %d\\\\n\\", i);\\r\\n}\\r\\n```\\r\\n\\r\\nThe complete program including some timing code is available [here](http://gist.github.com/613157).  It takes a bit more than 4 minutes to publish 10000 messages.\\r\\n\\r\\n## Streaming Lightweight Publisher Confirms\\r\\n\\r\\nThere are two problems with using transactions in this case.  The first is that they are blocking: the publisher has to wait for the broker to process each message.  Knowing that all the messages with the possible exception of the last one were successfully processed is, usually, too strong a guarantee; it would be enough if the publisher knew which messages had not yet been processed when the broker died.  The second problem is that transactions are needlessly heavy: every commit requires a fsync(), which takes a lot of time to complete.\\r\\n\\r\\nEnter Confirms: once a channel is put into confirm mode, the broker will confirm messages as it processes them.  Since this is done asynchronously, the producer can stream publishes and not wait for the broker and the broker can batch disk writes effectively.\\r\\n\\r\\nHere is the above example, but using confirms:\\r\\n\\r\\n```java\\r\\nprivate volatile SortedSet<Long> unconfirmedSet =\\r\\n    Collections.synchronizedSortedSet(new TreeSet());\\r\\n\\r\\n...\\r\\n\\r\\nch.setConfirmListener(new ConfirmListener() {\\r\\n    public void handleAck(long seqNo, boolean multiple) {\\r\\n        if (multiple) {\\r\\n            unconfirmedSet.headSet(seqNo+1).clear();\\r\\n        } else {\\r\\n            unconfirmedSet.remove(seqNo);\\r\\n        }\\r\\n    }\\r\\n    public void handleNack(long seqNo, boolean multiple) {\\r\\n        // handle the lost messages somehow\\r\\n    }\\r\\n});\\r\\nch.confirmSelect();\\r\\nfor (long i = 0; i < MSG_COUNT; ++i) {\\r\\n     unconfirmedSet.add(ch.getNextPublishSeqNo());\\r\\n     ch.basicPublish(\\"\\", QUEUE_NAME, MessageProperties.PERSISTENT_BASIC,\\r\\n                       \\"nop\\".getBytes());\\r\\n }\\r\\nwhile (unconfirmedSet.size() > 0)\\r\\n     Thread.sleep(10);\\r\\n```\\r\\n\\r\\nThe full code is available [here](http://hg.rabbitmq.com/rabbitmq-java-client/file/default/test/src/com/rabbitmq/examples/ConfirmDontLoseMessages.java).  Before going on, it is worth mentioning that running this takes around 2 seconds.  It is more than 100 times faster than the transactional code.\\r\\n\\r\\nWhat does the code do?  It starts by declaring a set which will hold the ids of the so-far unconfirmed messages.  Then, it sets the channel into confirm mode and attaches an AckListener to the channel.  As it publishes messages, it adds them to the set; at the same time, the AckListener removes messages from the set as it receives confirms.  Finally, the producer waits for all the messages to be confirmed.  The set always holds the messages which need to be retransmitted in case of a failure.\\r\\n\\r\\n## How Confirms Work\\r\\n\\r\\nConfirms extend standard AMQP by adding the confirm class.  This class contains only two methods, *confirm.select* and *confirm.select-ok*.  In addition, the *basic.ack* method can be sent to clients.\\r\\n\\r\\nThe *confirm.select* method enables publisher confirms on a channel.  Note that a transactional channel cannot be put into confirm mode and a confirm mode channel cannot be made transactional.\\r\\n\\r\\nWhen the *confirm.select* method is sent/received, the publisher/broker begins numbering publishes (the first publish after the *confirm.select* is 1).  Once a channel is in confirm mode, the publisher should expect to receive *basic.ack* methods.  The *delivery-tag* field indicates the number of the confirmed message.\\r\\n\\r\\nWhen the broker acknowledges a message, it assumes responsibility for it and informs the publisher that it has been handled successfully; what \\"handled successfully\\" means is context-dependent.\\r\\n\\r\\nThe basic rules are as follows:\\r\\n\\r\\n* an un-routable mandatory or immediate message is confirmed right after the *basic.return*;\\r\\n* otherwise, a transient message is confirmed the moment it is enqueued; and,\\r\\n* a persistent message is confirmed when it is persisted to disk or when it is consumed on every queue.\\r\\n\\r\\n![](pubacks.svg)\\r\\n\\r\\nNote that for a persistent message to be confirmed, it must be written to disk or ack\'d **on all the queues** it was delivered to.  With regard to confirms, persistent messages delivered to non-durable queues behave like transient messages.  Queue deletion, queue purge and [basic.reject](/blog/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq)&lcub;requeue=false} simulate a consumer acknowledgement.  With respect to [per-queue ttl](/docs/ttl#queue-ttl), message expiry simulates a consumer acknowledgement.\\r\\n\\r\\nIf more than one of these conditions are met, only the first causes a confirm to be sent.  Every published message will be confirmed sooner or later and no message will be confirmed more than once.   Since the *basic.return* is sent before the *basic.ack*, once a publisher receives a *basic.ack*, it knows that it will never hear of that message again.\\r\\n\\r\\nThe broker may always set the *multiple* bit in the *basic.ack*s.  A *basic.ack* with multiple set means that all messages up-to-and-including *delivery-tag* are acknowledged.\\r\\n\\r\\nThere are some gotchas regarding confirms.  Firstly, the broker makes no guarantees as to when a message will be confirmed, only that it will be confirmed.  Secondly, message processing slows down as un-confirmed messages pile up: the broker does several *O(log(number-of-unconfirmed-messages))* operations for each confirm-mode publish.  Thirdly, if the connection between the publisher and broker drops with outstanding confirms, it does not necessarily mean that the messages were lost, so republishing may result in duplicate messages.  Lastly, if something bad should happen inside the broker and cause it to lose messages, it will *basic.nack* those messages (hence, the *handleNack()* in *ConfirmHandler*).\\r\\n\\r\\nIn summary, Confirms give clients a lightweight way of keeping track of which messages have been processed by the broker and which would need re-publishing in case of broker shutdown or network failure."},{"id":"/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231","metadata":{"permalink":"/rabbitmq-website/blog/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-02-07-who-are-you-authentication-and-authorisation-in-rabbitmq-231/index.md","source":"@site/blog/2011-02-07-who-are-you-authentication-and-authorisation-in-rabbitmq-231/index.md","title":"Who are you? Authentication and authorisation in RabbitMQ 2.3.1","description":"RabbitMQ 2.3.1 introduces a couple of new plugin mechanisms, allowing you much more control over how users authenticate themselves against Rabbit, and how we determine what they are authorised to do. There are three questions of concern here:","date":"2011-02-07T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":3.17,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Who are you? Authentication and authorisation in RabbitMQ 2.3.1","tags":["New Features","HowTo"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Introducing Publisher Confirms","permalink":"/rabbitmq-website/blog/2011/02/10/introducing-publisher-confirms"},"nextItem":{"title":"RabbitMQ, backing stores, databases and disks","permalink":"/rabbitmq-website/blog/2011/01/20/rabbitmq-backing-stores-databases-and-disks"}},"content":"RabbitMQ 2.3.1 introduces a couple of new plugin mechanisms, allowing you much more control over how users authenticate themselves against Rabbit, and how we determine what they are authorised to do. There are three questions of concern here:\\r\\n\\r\\n1. How does the client prove its identity over the wire?\\r\\n1. Where do users and authentication information (e.g. password hashes) live?\\r\\n1. Where does permission information live?\\r\\n\\r\\nQuestion 1 is answered in the case of AMQP by [SASL](http://en.wikipedia.org/wiki/Simple_Authentication_and_Security_Layer) - a simple protocol for pluggable authentication mechanisms that is embedded within AMQP (and various other protocols). SASL lets a client and a server negotiate and use an authentication mechanism, without the \\"outer\\" protocol having to know any of the details about how authentication works.\\r\\n\\r\\nSASL offers a number of \\"mechanisms\\". Since the beginning, RabbitMQ has supported the PLAIN mechanism, which basically consists of sending a username and password over the wire in plaintext (of course possibly the whole connection might be protected by SSL). It\'s also supported the variant AMQPLAIN mechanism (which is conceptually identical to PLAIN but slightly easier to implement if you have an AMQP codec lying around). RabbitMQ 2.3.1 adds a plugin system allowing you to add or configure more mechanisms, and we\'ve written an example plugin which implements the SASL EXTERNAL mechanism.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThe SASL EXTERNAL mechanism basically says \\"somehow determine the user\'s identity by some mechanism outside the context of the protocol\\". In [rabbitmq-auth-mechanism-ssl](/docs/access-control#certificate-authentication) we take this to be SSL. When this plugin is installed and [enabled](/docs/authentication), clients can connect without supplying a username and password if they connect with SSL and present a client certificate which is trusted by the server\'s CA. In this case we take the username to be the Common Name of the certificate presented. As long as that username exists, they are let in.\\r\\n\\r\\nBut does that username exist? And what permissions are recorded against it? This is where we face up to questions number 2 (aka authentication) and 3 (aka authorisation).\\r\\n\\r\\nAgain, since the beginning, RabbitMQ has contained an internal database of users and permissions, managed though [rabbitmqctl](/docs/man/rabbitmqctl.8), and more recently the [management plugin](/docs/management). And again, RabbitMQ 2.3.1 adds a plugin system that allows you to augment or replace this database.\\r\\n\\r\\nAnd again, we\'ve written a plugin to do something interesting. [rabbitmq-auth-backend-ldap](/docs/ldap) lets you authenticate your users and check authorisation against an [LDAP](http://en.wikipedia.org/wiki/LDAP) database. This can entirely replace the built in database, or just augment it. [Configuring this plugin for authentication](http://hg.rabbitmq.com/rabbitmq-auth-backend-ldap/file/default/README) is (relatively) easy once you have an LDAP server up and running; you provide a template Distinguished Name for all your users (so that for example a user logging in as \\"guest\\" might have the DN \\"cn=guest,ou=People,dc=example,dc=com\\", and the plugin will attempt to bind to the LDAP server to check if they can log in. Easy!\\r\\n\\r\\nConfiguring the plugin for authorisation is hard though. Well, complicated. The problem is that LDAP has no ideas about how permissions should work in an AMQP broker (horrendous oversight!) and so we need to decide on some rules ourselves. The [README-authorisation](http://hg.rabbitmq.com/rabbitmq-auth-backend-ldap/file/default/README-authorisation) documents how this works in some detail, but in short there is a simple hierarchical query mechanism which lets you build queries against the LDAP database. For example:\\r\\n\\r\\n```erlang\\r\\n{vhost_access_query, {exists, \\"ou=${vhost},ou=vhosts,dc=example,dc=com\\"}}\\r\\n```\\r\\n\\r\\nis a simple query which determines whether LDAP users can see a virtual host based on whether a corresponding Organisational Unit exists in LDAP, while:\\r\\n\\r\\n```erlang\\r\\n{resource_access_query,\\r\\n {for, [{resource, exchange,\\r\\n         {for, [{permission, configure,\\r\\n                 { in_group, \\"cn=wheel,ou=groups,dc=example,dc=com\\" } },\\r\\n                {permission, write, {constant, true}},\\r\\n                {permission, read,  {constant, true}}\\r\\n               ]}},\\r\\n        {resource, queue, {constant, true}} ]}}\\r\\n```\\r\\n\\r\\nis a more complex query which would allow members of the \\"wheel\\" group to declare and delete exchanges, and allow all users to do everything else.\\r\\n\\r\\nSo, what do you think? Is this useful to you? How could it be improved?"},{"id":"/2011/01/20/rabbitmq-backing-stores-databases-and-disks","metadata":{"permalink":"/rabbitmq-website/blog/2011/01/20/rabbitmq-backing-stores-databases-and-disks","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-01-20-rabbitmq-backing-stores-databases-and-disks/index.md","source":"@site/blog/2011-01-20-rabbitmq-backing-stores-databases-and-disks/index.md","title":"RabbitMQ, backing stores, databases and disks","description":"From time to time, on","date":"2011-01-20T00:00:00.000Z","tags":[{"inline":true,"label":"Introductory","permalink":"/rabbitmq-website/blog/tags/introductory"}],"readingTime":7.365,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"RabbitMQ, backing stores, databases and disks","tags":["Introductory"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"Who are you? Authentication and authorisation in RabbitMQ 2.3.1","permalink":"/rabbitmq-website/blog/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231"},"nextItem":{"title":"Ruby AMQP 0.7 released!","permalink":"/rabbitmq-website/blog/2011/01/19/ruby-amqp-0-7-released"}},"content":"From time to time, on\\r\\nour [mailing\\r\\nlist](https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss) and elsewhere, the idea comes up of using a\\r\\ndifferent *backing store* within RabbitMQ. The backing store is\\r\\nthe bit that\'s responsible for writing messages to disk (a message can\\r\\nbe written to disk for a number of reasons) and it\'s a fairly frequent\\r\\nsuggestion to see what RabbitMQ would look like if its own backing\\r\\nstore was replaced with another storage system.\\r\\n\\r\\nSuch a change would permit functionality that is not currently\\r\\npossible, for example out-of-band queue browsing, or distributed\\r\\nstorage, but there is a fundamental difference in the nature of data\\r\\nstorage and access patterns between a message broker such as RabbitMQ\\r\\nand a generic database. Indeed RabbitMQ deliberately does not store\\r\\nmessages in such a database.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nFirstly we need to discuss what properties RabbitMQ itself expects of\\r\\nany backing store. RabbitMQ writes messages to disk in two cases:\\r\\neither the message has been published in such a way that it must be\\r\\nwritten to disk (e.g. published with `delivery_mode = 2`)\\r\\nor memory pressure is causing RabbitMQ to start running out of RAM and\\r\\nso it is pushing messages to disk in order to free up RAM. In the\\r\\nfirst case, just because we\'ve written the message to disk, does not\\r\\nmean that we\'re going to forget about it from RAM: if memory is\\r\\nabundant then there\'s no reason to incur the cost of a subsequent disk\\r\\nread.\\r\\n\\r\\nIn the second case, it means that any backing store that keeps\\r\\neverything in RAM all the time is immediately not a good fit: RabbitMQ\\r\\nwrites messages to disk in order to free up RAM, thus if the \\"writing\\r\\nto disk\\" bit actually just moves the message from one area of RAM to\\r\\nanother without freeing up RAM then nothing has been gained. Using\\r\\nsuch a backing store might work and it might achieve the improvements\\r\\nin functionality desired, but such a change would have substantial\\r\\nimpact on the scalability of RabbitMQ: it would no longer be able to\\r\\nabsorb more messages than can be kept in RAM, which was one of the\\r\\n*raisons d\'être* for the *new persister* work that led to\\r\\nRabbitMQ\'s current default backing store.\\r\\n\\r\\nSome databases or key-value stores write disk contents\\r\\nby initially writing a snapshot of their entire data set, and then\\r\\nwriting deltas to that data set. After a while, either time based or\\r\\nbased on the number of deltas, or ratio of deltas to snapshot size, a\\r\\nnew snapshot is written, and then the previous snapshot and all its\\r\\ndeltas can be thrown away. This is how RabbitMQ\'s *old persister*\\r\\nworked. The problem with this is that it can repeatedly cause vast\\r\\namounts of data to be unnecessarily rewritten. Imagine you have two\\r\\nqueues, one of which is entirely static: no one is publishing messages\\r\\nto it, and no one is consuming messages from it, it\'s just sitting\\r\\nthere, but it contains several million messages, all of which have\\r\\nbeen written to disk. The other queue is almost always empty, but is\\r\\nmoving very quickly -- thousands of messages a second are being\\r\\npublished and consumed from it. Every message sent to that queue has\\r\\nto be written to disk, but they\'re all being consumed as soon as\\r\\nthey\'ve been written to disk. Consider the effect of this scenario on\\r\\nthe backing store: the second queue will cause a rapid stream of\\r\\ndeltas to occur but whenever the snapshot is rewritten, it\'ll cause\\r\\nthe entire contents of the first queue to be rewritten too *even\\r\\nthough there has been no change to that queue\'s contents*. So\\r\\nagain, backing stores that write messages to disk in this way are\\r\\nlikely to be a poor fit for RabbitMQ\'s needs.\\r\\n\\r\\nSo suitable backing stores (assuming the performance and scalability\\r\\nproperties that RabbitMQ has need to be kept: this is by no means\\r\\ncertain in all scenarios) would be able to store a volume of data\\r\\nbounded only by disk size rather than RAM, and also have a reasonably\\r\\nsophisticated means of storing data on disk such that unchanged data\\r\\nwon\'t be rewritten indefinitely.\\r\\n\\r\\nThere are a couple of further aspects of RabbitMQ\'s default backing\\r\\nstore that are worth mentioning. Queues themselves decide when and\\r\\nwhether to write a message to disk. But a single message can be sent\\r\\nto multiple queues and it is obviously advantageous to make sure each\\r\\nmessage only gets written to disk once. However, there are two\\r\\ndistinct pieces of information here: firstly, the message content\\r\\nitself. This is the same in every queue that the message has been sent\\r\\nto, and should only be written to disk once, regardless of the number\\r\\nof queues it goes to; note that subsequent writes of this do not need\\r\\nto do a value comparison: if the ID of the message is known to the\\r\\nbacking store then the message body will match what is already on disk\\r\\n-- message content is never altered by the broker. The second piece of\\r\\ninformation is the existence of the message in each queue: where in\\r\\nthe queue it lies, what its neighbours are, and what its\\r\\nqueue-specific status is. This second piece of information is what\\r\\nallows RabbitMQ to start up, recover messages and queues from disk and\\r\\nensure that the messages in each queue are in the same order as when\\r\\nRabbitMQ was shut down.\\r\\n\\r\\nThus RabbitMQ\'s default backing store consists of a\\r\\nnode-global *message store* which is concerned only with writing\\r\\nmessage contents to disk; and a per queue *queue index* which\\r\\nuses a very different format for writing per message per queue data to\\r\\ndisk. Because these two needs are very specific, there are an awful\\r\\nlot of optimisations that can be applied (and we have!).\\r\\n\\r\\nGeneric database benchmarks normally show that read performance vastly\\r\\nout performs write performance. If it doesn\'t then that normally means\\r\\nthe writes aren\'t actually going to disk (with `fsync`), or\\r\\nthere\'s a bug which is crippling read performance. And indeed,\\r\\ndatabases have historically been optimised for read-heavy\\r\\nworkloads. This matches their general use case: there is a slowly\\r\\nexpanding data set which must be queried in various different ways.\\r\\nDeletions tend to be quite rare: if you think about the typical\\r\\nwebsite shopping basket on top of a relational database, then unless a\\r\\ncustomer deletes their account, there are very few reasons to ever\\r\\nissue deletions -- even if a product is discontinued, you\'re probably\\r\\njust going to set a flag on that product row because otherwise you\\r\\nrisk stopping customers from being able to see their order history\\r\\n(assuming it\'s normalised).\\r\\n\\r\\nSo the vast volume of data in most databases is fairly static. This is\\r\\nthe exact opposite of data in message brokers: for us, *reading*\\r\\ndata is the rarest operation, and *writing* and *deleting*\\r\\ndata are the common cases. Ideally, if RabbitMQ is running in\\r\\nplenty of memory, there will never be any reads from disk at\\r\\nall. There will only be writes for messages that are published in such\\r\\na way that they have to be written to disk, and even then, provided we\\r\\ncan get the message out to a consumer quickly enough, there are many\\r\\nways in which we can optimise out those writes. We only ever read data\\r\\nwhen memory pressure has forced us to write messages to disk and then\\r\\nforget about the message from RAM. Read performance is certainly\\r\\nimportant: we work hard to make sure RabbitMQ gets rid of data as fast\\r\\nas possible (without utilising `/dev/null`) and being able\\r\\nto read messages from disk quickly is part of that. But avoiding the\\r\\nwrite in the first place is the goal.\\r\\n\\r\\nIn fact, as far as message brokers are concerned, it\'s best to think\\r\\nof RAM as a large write-back cache for the disk, and then the task is\\r\\nto optimise the management of this cache to maximise the elimination of\\r\\nwrites by delaying them for as long as possible in the hope that the\\r\\ncorresponding deletion occurs before the write has really gone to\\r\\ndisk. This is quite obviously very different from normal databases\\r\\nwhich do not try to make gains from the lifespan of data being so\\r\\nshort as it frequently is in a message broker.\\r\\n\\r\\nNone of this is meant to deter efforts to make RabbitMQ work with\\r\\nalternative backing stores, but merely to explain why we decided to do\\r\\nour own thing when writing the *new persister* for RabbitMQ\\r\\n(which first came out with RabbitMQ version 2.0.0) rather than use an\\r\\noff-the-shelf data store. It explains why building a high performance\\r\\nmessage broker directly on top of a normal database is tricky at best,\\r\\nand why the nature of data in a message broker is very different from\\r\\nthe nature of data in a database."},{"id":"/2011/01/19/ruby-amqp-0-7-released","metadata":{"permalink":"/rabbitmq-website/blog/2011/01/19/ruby-amqp-0-7-released","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-01-19-ruby-amqp-0-7-released/index.md","source":"@site/blog/2011-01-19-ruby-amqp-0-7-released/index.md","title":"Ruby AMQP 0.7 released!","description":"I\'m happy to announce that the AMQP 0.7 is released, as I promised in the previous blog post. So what are the changes?","date":"2011-01-19T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":3.655,"hasTruncateMarker":true,"authors":[{"name":"Jakub Stastny","key":"botanicus","page":null}],"frontMatter":{"title":"Ruby AMQP 0.7 released!","tags":["New Features"],"authors":["botanicus"]},"unlisted":false,"prevItem":{"title":"RabbitMQ, backing stores, databases and disks","permalink":"/rabbitmq-website/blog/2011/01/20/rabbitmq-backing-stores-databases-and-disks"},"nextItem":{"title":"What\'s Going on with the Ruby AMQP Gem?","permalink":"/rabbitmq-website/blog/2011/01/12/ruby-amqp-gem-intro"}},"content":"I\'m happy to announce that the AMQP 0.7 is released, as I promised in the [previous blog post](/blog/2011/01/12/ruby-amqp-gem-intro). So what are the changes?\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n![](amqp-071.png)\\r\\n\\r\\n*When you install the AMQP gem, you\'ll see changes of the current version. (How did I do that? With [changelog gem](http://github.com/botanicus/changelog) and a bit of [gemspec magic](https://github.com/ruby-amqp/amqp/blob/master/amqp.gemspec#L29).)*\\r\\n\\r\\n## Callback for MQ#queue\\r\\n\\r\\nSynchronous API for `Queue.Declare`/`Queue.Declare-Ok` request/response was exposed via asynchronous callback:\\r\\n\\r\\n```ruby\\r\\nchannel = MQ.new\\r\\nfanout  = channel.fanout(:task_fanout)\\r\\nchannel.queue(:tasks) do |queue, message_count, consumer_count|\\r\\n  puts \\"Queue #{queue.name} declared!\\"\\r\\n  puts \\"Message count: #{message_count}\\"\\r\\n  puts \\"Consumer count: #{consumer_count}\\"\\r\\nend\\r\\n```\\r\\n\\r\\n## Auto-named queues &amp; not rewritting of anonymous entities in MQ#queues and MQ#exchanges\\r\\n\\r\\nIf a queue is declared with an empty name, the broker is supposed to generate random name. In previous versions of the Ruby AMQP this wasn\'t supported, because the synchronous API (waiting for `Queue.Declare-Ok` was missing). Not anymore:\\r\\n\\r\\n```ruby\\r\\nchannel = MQ.new\\r\\nchannel.queue(\\"\\") do |queue|\\r\\n  puts \\"Queue with name #{queue.name} declared!\\"\\r\\nend\\r\\n\\r\\n# OUTPUT: Queue with name amq.gen-PfCGdyBA4Sr4rkZg3IN3Kw== declared!\\r\\n```\\r\\n\\r\\nThe same should apply for exchanges, but this isn\'t supported by the current version of RabbitMQ.\\r\\n\\r\\nAlso, in the previous AMQP versions, the `MQ#queues`, `MQ#exchanges` and similar was just a hash, hence if given entity was anonymous (the name was `nil`), and if the collection already included another anonymous instance, then the one which was already in the collection was rewritten.\\r\\n\\r\\n## Callback for MQ::Queue#bind\\r\\n\\r\\n`MQ::Queue#bind` can take a callback, as well as `MQ#queue` now can:\\r\\n\\r\\n```ruby\\r\\nchannel = MQ.new\\r\\nfanout  = channel.fanout(:task_fanout)\\r\\nchannel.queue(:tasks).bind(fanout) do |queue|\\r\\n  puts \\"Queue #{queue.name} was bound!\\"\\r\\nend\\r\\n```\\r\\n\\r\\n## AMQP URL\\r\\n\\r\\nThanks to [majek](http://github.com/majek), author of the [Puka](http://github.com/majek/puka) AMQP client for Python, you can use URL instead of option hash as an argument for `AMQP.connect` and `AMQP.start`:\\r\\n\\r\\n```ruby\\r\\nAMQP.start(\\"amqps:/\\")\\r\\n\\r\\n# Will resolve to: {vhost: \\"/\\", port: 5671, ssl: true}\\r\\n\\r\\nAMQP.start(\\"amqp://botanicus@localhost:1111/\\")\\r\\n\\r\\n# Will resolve to: {user: \\"botanicus\\", vhost: \\"/\\", host: \\"localhost\\", port: 1111, ssl: false}\\r\\n```\\r\\n\\r\\n## MQ::Exchange.default\\r\\n\\r\\nThe default exchange is a direct exchange with an empty name where all the queues are automatically bound (and you can\'t bind there anything manually). Do not confuse the default exchange with `amq.direct` which is only a predefined direct exchange without any \\"magic\\" abilities).\\r\\n\\r\\n## Fail if an entity is re-declared with different options\\r\\n\\r\\nRather than wait for the server, than if possible we let this fail on the client, so the user gets more descriptive error message:\\r\\n\\r\\n```ruby\\r\\nchannel = MQ.new\\r\\nchannel.queue(:tasks, auto_delete: true)\\r\\nchannel.queue(:tasks, auto_delete: false)\\r\\n\\r\\n# Exception: There is already an instance called tasks with options\\r\\n\\r\\n{:queue => :tasks, :nowait => true, :auto_delete => true},\\r\\nyou can\'t define the same instance with different options ({:queue => :tasks,\\r\\n:nowait => true, :auto_delete => false})! (MQ::IncompatibleOptionsError)\\r\\n```\\r\\n\\r\\n## Don\'t reconnect if the credentials are invalid\\r\\n\\r\\nAMQP reconnects automatically if the connection failed. It did try to reconnect even on an error like providing invalid credentials. I changed it to register the reconnect hook after the connection is actually established, so if for whatever reason the connection fails, it won\'t try to reconnect.\\r\\n\\r\\n## rSpec 2 specs\\r\\n\\r\\nThis is still work in progress, you can check [the spec/ directory](https://github.com/ruby-amqp/amqp-spec). Huge thanks to [arvicco](https://github.com/arvicco/) and [michaelklishin](https://github.com/michaelklishin) for their work on this!\\r\\n\\r\\n## Issues\\r\\n\\r\\nWe closed nearly all issues at [tmm1/amqp](https://github.com/tmm1/amqp/issues) repository. Please do not report any further bugs there, use [ruby-amqp/amqp](https://github.com/ruby-amqp/amqp/issues) instead.\\r\\n\\r\\n## Friendlier environment for contributors\\r\\n\\r\\nWe use bundler now, so if you want to contribute or just run the tests, just clone the repo, run `bundle install` and voila, that\'s it! There\'s also `bin/irb` for easier debugging.\\r\\n\\r\\nSpeaking about them, **I\'d really want to thank all the contributors**, their work really helped to get the AMQP gem where it is now. Since the beginning 22 people contributed to the project, and 5 of them have more than 5 commits. Check the [CONTRIBUTORS](https://github.com/ruby-amqp/amqp/blob/0.7.x-stable/CONTRIBUTORS) file for more details!\\r\\n\\r\\n## Plans for AMQP 0.8\\r\\n\\r\\nThe next 0.8 release will bring some major API changes: there won\'t be two separate constants `MQ` and `AMQP`, but only the second one. The `MQ` class will become `AMQP::Channel`, so we will be compliant with the official AMQP terminology and we also want to introduce **support for AMQP 0.9.1** via the [AMQ-Protocol gem](https://github.com/ruby-amqp/amq-protocol).\\r\\n\\r\\n## Links\\r\\n\\r\\n* [RDoc API Documentation](http://rubydoc.info/github/ruby-amqp/amqp)\\r\\n* [GitHub repository](http://github.com/amqp-dev/amqp)\\r\\n* [GitHub issues](https://github.com/ruby-amqp/amqp/issues)\\r\\n* [Ruby AMQP Google Group](http://groups.google.com/group/ruby-amqp)\\r\\n\\r\\nAny comments, ideas? You\'re always welcome to drop by at Jabber MUC **amqp-dev@conf.netlab.cz**, and tell us what do you think!"},{"id":"/2011/01/12/ruby-amqp-gem-intro","metadata":{"permalink":"/rabbitmq-website/blog/2011/01/12/ruby-amqp-gem-intro","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2011-01-12-ruby-amqp-gem-intro/index.md","source":"@site/blog/2011-01-12-ruby-amqp-gem-intro/index.md","title":"What\'s Going on with the Ruby AMQP Gem?","description":"In the past year development of the AMQP gem was practicaly stagnating, as its original author Aman Gupta (@tmm1) was busy. A lot of bugs stayed unresolved, the code was getting old and out-dated and no new features or documentation were made.","date":"2011-01-12T00:00:00.000Z","tags":[{"inline":true,"label":"Introductory","permalink":"/rabbitmq-website/blog/tags/introductory"}],"readingTime":4.785,"hasTruncateMarker":true,"authors":[{"name":"Jakub Stastny","key":"botanicus","page":null}],"frontMatter":{"title":"What\'s Going on with the Ruby AMQP Gem?","tags":["Introductory"],"authors":["botanicus"]},"unlisted":false,"prevItem":{"title":"Ruby AMQP 0.7 released!","permalink":"/rabbitmq-website/blog/2011/01/19/ruby-amqp-0-7-released"},"nextItem":{"title":"AMQP 1.0 prototyping","permalink":"/rabbitmq-website/blog/2010/12/01/amqp-10-prototyping"}},"content":"In the past year development of the AMQP gem was practicaly stagnating, as its original author [Aman Gupta](https://github.com/tmm1) ([@tmm1](http://twitter.com/tmm1)) was busy. A lot of bugs stayed unresolved, the code was getting old and out-dated and no new features or documentation were made.\\r\\n\\r\\nAt this point I started to talk with the RabbitMQ guys about possible collaboration on this. Actually originally I contacted VMware when I saw [Ezra Zygmuntowicz](http://twitter.com/ezmobius) looking for people to his cloud team, but when I found that VMware recently acquired the RabbitMQ project in London, I got interested. I signed the contract, switched from `script/console` to Wireshark and the RabbitMQ Tracer and since November I\'ve been happily hacking on the AMQP and AMQ-Protocol gems.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nTo introduce myself, my name\'s [Jakub Stastny](https://github.com/botanicus) ([@botanicus](http://twitter.com/botanicus)) and I work as a Ruby contractor. I contributed to such projects as RubyGems, Merb and rSpec and I wrote my own framework called [Rango](http://www.rubyinside.com/rango-ruby-web-app-framework-2858.html), the only Ruby framework with template inheritance. I work with Node.js as well and I created [Minitest.js](https://github.com/botanicus/minitest.js), BDD framework for testing asynchronous code. My other hobbies are [photography](http://www.flickr.com/photos/jakub-stastny/sets/72157625593607741) and travelling.\\r\\n\\r\\nI asked Aman if I can take over the maintainership over the AMQP gem and he was happy to do so. At this point other two guys, Michael Klishin ([michaelklishin](https://github.com/michaelklishin)) and Ar Vicco ([arvicco](https://github.com/arvicco)) showed interest in the development, so we created [ruby-amqp organisation](https://github.com/ruby-amqp) at GitHub and forked the original code there, as well as a few other related repositories. The GitHub guys were happy to make our repository to be the main one, instead of just a fork, so since now, everything will be there (except the *old* issues which are still on tmm1\'s fork and which we want to solve and close soon).\\r\\n\\r\\n## Soo What\'s New?\\r\\n\\r\\n### Test Suite\\r\\n\\r\\nAt the beginning, there were barely any tests at all, so it was basically impossible to tell if the changes I made break something or not. So I started to write some. In the later stage, when michaelklishin and arvicco joined the development, we rewrote the few original Bacon specs to rSpec 2 and now arvicco is porting [his specs](https://github.com/ruby-amqp/amqp-spec) which he happened to write some time ago to the main repository. Arvicco has also written [amqp-spec](https://github.com/ruby-amqp/amqp-spec), superset of [em-spec](https://github.com/tmm1/em-spec) for testing the AMQP gem.\\r\\n\\r\\n### AMQP 0.9.1\\r\\n\\r\\nCurrently the gem speaks only AMQP 0.8, which is more than 2 years old version, so probably the most important upcoming feature is support of AMQP 0.9.1. Because this is something what can be beneficial for other clients as well, I decided to create a new library called [AMQ-protocol](https://github.com/ruby-amqp/amq-protocol). It\'s using [rabbitmq-codegen](https://github.com/rabbitmq/rabbitmq-codegen) as many others client libraries.\\r\\n\\r\\nOne of the main goals of this gem is to be really fast and memory-efficient (not for the sake of memory-efficiency itself, but because the garbage collector of MRI[^1] is quite weak) MRI. I\'m about to create some benchmarks soon to see if the performance is better and how much.\\r\\n\\r\\nAMQ-Protocol is still work-in-progress. It works, but it still needs some polishing, refactoring and optimizations, as well as documentation and tests.\\r\\n\\r\\n### Other Changes\\r\\n\\r\\nI fixed a lot of bugs and I merged all the pending pull requests to the main repository. I\'m going to write more about the changes once I\'ll release AMQP 0.7. I released 0.7.pre recently, you can try it by running `gem install amqp --pre`, which would be greatly appreciated. As the work on the test suite is still in progress now, the release process is kind of russian roulette at the moment.\\r\\n\\r\\n## Backward compatibility\\r\\n\\r\\nI fixed quite a few bugs and obviously the fixed code is never backward-compatible with the old buggy one. One of the major changes is that `MQ#queues` (as well as `MQ#fanouts` etc) is not a hash anymore, but an array-like collection with hash-like[^2] behaviour. It does NOT override anonymous instances when another anonymous instance is created (as it used to do before) and it does support server-generated names. So instead of `MQ#queues[nil] = <first instance>` and then `MQ#queues[nil] = <second instance>`) it now just adds both instances to the collection and when it receives `Queue.Declare-Ok` from the server, it updates the name to it.\\r\\n\\r\\n## Future plans\\r\\n\\r\\nThe AMQP gem is very opinionated. If you don\'t want to use EventMachine, you\'re out of luck. You might want to use something more low-level like `IO.select` or just another async library like [cool.io](http://coolio.github.com). You might not even want to care about the asynchronous code at all.\\r\\n\\r\\nIt\'d be great if we could have one really **un-opinionated AMQP client library** which only job would be to expose low-level API defined by the AMQP protocol without any abstraction like hidding channels etc. Such library would be intended for another library implementators rather than for the end users. AMQP is a complex protocol and because of some design decisions it\'s pretty hard to design a good and easy-to-use (opinionated) client library for it. So some basic library which doesn\'t make any assumptions would help others to play around and try to implement their own, opinionated libraries on top of this one without the need to manually implement the hard stuff like encoding/decoding or basic socket communication.\\r\\n\\r\\n## Questions? Ideas? Get in touch!\\r\\n\\r\\nAre you interested in the AMQP gem development? Do you want to participate or do you have some questions? Feel free to contact me, either by comments under this blog post, or you can drop me an e-mail to [stastny@101ideas.cz](mailto:stastny@101ideas.cz) or drop by to Jabber MUC[^3] room at **amqp-dev@conf.netlab.cz** where all the current maintainers usually are. And for all the news make sure you are following me on [Twitter](http://twitter.com/botanicus)!\\r\\n\\r\\n[^1]: Matz Ruby Implementation, the original and most widely-used Ruby implementation\\r\\n[^2]: Or is the adjective hash-ish?\\r\\n[^3]: Multi user chat"},{"id":"/2010/12/01/amqp-10-prototyping","metadata":{"permalink":"/rabbitmq-website/blog/2010/12/01/amqp-10-prototyping","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-12-01-amqp-10-prototyping/index.md","source":"@site/blog/2010-12-01-amqp-10-prototyping/index.md","title":"AMQP 1.0 prototyping","description":"We have been prototyping support for a new protocol, as is our wont.  This one is called \\"AMQP 1.0 R0\\", and it is the new issue from the AMQP working group (of which RabbitMQ, and latterly VMware, are a member). The \\"R0\\" indicates that it\'s the first revision of a recommendation. The specification is incomplete: there are many TODOs, and to a large extent it is unproven. Those two facts are part of what prompted this prototyping.","date":"2010-12-01T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"Hasenwerkstatt","permalink":"/rabbitmq-website/blog/tags/hasenwerkstatt"}],"readingTime":1.895,"hasTruncateMarker":false,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"AMQP 1.0 prototyping","tags":["New Features","Hasenwerkstatt"],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"What\'s Going on with the Ruby AMQP Gem?","permalink":"/rabbitmq-website/blog/2011/01/12/ruby-amqp-gem-intro"},"nextItem":{"title":"Chapter 1: Introduction to Distributed Systems","permalink":"/rabbitmq-website/blog/2010/11/17/chapter-1-introduction-to-distributed-systems"}},"content":"We have been prototyping support for a new protocol, as is our wont.  This one is called \\"AMQP 1.0 R0\\", and it is the new issue from the AMQP working group (of which RabbitMQ, and latterly VMware, are a member). The \\"R0\\" indicates that it\'s the first revision of a recommendation. The specification is incomplete: there are many TODOs, and to a large extent it is unproven. Those two facts are part of what prompted this prototyping.\\r\\n\\r\\nThe prototype code is mirrored at github: [http://github.com/rabbitmq/rabbitmq-amqp1.0](http://github.com/rabbitmq/rabbitmq-amqp1.0). It is built [just the same](/plugin-development) as all our plugins.\\r\\n\\r\\nThe AMQP 1.0 R0 specification differs from the specification of previous versions of AMQP, in that it does not define a broker model; i.e., it doesn\'t define exchanges queues and bindings, or their equivalents. The protocol is really only about transferring messages from one agent to another, and then agreeing on what the outcome was. That means it is amenable to bolting on to a message broker implementation, among other uses -- the idea is that one can adapt an  existing model to suit.\\r\\n\\r\\nIn our case, the incumbent model is that of AMQP 0-9-1, with some generalisations and extensions (for example, chained bindings). Our target with the prototype is therefore to be able to get something useful done with both 1.0 clients and 0-9-1 clients connected at the same time.\\r\\n\\r\\nWell, the good news is, we\'ve achieved that. In fact the plugin can be set up to replace Rabbit\'s usual network listener, and will happily talk to AMQP 0-8, 0-9-1, and 1.0 clients. We did have to do some invention along the way, and there are some parts of the specification that we are conspicuously not implementing. These will be detailed in the README soon.\\r\\n\\r\\nOne large part of the invention is to fill in semantics where the specification is silent. Some of these are detailed in [this client-broker protocol](amqp-broker-prototype.pdf) work we did for the AMQP working group. We\'re hoping the prototyping will help fill this out some more.\\r\\n\\r\\nNext week I\'ll be taking our prototype to the [AMQP 1.0 \\"Connectathon\\"](http://www.amqp.org/confluence/display/AMQP/Connectathon+1+%28Dec+2010%29\\r\\n), where it\'ll be tested against other implementations of the core protocol (not all of which are open source). Again, this will help to flush out barriers to interoperability in the specification."},{"id":"/2010/11/17/chapter-1-introduction-to-distributed-systems","metadata":{"permalink":"/rabbitmq-website/blog/2010/11/17/chapter-1-introduction-to-distributed-systems","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-11-17-chapter-1-introduction-to-distributed-systems/index.md","source":"@site/blog/2010-11-17-chapter-1-introduction-to-distributed-systems/index.md","title":"Chapter 1: Introduction to Distributed Systems","description":"RabbitMQ needs more and better documentation. (And who doesn\'t?) In particular, we need more and better introductory material that introduces the reader to various basic concepts, explains why they\'re important, and motivates him or her to keep reading and learn more about RabbitMQ. Here\'s a cut at Chapter 1 of that introduction. Your comments are welcome, and Chapters 2 and 3 will follow soon.","date":"2010-11-17T00:00:00.000Z","tags":[{"inline":true,"label":"Introductory","permalink":"/rabbitmq-website/blog/tags/introductory"}],"readingTime":6.41,"hasTruncateMarker":true,"authors":[{"name":"John DeTreville","key":"jdetreville","page":null}],"frontMatter":{"title":"Chapter 1: Introduction to Distributed Systems","tags":["Introductory"],"authors":["jdetreville"]},"unlisted":false,"prevItem":{"title":"AMQP 1.0 prototyping","permalink":"/rabbitmq-website/blog/2010/12/01/amqp-10-prototyping"},"nextItem":{"title":"rabbitmq + node.js = rabbit.js","permalink":"/rabbitmq-website/blog/2010/11/12/rabbitmq-nodejs-rabbitjs"}},"content":"RabbitMQ needs more and better documentation. (And who doesn\'t?) In particular, we need more and better introductory material that introduces the reader to various basic concepts, explains why they\'re important, and motivates him or her to keep reading and learn more about RabbitMQ. Here\'s a cut at Chapter 1 of that introduction. Your comments are welcome, and Chapters 2 and 3 will follow soon.\\r\\n(You probably already know all of this, but a surprising number of people don\'t. This introduction is for them.)\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## The Old Future\\r\\n\\r\\nLong, long ago, the American science-fiction writer Isaac Asimov imagined a future world in which one single giant computer, Multivac, would control all of mankind\'s affairs. Information would flow in from people and businesses and governments across the globe, and Multivac would store it and process it, and send exactly the right important new information right back out. All sorts of futuristic questions would pour in from our future selves, and the right futuristic answers would just pour back out. This future was a great place!\\r\\n\\r\\nAnd our present-day world isn\'t all that different from Asimov\'s future, just without all that shininess. We\'ve got the Internet, and it connects people and businesses and governments all over the globe, and information flows in, and information flows out, and questions pour in, and answers pour out. We\'ve got our Googles and our Amazons and our eBays and our Facebooks, and our lives keep getting better every day. More and better information; more and better storage and processing; more and better answers.\\r\\n\\r\\nBut Asimov was only a lowly Ph.D. chemist turned science-fiction writer, not any sort of real Computer Scientist like we have now, and he never worked out all (or, really, *any!*) of the technical details of *exactly* how you\'d build that one giant, all-knowing, all-powerful Multivac at the North Pole, and *exactly* who\'d pay for it, and *exactly* what uses they\'d allow, and *so* on. He left that part for future generations to figure out, if in fact they could. And as time has gone by, it\'s also turned out that any one single computer that anyone can buy at the computer shop down the street is still several orders of magnitude too small and too weak to control all of mankind\'s affairs. That\'s the bad news.\\r\\n\\r\\n## The New Future\\r\\n\\r\\nThe good news, which Asimov didn\'t anticipate (ha!), is that computers here in the future are *cheap*, almost dirt cheap, being made largely of silicon, which is after all just processed dirt. So if any one computer you can buy at the shop (or rent on the cloud from Amazon, or whatever) has a million times too little storage or processing power for what you want to do to or for mankind, just get a million of them and plug them together! (Some assembly required.) Google is close to doing just that, just as soon as it completes its takeover of the North Pole, and everyone else is trying to follow close behind. Google\'s got its own computers to execute its plans for the world, and Facebook\'s got its own computers and its own plans too, and the CIA too, and your company or organization too, and everyone cooperates and competes in controlling all of mankind\'s affairs. Our old *centralized* computer systems couldn\'t possibly grow big enough, so we\'re replacing them with shiny new *distributed* systems that could presumably grow bigger forever. And our lives keep getting better every day.\\r\\n\\r\\nBut getting your million computers (or even just a thousand, or even fewer!) to work together on their assigned tasks isn\'t as easy as it might sound to your upper management. One given server computer might crash once a year due to bad hardware or bad software or bad power or bad whatever, and that\'s usually being pretty optimistic. If you have only a thousand server computers, one will crash on the average every 9 hours; if you had a million, one would crash about every 30 seconds; if you had a billion, which not even Google has *yet*, about 30 would crash every second, and good luck getting the remainder not to crash or otherwise go bonkers too! One *centralized* computer can be either *up* or *down*, and that\'s it, but a *distributed* computer system is more likely to be 99% up and 1% down at any moment, and the 1% that\'s down keeps shifting around and further confusing the other 99%. Problems in distributed systems are unavoidable, and they can multiply without bound. Welcome to the future!\\r\\n\\r\\nYou may have just a thousand computers so far, or maybe just a hundred, or maybe even just ten or so, but you\'re still going to have problems and bad things are still going to happen. Crashes are one obvious cause, but lost messages or misconfigured systems or subtle race conditions all add to the error rate too. If you can\'t think of half a dozen more potential problems with large distributed systems, you\'ve probably never built or operated one. It would be impossibly hard to build that one giant Multivac at the North Pole, but it might be even harder to figure out exactly how those zillion smaller computers that you buy instead will ever work together. What to do?\\r\\n\\r\\n## Perfect Reliability (Not really)\\r\\n\\r\\nThere\'s a great saying: If you ever see a computer system described as _reliable_, look for the asterisk and the footnote that says _Not really_. Perfect reliability is impossible to achieve. Put your computers in an expensive data center in California, and one sufficiently large earthquake can knock them all out. Spread them out across a bunch of expensive data centers on different continental plates, and you just need a few more earthquakes (or tsunamis, or whatever) to knock enough of your computers (or network links, or whatever) to render the others useless. Enough natural or man-made catastrophes can ruin anything, and they can happen a lot more often than you might think, especially the man-made ones! That\'s the bad news.\\r\\n\\r\\nThe good news is, while you can\'t build perfectly reliable systems, you can build systems that are reliable *enough,* whatever that happens to be. That is, you can build computer systems that are arbitrarily reliable. You can ensure that if *enough* of your computers are up and connected and working correctly, then the system as a whole will continue to do the right things, and that even if more fail, then the system as a whole still won\'t do anything wrong. (It might not do anything at all, but that\'s life.) If you want more reliability, you can buy more computers (maybe a lot more) and connect them properly. If you know how.\\r\\n\\r\\n## Cargo Cults and Banks\\r\\n\\r\\nUnfortunately, much of the time, it seems that our distributed-system needs are growing faster than our expertise. Distributed systems are hard to build and they may never become all that easy. Right now, it\'s often all we can do adopt *best practices*, to look at distributed systems that got it right, and try to figure out why they succeeded, and to try to duplicate their success. It\'s a little like running your own cargo cult, but without all the coconuts.\\r\\n\\r\\n*Banks* are in many ways an excellent industry to study and perhaps to imitate. Banks (and other financial institutions) can clearly care *very* much about reliability, and banks have been building pretty large, pretty reliable distributed systems for some while now. Banks today tend to build their reliable distributed systems atop reliable *message-queuing systems,* and they\'ve even developed an open standard for such message-queuing systems, and that\'s worked out pretty well for them, and that\'s what we\'ll look at next."},{"id":"/2010/11/12/rabbitmq-nodejs-rabbitjs","metadata":{"permalink":"/rabbitmq-website/blog/2010/11/12/rabbitmq-nodejs-rabbitjs","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-11-12-rabbitmq-nodejs-rabbitjs/index.md","source":"@site/blog/2010-11-12-rabbitmq-nodejs-rabbitjs/index.md","title":"rabbitmq + node.js = rabbit.js","description":"For those who have been away from the internets, node.js is an evented JavaScript engine based on Google\'s V8. Because it is essentially one big, efficient event loop, it\'s a natural fit for programs that shuffle data backwards and forwards with little state in-between. And it\'s fun to program, an opinion apparently lots of people share, because there have been loads of libraries crop up around it.","date":"2010-11-12T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"},{"inline":true,"label":"Hasenwerkstatt","permalink":"/rabbitmq-website/blog/tags/hasenwerkstatt"}],"readingTime":2.82,"hasTruncateMarker":false,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"rabbitmq + node.js = rabbit.js","tags":["HowTo","Hasenwerkstatt"],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"Chapter 1: Introduction to Distributed Systems","permalink":"/rabbitmq-website/blog/2010/11/17/chapter-1-introduction-to-distributed-systems"},"nextItem":{"title":"Exchange to Exchange bindings","permalink":"/rabbitmq-website/blog/2010/10/19/exchange-to-exchange-bindings"}},"content":"For those who have been away from the internets, [node.js](http://nodejs.org/) is an evented JavaScript engine based on Google\'s V8. Because it is essentially one big, efficient event loop, it\'s a natural fit for programs that shuffle data backwards and forwards with little state in-between. And it\'s fun to program, an opinion apparently lots of people share, because there have been loads of libraries crop up around it.\\r\\n\\r\\nAmong the more impressive of these libraries is [Socket.IO](http://github.com/LearnBoost/Socket.IO).  One can combine Socket.IO with node.js\'s built-in web server to make a websocket server, with a socket abstraction for browsers that degrades to XHR tricks for when there\'s no websockets. (I would be happy to believe that node.js and Socket.IO were made for us by a benevolent and foresightful precursor race; but of course, they were made by hard-working clever people.  Thank you, people!)\\r\\n\\r\\nOnce one has a socket abstraction in the browser, a whole world opens up. Specifically, for our purposes, a whole world of messaging. Since node.js has an [AMQP client](http://github.com/ry/node-amqp), we can easily hook it up with RabbitMQ; not only to bridge to other protocols and back-end systems, but also to provide messaging *between* browsers, and between application servers, and so on.\\r\\n\\r\\nFollowing on from the [work we\'ve been doing with Martin Sustrik](http://github.com/rabbitmq/rmq-0mq) of [ZeroMQ](http://www.zeromq.com/), I decided to make a very simple protocol for using on the browser sockets, reflecting the messaging patterns used in ZeroMQ (and thereby in [RMQ-0MQ](http://github.com/rabbitmq/rmq-0mq/wiki)) -- **pub/sub**, **request/reply**, and **push/pull** (or pipeline). I wrote a node.js library that uses RabbitMQ to implement message patterns using its routing and buffering; the bridging then comes for free, since RabbitMQ has a bunch of protocol adapters and clients for various languages.\\r\\n\\r\\nA brief explanation of the messaging patterns:\\r\\n\\r\\n**Publish/Subscribe** is for the situation in which a published message should be delivered to multiple subscribers. In the general case, various kinds of routing can be used to filter the messages for each subscriber. This might be used to broadcast notifications from a backend system to users\' browsers, for example.\\r\\n\\r\\n**Request/Reply** is for RPC over messaging; requests are distributed round-robin among worker processes, and replies are routed back to the requesting socket. This might be used by browsers to query back-end services; or even for browsers to query each other.\\r\\n\\r\\n**Pipeline** is for chaining together processes.  Messages are pushed to worker processes in a round-robin, which themselves may push to another stage of processing. This might be used to co-ordinate a workflow among sets of users (or indeed individuals).\\r\\n\\r\\nHaving duly dispensed with ado, here is **[rabbit.js](http://github.com/squaremo/rabbit.js)**.\\r\\n\\r\\nAll it needs is a bare-bones [RabbitMQ](/docs/install-generic-unix) and node.js installed; and, the node-amqp and Socket.IO libraries.  Instructions and the locations of these things are in the [README](http://github.com/squaremo/rabbit.js/blob/master/README.md). (Do note that you need [my fork of node-amqp](http://github.com/squaremo/node-amqp).)\\r\\n\\r\\nIt also includes a tiny message socket server; that is, a node.js server that accepts socket connections and speaks in length-prefixed messages. Since it\'s all going through RabbitMQ, you can talk to the browsers hooked up with Socket.IO via a socket.  You can also use the in-process pipe server from code running in node.js itself.\\r\\n\\r\\nAll in all, I am surprised how much I could get done with only a handful of lines of code and some technologies that each hit a sweet spot -- node.js for fun network server programming, Socket.IO for magical browser sockets, and RabbitMQ for the no-tears messaging."},{"id":"/2010/10/19/exchange-to-exchange-bindings","metadata":{"permalink":"/rabbitmq-website/blog/2010/10/19/exchange-to-exchange-bindings","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-10-19-exchange-to-exchange-bindings/index.md","source":"@site/blog/2010-10-19-exchange-to-exchange-bindings/index.md","title":"Exchange to Exchange bindings","description":"Arriving in RabbitMQ 2.1.1, is support for bindings between exchanges. This is an extension of the AMQP specification and making use of this feature will (currently) result in your application only functioning with RabbitMQ, and not the myriad of other AMQP 0-9-1 broker implementations out there. However, this extension brings a massive increase to the expressivity and flexibility of routing topologies, and solves some scalability issues at the same time.","date":"2010-10-19T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":6.54,"hasTruncateMarker":true,"authors":[{"name":"Matthew Sackman","key":"matthew","page":null}],"frontMatter":{"title":"Exchange to Exchange bindings","tags":["New Features"],"authors":["matthew"]},"unlisted":false,"prevItem":{"title":"rabbitmq + node.js = rabbit.js","permalink":"/rabbitmq-website/blog/2010/11/12/rabbitmq-nodejs-rabbitjs"},"nextItem":{"title":"RabbitMQ/0MQ bridge","permalink":"/rabbitmq-website/blog/2010/10/18/rabbitmq0mq-bridge"}},"content":"Arriving in RabbitMQ 2.1.1, is support for bindings between exchanges. This is an extension of the AMQP specification and making use of this feature will (currently) result in your application only functioning with RabbitMQ, and not the myriad of other AMQP 0-9-1 broker implementations out there. However, this extension brings a massive increase to the expressivity and flexibility of routing topologies, and solves some scalability issues at the same time.\\r\\n\\r\\nNormal bindings allow exchanges to be bound to queues: messages published to an exchange will, provided the various criteria  of the exchange and its bindings are met, pass through the various bindings and be appended to the queue at the end of each binding. That\'s fine for a lot of use cases, but there\'s very little flexibility there: it\'s always just one hop -- the message being published to one exchange, with one set of bindings, and consequently one possible set of destinations. If you need something more flexible then you\'d have to resort to publishing the same message multiple times. With exchange-to-exchange bindings, a message published once, can flow through any number of exchanges, with different types, and vastly more sophisticated routing topologies than previously possible.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n## Example: Logging\\r\\n\\r\\nImagine a generic logging scenario: you want to \\"tap\\" into various parts of your message flows within RabbitMQ to check on the stream of messages that is flowing through that particular exchange. You can\'t do this to a queue, so the most obvious solution is to add a fresh queue which is going to be your logging queue, and to bind it to the exchange you\'re interested in. Now depending on the type of exchange and your binding key, you may receive none, some or all of the messages going through that exchange. This could be represented by the following diagram:\\r\\n\\r\\n![](e2e-1.svg)\\r\\n\\r\\nHowever, what about if you have multiple logging queues -- you might have one for syslog, one for the console, one for some third party management software. It would be much simpler to be able to treat all of these as single entity: thus requiring the addition of one binding, as above, to wire all of these to the same source exchange. With exchange-to-exchange bindings, you can now do this:\\r\\n\\r\\n![](e2e-2.svg)\\r\\n\\r\\nNow, we have our existing logging exchange with a couple of queues receiving all messages from it, and we just need to add one new binding (the one in *RabbitMQ-orange*) between the exchange we\'re interested in, and our logging exchange. Whilst both exchanges here are fanout, there\'s no need for this to be the case: we might have different logging queues which are interested in only subsets of the messages that are flowing through the logging exchange. So that exchange could well be a topic exchange:\\r\\n\\r\\n![](e2e-3.svg)\\r\\n\\r\\nSo now we have that *syslog* is only going to receive errors (i.e. messages with a routing key prefixed by `error.`), whilst the *console* receives all messages. But in both cases, this behaviour applies regardless of the source of the messages: the logging exchange can be bound to zero, one, or many exchanges as necessary:\\r\\n\\r\\n![](e2e-3a.svg)\\r\\n\\r\\n## Usage\\r\\n\\r\\nThe existing `queue.bind` AMQP method suggests, by its naming, that the action you\'re performing is to *bind a queue to an exchange*. This is slightly confusing because the messages are actually flowing from the exchange, through the binding, and to the queue. However, the easy part is that the method has a field for the `queue` name, the `exchange` name, and the binding key.\\r\\n\\r\\nWe have introduced `exchange.bind` and `exchange.unbind` AMQP methods. Sadly, because both of the end-points of such bindings are exchanges, and we can\'t have two fields both called `exchange`, we\'ve had to come up with a different naming scheme. We\'ve chosen here to reflect the flow of messages. Thus the field `source` indicates the name of the exchange from which messages enter the binding, and the field `destination` indicates the name of the exchange to which messages are passed.\\r\\n\\r\\nWe have added support for exchange-to-exchange bindings in our Java, .Net and Erlang clients. We hope other community-contributed clients will add support soon.\\r\\n\\r\\nThe binding created by `exchange.bind` is semantically identical to `queue.bind` bindings: unidirectional, binding keys and exchange types operate as normal, but both endpoints (the source and destination) of the binding are exchanges.\\r\\n\\r\\nJust like with `queue.bind`, multiple distinct bindings can be created between the same binding-endpoints. We detect and eliminate cycles during message delivery, and ensure that transitively, over any routing topology, for every queue to which a given message is routed, each queue will receive exactly one copy of that message. Exchanges which are declared as `auto-delete` will still be removed when all the bindings for which that exchange is the source are removed, regardless of whether the destination of those bindings are to queues or exchanges. Note that an auto-delete exchange will only be deleted when all bindings for which the exchange is the *source* are removed: if you add exchange-to-exchange bindings for which the given exchange is the *destination* then that exchange will not be auto-deleted on removal of those bindings. This mirrors the fact that an `auto-delete` queue is not deleted when bindings to that queue are removed.\\r\\n\\r\\n## Example 2: Presence\\r\\n\\r\\nImagine a chat system. Every user is going to have a queue, which holds all of the messages sent to that user. That queue also should be sent presence notifications: the events that indicate whether the person\'s friend is coming online or going offline.\\r\\n\\r\\nOur imaginary person is called John. When John comes online, he\'s going to publish a message to the exchange `presence` saying that he\'s online and available for chat. The `presence` exchange will thus be a `direct` exchange, and John will publish his presence to that exchange with a `routing key` of \\"John\\". Thus all of John\'s friends need to be subscribed to the `presence` exchange (i.e. they need to have a binding to their own queue from that exchange), with a binding key of \\"John\\". When logging in, John himself needs to bind his queue to the `presence` exchange, with one binding per friend: each binding carrying a different `binding key` (e.g. a binding with key of `Alice`, `Bill` etc). The overall system (just for presence) might look a bit like this:\\r\\n\\r\\n![](e2e-4.svg)\\r\\n\\r\\nHere we see John is friends with Alice and Bill (thus he binds to his queue from the presence exchange with routing keys of `Alice` and `Bill`). Alice and Bill are not friends with each other, but each of them have several other friends, each including John.\\r\\n\\r\\nThus when each person comes online, they must create their queue, and they must create bindings to that queue for each of their friends. In a large chat system, the average number of friends might be about 20, and there may be hundreds if not thousands of people coming online or going offline every minute. At this point, the churn rate in the bindings may become a severe performance bottleneck. With exchange-to-exchange bindings, this problem can be solved. The trick is to allow the friendship relations to be expressed solely by exchange-to-exchange bindings, which can be left in place even when users go offline. When the user comes online, they then need only to create their queue and a single binding:\\r\\n\\r\\n![](e2e-5.svg)\\r\\n\\r\\nAs usual, messages that are routed to exchanges with no bindings just vanish, so there is no buffering going on if John is offline, so `John_queue` doesn\'t exist: the exchange `John` discards all the messages sent to it in this case. Thus as a result, the exchange-to-exchange binding mesh only needs modifying when people add friends or remove friends, and the loading induced by friends coming online or going offline is vastly reduced.\\r\\n\\r\\nAnd this is merely the start: *far* more complex routing topologies are now possible with exchange-to-exchange bindings..."},{"id":"/2010/10/18/rabbitmq0mq-bridge","metadata":{"permalink":"/rabbitmq-website/blog/2010/10/18/rabbitmq0mq-bridge","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-10-18-rabbitmq0mq-bridge/index.md","source":"@site/blog/2010-10-18-rabbitmq0mq-bridge/index.md","title":"RabbitMQ/0MQ bridge","description":"Recently, Michael Bridgen and I implemented a bridge to connect the RabbitMQ broker with applications using 0MQ for messaging.","date":"2010-10-18T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"},{"inline":true,"label":"Hasenwerkstatt","permalink":"/rabbitmq-website/blog/tags/hasenwerkstatt"}],"readingTime":4.715,"hasTruncateMarker":true,"authors":[{"name":"Martin Sustrik","key":"sustrik","page":null}],"frontMatter":{"title":"RabbitMQ/0MQ bridge","tags":["New Features","Hasenwerkstatt"],"authors":["sustrik"]},"unlisted":false,"prevItem":{"title":"Exchange to Exchange bindings","permalink":"/rabbitmq-website/blog/2010/10/19/exchange-to-exchange-bindings"},"nextItem":{"title":"Prompt-a-licious","permalink":"/rabbitmq-website/blog/2010/10/02/prompt-a-licious"}},"content":"Recently, Michael Bridgen and I implemented a bridge to connect the RabbitMQ broker with applications using [0MQ](http://www.zeromq.com/) for messaging.\\r\\n\\r\\nHere it is: [http://github.com/rabbitmq/rmq-0mq](http://github.com/rabbitmq/rmq-0mq)\\r\\n\\r\\nSo: What kind of benefit the users can get by using both products in parallel?\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nIn short, there are two different points of view involved here. RabbitMQ users will experience different benefits than users of 0MQ. Those already using both will simply get an easy way to interconnect the two technologies.\\r\\n\\r\\nThis is RabbitMQ blog so let\'s start with Rabbit-focused point of view.\\r\\n\\r\\nFirst and most obviously, using 0MQ as a client for RabbitMQ broker makes sense on the platforms where there\'s no AMQP client available. Ever fancied speaking to RabbitMQ broker from Lisp? Or -- say -- from Cobol? The bridge may come handy here.\\r\\n\\r\\nThe same applies to OS/HW platforms. Do you need to speak to the broker from a device heavily constrained on memory, with very slow CPU or limited battery life? 0MQ client is pretty concise and very fast, which means that you\'ll get reasonable performance even on slow chips. Effectiveness also translates to lower power consumption, which in turn makes the battery last longer. The r0mq bridge itself is collocated with the RabbitMQ broker requiring no additional resources on the client.\\r\\n\\r\\nAnother usage of the bridge is much more sophisticated. If you are using RabbitMQ in very simple scenarios you may not even appreciate it. If you are managing a big geographically distributed system, it may become a lifesaver. The bridge can be used to interconnect RabbitMQ brokers into loose federation. Just edit the configuration files for the two brokers and everything will just work. You won\'t have to care about order of starting up the brokers, managing the reconnections after network disruptions etc. A nice feature is that these federations are truly distributed. There\'s no need for central governance of the federation. Simply connect your broker to a broker in a different company. That one in turn connects to brokers in yet different companies etc. Ultimately you end up with loose world-wide federation maintained in collaborative fashion by all the participants.\\r\\n\\r\\nYet one more advantage you may take advantage of is efficient usage of network resources. Unlike AMQP, 0MQ allows you to split your messaging traffic into logically separate flows. You pass your entertainment video in a separate flow from commands used to keep the aircraft flying. This not only means that you\'ll never experience head-of-line blocking problems, but also that network-level QoS can be set separately for the entertainment channel and for the steering system. Also, network engineers will appreciate that you can monitor the network traffic flow-by-flow rather than having a big opaque chunk of bandwidth used by \\"messaging\\".\\r\\n\\r\\nFinally, 0MQ is bundled with OpenPGM library which implements a reliable mutlicast protocol called PGM. The r0mq bridge thus allows to multicast messages from RabbitMQ broker to the clients (0MQ clients to\\r\\nbe precise -- AMQP has no multicast support). This kind of functionality is extremely useful in scenarios where a lot of identical data is passed to many boxes on the LAN. If a separate copy of each datum is sent to each subscriber, you can easily exceed capacity of your network. With multicast, data is sent once only to all the subscribers thus keeping the bandwidth usage constant even when the number of subscribers grows.\\r\\n\\r\\nWhen you looking at r0mq bridge from the other side, you are probably developing at a low level using 0MQ as your network transport.\\r\\n\\r\\nUsing RabbitMQ broker has some obvious uses. The most trivial of them is to use the broker as a bridge to connect 0MQ applications to AMQP, STOMP or XMPP applications.\\r\\n\\r\\nHowever, the real use case is to use RabbitMQ as a \\"device\\" in 0MQ network. 0MQ comes with few simple precompiled devices. Some hardware can be used as 0MQ device (say IP switch in case of multicast\\r\\ntransport). There\'ve been some attempts to create more sophisticated devices but these are in very early stages of development. So, what 0MQ developers are missing is a full-blown, sophisticated and\\r\\nproduction-ready device.\\r\\n\\r\\nRabbitMQ broker can serve as such a device. First of all, it has been deployed widely and thus it is stable enough to be used in production environment safely. As for the feature set, it offers much more than anything found in 0MQ world. The two most useful features are persistence and monitoring.\\r\\n\\r\\nPersistence means that the messages passing through the broker are saved on the disk. When you shut down the broker, if the box crashes because of power outage or a different technical problem, the messages are still available on the disk. When the broker is restarted they will be sent further as if the crash hasn\'t happened. It is similar to how email works.\\r\\n\\r\\nMonitoring is asked for maybe even more often than persistence. Once you have a non-trivial system you want to know what each node is doing: How many messages there are stored for a particular feed What\'s the current throughput? And so on. RabbitMQ can tell you these things through its [command-line tools](/docs/man/rabbitmqctl.8) or through the [management plugin](/docs/management).\\r\\n\\r\\nAs a conclusion I would like to stress that bridging 0MQ and RabbitMQ is not just that dumb kind of bridge you get when you bridge two incompatible but more or less equivalent products. RabbitMQ and 0MQ are focusing on different aspects of messaging. 0MQ puts much more focus on how the messages are transferred over the wire. RabbitMQ, on the other hand, focuses on how messages are stored, filtered and monitored. By combining the two technologies you can get the best from both worlds.\\r\\n\\r\\nEnjoy!"},{"id":"/2010/10/02/prompt-a-licious","metadata":{"permalink":"/rabbitmq-website/blog/2010/10/02/prompt-a-licious","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-10-02-prompt-a-licious/index.md","source":"@site/blog/2010-10-02-prompt-a-licious/index.md","title":"Prompt-a-licious","description":"I am setting up my old MacBook, reclaimed from my housemate, to be usable for the programmings.","date":"2010-10-02T00:00:00.000Z","tags":[{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to"}],"readingTime":0.885,"hasTruncateMarker":true,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"Prompt-a-licious","tags":["HowTo"],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"RabbitMQ/0MQ bridge","permalink":"/rabbitmq-website/blog/2010/10/18/rabbitmq0mq-bridge"},"nextItem":{"title":"Broker vs Brokerless","permalink":"/rabbitmq-website/blog/2010/09/22/broker-vs-brokerless"}},"content":"![](prompt.png)\\r\\n\\r\\nI am setting up my old MacBook, reclaimed from my housemate, to be usable for the programmings.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nThe first step was to [install homebrew](http://github.com/mxcl/homebrew/wiki/installation). I\'m finding it a bit friendlier than macports, which seems to be irretrievably broken on the other MacBook.\\r\\n\\r\\nAfter a few more steps (git, mercurial, node, rabbitmq of course), I found myself missing my pretty [hg-prompt](http://stevelosh.com/projects/hg-prompt/) bash prompt. But I\'m working with git much more these days, so I wondered if there was something that could do both.\\r\\n\\r\\nThere is: vcprompt, and what do you know it\'s in homebrew.\\r\\n\\r\\n```shell\\r\\n$ brew install vcprompt\\r\\n```\\r\\n\\r\\nTo get the pretty prompt, I more or less transcribed what I had from hg-prompt.  In `.bashrc`:\\r\\n\\r\\n```shell\\r\\nD=$\'\\\\e[37;40m\'\\r\\nPINK=$\'\\\\e[35;40m\'\\r\\nGREEN=$\'\\\\e[32;40m\'\\r\\nORANGE=$\'\\\\e[33;40m\'\\r\\n\\r\\nvc_ps1() {\\r\\n    vcprompt -f \\"(%n:${PINK}%b${D}${GREEN}%u%m${D})\\" 2>/dev/null\\r\\n}\\r\\n\\r\\nexport PS1=\'${GREEN}\\\\u@\\\\h${D} in ${ORANGE}\\\\w${D}$(vc_ps1)\\\\n$ \'\\r\\n```\\r\\n\\r\\nBy the way, if like me you forget which of `.bashrc` and `.bash_profile` is for what, this post explains it[http://www.joshstaiger.org/archives/2005/07/bash_profile_vs.html].\\r\\n\\r\\nIf you want to get fancy, there\'s a guide to customising the bash prompt on the [Arch Linux wiki](http://wiki.archlinux.org/index.php/Color_Bash_Prompt)."},{"id":"/2010/09/22/broker-vs-brokerless","metadata":{"permalink":"/rabbitmq-website/blog/2010/09/22/broker-vs-brokerless","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-09-22-broker-vs-brokerless/index.md","source":"@site/blog/2010-09-22-broker-vs-brokerless/index.md","title":"Broker vs Brokerless","description":"The RabbitMQ team has been working with Martin Sustrik to provide code and documentation for using RabbitMQ and ZeroMQ together.  Why is this a good idea?  Because the broker and brokerless approaches are complementary.  We\'ll be posting more about this as the codebase evolves.  This post is introductory and can be seen as commentary on Ilya Grigorik\'s excellent introduction to ZeroMQ and the InfoQ summary of Ilya\'s article.","date":"2010-09-22T00:00:00.000Z","tags":[],"readingTime":5.145,"hasTruncateMarker":true,"authors":[{"name":"Alexis Richardson","key":"alexis","page":null}],"frontMatter":{"title":"Broker vs Brokerless","tags":[],"authors":["alexis"]},"unlisted":false,"prevItem":{"title":"Prompt-a-licious","permalink":"/rabbitmq-website/blog/2010/10/02/prompt-a-licious"},"nextItem":{"title":"RabbitMQ on github","permalink":"/rabbitmq-website/blog/2010/09/20/rabbitmq-on-github"}},"content":"The RabbitMQ team has been working with Martin Sustrik to provide [code and documentation for using RabbitMQ and ZeroMQ together](http://github.com/rabbitmq/rmq-0mq/wiki).  Why is this a good idea?  Because the broker and brokerless approaches are complementary.  We\'ll be posting more about this as the codebase evolves.  This post is introductory and can be seen as commentary on [Ilya Grigorik\'s excellent introduction to ZeroMQ](http://www.igvita.com/2010/09/03/zeromq-modern-fast-networking-stack/) and the [InfoQ summary of Ilya\'s article](http://www.infoq.com/news/2010/09/introduction-zero-mq).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nI like ZeroMQ and think it is useful - of which more below.  But I have seen some brash claims made on its behalf. This [can lead to confusion](http://www.reddit.com/r/programming/comments/d9jrm/zeromq_networking_stack_sending_millions_of_small/).\\r\\n\\r\\nSo what is the \'brokerless\' model?  In the comments to Ilya\'s and the InfoQ post, ZeroMQ is compared to SCTP and to JGroups.  These are important technologies and form a helpful starting point for thinking about brokerless messaging patterns.  Let\'s look at what you might need if you combine messaging (like SCTP) with pubsub groups (like JGroups) to make arbitrary networks using \'brokerless\' peers.\\r\\n\\r\\n**Some things you might need in a brokerless network**\\r\\n\\r\\nIf you set up a brokerless messaging network, three things that you might need are: discovery, availability and management.\\r\\n\\r\\nDiscovery is the problem of maintaining a roster of peers that a system can send messages to, and who can join this roster.\\r\\n\\r\\nAvailability is the problem of dealing with peers disappearing from time to time.  For example if you have 50 subscribers to a feed, and only 40 of them are available to receive updates, should you keep a copy of their messages until they reappear?  That could mean \\"for a very long time\\".   And if you do keep messages and lists of \\"who has seen what\\", then where is it best to do this?\\r\\n\\r\\nThis is also a problem when message receivers do not respond quickly. To [quote from Martin Sustrik of ZeroMQ](http://news.ycombinator.com/item?id=1662868), \\"You can never differentiate between \'network error and \'no response received\'. TCP in no better. You\'ll have accept that or keep with a single box.\\"\\r\\n\\r\\nManagement is an interesting area for analysis too.  ZeroMQ\'s model aligns messaging closely with sockets.  This means that, like in TCP, \'any\' communication network can be implemented in such a way that it provides some messaging capability.  But, networks can be arbitrarily complex.  For example unless you don\'t care about it (and you may not) management of \\"who is connected to who, and who can be connected to who\\" can get complicated.   This kind of management problem gets more difficult the more you scale.  Models like JGroups usually make this problem go away by making a simplifying assumption, i.e.: everyone in the group talks to everyone else in the group.  Easy :-)\\r\\n\\r\\nI am not suggesting that you always need these things.  The ZeroMQ philosophy is to home right in on networking, and this creates focus.  But if you do need them then you might end up implementing them yourself.  Enter the broker...\\r\\n\\r\\n**How can a broker help to solve these problems **\\r\\n\\r\\nBrokers can provide solutions for discovery, availability and management.  They can also form reliable networks, e.g. for email delivery and instant messaging services.\\r\\n\\r\\nFirst: what is a \'broker\'?  It is both a leader, and an intermediary.\\r\\n\\r\\nA broker is a leader.  In distributed computing, the problems of management, discovery and availability are typically solved by electing a leader among the set of distributed components.  In the world of \\"messaging\\", such a leader is usually known as a \\"broker\\".  Stating that in order to be a leader, you need to be a broker, makes it much easier to work out who is the leader, than in a completely brokerless system in which \\"anyone can lead, but nobody knows how\\".\\r\\n\\r\\nA broker is also an intermediary.  For example, instead of having to connect everyone in the group directly, communicators simply connect to the broker (or brokers).  A broker may also be used to solve availability problems such as \\"offline consumer\\", by providing persistence and managing recovery on behalf of systems that cannot do it themselves.\\r\\n\\r\\nThus, brokers **simplify** network design by making reasonable assumptions.  Of course, when those assumptions don\'t hold, you may not want a broker.\\r\\n\\r\\n**Brokers are not \'centralized\'**\\r\\n\\r\\nA commonly held misconception about brokers is that they are \'centralized\'.  Brokers are NOT necessarily a \'centralized\' solution.  Intermediaries can be decentralized.  You can have multiple brokers in a single network in order to increase throughput and availability.  Sometimes these networks of servers are called federations.  Note that individual brokers do not need to be \'highly available\' in order to have a redundant network of servers.\\r\\n\\r\\nThis is, for example, how email (SMTP) and XMPP networks work.  Both email and instant messaging are brokered models, and both use multiple brokers in a simple and redundant way.  For example, mail transfer agents provide a delivery and routing network for email.  It would be difficult to come up with a design for this that was completely peer to peer, without reinventing \'special peers\' - also known as brokers.\\r\\n\\r\\n**So what model is simplest?**\\r\\n\\r\\nPeer to peer models are not **inherently** more or less simple than brokered models.  If you do not need discovery, availability, management, or intermediation then it may be simpler to not use them.  But if you need them, it may be simpler to not implement them yourself.\\r\\n\\r\\nNetworks of servers (brokers) are not more or less redundant or decentralized than networks of clients (peers).  Both the broker and brokerless model have their pros and cons in terms of reliability, and other considerations eg latency.\\r\\n\\r\\nThe two models solve different problems.\\r\\n\\r\\nFor example, RabbitMQ and ZeroMQ are complementary.  From a RabbitMQ point of view ZeroMQ is a \'smart client\' that can use its buffers like a queue.  That\'s useful in some cases.  From a ZeroMQ point of view, RabbitMQ is a network device that provides services that you would not necessarily want to have to implement yourself.\\r\\n\\r\\nWe want our customers and users to always have the best toolset available which is why we have provided the [Github repo for you to play with](http://github.com/rabbitmq/rmq-0mq/wiki).  Thanks again to Martin Sustrik for his work on this.\\r\\n\\r\\nWatch this space for more on this interesting area of work and discussion."},{"id":"/2010/09/20/rabbitmq-on-github","metadata":{"permalink":"/rabbitmq-website/blog/2010/09/20/rabbitmq-on-github","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-09-20-rabbitmq-on-github/index.md","source":"@site/blog/2010-09-20-rabbitmq-on-github/index.md","title":"RabbitMQ on github","description":"We\'ve received quite a few requests recently for us to put the RabbitMQ code on github.","date":"2010-09-20T00:00:00.000Z","tags":[],"readingTime":0.86,"hasTruncateMarker":false,"authors":[{"name":"David Wragg","key":"david","page":null}],"frontMatter":{"title":"RabbitMQ on github","tags":[],"authors":["david"]},"unlisted":false,"prevItem":{"title":"Broker vs Brokerless","permalink":"/rabbitmq-website/blog/2010/09/22/broker-vs-brokerless"},"nextItem":{"title":"Very fast and scalable topic routing - part 1","permalink":"/rabbitmq-website/blog/2010/09/14/very-fast-and-scalable-topic-routing-part-1"}},"content":"We\'ve received quite a few requests recently for us to put the RabbitMQ code on [github](http://github.com/).\\r\\n\\r\\nRabbitMQ is open source, and the [Mercurial repositories](http://hg.rabbitmq.com/) where we work on the code are publicly accessible. But github is rapidly establishing itself as the Facebook of open-source development: It makes it easy to follow projects and participate in their development, all within a slick web-based UI.\\r\\n\\r\\nSo from today, we are mirroring our repositories to github.  You can find them at [http://github.com/rabbitmq](http://github.com/rabbitmq).  The repositories on github track our Mercurial repositories with a delay of a few minutes.\\r\\n\\r\\nThe main development of RabbitMQ will continue to take place on Mercurial. Converting our development workflow and infrastructure to git would take a lot of effort that we\'d prefer to spend improving RabbitMQ. And besides, members of the team differ in their opinions about the relative merits of hg and git.\\r\\n\\r\\nIf you wish to contribute to RabbitMQ, we are happy to receive changes via github, or Mercurial hosting sites such as [bitbucket](http://bitbucket.org/), or even as old-fashioned patches!"},{"id":"/2010/09/14/very-fast-and-scalable-topic-routing-part-1","metadata":{"permalink":"/rabbitmq-website/blog/2010/09/14/very-fast-and-scalable-topic-routing-part-1","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-09-14-very-fast-and-scalable-topic-routing-part-1/index.md","source":"@site/blog/2010-09-14-very-fast-and-scalable-topic-routing-part-1/index.md","title":"Very fast and scalable topic routing - part 1","description":"Among other things, lately we have been preoccupied with improving RabbitMQ\'s routing performance. In particular we have looked into speeding up topic exchanges by using a few well-known algorithms as well as some other tricks. We were able to reach solutions many times faster than our current implementation.","date":"2010-09-14T00:00:00.000Z","tags":[],"readingTime":4.39,"hasTruncateMarker":true,"authors":[{"name":"Vlad Alexandru Ionescu","key":"vlad","page":null}],"frontMatter":{"title":"Very fast and scalable topic routing - part 1","tags":[],"authors":["vlad"]},"unlisted":false,"prevItem":{"title":"RabbitMQ on github","permalink":"/rabbitmq-website/blog/2010/09/20/rabbitmq-on-github"},"nextItem":{"title":"Management plugin - preview release","permalink":"/rabbitmq-website/blog/2010/09/07/management-plugin-preview-release"}},"content":"Among other things, lately we have been preoccupied with improving RabbitMQ\'s routing performance. In particular we have looked into speeding up topic exchanges by using a few well-known algorithms as well as some other tricks. We were able to reach solutions many times faster than our current implementation.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nFirst, a little about the problem we are trying to solve. Here is a quote from the AMQP 0-9-1 spec:\\r\\n\\r\\nThe topic exchange type works as follows:\\r\\n\\r\\n1. A message queue binds to the exchange using a routing pattern, P.\\r\\n1. A publisher sends the exchange a message with the routing key R.\\r\\n1. The message is passed to the message queue if R matches P.\\r\\n\\r\\n*The routing key used for a topic exchange MUST consist of zero or more words delimited by dots. Each word may contain the letters A-Z and a-z and digits 0-9.*\\r\\n\\r\\n*The routing pattern follows the same rules as the routing key with the addition that * matches a single word, and # matches zero or more words. Thus the routing pattern *.stock.# matches the routing keys usd.stock and eur.stock.db but not stock.nasdaq.*\\r\\nOur goal is to match messages (routing keys) against bindings (patterns) in a fast and scalable manner.\\r\\n\\r\\nHere is a list of approaches that we tried out:\\r\\n\\r\\n1. **Caching messages\' topics on a per-word basis**. This is what the AMQP spec suggests and there are some studies on this already.\\r\\n2. **Indexing patterns on a per-word basis**. This is similar with 1, except we prepare the patterns beforehand, rather than preparing for topic keys that have been previously sent.\\r\\n3. **Trie implementation**. Arrange the words in the patterns in a trie structure and follow a route down the trie to see if a particular topic matches.\\r\\n4. **A deterministic finite automate (DFA) implementation**. This is a well-known approach for string matching, in general.\\r\\n\\r\\nEach of these approaches have pros and cons. We generally aimed for:\\r\\n\\r\\n* good complexity in both space and time, to make it scalable\\r\\n* ease of implementation\\r\\n* good performance for the commonly used situations\\r\\n* good worst-case performance\\r\\n* making it quick in the simple cases (where scalability in number of bindings is not a concern)\\r\\n\\r\\nFrom the start, we were able to beat the current implementation by a factor of 3 times (in all cases) just by being more careful when splitting the keys into words (not repeating splitting both the pattern and the topic for each pattern, every time).\\r\\n\\r\\nWe found approaches 1 and 2 to be particularly unfit for the needs. They were the slowest, they do not have a good complexity, because they involve intersecting sets for each level, and they can not be adapted to include functionality for \\"#\\". Thus, we concentrated our attention on approaches 3 and 4.\\r\\n\\r\\n**The trie**\\r\\n\\r\\nHere is an example of a trie structure, if we were to add patterns \\"a.b.c\\", \\"a.*.b.c\\", \\"a.#.c\\", \\"b.b.c\\":\\r\\n\\r\\n![](trie-example.png)\\r\\n\\r\\nIn order to match a pattern (say for example \\"a.d.d.d.c\\"), we start at root and follow the topic string down the tree word by word. We can go deeper either through an exact match, a \\"*\\" or a \\"#\\". In the case of the \\"#\\" we can go deeper with all the versions of the tail of the topic. For our example, we would go through \\"#\\" with \\"d.d.d.c\\", \\"d.d.c\\", \\"d.c\\", \\"c\\" and \\"\\".\\r\\n\\r\\nThe trie implementation has a number of advantages: good size complexity; adding a new binding is cheap; and it is the easiest to implement; but, also the disadvantage that it backtracks for \\"*\\" and \\"#\\", in order to find all possible matches.\\r\\n\\r\\n**The DFA**\\r\\n\\r\\nThis approach is based on constructing an NFA that accepts the patterns of the bindings, and from it constructing the equivalent DFA and using it instead. Since we are also interested in which pattern matches and not only if it matches or not, we cannot merge the tails of the patterns in the NFA.\\r\\n\\r\\nTo construct the DFA, we modeled the behaviour of \\"#\\" like this:\\r\\n\\r\\n![](modelling-hash.png)\\r\\n\\r\\nFor example, the patterns \\"a.b.c\\", \\"a.*.b.c\\", \\"a.#.c\\", \\"b.b.c\\" would be represented in an NFA like this:\\r\\n\\r\\n![](nfa-example.png)\\r\\n\\r\\nThe nodes 11, 4, 6 and 8 would have information attached to them which would point to the respective bindings.\\r\\n\\r\\nIn order to convert the NFA to a DFA, we tried various approaches and went as far as generating source code for the structures behind the graphs, to make it as fast as possible. The best solution we ended up with was building the DFA on the fly, the same way it is built in good regular expressions compilers (see for example [this article](http://swtch.com/~rsc/regexp/regexp3.html)).\\r\\n\\r\\nThe advantage of the DFA approach is that there is no need to backtrack, once the DFA has been built. On the other hand, there are quite a number of disadvantages: it occupies significantly more memory than the trie; there is a significant cost for adding new bindings, since the entire DFA has to be dropped and rebuilt; and it is more complex and therefore harder to implement and maintain.\\r\\n\\r\\nIn the following articles we will present more details about the two structures, how they performed in benchmarks, their space and time complexities and the details behind the DFA optimizations that we have tried.\\r\\n\\r\\nTo be continued."},{"id":"/2010/09/07/management-plugin-preview-release","metadata":{"permalink":"/rabbitmq-website/blog/2010/09/07/management-plugin-preview-release","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-09-07-management-plugin-preview-release/index.md","source":"@site/blog/2010-09-07-management-plugin-preview-release/index.md","title":"Management plugin - preview release","description":"The previously mentioned management plugin is now in a state where it\'s worth looking at and testing. In order to make this easy, I\'ve made a special once-only binary release just for the management plugin (in future we\'ll make binary releases of it just like the other plugins). Download all the .ez files from here and install them as described here, then let us know what you think. (Update 2010-09-22: Note that the plugins referenced in this blog post are for version 2.0.0 of RabbitMQ. We\'ve now released 2.1.0 - for this and subsequent versions you can get the management plugin from here).","date":"2010-09-07T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":2.095,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Management plugin - preview release","tags":["New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Very fast and scalable topic routing - part 1","permalink":"/rabbitmq-website/blog/2010/09/14/very-fast-and-scalable-topic-routing-part-1"},"nextItem":{"title":"Growing Up","permalink":"/rabbitmq-website/blog/2010/08/27/growing-up"}},"content":"The [previously mentioned](/blog/2010/08/06/management-monitoring-and-statistics) management plugin is now in a state where it\'s worth looking at and testing. In order to make this easy, I\'ve made a special once-only binary release just for the management plugin (in future we\'ll make binary releases of it just like the other plugins). Download all the .ez files from [here](https://www.rabbitmq.com/releases/plugins/v2.0.0-management-preview/) and install them as described [here](/docs/plugins), then let us know what you think. (Update 2010-09-22: Note that the plugins referenced in this blog post are for version 2.0.0 of RabbitMQ. We\'ve now released 2.1.0 - for this and subsequent versions you can get the management plugin from [here](/docs/plugins)).\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nAfter installation, point your browser at http://*server-name*:55672/mgmt/. You will need to authenticate as a RabbitMQ user (on a fresh installation the user \\"guest\\" is created with password \\"guest\\"). From here you can manage exchanges, queues, bindings, virtual hosts, users and permissions. Hopefully the UI is fairly self-explanatory.\\r\\n\\r\\nThe management UI is implemented as a single static HTML page which makes background queries to the HTTP API. As such it makes heavy use of Javascript. It has been tested with recent versions of Firefox, Chromium and Safari, and with versions of Microsoft Internet Explorer back to 6.0. Lynx users should use the HTTP API directly :smiley:\\r\\n\\r\\nThe management plugin will create an HTTP-based API at http://*server-name*:55672/api/. Browse to that location for more information on the API. For convenience the documentation can also be obtained [from our Mercurial server](http://hg.rabbitmq.com/rabbitmq-management/raw-file/3646dee55e02/priv/www-api/help.html).\\r\\n\\r\\n**WARNING:** *The management plugin is still at an early stage of development*. You should be aware of the following limitations:\\r\\n\\r\\n* Permissions are only enforced sporadically. If a user can authenticate with the HTTP API, they can do anything.\\r\\n* Installing the management plugin will turn on fine-grained statistics in the server. This can slow a CPU-bound server by 5-10%.\\r\\n* All sorts of other features may be missing or buggy. See the [TODO](http://hg.rabbitmq.com/rabbitmq-management/file/3646dee55e02/TODO) file for more information.\\r\\n\\r\\nNote: if you want to build the plugin yourself, you should be aware that right now the Erlang client does not work in the default branch, so you need a mix of versions. The following commands should work:\\r\\n\\r\\n```shell\\r\\nhg clone http://hg.rabbitmq.com/rabbitmq-public-umbrella\\r\\ncd rabbitmq-public-umbrella\\r\\nmake checkout\\r\\nhg update -r rabbitmq_v2_0_0 -R rabbitmq-server\\r\\nhg update -r rabbitmq_v2_0_0 -R rabbitmq-codegen\\r\\nhg update -r rabbitmq_v2_0_0 -R rabbitmq-erlang-client\\r\\nhg clone http://hg.rabbitmq.com/rabbitmq-management\\r\\nmake\\r\\ncd rabbitmq-management\\r\\nmake\\r\\n```\\r\\n\\r\\nOf course this will be fixed soon.\\r\\n(Ignore the above, this is fixed.)\\r\\n\\r\\nFinally, this post would not be complete without some screenshots...\\r\\n\\r\\n![](mgmt1.png)\\r\\n\\r\\n![](mgmt2.png)\\r\\n\\r\\n![](mgmt3.png)"},{"id":"/2010/08/27/growing-up","metadata":{"permalink":"/rabbitmq-website/blog/2010/08/27/growing-up","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-08-27-growing-up/index.md","source":"@site/blog/2010-08-27-growing-up/index.md","title":"Growing Up","description":"Some three and a half years after we launched RabbitMQ, we have this week released RabbitMQ 2.0.","date":"2010-08-27T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":8.665,"hasTruncateMarker":true,"authors":[{"name":"Alexis Richardson","key":"alexis","page":null}],"frontMatter":{"title":"Growing Up","tags":["New Features"],"authors":["alexis"]},"unlisted":false,"prevItem":{"title":"Management plugin - preview release","permalink":"/rabbitmq-website/blog/2010/09/07/management-plugin-preview-release"},"nextItem":{"title":"Management, monitoring and statistics","permalink":"/rabbitmq-website/blog/2010/08/06/management-monitoring-and-statistics"}},"content":"Some three and a half years after we launched RabbitMQ, we have this week released [RabbitMQ 2.0](http://lists.rabbitmq.com/pipermail/rabbitmq-announce/2010-August/000028.html).\\r\\n\\r\\nThis means some big changes.  The most important of these is our new Scalable Storage Engine.  RabbitMQ has always provided persistence for failure recovery.  But now, you can happily push data into Rabbit regardless of how much data is already stored, and you don\'t need to worry about slow consumers disrupting processing.  As the demands on your application grow, Rabbit can scale with you, in a stable, reliable way.\\r\\n\\r\\nBefore introducing RabbitMQ 2.0, let me reiterate that as Rabbit evolves you can count on the same high level of commitment to you as a customer or end user, regardless of whether you are a large enterprise, or a next-gen start-up, or an open source community.  As always, [get in touch](mailto:info@rabbitmq.com) if you need help or commercial support.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\n**New capabilities**\\r\\n\\r\\nSo what can you expect? In short, a more capable bunny.  In particular:\\r\\n1. RabbitMQ 2.0 has an all new Scalable Storage Engine.  There is also a persistence API.\\r\\n2. [Native support for multi-protocol messaging](/blog/2010/08/04/rabbitmq-and-amqp-0-9-1) delivering better interoperability and more choice\\r\\n3. The release coincides with first class [Spring integration](http://www.springsource.org/spring-amqp) for both Java and .NET from SpringSource - with more to come e.g. a [Grails plugin](http://blog.springsource.com/2010/08/23/rabbitmq-plugin-for-grails-early-access/)\\r\\n4. Foundations for future additional [management and monitoring features](/blog/2010/08/06/management-monitoring-and-statistics) as part of rabbit-management and other tools\\r\\n5. Plugins are now distributed as drop-in binary packages, making them much easier to use.\\r\\n\\r\\nAs always, read the [full release notes](http://lists.rabbitmq.com/pipermail/rabbitmq-announce/attachments/20100825/2c672695/attachment.txt) before upgrading.\\r\\n\\r\\n\\r\\n**Scalable Storage means greater stability**\\r\\n\\r\\nThe vision of Rabbit is that messaging should just works. Part of this is the need for stable behaviour at scale. You ideally need a broker that you can just start up and forget about. Our new Scalable Storage Engine takes us closer to this.\\r\\nRabbitMQ has always had its own storage engine whose job is to persist messages. We use this to provide guaranteed eventual delivery, support for transactions, and [high availability](/docs/3.13/ha).\\r\\n\\r\\nBut, in RabbitMQ 1.x, the broker used a naive albeit effective storage model: every message stored on disk would also be cached in RAM. While this helps performance it makes it much harder to manage scale unless you are able to predict growth and overprovision memory accordingly.\\r\\n\\r\\nWith RabbitMQ 2.0, the broker is capable of completely flushing messages to disk. It has a much smarter caching and paging model. This improves memory usage by paging messages out to disk, and in from disk, as needed.  In other words, you don\'t have to worry about one slow consumer disrupting your entire set up, and can happily push data into Rabbit regardless of how much data is already stored.  This improves stability at scale.\\r\\n\\r\\nWe\'ll blog about this soon.  In the meantime, please try it out.  Storage enthusiasts might like to check out the [notes in the codebase](http://hg.rabbitmq.com/rabbitmq-server/file/5061e6041732/src/rabbit_msg_store.erl).\\r\\n\\r\\n**Storage API**\\r\\n\\r\\nRabbitMQ now provides a storage API. This allows pluggable persistence. \\r\\n\\r\\nRabbitMQ includes its own persistent message database, which is optimised for messaging use cases. But what if you just have to use Oracle or MySQL? Or, what if you want to experiment with combinations of RabbitMQ with the latest and greatest NoSQL key-value store? Now you can do that.  Please contact us if you want to write a driver for your favourite store.\\r\\n\\r\\n**Natively Multiprotocol**\\r\\n\\r\\nOur aim is lower the cost of integration by making messaging simpler, providing a stable manageable server, and supporting the main technologies that you need.\\r\\n\\r\\nRabbit has supported AMQP since its very inception. RabbitMQ began with support for AMQP 0-8, and as AMQP evolved, added support for 0-9-1 on a branch.  [AMQP 0-9-1](http://www.amqp.org/confluence/download/attachments/720900/amqp0-9-1.pdf) is fewer than 50 pages long, making it highly readable, as well as tree-friendly. A shorter, simpler protocol is easier to implement and validate which is important for customers who want AMQP from more than one vendor.\\r\\n\\r\\nWith the 2.0 release, RabbitMQ can now directly support multiple protocols at its core - with AMQP 0-8 and 0-9-1 pre-integrated. \\r\\nIn addition, RabbitMQ extensions provide support for a wide range of protocols including [XMPP](http://hg.rabbitmq.com/rabbitmq-xmpp/), [STOMP](http://hg.rabbitmq.com/rabbitmq-stomp/), [HTTP JSON/RPC](http://hg.rabbitmq.com/rabbitmq-jsonrpc/), pubsub for HTTP (e.g. Google\'s [PubSubHubBub](http://github.com/tonyg/rabbithub)), and [SMTP](http://hg.rabbitmq.com/rabbitmq-smtp/).\\r\\n\\r\\nContact us if you want support for more protocols, or have questions about our future plans; e.g.: providing a safe evolutionary path to future versions of AMQP.\\r\\n\\r\\n**Better Plugin Support**\\r\\n\\r\\nWe aim to provide support for a wide range of messaging applications without making the broker bloated and complex.  [Plugins](/plugin-development) are key to this.  They let us and you extend and customise the capability of RabbitMQ.  Previously you could only load our plugins by building from source.  With the 2.0 release we are distributing pre-compiled plugins.  Drop them into a directory from where RabbitMQ can load them.\\r\\n\\r\\nTo get a feel for what you can do, I recommend taking a look at Tony Garnock-Jones excellent [introduction to plugins](http://www.erlang-factory.com/upload/presentations/229/ErlangFactorySFBay2010-TonyGarnock-Jones.pdf) from the last Erlang Factory.  Congratulations are due to [Jon Brisbin](http://jbrisbin.com/web2/archives/13/) for being the first person to create a plugin for RabbitMQ 2.0, in less than a day or two, adding [webhooks for RabbitMQ](http://github.com/jbrisbin/rabbitmq-webhooks).  Matthew Sackman and Tony Garnock-Jones have also created [some](http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2010-April/006808.html) [custom](http://github.com/tonyg/script-exchange) [exchanges](http://github.com/tonyg/presence-exchange).  Please note that many of these are demos and examples so the usual caveats apply.\\r\\n\\r\\n**First class Spring support in Java and .NET from SpringSource**\\r\\n\\r\\nWe think that messaging should be intuitive regardless of the application platform you develop for. In Java, the clear leader is Spring and we are part of the SpringSource division of Vmware, thus adding fully fledged Spring support was a must. We are extremely grateful to Mark Fisher and Mark Pollack from the SpringSource team for bringing this to fruition. With the release of RabbitMQ 2.0 we are highlighting to the whole community that [Spring support is officially available](http://www.springsource.org/spring-amqp).\\r\\n\\r\\nIf you are a .NET user, you have been able to run RabbitMQ as a Windows service, and use it from [.NET languages and WCF](/client-libraries/dotnet) for some years now. This is great if you want to do messaging from Windows based applications, such as Excel, to back end services written in Java or any other of the hundreds of AMQP integration points. Now, with Spring.NET support we offer you a common application development model as well, that works equally well in both Java and .NET.\\r\\n\\r\\n**Putting it all together: more freedom to choose**\\r\\n\\r\\nWe believe that protocol interoperability and easier integration give you choice. What if you are deploying for the enterprise, and need to connect RabbitMQ to legacy enterprise messaging systems that do not support AMQP? Spring gives you a way forward. With Spring Integration, you have first class access to most messaging systems. Our commitment is to support customers\' choice of technology.  Freedom from lock-in means that you can expect to evolve your systems in line with business needs, instead of being constrained by vendors\' product plans and pricing schemes.\\r\\n\\r\\n**Management and monitoring**\\r\\n\\r\\nWe have made important improvements to Rabbit\'s management, and overall serviceability. \\r\\n\\r\\nRock solid management, across \'any\' use case, is the heart of what makes messaging non-trivial. It\'s easy to find messaging tools that focus on just one or two use cases, and do a reasonable job. But providing that all important it just works experience in the majority of cases at once, and then running stably over time, and not crashing once a month at 2am, well that\'s hard. It takes care and it really needs good management tooling.\\r\\n\\r\\nRabbit has always provided some [tools for management](/docs/man/rabbitmqctl.8) and the community has done an [outstanding job](http://blog.scoutapp.com/articles/2010/03/08/rabbitmq-monitoring-plugins) in [extending them](http://alicetheapp.com/) and [making them more useful](http://blog.dossot.net/2010/01/monitoring-rabbitmq-with-zabbix.html) and [relevant](http://github.com/b/cookbooks/tree/master/rabbitmq). But we want more features, and this means making changes to the broker, and especially at the API level.  These APIs are critical for showing end users what we think is important about messaging, and what is not. How people interact with a tool, and how they use it, defines their relationship with that tool. \\r\\n\\r\\nIn 2.0 you will find support for instrumentation for gathering metrics and statistics about the health of your Rabbit, without significantly impacting performance. Typically people expect to see: current message rates, emerging bottlenecks, support for remedial action such as telling specific clients to throttle back when the broker is busy. [Features like these will become visible](/blog/2010/08/06/management-monitoring-and-statistics) as part of [the rabbit-management plugin](http://hg.rabbitmq.com/rabbitmq-management/) and other tools.  The foundations are now in place for their addition incrementally. \\r\\n\\r\\n**Tell us what else you want from management**\\r\\n\\r\\nPlease contact us with requests and ideas for more management and monitoring features. We\'ll be adding more to RabbitMQ\'s core, making it even easier to operate a large Rabbit installation 24/7, indefinitely. We\'ll be looking for feedback from the community to make sure it\'s really easy for people to integrate management and monitoring feeds into their favourite tools. \\r\\n\\r\\nPlus, for SpringSource customers: expect each new feature to also show up in the Hyperic plugin, enabling you to monitor and manage RabbitMQ brokers, queues and exchanges inside your complete Spring stack and thus derive immediate in context intelligence about the overall behaviour of your application.\\r\\n\\r\\n**What else is next and how can I help?**\\r\\n\\r\\nAs much as possible, future features will appear in stages. Our release philosophy will be evolutionary, while keeping the same focus on quality as with the previous releases. We\'ll be working very hard on all of the following items, and more besides, so please get in touch if you want to use them or help:\\r\\n\\r\\n1. Making Rabbit even easier to use.\\r\\n2. Even better support for community plugins!\\r\\n3. Elastic messaging for cloud services on [EC2 and elsewhere](http://addons.heroku.com/)\\r\\n4. New styles of federation, complementing our existing [rabbitmq-shovel relay](http://hg.rabbitmq.com/rabbitmq-shovel/file/e96b29ca5cbb/README)\\r\\n5. Even better HA, to cover a wider class of failover cases\\r\\nWe want your feedback! The best way you can help is to talk about what you want to do on [the rabbitmq-discuss mailing list](http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss). That\'s also the best place for you to get help if you need it. Or, if you want to go public to the max: talk to us on Twitter where we are @rabbitmq\\r\\n\\r\\n**Thank you**\\r\\n\\r\\nWe want to thank two groups of people for getting us to here.\\r\\nFirst, the community. We especially wish to thank those people who tested the new persistence technology throughout this year.\\r\\nSecond, we want to thank our customers and everyone else who has commercially sponsored RabbitMQ over the years. Whether you bought a new feature, or took a real risk with us, your contribution is just as important to us."},{"id":"/2010/08/06/management-monitoring-and-statistics","metadata":{"permalink":"/rabbitmq-website/blog/2010/08/06/management-monitoring-and-statistics","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-08-06-management-monitoring-and-statistics/index.md","source":"@site/blog/2010-08-06-management-monitoring-and-statistics/index.md","title":"Management, monitoring and statistics","description":"For a long time the management and monitoring capabilities built into RabbitMQ have consisted of rabbitmqctl. While it\'s a reasonable tool for management (assuming you like the command line), rabbitmqctl has never been very powerful as a monitoring tool. So we\'re going to build something better.","date":"2010-08-06T00:00:00.000Z","tags":[{"inline":true,"label":"Blueprints","permalink":"/rabbitmq-website/blog/tags/blueprints"},{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":1.865,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"Management, monitoring and statistics","tags":["Blueprints","New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Growing Up","permalink":"/rabbitmq-website/blog/2010/08/27/growing-up"},"nextItem":{"title":"RabbitMQ and AMQP 0-9-1","permalink":"/rabbitmq-website/blog/2010/08/04/rabbitmq-and-amqp-0-9-1"}},"content":"![](screenshot1.png)\\r\\n\\r\\nFor a long time the management and monitoring capabilities built into RabbitMQ have consisted of rabbitmqctl. While it\'s a reasonable tool for management (assuming you like the command line), rabbitmqctl has never been very powerful as a monitoring tool. So we\'re going to build something better.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nOf course, plenty of people don\'t like command line tools and so several people have built alternate means of managing RabbitMQ. [Alice / Wonderland](http://willcodeforfoo.com/2009/07/13/announcing-alice/) and [Spring AMQP](http://www.springsource.org/spring-amqp) are two that leap to mind. However there isn\'t much standardisation, and people don\'t always find it very convenient to talk to Rabbit via epmd. So we\'re going to build something easier.\\r\\n\\r\\nWith that in mind, I\'d like to announce the existence of [RabbitMQ Management](http://hg.rabbitmq.com/rabbitmq-management/). This is a plugin to provide management and monitoring via a RESTful interface, with a web GUI. Think of it as being like a super-Alice, and also an integration point for any other tools that people want to build.\\r\\n\\r\\nSo RabbitMQ Management will allow easier management and better monitoring. How better? Well, as part of the upcoming rabbit release we\'ve added a statistics gathering feature to the broker. This can count messages as they\'re published, routed, delivered and acked, on a per channel / queue / exchange basis, so we can determine things like which channels are publishing fast or consuming slowly, which queues are being published to from which exchanges, which connections and hosts are busiest, and so on.\\r\\n\\r\\nOf course, doing all this extra bookkeeping comes at a cost; when statistics gathering is turned on the server can run around 10% slower (assuming it\'s CPU-bound; which usually means handling transient messages. If it\'s IO bound the performance impact will likely be less). At the moment statistics gathering is turned on automatically when the management plugin is installed but we\'ll make it configurable.\\r\\n\\r\\nWith that, I\'d like to add a warning: it\'s currently at a **very** early stage of development, and really should not be trusted for anything other than experimentation and playing with. The REST API will change, the UI will change, the plugin might crash your server, and the [TODO](http://hg.rabbitmq.com/rabbitmq-management/file/250292c41ff7/TODO) is currently almost hilariously long. But hopefully this gives you an idea of what we\'re going to do."},{"id":"/2010/08/04/rabbitmq-and-amqp-0-9-1","metadata":{"permalink":"/rabbitmq-website/blog/2010/08/04/rabbitmq-and-amqp-0-9-1","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-08-04-rabbitmq-and-amqp-0-9-1/index.md","source":"@site/blog/2010-08-04-rabbitmq-and-amqp-0-9-1/index.md","title":"RabbitMQ and AMQP 0-9-1","description":"Since the beginning, RabbitMQ has implemented the 0-8 version of the AMQP specification. This was the first publicly-available version, but there\'s been plenty of development since then. In particular, we\'ve wanted to support the 0-9-1 version of AMQP for a while now.","date":"2010-08-04T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":1.53,"hasTruncateMarker":true,"authors":[{"name":"Simon MacMullen","key":"simon","page":null}],"frontMatter":{"title":"RabbitMQ and AMQP 0-9-1","tags":["New Features"],"authors":["simon"]},"unlisted":false,"prevItem":{"title":"Management, monitoring and statistics","permalink":"/rabbitmq-website/blog/2010/08/06/management-monitoring-and-statistics"},"nextItem":{"title":"Well, I\'ll let you go ... basic.reject in RabbitMQ","permalink":"/rabbitmq-website/blog/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq"}},"content":"Since the beginning, RabbitMQ has implemented the 0-8 version of the AMQP specification. This was the first publicly-available version, but there\'s been plenty of development since then. In particular, we\'ve wanted to support the 0-9-1 version of AMQP for a while now.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nFor around the last year we\'ve maintained a 0-9-1-supporting branch of the broker and clients in Mercurial, and interested users have been running that version as it matures. Well, it\'s finally mature and we\'re now merging the 0-9-1 support into the default branch. This means it\'ll be in the next release.\\r\\n\\r\\nAt this point, you\'re probably wondering what the differences are between 0-8 and 0-9-1. Well, the good news is that the differences are not huge, and are entirely sensible. 0-9-1 mostly cleans up the 0-8 spec, explaining more clearly how the broker and clients are expected to behave in certain edge cases, and removing a whole load of ambiguity and half (or less) thought out features from 0-8.\\r\\n\\r\\nIn fact, if you\'re running 1.8.0 or later, you\'re already running a broker with [most of the semantic changes](http://lists.rabbitmq.com/pipermail/rabbitmq-announce/2010-June/000025.html) from 0-9-1. But the wire protocol has changed a bit too, so it matters whether you\'re speaking 0-9-1 or 0-8.\\r\\n\\r\\nFor the Java and Erlang clients, we\'re intending to simply switch to supporting AMQP 0-9-1 exclusively in the next release. The .NET library already supports multiple protocols, so we\'re adding 0-9-1 as another option (and making it the default). For the broker we\'re going to support both AMQP 0-9-1 and AMQP 0-8. For any other client libraries we encourage you to speak to the library developer :wink:\\r\\n\\r\\nThis means that this time **it\'s safe to upgrade just your broker, or your broker and all your clients, but it\'s not safe to upgrade your clients without upgrading your broker!**\\r\\n\\r\\nThank you for your attention."},{"id":"/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq","metadata":{"permalink":"/rabbitmq-website/blog/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-08-03-well-ill-let-you-go-basicreject-in-rabbitmq/index.md","source":"@site/blog/2010-08-03-well-ill-let-you-go-basicreject-in-rabbitmq/index.md","title":"Well, I\'ll let you go ... basic.reject in RabbitMQ","description":"Support for AMQP\'s basic.reject just landed on default. It\'s taken this long because we couldn\'t agree on a single set of semantics that followed the specification, was actually useful, and wasn\'t too complicated to implement.","date":"2010-08-03T00:00:00.000Z","tags":[{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features"}],"readingTime":2.07,"hasTruncateMarker":true,"authors":[{"name":"Michael Bridgen","key":"mikeb","page":null}],"frontMatter":{"title":"Well, I\'ll let you go ... basic.reject in RabbitMQ","tags":["New Features"],"authors":["mikeb"]},"unlisted":false,"prevItem":{"title":"RabbitMQ and AMQP 0-9-1","permalink":"/rabbitmq-website/blog/2010/08/04/rabbitmq-and-amqp-0-9-1"},"nextItem":{"title":"Hello, World!","permalink":"/rabbitmq-website/blog/2010/08/01/hello-world"}},"content":"Support for AMQP\'s `basic.reject` just landed on default. It\'s taken this long because we couldn\'t agree on a single set of semantics that followed the specification, was actually useful, and wasn\'t too complicated to implement.\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nFirst up, this is what RabbitMQ\'s `basic.reject` will do: if you supply `requeue=false` it will discard the message (this is in lieu of dead-lettering it, until we have a dead letter feature); if you supply `requeue=true`, it will release it back on to the queue, to be delivered again.\\r\\n\\r\\nThe first is useful from a error handling point of view; if your application cannot process a particular message, you can get rid of it. At the minute, it\'s semantically the same as just acking the message; but, given a dead-letter mechanism, it will mean unprocessable messages can be picked up elsewhere for diagnosis.\\r\\n\\r\\nThe second, with `requeue=true`, is useful for example if your application needs a \\"message lock\\" semantics. In this scenario, a consumer can be delivered a message, then decide not to deal with it after all, and place it back on the queue. Note that RabbitMQ *doesn\'t take care to stop the same consumer getting the message again* -- see below.\\r\\n\\r\\nThe AMQP 0-9-1 specification says a number of seemingly incompatible things about basic.reject. For a start, it says in the method description\\r\\n\\r\\n> The client MUST NOT use this method as a means of selecting messages to process.\\r\\n\\r\\nand in the specification XML (but not in the generated PDF),\\r\\n\\r\\n> The server MUST NOT deliver the message to the same client within the\\r\\ncontext of the current channel. The recommended strategy is to attempt to\\r\\ndeliver the message to an alternative consumer, and if that is not possible,\\r\\nto move the message to a dead-letter queue. The server MAY use more\\r\\nsophisticated tracking to hold the message on the queue and redeliver it to\\r\\nthe same client at a later stage.\\r\\n\\r\\nThis seems to suggest that the server has to take care not to deliver the message to the same consumer twice, but consumers are not allowed to rely on this prohibition. This means `basic.reject` could either redeliver the message or dead-letter it, which makes it useless for the \\"message lock\\" scenario given above.\\r\\n\\r\\nSo, we have chosen to implement the simplest thing that is useful, which is to re-enqueue the message and treat it as though it were completely new. This means the consumer can receive again a message it has rejected."},{"id":"/2010/08/01/hello-world","metadata":{"permalink":"/rabbitmq-website/blog/2010/08/01/hello-world","editUrl":"https://github.com/rabbitmq/rabbitmq-website/tree/main/blog/2010-08-01-hello-world/index.md","source":"@site/blog/2010-08-01-hello-world/index.md","title":"Hello, World!","description":"And welcome to the all-new RabbitMQ blog!","date":"2010-08-01T00:00:00.000Z","tags":[],"readingTime":0.52,"hasTruncateMarker":true,"authors":[{"name":"David Wragg","key":"david","page":null}],"frontMatter":{"title":"Hello, World!","tags":[],"authors":["david"]},"unlisted":false,"prevItem":{"title":"Well, I\'ll let you go ... basic.reject in RabbitMQ","permalink":"/rabbitmq-website/blog/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq"}},"content":"And welcome to the all-new RabbitMQ blog!\\r\\n\\r\\n<!-- truncate -->\\r\\n\\r\\nAs you may know, RabbitMQ was recently acquired by [SpringSource](http://www.springsource.com/), a division of [VMware](http://www.vmware.com/).  Prior to that, the RabbitMQ developers worked at [LShift](http://www.lshift.net), and we used to write on the LShift blog.  You can still read [the old RabbitMQ posts there](http://www.lshift.net/blog/category/lshift-sw/rabbitmq).\\r\\n\\r\\nBut now it\'s time for the RabbitMQ team to have its own blog. We have lots to write about: RabbitMQ itself, and new features as they appear; our more experimental projects; and what\'s going on in the RabbitMQ community and the world of messaging in general.  The first real post will follow shortly."}],"blogListPaginated":[{"items":["/2025/04/24/rabbitmq-is-not-affected-by-cve-2025-32433","/2025/04/16/amqp-websocket","/2025/04/15/rabbitmq-4.1.0-is-released","/2025/04/14/rabbitmq-4.0.9-is-released","/2025/04/08/4.1-performance-improvements","/2025/04/04/new-k8s-peer-discovery","/2025/02/26/rabbitmq-4.0.7-is-released","/2025/02/11/rabbitmq-4.0.6-is-released","/2025/02/07/tanzu-rabbitmq-3.13.8-is-released","/2025/02/07/rabbitmq-3.13.8-is-released"],"metadata":{"permalink":"/rabbitmq-website/blog","page":1,"postsPerPage":10,"totalPages":18,"totalCount":174,"nextPage":"/rabbitmq-website/blog/page/2","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2025/01/17/how-are-the-messages-stored","/2024/12/18/epmd-public-exposure","/2024/12/16/rabbitmq-4.0.5-is-released","/2024/12/13/amqp-filter-expressions","/2024/10/11/modified-outcome","/2024/09/02/amqp-flow-control","/2024/08/28/quorum-queues-in-4.0","/2024/08/21/amqp-benchmarks","/2024/08/11/package-repository-updates","/2024/08/05/native-amqp"],"metadata":{"permalink":"/rabbitmq-website/blog/page/2","page":2,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog","nextPage":"/rabbitmq-website/blog/page/3","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2024/05/31/new-community-support-policy","/2024/05/23/erlang27-support","/2024/03/11/rabbitmq-3.13.0-announcement","/2024/01/11/3.13-release","/2024/01/04/new-website","/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2023/07/21/mqtt5","/2023/05/17/rabbitmq-3.12-performance-improvements","/2023/04/04/announcing-rabbitmq-community-discord-server"],"metadata":{"permalink":"/rabbitmq-website/blog/page/3","page":3,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/2","nextPage":"/rabbitmq-website/blog/page/4","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2023/03/21/native-mqtt","/2023/03/02/quorum-queues-migration","/2022/08/30/high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9","/2022/08/01/rabbitmq-3.11.0-release-calendar","/2022/07/22/oidc-integration","/2022/07/20/required-feature-flags-in-rabbitmq-3.11","/2022/07/13/rabbitmq-3-11-feature-preview-super-streams","/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams","/2022/05/31/flame-graphs","/2022/05/16/rabbitmq-3.10-performance-improvements"],"metadata":{"permalink":"/rabbitmq-website/blog/page/4","page":4,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/3","nextPage":"/rabbitmq-website/blog/page/5","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2022/05/05/rabbitmq-3.10-release-overview","/2022/04/26/centos-7-support-discontinued","/2022/03/29/at-least-once-dead-lettering","/2022/03/24/rabbitmq-3.10.0-release-calendar","/2022/02/21/gatekeeper-validation","/2021/12/16/rabbitmq-not-affected-by-log4j-vulnerability","/2021/10/07/rabbitmq-streams-interoperability","/2021/09/13/rabbitmq-streams-offset-tracking","/2021/08/21/4.0-deprecation-announcements","/2021/07/28/rabbitmq-streams-message-deduplication"],"metadata":{"permalink":"/rabbitmq-website/blog/page/5","page":5,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/4","nextPage":"/rabbitmq-website/blog/page/6","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2021/07/23/connecting-to-streams","/2021/07/19/rabbitmq-streams-first-application","/2021/07/13/rabbitmq-streams-overview","/2021/07/09/rabbitmq-3.9.0-release-calendar","/2021/05/03/alerting","/2021/03/31/migrate-off-of-bintray","/2021/03/23/erlang-24-support-roadmap","/2021/03/01/auth-attempts-metrics","/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0","/2020/11/06/this-month-in-rabbitmq-augsep-2020-recap"],"metadata":{"permalink":"/rabbitmq-website/blog/page/6","page":6,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/5","nextPage":"/rabbitmq-website/blog/page/7","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2020/08/31/this-month-in-rabbitmq-july-2020-recap","/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved","/2020/07/30/this-month-in-rabbitmq-june-2020-recap","/2020/07/07/disaster-recovery-and-high-availability-101","/2020/06/30/this-month-in-rabbitmq-may-2020-recap","/2020/06/23/quorum-queues-local-delivery","/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1"],"metadata":{"permalink":"/rabbitmq-website/blog/page/7","page":7,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/6","nextPage":"/rabbitmq-website/blog/page/8","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2020/06/18/cluster-sizing-and-other-considerations","/2020/06/04/how-to-run-benchmarks","/2020/06/01/this-month-in-rabbitmq-april-2020-recap","/2020/05/15/quorum-queues-and-flow-control-stress-tests","/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks","/2020/05/04/quorum-queues-and-flow-control-the-concepts","/2020/04/21/quorum-queues-and-why-disks-matter","/2020/04/20/rabbitmq-gets-an-ha-upgrade","/2020/04/13/this-month-in-rabbitmq-march-2020-recap","/2020/03/10/this-month-in-rabbitmq-february-2020-recap"],"metadata":{"permalink":"/rabbitmq-website/blog/page/8","page":8,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/7","nextPage":"/rabbitmq-website/blog/page/9","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2020/02/12/this-month-in-rabbitmq-january-2020-recap","/2020/01/09/this-month-in-rabbitmq-december-2019-recap","/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system","/2019/12/07/this-month-in-rabbitmq-november-2019-recap","/2019/11/13/this-month-in-rabbitmq-november-2019","/2019/11/11/rabbitmq-3-8-release-overview","/2019/09/09/this-month-in-rabbitmq-september-2019","/2019/08/12/this-month-in-rabbitmq-august-2019","/2019/07/09/this-month-in-rabbitmq-july-2019","/2019/06/06/this-month-in-rabbitmq-june-2019"],"metadata":{"permalink":"/rabbitmq-website/blog/page/9","page":9,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/8","nextPage":"/rabbitmq-website/blog/page/10","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2019/05/13/this-month-in-rabbitmq-may-2019","/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags","/2019/04/03/this-month-in-rabbitmq-april-3-2019","/2019/03/08/this-month-in-rabbitmq-march-7-2019","/2019/02/07/this-month-in-rabbitmq-feb-7-2019","/2019/01/08/this-month-in-rabbitmq-jan-8-2019","/2018/12/04/this-month-in-rabbitmq-dec-4-2018","/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","/2018/02/22/new-configuration-format-in-rabbitmq-3-7","/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7"],"metadata":{"permalink":"/rabbitmq-website/blog/page/10","page":10,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/9","nextPage":"/rabbitmq-website/blog/page/11","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2018/02/05/whats-new-in-rabbitmq-3-7","/2017/10/18/new-reactive-client-for-rabbitmq-http-api","/2017/09/29/rabbitmq-java-client-5-0-is-released","/2016/12/15/brand-new-rabbitmqctl-in-3-7-0","/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","/2016/11/24/rabbitmq-java-client-4-0-is-released","/2015/12/28/whats-new-in-rabbitmq-3-6-0","/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","/2015/04/16/scheduling-messages-with-rabbitmq","/2014/10/30/understanding-memory-use-with-rabbitmq-3-4"],"metadata":{"permalink":"/rabbitmq-website/blog/page/11","page":11,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/10","nextPage":"/rabbitmq-website/blog/page/12","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3","/2014/04/10/consumer-bias-in-rabbitmq-3-3","/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3","/2014/04/02/breaking-things-with-rabbitmq-3-3","/2014/02/19/distributed-semaphores-with-rabbitmq","/2014/01/23/preventing-unbounded-buffers-with-rabbitmq","/2013/12/16/using-consumer-priorities-with-rabbitmq","/2013/10/23/federated-queues-in-3-2-0","/2013/06/03/using-elixir-to-write-rabbitmq-plugins","/2013/05/01/rabbitmq-3-1-0-in-images"],"metadata":{"permalink":"/rabbitmq-website/blog/page/12","page":12,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/11","nextPage":"/rabbitmq-website/blog/page/13","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2012/11/20/whats-new-in-rabbitmq-3-0","/2012/11/19/breaking-things-with-rabbitmq-3-0","/2012/09/12/mqtt-adapter","/2012/05/29/jason-and-alvaros-excellent-rabbit-book","/2012/05/14/introducing-rabbitmq-web-stomp","/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","/2012/04/25/rabbitmq-performance-measurements-part-2","/2012/04/17/london-realtime-hackweekend","/2012/04/16/rabbitmq-performance-measurements-part-1","/2012/02/23/how-to-compose-apps-using-websockets"],"metadata":{"permalink":"/rabbitmq-website/blog/page/13","page":13,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/12","nextPage":"/rabbitmq-website/blog/page/14","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2012/02/21/atomizejs-distributed-software-transactional-memory","/2012/01/24/sockjs-0-2-released","/2011/12/20/rabbitmq-2-7-0-and-2-7-1-are-released","/2011/11/30/ponies-dragons-and-socks","/2011/10/27/performance-of-queues-when-less-is-more","/2011/10/25/high-availability-in-rabbitmq-solving-part-of-the-puzzle","/2011/10/19/keeping-it-realtime-conference-portland-or","/2011/09/26/pubsubhuddle-realtime-web-talk","/2011/09/24/sizing-your-rabbits","/2011/09/16/pubsub-huddle"],"metadata":{"permalink":"/rabbitmq-website/blog/page/14","page":14,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/13","nextPage":"/rabbitmq-website/blog/page/15","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2011/09/13/sockjs-websocket-emulation","/2011/09/09/rabbitmq-tracing-a-ui-for-the-firehose","/2011/09/01/rabbitmq-on-heroku","/2011/08/22/sockjs-web-messaging-aint-easy","/2011/08/16/using-the-rabbitmq-service-on-cloud-foundry-with-nodejs","/2011/08/10/rabbitmq-cloud-foundry-cloud-messaging-that-just-works","/2011/07/08/puka-rethinking-amqp-clients","/2011/06/30/zeromq-erlang","/2011/06/22/federation-plugin-preview-release","/2011/06/16/rabbitmq-250-released"],"metadata":{"permalink":"/rabbitmq-website/blog/page/15","page":15,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/14","nextPage":"/rabbitmq-website/blog/page/16","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2011/05/17/can-you-hear-the-drums-erlando","/2011/03/28/very-fast-and-scalable-topic-routing-part-2","/2011/03/23/sender-selected-distribution","/2011/03/01/ruby-amqp-benchmarks","/2011/02/10/introducing-publisher-confirms","/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231","/2011/01/20/rabbitmq-backing-stores-databases-and-disks","/2011/01/19/ruby-amqp-0-7-released","/2011/01/12/ruby-amqp-gem-intro","/2010/12/01/amqp-10-prototyping"],"metadata":{"permalink":"/rabbitmq-website/blog/page/16","page":16,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/15","nextPage":"/rabbitmq-website/blog/page/17","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2010/11/17/chapter-1-introduction-to-distributed-systems","/2010/11/12/rabbitmq-nodejs-rabbitjs","/2010/10/19/exchange-to-exchange-bindings","/2010/10/18/rabbitmq0mq-bridge","/2010/10/02/prompt-a-licious","/2010/09/22/broker-vs-brokerless","/2010/09/20/rabbitmq-on-github","/2010/09/14/very-fast-and-scalable-topic-routing-part-1","/2010/09/07/management-plugin-preview-release","/2010/08/27/growing-up"],"metadata":{"permalink":"/rabbitmq-website/blog/page/17","page":17,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/16","nextPage":"/rabbitmq-website/blog/page/18","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2010/08/06/management-monitoring-and-statistics","/2010/08/04/rabbitmq-and-amqp-0-9-1","/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq","/2010/08/01/hello-world"],"metadata":{"permalink":"/rabbitmq-website/blog/page/18","page":18,"postsPerPage":10,"totalPages":18,"totalCount":174,"previousPage":"/rabbitmq-website/blog/page/17","blogDescription":"Blog","blogTitle":"Blog"}}],"blogTags":{"/rabbitmq-website/blog/tags/security":{"inline":true,"label":"security","permalink":"/rabbitmq-website/blog/tags/security","items":["/2025/04/24/rabbitmq-is-not-affected-by-cve-2025-32433","/2024/12/18/epmd-public-exposure","/2022/07/22/oidc-integration"],"pages":[{"items":["/2025/04/24/rabbitmq-is-not-affected-by-cve-2025-32433","/2024/12/18/epmd-public-exposure","/2022/07/22/oidc-integration"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/security","page":1,"postsPerPage":10,"totalPages":1,"totalCount":3,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/amqp-1-0":{"inline":true,"label":"AMQP 1.0","permalink":"/rabbitmq-website/blog/tags/amqp-1-0","items":["/2025/04/16/amqp-websocket","/2024/12/13/amqp-filter-expressions","/2024/10/11/modified-outcome","/2024/09/02/amqp-flow-control","/2024/08/21/amqp-benchmarks","/2024/08/05/native-amqp"],"pages":[{"items":["/2025/04/16/amqp-websocket","/2024/12/13/amqp-filter-expressions","/2024/10/11/modified-outcome","/2024/09/02/amqp-flow-control","/2024/08/21/amqp-benchmarks","/2024/08/05/native-amqp"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/amqp-1-0","page":1,"postsPerPage":10,"totalPages":1,"totalCount":6,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/web-messaging":{"inline":true,"label":"Web Messaging","permalink":"/rabbitmq-website/blog/tags/web-messaging","items":["/2025/04/16/amqp-websocket","/2012/05/14/introducing-rabbitmq-web-stomp","/2012/02/23/how-to-compose-apps-using-websockets","/2012/02/21/atomizejs-distributed-software-transactional-memory","/2012/01/24/sockjs-0-2-released","/2011/11/30/ponies-dragons-and-socks","/2011/10/19/keeping-it-realtime-conference-portland-or","/2011/09/26/pubsubhuddle-realtime-web-talk","/2011/09/13/sockjs-websocket-emulation","/2011/08/22/sockjs-web-messaging-aint-easy"],"pages":[{"items":["/2025/04/16/amqp-websocket","/2012/05/14/introducing-rabbitmq-web-stomp","/2012/02/23/how-to-compose-apps-using-websockets","/2012/02/21/atomizejs-distributed-software-transactional-memory","/2012/01/24/sockjs-0-2-released","/2011/11/30/ponies-dragons-and-socks","/2011/10/19/keeping-it-realtime-conference-portland-or","/2011/09/26/pubsubhuddle-realtime-web-talk","/2011/09/13/sockjs-websocket-emulation","/2011/08/22/sockjs-web-messaging-aint-easy"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/web-messaging","page":1,"postsPerPage":10,"totalPages":1,"totalCount":10,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/rabbit-mq-4-1":{"inline":true,"label":"RabbitMQ 4.1","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-1","items":["/2025/04/16/amqp-websocket","/2025/04/15/rabbitmq-4.1.0-is-released","/2025/04/08/4.1-performance-improvements","/2025/04/04/new-k8s-peer-discovery","/2024/12/13/amqp-filter-expressions"],"pages":[{"items":["/2025/04/16/amqp-websocket","/2025/04/15/rabbitmq-4.1.0-is-released","/2025/04/08/4.1-performance-improvements","/2025/04/04/new-k8s-peer-discovery","/2024/12/13/amqp-filter-expressions"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-1","page":1,"postsPerPage":10,"totalPages":1,"totalCount":5,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/new-features":{"inline":true,"label":"New Features","permalink":"/rabbitmq-website/blog/tags/new-features","items":["/2025/04/16/amqp-websocket","/2024/12/13/amqp-filter-expressions","/2024/10/11/modified-outcome","/2024/08/05/native-amqp","/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2023/07/21/mqtt5","/2022/07/13/rabbitmq-3-11-feature-preview-super-streams","/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams","/2022/05/05/rabbitmq-3.10-release-overview","/2022/03/29/at-least-once-dead-lettering","/2021/10/07/rabbitmq-streams-interoperability","/2021/09/13/rabbitmq-streams-offset-tracking","/2021/07/28/rabbitmq-streams-message-deduplication","/2021/07/23/connecting-to-streams","/2021/07/19/rabbitmq-streams-first-application","/2021/07/13/rabbitmq-streams-overview","/2021/05/03/alerting","/2021/03/01/auth-attempts-metrics","/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0","/2020/04/20/rabbitmq-gets-an-ha-upgrade","/2019/11/11/rabbitmq-3-8-release-overview","/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags","/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","/2018/02/22/new-configuration-format-in-rabbitmq-3-7","/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7","/2018/02/05/whats-new-in-rabbitmq-3-7","/2017/10/18/new-reactive-client-for-rabbitmq-http-api","/2017/09/29/rabbitmq-java-client-5-0-is-released","/2016/12/15/brand-new-rabbitmqctl-in-3-7-0","/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","/2016/11/24/rabbitmq-java-client-4-0-is-released","/2015/12/28/whats-new-in-rabbitmq-3-6-0","/2015/04/16/scheduling-messages-with-rabbitmq","/2014/10/30/understanding-memory-use-with-rabbitmq-3-4","/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3","/2014/04/10/consumer-bias-in-rabbitmq-3-3","/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3","/2014/04/02/breaking-things-with-rabbitmq-3-3","/2014/01/23/preventing-unbounded-buffers-with-rabbitmq","/2013/12/16/using-consumer-priorities-with-rabbitmq","/2013/10/23/federated-queues-in-3-2-0","/2013/05/01/rabbitmq-3-1-0-in-images","/2012/11/20/whats-new-in-rabbitmq-3-0","/2012/11/19/breaking-things-with-rabbitmq-3-0","/2012/09/12/mqtt-adapter","/2012/05/14/introducing-rabbitmq-web-stomp","/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","/2011/12/20/rabbitmq-2-7-0-and-2-7-1-are-released","/2011/10/27/performance-of-queues-when-less-is-more","/2011/10/25/high-availability-in-rabbitmq-solving-part-of-the-puzzle","/2011/09/09/rabbitmq-tracing-a-ui-for-the-firehose","/2011/06/22/federation-plugin-preview-release","/2011/03/23/sender-selected-distribution","/2011/02/10/introducing-publisher-confirms","/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231","/2011/01/19/ruby-amqp-0-7-released","/2010/12/01/amqp-10-prototyping","/2010/10/19/exchange-to-exchange-bindings","/2010/10/18/rabbitmq0mq-bridge","/2010/09/07/management-plugin-preview-release","/2010/08/27/growing-up","/2010/08/06/management-monitoring-and-statistics","/2010/08/04/rabbitmq-and-amqp-0-9-1","/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq"],"pages":[{"items":["/2025/04/16/amqp-websocket","/2024/12/13/amqp-filter-expressions","/2024/10/11/modified-outcome","/2024/08/05/native-amqp","/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2023/07/21/mqtt5","/2022/07/13/rabbitmq-3-11-feature-preview-super-streams","/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams","/2022/05/05/rabbitmq-3.10-release-overview"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/new-features","page":1,"postsPerPage":10,"totalPages":7,"totalCount":65,"nextPage":"/rabbitmq-website/blog/tags/new-features/page/2","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2022/03/29/at-least-once-dead-lettering","/2021/10/07/rabbitmq-streams-interoperability","/2021/09/13/rabbitmq-streams-offset-tracking","/2021/07/28/rabbitmq-streams-message-deduplication","/2021/07/23/connecting-to-streams","/2021/07/19/rabbitmq-streams-first-application","/2021/07/13/rabbitmq-streams-overview","/2021/05/03/alerting","/2021/03/01/auth-attempts-metrics","/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/new-features/page/2","page":2,"postsPerPage":10,"totalPages":7,"totalCount":65,"previousPage":"/rabbitmq-website/blog/tags/new-features","nextPage":"/rabbitmq-website/blog/tags/new-features/page/3","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2020/04/20/rabbitmq-gets-an-ha-upgrade","/2019/11/11/rabbitmq-3-8-release-overview","/2019/04/23/simplifying-rolling-upgrades-between-minor-versions-with-feature-flags","/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","/2018/02/22/new-configuration-format-in-rabbitmq-3-7","/2018/02/18/peer-discovery-subsystem-in-rabbitmq-3-7","/2018/02/05/whats-new-in-rabbitmq-3-7","/2017/10/18/new-reactive-client-for-rabbitmq-http-api","/2017/09/29/rabbitmq-java-client-5-0-is-released","/2016/12/15/brand-new-rabbitmqctl-in-3-7-0"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/new-features/page/3","page":3,"postsPerPage":10,"totalPages":7,"totalCount":65,"previousPage":"/rabbitmq-website/blog/tags/new-features/page/2","nextPage":"/rabbitmq-website/blog/tags/new-features/page/4","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","/2016/11/24/rabbitmq-java-client-4-0-is-released","/2015/12/28/whats-new-in-rabbitmq-3-6-0","/2015/04/16/scheduling-messages-with-rabbitmq","/2014/10/30/understanding-memory-use-with-rabbitmq-3-4","/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3","/2014/04/10/consumer-bias-in-rabbitmq-3-3","/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3","/2014/04/02/breaking-things-with-rabbitmq-3-3","/2014/01/23/preventing-unbounded-buffers-with-rabbitmq"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/new-features/page/4","page":4,"postsPerPage":10,"totalPages":7,"totalCount":65,"previousPage":"/rabbitmq-website/blog/tags/new-features/page/3","nextPage":"/rabbitmq-website/blog/tags/new-features/page/5","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2013/12/16/using-consumer-priorities-with-rabbitmq","/2013/10/23/federated-queues-in-3-2-0","/2013/05/01/rabbitmq-3-1-0-in-images","/2012/11/20/whats-new-in-rabbitmq-3-0","/2012/11/19/breaking-things-with-rabbitmq-3-0","/2012/09/12/mqtt-adapter","/2012/05/14/introducing-rabbitmq-web-stomp","/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","/2011/12/20/rabbitmq-2-7-0-and-2-7-1-are-released","/2011/10/27/performance-of-queues-when-less-is-more"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/new-features/page/5","page":5,"postsPerPage":10,"totalPages":7,"totalCount":65,"previousPage":"/rabbitmq-website/blog/tags/new-features/page/4","nextPage":"/rabbitmq-website/blog/tags/new-features/page/6","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2011/10/25/high-availability-in-rabbitmq-solving-part-of-the-puzzle","/2011/09/09/rabbitmq-tracing-a-ui-for-the-firehose","/2011/06/22/federation-plugin-preview-release","/2011/03/23/sender-selected-distribution","/2011/02/10/introducing-publisher-confirms","/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231","/2011/01/19/ruby-amqp-0-7-released","/2010/12/01/amqp-10-prototyping","/2010/10/19/exchange-to-exchange-bindings","/2010/10/18/rabbitmq0mq-bridge"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/new-features/page/6","page":6,"postsPerPage":10,"totalPages":7,"totalCount":65,"previousPage":"/rabbitmq-website/blog/tags/new-features/page/5","nextPage":"/rabbitmq-website/blog/tags/new-features/page/7","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2010/09/07/management-plugin-preview-release","/2010/08/27/growing-up","/2010/08/06/management-monitoring-and-statistics","/2010/08/04/rabbitmq-and-amqp-0-9-1","/2010/08/03/well-ill-let-you-go-basicreject-in-rabbitmq"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/new-features/page/7","page":7,"postsPerPage":10,"totalPages":7,"totalCount":65,"previousPage":"/rabbitmq-website/blog/tags/new-features/page/6","blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/releases":{"inline":true,"label":"Releases","permalink":"/rabbitmq-website/blog/tags/releases","items":["/2025/04/15/rabbitmq-4.1.0-is-released","/2025/04/14/rabbitmq-4.0.9-is-released","/2025/02/26/rabbitmq-4.0.7-is-released","/2025/02/11/rabbitmq-4.0.6-is-released","/2025/02/07/tanzu-rabbitmq-3.13.8-is-released","/2025/02/07/rabbitmq-3.13.8-is-released","/2024/12/16/rabbitmq-4.0.5-is-released"],"pages":[{"items":["/2025/04/15/rabbitmq-4.1.0-is-released","/2025/04/14/rabbitmq-4.0.9-is-released","/2025/02/26/rabbitmq-4.0.7-is-released","/2025/02/11/rabbitmq-4.0.6-is-released","/2025/02/07/tanzu-rabbitmq-3.13.8-is-released","/2025/02/07/rabbitmq-3.13.8-is-released","/2024/12/16/rabbitmq-4.0.5-is-released"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/releases","page":1,"postsPerPage":10,"totalPages":1,"totalCount":7,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/rabbit-mq-4-0":{"inline":true,"label":"RabbitMQ 4.0","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0","items":["/2025/04/14/rabbitmq-4.0.9-is-released","/2025/02/26/rabbitmq-4.0.7-is-released","/2025/02/11/rabbitmq-4.0.6-is-released","/2024/12/16/rabbitmq-4.0.5-is-released","/2024/10/11/modified-outcome","/2024/09/02/amqp-flow-control","/2024/08/28/quorum-queues-in-4.0","/2024/08/21/amqp-benchmarks","/2024/08/05/native-amqp"],"pages":[{"items":["/2025/04/14/rabbitmq-4.0.9-is-released","/2025/02/26/rabbitmq-4.0.7-is-released","/2025/02/11/rabbitmq-4.0.6-is-released","/2024/12/16/rabbitmq-4.0.5-is-released","/2024/10/11/modified-outcome","/2024/09/02/amqp-flow-control","/2024/08/28/quorum-queues-in-4.0","/2024/08/21/amqp-benchmarks","/2024/08/05/native-amqp"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/rabbit-mq-4-0","page":1,"postsPerPage":10,"totalPages":1,"totalCount":9,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/announcements":{"inline":true,"label":"Announcements","permalink":"/rabbitmq-website/blog/tags/announcements","items":["/2025/04/08/4.1-performance-improvements","/2025/04/04/new-k8s-peer-discovery","/2024/08/11/package-repository-updates","/2024/05/31/new-community-support-policy","/2024/05/23/erlang27-support","/2024/03/11/rabbitmq-3.13.0-announcement","/2023/04/04/announcing-rabbitmq-community-discord-server","/2022/05/05/rabbitmq-3.10-release-overview","/2021/12/16/rabbitmq-not-affected-by-log4j-vulnerability","/2021/08/21/4.0-deprecation-announcements"],"pages":[{"items":["/2025/04/08/4.1-performance-improvements","/2025/04/04/new-k8s-peer-discovery","/2024/08/11/package-repository-updates","/2024/05/31/new-community-support-policy","/2024/05/23/erlang27-support","/2024/03/11/rabbitmq-3.13.0-announcement","/2023/04/04/announcing-rabbitmq-community-discord-server","/2022/05/05/rabbitmq-3.10-release-overview","/2021/12/16/rabbitmq-not-affected-by-log4j-vulnerability","/2021/08/21/4.0-deprecation-announcements"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/announcements","page":1,"postsPerPage":10,"totalPages":1,"totalCount":10,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/performance":{"inline":true,"label":"performance","permalink":"/rabbitmq-website/blog/tags/performance","items":["/2025/04/08/4.1-performance-improvements","/2024/09/02/amqp-flow-control","/2024/08/21/amqp-benchmarks","/2024/01/11/3.13-release","/2023/05/17/rabbitmq-3.12-performance-improvements","/2023/03/21/native-mqtt","/2022/05/31/flame-graphs","/2022/05/16/rabbitmq-3.10-performance-improvements","/2021/03/23/erlang-24-support-roadmap","/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1","/2020/06/18/cluster-sizing-and-other-considerations","/2020/06/04/how-to-run-benchmarks","/2020/05/15/quorum-queues-and-flow-control-stress-tests","/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks","/2020/05/04/quorum-queues-and-flow-control-the-concepts","/2020/04/21/quorum-queues-and-why-disks-matter","/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","/2017/10/18/new-reactive-client-for-rabbitmq-http-api","/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3","/2014/04/10/consumer-bias-in-rabbitmq-3-3","/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3","/2012/04/25/rabbitmq-performance-measurements-part-2","/2012/04/16/rabbitmq-performance-measurements-part-1"],"pages":[{"items":["/2025/04/08/4.1-performance-improvements","/2024/09/02/amqp-flow-control","/2024/08/21/amqp-benchmarks","/2024/01/11/3.13-release","/2023/05/17/rabbitmq-3.12-performance-improvements","/2023/03/21/native-mqtt","/2022/05/31/flame-graphs","/2022/05/16/rabbitmq-3.10-performance-improvements","/2021/03/23/erlang-24-support-roadmap","/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/performance","page":1,"postsPerPage":10,"totalPages":3,"totalCount":28,"nextPage":"/rabbitmq-website/blog/tags/performance/page/2","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1","/2020/06/18/cluster-sizing-and-other-considerations","/2020/06/04/how-to-run-benchmarks","/2020/05/15/quorum-queues-and-flow-control-stress-tests","/2020/05/14/quorum-queues-and-flow-control-single-queue-benchmarks","/2020/05/04/quorum-queues-and-flow-control-the-concepts","/2020/04/21/quorum-queues-and-why-disks-matter","/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/performance/page/2","page":2,"postsPerPage":10,"totalPages":3,"totalCount":28,"previousPage":"/rabbitmq-website/blog/tags/performance","nextPage":"/rabbitmq-website/blog/tags/performance/page/3","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2017/10/18/new-reactive-client-for-rabbitmq-http-api","/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","/2015/10/06/new-credit-flow-settings-on-rabbitmq-3-5-5","/2014/04/14/finding-bottlenecks-with-rabbitmq-3-3","/2014/04/10/consumer-bias-in-rabbitmq-3-3","/2014/04/03/an-end-to-synchrony-performance-improvements-in-3-3","/2012/04/25/rabbitmq-performance-measurements-part-2","/2012/04/16/rabbitmq-performance-measurements-part-1"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/performance/page/3","page":3,"postsPerPage":10,"totalPages":3,"totalCount":28,"previousPage":"/rabbitmq-website/blog/tags/performance/page/2","blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/kubernetes":{"inline":true,"label":"kubernetes","permalink":"/rabbitmq-website/blog/tags/kubernetes","items":["/2025/04/04/new-k8s-peer-discovery","/2022/02/21/gatekeeper-validation","/2021/05/03/alerting","/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0","/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved"],"pages":[{"items":["/2025/04/04/new-k8s-peer-discovery","/2022/02/21/gatekeeper-validation","/2021/05/03/alerting","/2020/11/17/rabbitmq-kubernetes-operator-reaches-1-0","/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/kubernetes","page":1,"postsPerPage":10,"totalPages":1,"totalCount":5,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/tanzu-rabbit-mq":{"inline":true,"label":"Tanzu RabbitMQ","permalink":"/rabbitmq-website/blog/tags/tanzu-rabbit-mq","items":["/2025/02/07/tanzu-rabbitmq-3.13.8-is-released"],"pages":[{"items":["/2025/02/07/tanzu-rabbitmq-3.13.8-is-released"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/tanzu-rabbit-mq","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/rabbit-mq-3-13":{"inline":true,"label":"RabbitMQ 3.13","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13","items":["/2025/02/07/tanzu-rabbitmq-3.13.8-is-released","/2025/02/07/rabbitmq-3.13.8-is-released"],"pages":[{"items":["/2025/02/07/tanzu-rabbitmq-3.13.8-is-released","/2025/02/07/rabbitmq-3.13.8-is-released"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/classic-queues":{"inline":true,"label":"Classic Queues","permalink":"/rabbitmq-website/blog/tags/classic-queues","items":["/2025/01/17/how-are-the-messages-stored"],"pages":[{"items":["/2025/01/17/how-are-the-messages-stored"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/classic-queues","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/quorum-queues":{"inline":true,"label":"Quorum Queues","permalink":"/rabbitmq-website/blog/tags/quorum-queues","items":["/2025/01/17/how-are-the-messages-stored","/2024/08/28/quorum-queues-in-4.0"],"pages":[{"items":["/2025/01/17/how-are-the-messages-stored","/2024/08/28/quorum-queues-in-4.0"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/quorum-queues","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/streams":{"inline":true,"label":"Streams","permalink":"/rabbitmq-website/blog/tags/streams","items":["/2025/01/17/how-are-the-messages-stored","/2024/12/13/amqp-filter-expressions","/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2022/07/13/rabbitmq-3-11-feature-preview-super-streams","/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams","/2021/10/07/rabbitmq-streams-interoperability","/2021/09/13/rabbitmq-streams-offset-tracking","/2021/07/28/rabbitmq-streams-message-deduplication","/2021/07/23/connecting-to-streams","/2021/07/19/rabbitmq-streams-first-application","/2021/07/13/rabbitmq-streams-overview"],"pages":[{"items":["/2025/01/17/how-are-the-messages-stored","/2024/12/13/amqp-filter-expressions","/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2022/07/13/rabbitmq-3-11-feature-preview-super-streams","/2022/07/05/rabbitmq-3-11-feature-preview-single-active-consumer-for-streams","/2021/10/07/rabbitmq-streams-interoperability","/2021/09/13/rabbitmq-streams-offset-tracking","/2021/07/28/rabbitmq-streams-message-deduplication","/2021/07/23/connecting-to-streams"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/streams","page":1,"postsPerPage":10,"totalPages":2,"totalCount":12,"nextPage":"/rabbitmq-website/blog/tags/streams/page/2","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2021/07/19/rabbitmq-streams-first-application","/2021/07/13/rabbitmq-streams-overview"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/streams/page/2","page":2,"postsPerPage":10,"totalPages":2,"totalCount":12,"previousPage":"/rabbitmq-website/blog/tags/streams","blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/technical-deep-dive":{"inline":true,"label":"Technical Deep Dive","permalink":"/rabbitmq-website/blog/tags/technical-deep-dive","items":["/2024/09/02/amqp-flow-control","/2023/07/21/mqtt5","/2023/03/21/native-mqtt","/2020/06/23/quorum-queues-local-delivery"],"pages":[{"items":["/2024/09/02/amqp-flow-control","/2023/07/21/mqtt5","/2023/03/21/native-mqtt","/2020/06/23/quorum-queues-local-delivery"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/technical-deep-dive","page":1,"postsPerPage":10,"totalPages":1,"totalCount":4,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/packages":{"inline":true,"label":"packages","permalink":"/rabbitmq-website/blog/tags/packages","items":["/2024/08/11/package-repository-updates"],"pages":[{"items":["/2024/08/11/package-repository-updates"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/packages","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x":{"inline":true,"label":"RabbitMQ 3.13.x","permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x","items":["/2024/05/31/new-community-support-policy","/2024/05/23/erlang27-support","/2024/03/11/rabbitmq-3.13.0-announcement","/2024/01/11/3.13-release","/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2023/07/21/mqtt5"],"pages":[{"items":["/2024/05/31/new-community-support-policy","/2024/05/23/erlang27-support","/2024/03/11/rabbitmq-3.13.0-announcement","/2024/01/11/3.13-release","/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2023/07/21/mqtt5"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/rabbit-mq-3-13-x","page":1,"postsPerPage":10,"totalPages":1,"totalCount":7,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/documentation":{"inline":true,"label":"Documentation","permalink":"/rabbitmq-website/blog/tags/documentation","items":["/2024/01/04/new-website"],"pages":[{"items":["/2024/01/04/new-website"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/documentation","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/programming-languages":{"inline":true,"label":"Programming Languages","permalink":"/rabbitmq-website/blog/tags/programming-languages","items":["/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2021/10/07/rabbitmq-streams-interoperability","/2021/09/13/rabbitmq-streams-offset-tracking","/2021/07/28/rabbitmq-streams-message-deduplication","/2021/07/23/connecting-to-streams","/2021/07/19/rabbitmq-streams-first-application","/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","/2017/10/18/new-reactive-client-for-rabbitmq-http-api","/2017/09/29/rabbitmq-java-client-5-0-is-released","/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","/2016/11/24/rabbitmq-java-client-4-0-is-released","/2013/06/03/using-elixir-to-write-rabbitmq-plugins","/2012/02/21/atomizejs-distributed-software-transactional-memory","/2011/06/30/zeromq-erlang","/2011/05/17/can-you-hear-the-drums-erlando"],"pages":[{"items":["/2023/10/24/stream-filtering-internals","/2023/10/16/stream-filtering","/2021/10/07/rabbitmq-streams-interoperability","/2021/09/13/rabbitmq-streams-offset-tracking","/2021/07/28/rabbitmq-streams-message-deduplication","/2021/07/23/connecting-to-streams","/2021/07/19/rabbitmq-streams-first-application","/2018/04/10/rabbitmq-java-client-metrics-with-micrometer-and-datadog","/2017/10/18/new-reactive-client-for-rabbitmq-http-api","/2017/09/29/rabbitmq-java-client-5-0-is-released"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/programming-languages","page":1,"postsPerPage":10,"totalPages":2,"totalCount":16,"nextPage":"/rabbitmq-website/blog/tags/programming-languages/page/2","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2016/11/30/metrics-support-in-rabbitmq-java-client-4-0","/2016/11/24/rabbitmq-java-client-4-0-is-released","/2013/06/03/using-elixir-to-write-rabbitmq-plugins","/2012/02/21/atomizejs-distributed-software-transactional-memory","/2011/06/30/zeromq-erlang","/2011/05/17/can-you-hear-the-drums-erlando"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/programming-languages/page/2","page":2,"postsPerPage":10,"totalPages":2,"totalCount":16,"previousPage":"/rabbitmq-website/blog/tags/programming-languages","blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/mqtt":{"inline":true,"label":"MQTT","permalink":"/rabbitmq-website/blog/tags/mqtt","items":["/2023/07/21/mqtt5","/2023/03/21/native-mqtt"],"pages":[{"items":["/2023/07/21/mqtt5","/2023/03/21/native-mqtt"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/mqtt","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/how-to":{"inline":true,"label":"HowTo","permalink":"/rabbitmq-website/blog/tags/how-to","items":["/2023/03/02/quorum-queues-migration","/2022/07/22/oidc-integration","/2021/03/01/auth-attempts-metrics","/2014/10/30/understanding-memory-use-with-rabbitmq-3-4","/2014/04/02/breaking-things-with-rabbitmq-3-3","/2014/02/19/distributed-semaphores-with-rabbitmq","/2014/01/23/preventing-unbounded-buffers-with-rabbitmq","/2013/12/16/using-consumer-priorities-with-rabbitmq","/2013/10/23/federated-queues-in-3-2-0","/2013/06/03/using-elixir-to-write-rabbitmq-plugins","/2012/11/19/breaking-things-with-rabbitmq-3-0","/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","/2011/09/24/sizing-your-rabbits","/2011/08/16/using-the-rabbitmq-service-on-cloud-foundry-with-nodejs","/2011/06/22/federation-plugin-preview-release","/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231","/2010/11/12/rabbitmq-nodejs-rabbitjs","/2010/10/02/prompt-a-licious"],"pages":[{"items":["/2023/03/02/quorum-queues-migration","/2022/07/22/oidc-integration","/2021/03/01/auth-attempts-metrics","/2014/10/30/understanding-memory-use-with-rabbitmq-3-4","/2014/04/02/breaking-things-with-rabbitmq-3-3","/2014/02/19/distributed-semaphores-with-rabbitmq","/2014/01/23/preventing-unbounded-buffers-with-rabbitmq","/2013/12/16/using-consumer-priorities-with-rabbitmq","/2013/10/23/federated-queues-in-3-2-0","/2013/06/03/using-elixir-to-write-rabbitmq-plugins"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/how-to","page":1,"postsPerPage":10,"totalPages":2,"totalCount":18,"nextPage":"/rabbitmq-website/blog/tags/how-to/page/2","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2012/11/19/breaking-things-with-rabbitmq-3-0","/2012/05/11/some-queuing-theory-throughput-latency-and-bandwidth","/2011/09/24/sizing-your-rabbits","/2011/08/16/using-the-rabbitmq-service-on-cloud-foundry-with-nodejs","/2011/06/22/federation-plugin-preview-release","/2011/02/07/who-are-you-authentication-and-authorisation-in-rabbitmq-231","/2010/11/12/rabbitmq-nodejs-rabbitjs","/2010/10/02/prompt-a-licious"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/how-to/page/2","page":2,"postsPerPage":10,"totalPages":2,"totalCount":18,"previousPage":"/rabbitmq-website/blog/tags/how-to","blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/updates":{"inline":true,"label":"Updates","permalink":"/rabbitmq-website/blog/tags/updates","items":["/2022/08/30/high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9","/2022/05/05/rabbitmq-3.10-release-overview","/2022/04/26/centos-7-support-discontinued","/2021/03/31/migrate-off-of-bintray","/2021/03/23/erlang-24-support-roadmap","/2020/11/06/this-month-in-rabbitmq-augsep-2020-recap","/2020/08/31/this-month-in-rabbitmq-july-2020-recap","/2020/07/30/this-month-in-rabbitmq-june-2020-recap","/2020/06/30/this-month-in-rabbitmq-may-2020-recap","/2020/06/01/this-month-in-rabbitmq-april-2020-recap","/2020/04/13/this-month-in-rabbitmq-march-2020-recap","/2020/03/10/this-month-in-rabbitmq-february-2020-recap","/2020/02/12/this-month-in-rabbitmq-january-2020-recap","/2020/01/09/this-month-in-rabbitmq-december-2019-recap","/2019/12/07/this-month-in-rabbitmq-november-2019-recap","/2019/11/13/this-month-in-rabbitmq-november-2019","/2019/11/11/rabbitmq-3-8-release-overview","/2019/09/09/this-month-in-rabbitmq-september-2019","/2019/08/12/this-month-in-rabbitmq-august-2019","/2019/07/09/this-month-in-rabbitmq-july-2019","/2019/06/06/this-month-in-rabbitmq-june-2019","/2019/05/13/this-month-in-rabbitmq-may-2019","/2019/04/03/this-month-in-rabbitmq-april-3-2019","/2019/03/08/this-month-in-rabbitmq-march-7-2019","/2019/02/07/this-month-in-rabbitmq-feb-7-2019","/2019/01/08/this-month-in-rabbitmq-jan-8-2019","/2018/12/04/this-month-in-rabbitmq-dec-4-2018"],"pages":[{"items":["/2022/08/30/high-initial-memory-consumption-of-rabbitmq-nodes-on-centos-stream-9","/2022/05/05/rabbitmq-3.10-release-overview","/2022/04/26/centos-7-support-discontinued","/2021/03/31/migrate-off-of-bintray","/2021/03/23/erlang-24-support-roadmap","/2020/11/06/this-month-in-rabbitmq-augsep-2020-recap","/2020/08/31/this-month-in-rabbitmq-july-2020-recap","/2020/07/30/this-month-in-rabbitmq-june-2020-recap","/2020/06/30/this-month-in-rabbitmq-may-2020-recap","/2020/06/01/this-month-in-rabbitmq-april-2020-recap"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/updates","page":1,"postsPerPage":10,"totalPages":3,"totalCount":27,"nextPage":"/rabbitmq-website/blog/tags/updates/page/2","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2020/04/13/this-month-in-rabbitmq-march-2020-recap","/2020/03/10/this-month-in-rabbitmq-february-2020-recap","/2020/02/12/this-month-in-rabbitmq-january-2020-recap","/2020/01/09/this-month-in-rabbitmq-december-2019-recap","/2019/12/07/this-month-in-rabbitmq-november-2019-recap","/2019/11/13/this-month-in-rabbitmq-november-2019","/2019/11/11/rabbitmq-3-8-release-overview","/2019/09/09/this-month-in-rabbitmq-september-2019","/2019/08/12/this-month-in-rabbitmq-august-2019","/2019/07/09/this-month-in-rabbitmq-july-2019"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/updates/page/2","page":2,"postsPerPage":10,"totalPages":3,"totalCount":27,"previousPage":"/rabbitmq-website/blog/tags/updates","nextPage":"/rabbitmq-website/blog/tags/updates/page/3","blogDescription":"Blog","blogTitle":"Blog"}},{"items":["/2019/06/06/this-month-in-rabbitmq-june-2019","/2019/05/13/this-month-in-rabbitmq-may-2019","/2019/04/03/this-month-in-rabbitmq-april-3-2019","/2019/03/08/this-month-in-rabbitmq-march-7-2019","/2019/02/07/this-month-in-rabbitmq-feb-7-2019","/2019/01/08/this-month-in-rabbitmq-jan-8-2019","/2018/12/04/this-month-in-rabbitmq-dec-4-2018"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/updates/page/3","page":3,"postsPerPage":10,"totalPages":3,"totalCount":27,"previousPage":"/rabbitmq-website/blog/tags/updates/page/2","blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/resiliency":{"inline":true,"label":"Resiliency","permalink":"/rabbitmq-website/blog/tags/resiliency","items":["/2022/03/29/at-least-once-dead-lettering","/2020/07/07/disaster-recovery-and-high-availability-101"],"pages":[{"items":["/2022/03/29/at-least-once-dead-lettering","/2020/07/07/disaster-recovery-and-high-availability-101"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/resiliency","page":1,"postsPerPage":10,"totalPages":1,"totalCount":2,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/erlang":{"inline":true,"label":"Erlang","permalink":"/rabbitmq-website/blog/tags/erlang","items":["/2021/03/23/erlang-24-support-roadmap"],"pages":[{"items":["/2021/03/23/erlang-24-support-roadmap"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/erlang","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/introductory":{"inline":true,"label":"Introductory","permalink":"/rabbitmq-website/blog/tags/introductory","items":["/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved","/2012/04/16/rabbitmq-performance-measurements-part-1","/2011/09/24/sizing-your-rabbits","/2011/01/20/rabbitmq-backing-stores-databases-and-disks","/2011/01/12/ruby-amqp-gem-intro","/2010/11/17/chapter-1-introduction-to-distributed-systems"],"pages":[{"items":["/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved","/2012/04/16/rabbitmq-performance-measurements-part-1","/2011/09/24/sizing-your-rabbits","/2011/01/20/rabbitmq-backing-stores-databases-and-disks","/2011/01/12/ruby-amqp-gem-intro","/2010/11/17/chapter-1-introduction-to-distributed-systems"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/introductory","page":1,"postsPerPage":10,"totalPages":1,"totalCount":6,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/cloud":{"inline":true,"label":"Cloud","permalink":"/rabbitmq-website/blog/tags/cloud","items":["/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved","/2011/09/01/rabbitmq-on-heroku","/2011/08/10/rabbitmq-cloud-foundry-cloud-messaging-that-just-works"],"pages":[{"items":["/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved","/2011/09/01/rabbitmq-on-heroku","/2011/08/10/rabbitmq-cloud-foundry-cloud-messaging-that-just-works"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/cloud","page":1,"postsPerPage":10,"totalPages":1,"totalCount":3,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/diy":{"inline":true,"label":"DIY","permalink":"/rabbitmq-website/blog/tags/diy","items":["/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved"],"pages":[{"items":["/2020/08/10/deploying-rabbitmq-to-kubernetes-whats-involved"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/diy","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/capacity-planning":{"inline":true,"label":"Capacity Planning","permalink":"/rabbitmq-website/blog/tags/capacity-planning","items":["/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1","/2020/06/18/cluster-sizing-and-other-considerations"],"pages":[{"items":["/2020/06/22/cluster-sizing-case-study-quorum-queues-part-2","/2020/06/21/cluster-sizing-case-study-quorum-queues-part-1","/2020/06/20/cluster-sizing-case-study-mirrored-queues-part-2","/2020/06/19/cluster-sizing-case-study-mirrored-queues-part-1","/2020/06/18/cluster-sizing-and-other-considerations"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/capacity-planning","page":1,"postsPerPage":10,"totalPages":1,"totalCount":5,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/case-studies":{"inline":true,"label":"Case Studies","permalink":"/rabbitmq-website/blog/tags/case-studies","items":["/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system"],"pages":[{"items":["/2019/12/16/laika-gets-creative-with-rabbitmq-as-the-animation-companys-it-nervous-system"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/case-studies","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/talks-and-conferences":{"inline":true,"label":"Talks and Conferences","permalink":"/rabbitmq-website/blog/tags/talks-and-conferences","items":["/2011/10/19/keeping-it-realtime-conference-portland-or","/2011/09/26/pubsubhuddle-realtime-web-talk","/2011/09/16/pubsub-huddle"],"pages":[{"items":["/2011/10/19/keeping-it-realtime-conference-portland-or","/2011/09/26/pubsubhuddle-realtime-web-talk","/2011/09/16/pubsub-huddle"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/talks-and-conferences","page":1,"postsPerPage":10,"totalPages":1,"totalCount":3,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/hasenwerkstatt":{"inline":true,"label":"Hasenwerkstatt","permalink":"/rabbitmq-website/blog/tags/hasenwerkstatt","items":["/2010/12/01/amqp-10-prototyping","/2010/11/12/rabbitmq-nodejs-rabbitjs","/2010/10/18/rabbitmq0mq-bridge"],"pages":[{"items":["/2010/12/01/amqp-10-prototyping","/2010/11/12/rabbitmq-nodejs-rabbitjs","/2010/10/18/rabbitmq0mq-bridge"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/hasenwerkstatt","page":1,"postsPerPage":10,"totalPages":1,"totalCount":3,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false},"/rabbitmq-website/blog/tags/blueprints":{"inline":true,"label":"Blueprints","permalink":"/rabbitmq-website/blog/tags/blueprints","items":["/2010/08/06/management-monitoring-and-statistics"],"pages":[{"items":["/2010/08/06/management-monitoring-and-statistics"],"metadata":{"permalink":"/rabbitmq-website/blog/tags/blueprints","page":1,"postsPerPage":10,"totalPages":1,"totalCount":1,"blogDescription":"Blog","blogTitle":"Blog"}}],"unlisted":false}},"blogTagsListPath":"/rabbitmq-website/blog/tags","authorsMap":{"acogoluegnes":{"name":"Arnaud Cogoluègnes","url":"https://github.com/acogoluegnes","socials":{"github":"https://github.com/acogoluegnes","linkedin":"https://www.linkedin.com/in/arnaudcogoluegnes/","bluesky":"https://bsky.app/profile/acogoluegnes.bsky.social"},"imageURL":"https://github.com/acogoluegnes.png","key":"acogoluegnes","page":null},"alebedeff":{"name":"Alexey Lebedeff","url":"https://github.com/binarin","imageURL":"https://github.com/binarin.png","key":"alebedeff","page":null},"alexandru":{"name":"Alexandru Scvortov","key":"alexandru","page":null},"alexis":{"name":"Alexis Richardson","key":"alexis","page":null},"alvaro":{"name":"Álvaro Videla","key":"alvaro","page":null},"botanicus":{"name":"Jakub Stastny","key":"botanicus","page":null},"dansari":{"name":"David Ansari","url":"https://github.com/ansd","socials":{"github":"https://github.com/ansd","linkedin":"https://www.linkedin.com/in/ansd/","mastodon":"https://m.ansd.xyz/@ansd","bluesky":"https://bsky.app/profile/ansd.xyz"},"imageURL":"https://github.com/ansd.png","key":"dansari","page":null},"david":{"name":"David Wragg","key":"david","page":null},"dcorbacho":{"name":"Diana Parra Corbacho","url":"https://github.com/dcorbacho","imageURL":"https://github.com/dcorbacho.png","key":"dcorbacho","page":null},"ddrewitz":{"name":"Dormain Drewitz","key":"ddrewitz","page":null},"dfedotov":{"name":"Daniil Fedotov","key":"dfedotov","page":null},"ebyford":{"name":"Ed Byford","url":"https://github.com/edbyford","imageURL":"https://github.com/edbyford.png","key":"ebyford","page":null},"eef":{"name":"Erlang Ecosystem Foundation","url":"https://github.com/erlef","socials":{"github":"https://github.com/erlef"},"imageURL":"https://github.com/erlef.png","key":"eef","page":null},"emile":{"name":"Emile Joubert","key":"emile","page":null},"glazu":{"name":"Gerhard Lazu","key":"glazu","page":null},"jdetreville":{"name":"John DeTreville","key":"jdetreville","page":null},"jerry":{"name":"Jerry Kuch","key":"jerry","page":null},"jpedron":{"name":"Jean-Sébastien Pédron","url":"https://github.com/dumbbell","imageURL":"https://github.com/dumbbell.png","key":"jpedron","page":null},"jvanlightly":{"name":"Jack Vanlightly","key":"jvanlightly","page":null},"kura":{"name":"Michał Kuratczyk","url":"https://github.com/mkuratczyk","socials":{"github":"https://github.com/mkuratczyk","linkedin":"https://www.linkedin.com/in/mkuratczyk/","mastodon":"https://fosstodon.org/@kura","bluesky":"https://bsky.app/profile/mkuratczyk.bsky.social"},"imageURL":"https://github.com/mkuratczyk.png","key":"kura","page":null},"marek":{"name":"Marek Majkowski","key":"marek","page":null},"matthew":{"name":"Matthew Sackman","key":"matthew","page":null},"mgary":{"name":"Mirah Gary","url":"https://github.com/MirahImage","imageURL":"https://github.com/MirahImage.png","key":"mgary","page":null},"mikeb":{"name":"Michael Bridgen","key":"mikeb","page":null},"mklishin":{"name":"Michael Klishin","url":"https://github.com/michaelklishin","socials":{"github":"https://github.com/michaelklishin","linkedin":"https://www.linkedin.com/in/michaelklishin/","bluesky":"https://bsky.app/profile/michaelklishin.bsky.social"},"imageURL":"https://github.com/michaelklishin.png","key":"mklishin","page":null},"mrosales":{"name":"Marcial Rosales","url":"https://github.com/MarcialRosales","imageURL":"https://github.com/MarcialRosales.png","key":"mrosales","page":null},"nkarl":{"name":"Karl Nilsson","url":"https://github.com/kjnilsson","socials":{"github":"https://github.com/kjnilsson","linkedin":"https://www.linkedin.com/in/kjnils/","bluesky":"https://bsky.app/profile/kjnilsson.bsky.social"},"imageURL":"https://github.com/kjnilsson.png","key":"nkarl","page":null},"simon":{"name":"Simon MacMullen","key":"simon","page":null},"sustrik":{"name":"Martin Sustrik","key":"sustrik","page":null},"vlad":{"name":"Vlad Alexandru Ionescu","key":"vlad","page":null},"yparasol":{"name":"Yaron Parasol","key":"yparasol","page":null},"Zteve":{"name":"Steve Powell","key":"Zteve","page":null}}}},"docusaurus-plugin-content-pages":{"default":[{"type":"mdx","permalink":"/rabbitmq-website/amqp-0-9-1-errata","source":"@site/src/pages/amqp-0-9-1-errata.md","title":"AMQP 0-9-1 Errata","description":"Here we list errors and ambiguities in the 0-9-1 specification and provide our interpretations and corrections.","frontMatter":{"title":"AMQP 0-9-1 Errata"},"unlisted":false},{"type":"mdx","permalink":"/rabbitmq-website/amqp-0-9-1-protocol","source":"@site/src/pages/amqp-0-9-1-protocol.md","title":"AMQP 0-9-1 Protocol Specification","description":"AMQP 0-9-1 is a binary messaging protocol and semantic framework","frontMatter":{"title":"AMQP 0-9-1 Protocol Specification"},"unlisted":false},{"type":"mdx","permalink":"/rabbitmq-website/amqp-0-9-1-reference","source":"@site/src/pages/amqp-0-9-1-reference.md","title":"AMQP 0-9-1 Complete Reference Guide","description":"The AMQP 0-9-1 reference and original PDF and XML files","frontMatter":{"title":"AMQP 0-9-1 Complete Reference Guide"},"unlisted":false},{"type":"mdx","permalink":"/rabbitmq-website/community-plugins","source":"@site/src/pages/community-plugins.md","title":"Community Plugins","description":"<!--","frontMatter":{"title":"Community Plugins","displayed_sidebar":"otherInformationSidebar"},"unlisted":false},{"type":"jsx","permalink":"/rabbitmq-website/contact","source":"@site/src/pages/contact.js"},{"type":"mdx","permalink":"/rabbitmq-website/github","source":"@site/src/pages/github.md","title":"Using Git and GitHub","description":"<!--","frontMatter":{"title":"Using Git and GitHub"},"unlisted":false},{"type":"jsx","permalink":"/rabbitmq-website/","source":"@site/src/pages/index.js"},{"type":"mdx","permalink":"/rabbitmq-website/plugin-development","source":"@site/src/pages/plugin-development.md","title":"Plugin Development Basics","description":"<!--","frontMatter":{"title":"Plugin Development Basics"},"unlisted":false},{"type":"mdx","permalink":"/rabbitmq-website/trademark-guidelines","source":"@site/src/pages/trademark-guidelines.md","title":"RabbitMQ Trademark Guidelines","description":"<!--","frontMatter":{"title":"RabbitMQ Trademark Guidelines"},"unlisted":false},{"type":"mdx","permalink":"/rabbitmq-website/amqp-wireshark/","source":"@site/src/pages/amqp-wireshark/index.md","description":"<!--","frontMatter":{},"unlisted":false}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-theme-search-algolia":{},"configure-svgo":{},"docusaurus-theme-mermaid":{},"docusaurus-theme-github-codeblock":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}');

/***/ })

}]);